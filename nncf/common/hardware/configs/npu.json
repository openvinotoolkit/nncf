{
    "target_device": "NPU",
    "config": {
        "quantization": {
            "q8_a_sym": {
                "bits": 8,
                "mode": [
                    "symmetric"
                ],
                "granularity": "pertensor"
            },
            "q8_a": {
                "bits": 8,
                "mode": [
                    "symmetric",
                    "asymmetric"
                ],
                "granularity": "pertensor"
            },
            "q8_a_ch": {
                "bits": 8,
                "mode": [
                    "symmetric",
                    "asymmetric"
                ],
                "granularity": [
                    "perchannel",
                    "pertensor"
                ]
            },
            "q8_w_sym": {
                "bits": 8,
                "mode": "symmetric",
                "level_low": -128,
                "level_high": 127,
                "granularity": ["perchannel", "pertensor"]
            },
            "q8_w_asym": {
                "bits": 8,
                "mode": "asymmetric",
                "granularity": ["perchannel", "pertensor"]
            },
            // 4-bit configs
            "q4_tn": {
                "bits": 4,
                "mode": "symmetric",
                "granularity": "pertensor"
            },
            "q4_ch": {
                "bits": 4,
                "mode": "symmetric",
                "granularity": "perchannel"
            },
            "q4_w": {
                "bits": 4,
                "mode": "symmetric",
                "granularity": [
                    "perchannel",
                    "pertensor"
                ]
            },
            // 2-bit configs
            "q2_ch": {
                "bits": 2,
                "mode": "symmetric",
                "granularity": "perchannel"
            },
            "q2_w": {
                "bits": 2,
                "mode": "symmetric",
                "granularity": [
                    "perchannel",
                    "pertensor"
                ]
            }
        }
    },
    "operations": [
        {
            "type": "Convolution",
            "attributes": {
                "adjust_padding": true
            },
            "quantization": {
                "activations": ["q8_a", "q4_tn"],
                "weights": ["q8_w_sym", "q8_w_asym", "q4_w", "q2_w"]
            }
        },
        {
            "type": "DepthWiseConvolution",
            "quantization": {
                "activations": ["q8_a_ch", "q8_a"],
                "weights": ["q8_w_sym", "q8_w_asym", "q4_w", "q2_w"]
            }
        },
        {
            "type": "MatMul",
            "quantization": {
                "activations": ["q8_a", "q4_tn"],
                "weights": ["q8_w_sym", "q8_w_asym", "q4_w", "q2_w"]
            }
        },
        {
            "type": "Add",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": ["q8_a", "q4_tn"],
                "weights": ["q8_w_sym", "q8_w_asym", "q4_tn"]
            }
        },
        {
            "type": "Multiply",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": ["q8_a", "q4_tn"],
                "weights": ["q8_w_sym", "q8_w_asym", "q4_tn"]
            }
        },
        {
            "type": "Maximum",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": ["q8_a", "q4_tn"],
                "weights": ["q8_w_sym", "q8_w_asym", "q4_tn"]
            }
        },
        {
            "type": "Less",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "LessEqual",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "Greater",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "GreaterEqual",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "Divide",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "Minimum",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": ["q8_a", "q4_tn"],
                "weights": ["q8_w_sym", "q8_w_asym", "q4_tn"]
            }
        },
        {
            "type": "Equal",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "Subtract",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": ["q8_a", "q4_tn"],
                "weights": ["q8_w_sym", "q8_w_asym", "q4_tn"]
            }
        },
        {
            "type": "NotEqual",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "FloorMod",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "LogicalOr",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "LogicalXor",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "LogicalAnd",
            "attributes": {
                "scales": "unified"
            },
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "LogicalNot",
            "quantization": {
                "activations": "q8_a",
                "weights": ["q8_w_sym", "q8_w_asym"]
            }
        },
        {
            "type": "Power",
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "AvgPool",
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "NormalizeL2",
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "ReduceL2",
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "ReduceMean",
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "MaxPool"
        },
        {
            "type": "ReduceMax"
        },
        {
            "type": "Interpolate",
            "attributes": {
                "mode": "linear"
            },
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "Interpolate",
            "attributes": {
                "mode": "nearest"
            }
        },
        {
            "type": "MVN",
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "Concat",
            "attributes": {
                "scales": "unified"
            }
        },
        {
            "type": "LSTMSequence",
            "quantization": {
                "activations": "q8_a",
                "weights": "q8_w_sym"
            }
        },
        {
            "type": "GRUSequence",
            "quantization": {
                "activations": "q8_a",
                "weights": "q8_w_sym"
            }
        },
        {
            "type": "ReduceSum",
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "GroupNormalization",
            "quantization": {
                "activations": "q8_a"
            }
        },
        {
            "type": "ScaledDotProductAttention",
            "quantization": {
                "activations": "q8_a_sym"
            }
        },
        {"type": "Reshape"},
        {"type": "Flatten"},
        {"type": "Squeeze"},
        {"type": "Unsqueeze"},
        {"type": "Split"},
        {"type": "VariadicSplit"},
        {"type": "Crop"},
        {"type": "Transpose"},
        {"type": "Tile"},
        {"type": "StridedSlice"},
        {"type": "ShuffleChannels"},
        {"type": "Broadcast"},
        {"type": "Pad"},
        {"type": "ConvertLike"},
        // NNCF-specific extensions are below:
        {
            "type": "Embedding",
            "quantization": {
                "weights": [
                    "q8_w_sym", "q8_w_asym"
                ]
            }
        },
        {
            "type": "EmbeddingBag",
            "quantization": {
                "weights": [
                    "q8_w_sym", "q8_w_asym"
                ]
            }
        },
    ]
}
