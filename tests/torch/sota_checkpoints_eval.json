{
    "classification": {
        "imagenet": {
            "resnet50_imagenet": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet.json",
                "target_ov": 76.16,
                "target_pt": 76.15,
                "metric_type": "Acc@1",
                "model_description": "ResNet-50"
            },
            "resnet50_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet_int8.json",
                "reference": "resnet50_imagenet",
                "target_ov": 76.39,
                "target_pt": 76.45,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.5
            },
            "resnet50_imagenet_int8_per_tensor": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet_int8_per_tensor.json",
                "reference": "resnet50_imagenet",
                "target_ov": 76.35,
                "target_pt": 76.38,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int8_per_tensor.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 (per-tensor only)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.5
            },
            "resnet50_imagenet_int4_int8": {
                "config": "examples/torch/classification/configs/mixed_precision/resnet50_imagenet_mixed_int_hawq.json",
                "reference": "resnet50_imagenet",
                "target_ov": 75.74,
                "target_pt": 75.86                ,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int4_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "Mixed, 43.12% INT8 / 56.88% INT4",
                "diff_target_pt_min": -0.3,
                "diff_target_pt_max": 0.3
            },
            "resnet50_imagenet_rb_sparsity_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/resnet50_imagenet_rb_sparsity_int8.json",
                "reference": "resnet50_imagenet",
                "target_ov": 75.39,
                "target_pt": 75.42,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_rb_sparsity_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 + Sparsity 61% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "resnet50_imagenet_rb_sparsity50_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/resnet50_imagenet_rb_sparsity50_int8.json",
                "reference": "resnet50_imagenet",
                "target_ov": 75.44,
                "target_pt": 75.47,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_rb_sparsity50_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 + Sparsity 50% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1
            },
            "resnet50_imagenet_pruning_geometric_median": {
                "config": "examples/torch/classification/configs/pruning/resnet50_imagenet_pruning_geometric_median.json",
                "reference": "resnet50_imagenet",
                "target_ov": 75.57,
                "target_pt": 75.57,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_pruning_geometric_median.pth",
                "model_description": "ResNet-50",
                "compression_description": "Filter pruning, 40%, geometric median criterion"
            },
            "inception_v3_imagenet": {
                "config": "examples/torch/classification/configs/quantization/inception_v3_imagenet.json",
                "target_ov": 77.32,
                "target_pt": 77.33,
                "metric_type": "Acc@1",
                "model_description": "Inception V3",
                "multiprocessing_distributed": true
            },
            "inception_v3_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/inception_v3_imagenet_int8.json",
                "reference": "inception_v3_imagenet",
                "target_ov": 77.49,
                "target_pt": 77.43,
                "metric_type": "Acc@1",
                "resume": "inception_v3_imagenet_int8.pth",
                "model_description": "Inception V3",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 1.0,
                "multiprocessing_distributed": true
            },
            "inception_v3_imagenet_rb_sparsity_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/inception_v3_imagenet_rb_sparsity_int8.json",
                "reference": "inception_v3_imagenet",
                "target_ov": 76.34,
                "target_pt": 76.32,
                "metric_type": "Acc@1",
                "resume": "inception_v3_imagenet_rb_sparsity_int8.pth",
                "model_description": "Inception V3",
                "compression_description": "INT8 + Sparsity 61% (RB)",
                "diff_fp32_min": -1.1,
                "diff_fp32_max": 0.4,
                "multiprocessing_distributed": true
            },
            "mobilenet_v2_imagenet": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v2_imagenet.json",
                "target_ov": 71.87,
                "target_pt": 71.88,
                "metric_type": "Acc@1",
                "model_description": "MobileNet V2"
            },
            "mobilenet_v2_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v2_imagenet_int8.json",
                "reference": "mobilenet_v2_imagenet",
                "target_ov": 71.01,
                "target_pt": 71.24,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15,
                "diff_target_pt_min": -0.3,
                "diff_target_pt_max": 0.3
            },
            "mobilenet_v2_imagenet_int8_per_tensor": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v2_imagenet_int8_per_tensor.json",
                "reference": "mobilenet_v2_imagenet",
                "target_ov": 71.17,
                "target_pt": 71.28                ,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int8_per_tensor.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8 (per-tensor only)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15,
                "diff_target_pt_min": -0.3,
                "diff_target_pt_max": 0.3
            },
            "mobilenet_v2_imagenet_int4_int8": {
                "config": "examples/torch/classification/configs/mixed_precision/mobilenet_v2_imagenet_mixed_int_hawq.json",
                "reference": "mobilenet_v2_imagenet",
                "target_ov": 70.49,
                "target_pt": 70.57,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int4_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "Mixed, 58.88% INT8 / 41.12% INT4",
                "diff_fp32_min": -1.5,
                "diff_fp32_max": 0.4,
                "diff_target_pt_min": -0.3,
                "diff_target_pt_max": 0.3
            },
            "mobilenet_v2_imagenet_rb_sparsity_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/mobilenet_v2_imagenet_rb_sparsity_int8.json",
                "reference": "mobilenet_v2_imagenet",
                "target_ov": 71.07,
                "target_pt": 71.02,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_rb_sparsity_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8 + Sparsity 52% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15,
                "diff_target_pt_min": -0.3,
                "diff_target_pt_max": 0.3
            },
            "mobilenet_v3_small_imagenet": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v3_small_imagenet.json",
                "target_ov": 67.66,
                "target_pt": 67.66,
                "metric_type": "Acc@1",
                "model_description": "MobileNet V3 small"
            },
            "mobilenet_v3_small_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v3_small_imagenet_int8.json",
                "reference": "mobilenet_v3_small_imagenet",
                "target_ov": 66.92,
                "target_pt": 66.97,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v3_small_imagenet_int8.pth",
                "model_description": "MobileNet V3 small",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "squeezenet1_1_imagenet": {
                "config": "examples/torch/classification/configs/quantization/squeezenet1_1_imagenet.json",
                "target_ov": 58.19,
                "target_pt": 58.17,
                "metric_type": "Acc@1",
                "model_description": "SqueezeNet V1.1"
            },
            "squeezenet1_1_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/squeezenet1_1_imagenet_int8.json",
                "reference": "squeezenet1_1_imagenet",
                "target_ov": 58.15,
                "target_pt": 58.3,
                "metric_type": "Acc@1",
                "resume": "squeezenet1_1_imagenet_int8.pth",
                "model_description": "SqueezeNet V1.1",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "squeezenet1_1_imagenet_int8_per_tensor": {
                "config": "examples/torch/classification/configs/quantization/squeezenet1_1_imagenet_int8_per_tensor.json",
                "reference": "squeezenet1_1_imagenet",
                "target_ov": 58.06,
                "target_pt": 58.15,
                "metric_type": "Acc@1",
                "resume": "squeezenet1_1_imagenet_int8_per_tensor.pth",
                "model_description": "SqueezeNet V1.1",
                "compression_description": "INT8 (per-tensor only)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "squeezenet1_1_imagenet_int4_int8": {
                "config": "examples/torch/classification/configs/mixed_precision/squeezenet1_1_imagenet_mixed_int_hawq_old_eval.json",
                "reference": "squeezenet1_1_imagenet",
                "target_ov": 57.53,
                "target_pt": 57.59,
                "metric_type": "Acc@1",
                "resume": "squeezenet1_1_imagenet_int4_int8.pth",
                "model_description": "SqueezeNet V1.1",
                "compression_description": "Mixed, 52.83% INT8 / 47.17% INT4",
                "diff_fp32_min": -0.7,
                "diff_fp32_max": 0.7,
                "diff_target_pt_min": -0.3,
                "diff_target_pt_max": 0.3
            },
            "resnet18_imagenet": {
                "config": "examples/torch/classification/configs/binarization/resnet18_imagenet.json",
                "target_ov": 69.77,
                "target_pt": 69.76,
                "metric_type": "Acc@1",
                "model_description": "ResNet-18"
            },
            "resnet18_imagenet_binarization_xnor": {
                "config": "examples/torch/classification/configs/binarization/resnet18_imagenet_binarization_xnor.json",
                "reference": "resnet18_imagenet",
                "target_ov": 61.82,
                "target_pt": 61.88,
                "metric_type": "Acc@1",
                "resume": "resnet18_imagenet_binarization_xnor.pth",
                "model_description": "ResNet-18",
                "compression_description": "XNOR (weights), scale/threshold (activations)",
                "diff_fp32_min": -8.5,
                "diff_fp32_max": 0.1,
                "diff_target_pt_min": -0.3,
                "diff_target_pt_max": 0.3
            },
            "resnet18_imagenet_binarization_dorefa": {
                "config": "examples/torch/classification/configs/binarization/resnet18_imagenet_binarization_dorefa.json",
                "reference": "resnet18_imagenet",
                "target_ov": null,
                "target_pt": 61.49,
                "metric_type": "Acc@1",
                "resume": "resnet18_imagenet_binarization_dorefa.pth",
                "model_description": "ResNet-18",
                "compression_description": "DoReFa (weights), scale/threshold (activations)",
                "diff_fp32_min": -8.33,
                "diff_fp32_max": 0.1,
                "skip_ov": "Issue-22543"
            },
            "resnet18_imagenet_pruning_magnitude": {
                "config": "examples/torch/classification/configs/pruning/resnet18_imagenet_pruning_magnitude.json",
                "reference": "resnet18_imagenet",
                "target_ov": 69.26,
                "target_pt": 69.27,
                "metric_type": "Acc@1",
                "resume": "resnet18_imagenet_pruning_magnitude.pth",
                "model_description": "ResNet-18",
                "compression_description": "Filter pruning, 40%, magnitude criterion"
            },
            "resnet18_imagenet_pruning_geometric_median": {
                "config": "examples/torch/classification/configs/pruning/resnet18_imagenet_pruning_geometric_median.json",
                "reference": "resnet18_imagenet",
                "target_ov": 69.3,
                "target_pt": 69.31,
                "metric_type": "Acc@1",
                "resume": "resnet18_imagenet_pruning_geometric_median.pth",
                "model_description": "ResNet-18",
                "compression_description": "Filter pruning, 40%, geometric median criterion"
            },
            "resnet34_imagenet": {
                "config": "examples/torch/classification/configs/pruning/resnet34_imagenet.json",
                "target_ov": 73.3,
                "target_pt": 73.29,
                "metric_type": "Acc@1",
                "model_description": "ResNet-34"
            },
            "resnet34_imagenet_pruning_geometric_median_kd": {
                "config": "examples/torch/classification/configs/pruning/resnet34_imagenet_pruning_geometric_median_kd.json",
                "reference": "resnet34_imagenet",
                "target_ov": 73.12,
                "target_pt": 73.12,
                "metric_type": "Acc@1",
                "resume": "resnet34_imagenet_pruning_geometric_median_kd.pth",
                "model_description": "ResNet-34",
                "compression_description": "Filter pruning, 50%, geometric median criterion + KD"
            },
            "googlenet_imagenet": {
                "config": "examples/torch/classification/configs/pruning/googlenet_imagenet.json",
                "target_ov": 69.77,
                "target_pt": 69.78,
                "metric_type": "Acc@1",
                "model_description": "GoogLeNet"
            },
            "googlenet_imagenet_pruning_geometric_median": {
                "config": "examples/torch/classification/configs/pruning/googlenet_imagenet_pruning_geometric_median.json",
                "reference": "googlenet_imagenet",
                "target_ov": 69.45,
                "target_pt": 69.46,
                "metric_type": "Acc@1",
                "resume": "googlenet_imagenet_pruning_geometric_median.pth",
                "model_description": "GoogLeNet",
                "compression_description": "Filter pruning, 40%, geometric median criterion"
            }
        }
    },
    "object_detection": {
        "voc": {
            "ssd300_mobilenet_voc": {
                "config": "examples/torch/object_detection/configs/ssd300_mobilenet_voc.json",
                "target_ov": 62.28,
                "target_pt": 62.24,
                "metric_type": "Mean AP",
                "resume": "ssd300_mobilenet_voc.pth",
                "batch": 120,
                "model_description": "SSD300-MobileNet"
            },
            "ssd300_mobilenet_voc_magnitude_sparsity_int8": {
                "config": "examples/torch/object_detection/configs/ssd300_mobilenet_voc_magnitude_int8.json",
                "reference": "ssd300_mobilenet_voc",
                "target_ov": 63.01,
                "target_pt": 62.97,
                "metric_type": "Mean AP",
                "resume": "ssd300_mobilenet_voc_magnitude_sparsity_int8.pth",
                "model_description": "SSD300-MobileNet",
                "compression_description": "INT8 + Sparsity 70% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.8
            },
            "ssd300_vgg_voc": {
                "config": "examples/torch/object_detection/configs/ssd300_vgg_voc.json",
                "target_ov": 78.03,
                "target_pt": 78.28,
                "metric_type": "Mean AP",
                "resume": "ssd300_vgg_voc.pth",
                "batch": 120,
                "model_description": "SSD300-VGG-BN"
            },
            "ssd300_vgg_voc_int8": {
                "config": "examples/torch/object_detection/configs/ssd300_vgg_voc_int8.json",
                "reference": "ssd300_vgg_voc",
                "target_ov": 77.94,
                "target_pt": 77.89,
                "metric_type": "Mean AP",
                "resume": "ssd300_vgg_voc_int8.pth",
                "model_description": "SSD300-VGG-BN",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1
            },
            "ssd300_vgg_voc_magnitude_sparsity_int8": {
                "config": "examples/torch/object_detection/configs/ssd300_vgg_voc_magnitude_sparsity_int8.json",
                "reference": "ssd300_vgg_voc",
                "target_ov": 77.46,
                "target_pt": 77.67,
                "metric_type": "Mean AP",
                "resume": "ssd300_vgg_voc_magnitude_sparsity_int8.pth",
                "model_description": "SSD300-VGG-BN",
                "compression_description": "INT8 + Sparsity 70% (Magnitude)",
                "diff_fp32_max": 0.1
            },
            "ssd300_vgg_voc_pruning_geometric_median": {
                "config": "examples/torch/object_detection/configs/ssd300_vgg_voc_pruning_geometric_median.json",
                "reference": "ssd300_vgg_voc",
                "target_ov": 77.98,
                "target_pt": 78.35,
                "metric_type": "Mean AP",
                "resume": "ssd300_vgg_voc_pruning_geometric_median.pth",
                "batch": 32,
                "model_description": "SSD300-VGG-BN",
                "compression_description": "Filter pruning, 40%, geometric median criterion",
                "diff_fp32_max": 0.1
            },
            "ssd512_vgg_voc": {
                "config": "examples/torch/object_detection/configs/ssd512_vgg_voc.json",
                "target_ov": 80.58,
                "target_pt": 80.26,
                "metric_type": "Mean AP",
                "resume": "ssd512_vgg_voc.pth",
                "batch": 32,
                "model_description": "SSD512-VGG-BN"
            },
            "ssd512_vgg_voc_int8": {
                "config": "examples/torch/object_detection/configs/ssd512_vgg_voc_int8.json",
                "reference": "ssd512_vgg_voc",
                "target_ov": 80.19,
                "target_pt": 80.09,
                "metric_type": "Mean AP",
                "resume": "ssd512_vgg_voc_int8.pth",
                "batch": 32,
                "model_description": "SSD512-VGG-BN",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.2
            },
            "ssd512_vgg_voc_magnitude_sparsity_int8": {
                "config": "examples/torch/object_detection/configs/ssd512_vgg_voc_magnitude_sparsity_int8.json",
                "reference": "ssd512_vgg_voc",
                "target_ov": 79.98,
                "target_pt": 79.76,
                "metric_type": "Mean AP",
                "resume": "ssd512_vgg_voc_magnitude_sparsity_int8.pth",
                "batch": 32,
                "model_description": "SSD512-VGG-BN",
                "compression_description": "INT8 + Sparsity 70% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1
            }
        }
    },
    "semantic_segmentation": {
        "camvid": {
            "unet_camvid": {
                "config": "examples/torch/semantic_segmentation/configs/unet_camvid.json",
                "target_ov": 71.93,
                "target_pt": 71.95,
                "metric_type": "Mean IoU",
                "resume": "unet_camvid.pth",
                "model_description": "UNet",
                "multiprocessing_distributed": true
            },
            "unet_camvid_int8": {
                "config": "examples/torch/semantic_segmentation/configs/unet_camvid_int8.json",
                "reference": "unet_camvid",
                "target_ov": 71.88,
                "target_pt": 71.9,
                "metric_type": "Mean IoU",
                "resume": "unet_camvid_int8.pth",
                "model_description": "UNet",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true
            },
            "unet_camvid_magnitude_sparsity_int8": {
                "config": "examples/torch/semantic_segmentation/configs/unet_camvid_magnitude_sparsity_int8.json",
                "reference": "unet_camvid",
                "target_ov": 72.54,
                "target_pt": 72.46,
                "metric_type": "Mean IoU",
                "resume": "unet_camvid_magnitude_sparsity_int8.pth",
                "model_description": "UNet",
                "compression_description": "INT8 + Sparsity 60% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.7,
                "multiprocessing_distributed": true
            },
            "icnet_camvid": {
                "config": "examples/torch/semantic_segmentation/configs/icnet_camvid.json",
                "target_ov": 67.88,
                "target_pt": 67.89,
                "metric_type": "Mean IoU",
                "resume": "icnet_camvid.pth",
                "model_description": "ICNet",
                "multiprocessing_distributed": true
            },
            "icnet_camvid_int8": {
                "config": "examples/torch/semantic_segmentation/configs/icnet_camvid_int8.json",
                "reference": "icnet_camvid",
                "target_ov": 67.89,
                "target_pt": 67.86,
                "metric_type": "Mean IoU",
                "resume": "icnet_camvid_int8.pth",
                "model_description": "ICNet",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true
            },
            "icnet_camvid_magnitude_sparsity_int8": {
                "config": "examples/torch/semantic_segmentation/configs/icnet_camvid_magnitude_sparsity_int8.json",
                "reference": "icnet_camvid",
                "target_ov": 67.16,
                "target_pt": 67.17,
                "metric_type": "Mean IoU",
                "resume": "icnet_camvid_magnitude_sparsity_int8.pth",
                "model_description": "ICNet",
                "compression_description": "INT8 + Sparsity 60% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true
            }
        },
        "mapillary_vistas": {
            "unet_mapillary": {
                "config": "examples/torch/semantic_segmentation/configs/unet_mapillary.json",
                "target_ov": 56.24,
                "target_pt": 56.24,
                "metric_type": "Mean IoU",
                "resume": "unet_mapillary.pth",
                "model_description": "UNet",
                "multiprocessing_distributed": true
            },
            "unet_mapillary_int8": {
                "config": "examples/torch/semantic_segmentation/configs/unet_mapillary_int8.json",
                "reference": "unet_mapillary",
                "target_ov": 56.14,
                "target_pt": 56.08,
                "metric_type": "Mean IoU",
                "resume": "unet_mapillary_int8.pth",
                "model_description": "UNet",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true,
                "xfail_ov": "Issue-112675"
            },
            "unet_mapillary_magnitude_sparsity_int8": {
                "config": "examples/torch/semantic_segmentation/configs/unet_mapillary_magnitude_sparsity_int8.json",
                "reference": "unet_mapillary",
                "target_ov": 55.76,
                "target_pt": 55.7,
                "metric_type": "Mean IoU",
                "resume": "unet_mapillary_magnitude_sparsity_int8.pth",
                "model_description": "UNet",
                "compression_description": "INT8 + Sparsity 60% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true,
                "xfail_ov": "Issue-112675"
            },
            "unet_mapillary_pruning_geometric_median": {
                "config": "examples/torch/semantic_segmentation/configs/unet_mapillary_pruning_geometric_median.json",
                "reference": "unet_mapillary",
                "target_ov": 55.64,
                "target_pt": 55.64,
                "metric_type": "Mean IoU",
                "resume": "unet_mapillary_pruning_geometric_median.pth",
                "model_description": "UNet",
                "compression_description": "Filter pruning, 25%, geometric median criterion",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true
            }
        }
    }
}
