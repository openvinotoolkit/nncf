{
    "classification": {
        "imagenet": {
            "resnet50_imagenet": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet.json",
                "target": 76.15,
                "metric_type": "Acc@1",
                "model_description": "ResNet-50"
            },
            "resnet50_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet_int8.json",
                "reference": "resnet50_imagenet",
                "target": 76.46,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.5
            },
            "resnet50_imagenet_int8_per_tensor": {
                "config": "examples/torch/classification/configs/quantization/resnet50_imagenet_int8_per_tensor.json",
                "reference": "resnet50_imagenet",
                "target": 76.39,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int8_per_tensor.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 (per-tensor only)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.5
            },
            "resnet50_imagenet_int4_int8": {
                "config": "examples/torch/classification/configs/mixed_precision/resnet50_imagenet_mixed_int_hawq.json",
                "reference": "resnet50_imagenet",
                "target": 76.05,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_int4_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "Mixed, 43.12% INT8 / 56.88% INT4",
                "diff_fp32_min": -0.4,
                "diff_fp32_max": 0.4,
                "diff_target_min": -0.2,
                "diff_target_max": 0.2
            },
            "resnet50_imagenet_rb_sparsity_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/resnet50_imagenet_rb_sparsity_int8.json",
                "reference": "resnet50_imagenet",
                "target": 75.42,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_rb_sparsity_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 + Sparsity 61% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "resnet50_imagenet_rb_sparsity50_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/resnet50_imagenet_rb_sparsity50_int8.json",
                "reference": "resnet50_imagenet",
                "target": 75.5,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_rb_sparsity50_int8.pth",
                "model_description": "ResNet-50",
                "compression_description": "INT8 + Sparsity 50% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1
            },
            "resnet50_imagenet_pruning_geometric_median": {
                "config": "examples/torch/classification/configs/pruning/resnet50_imagenet_pruning_geometric_median.json",
                "reference": "resnet50_imagenet",
                "target": 75.57,
                "metric_type": "Acc@1",
                "resume": "resnet50_imagenet_pruning_geometric_median.pth",
                "model_description": "ResNet-50",
                "compression_description": "Filter pruning, 40%, geometric median criterion"
            },
            "inception_v3_imagenet": {
                "config": "examples/torch/classification/configs/quantization/inception_v3_imagenet.json",
                "target": 77.33,
                "metric_type": "Acc@1",
                "model_description": "Inception V3",
                "multiprocessing_distributed": true
            },
            "inception_v3_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/inception_v3_imagenet_int8.json",
                "reference": "inception_v3_imagenet",
                "target": 77.45,
                "metric_type": "Acc@1",
                "resume": "inception_v3_imagenet_int8.pth",
                "model_description": "Inception V3",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 1.0,
                "multiprocessing_distributed": true
            },
            "inception_v3_imagenet_rb_sparsity_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/inception_v3_imagenet_rb_sparsity_int8.json",
                "reference": "inception_v3_imagenet",
                "target": 76.36,
                "metric_type": "Acc@1",
                "resume": "inception_v3_imagenet_rb_sparsity_int8.pth",
                "model_description": "Inception V3",
                "compression_description": "INT8 + Sparsity 61% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.4,
                "multiprocessing_distributed": true
            },
            "mobilenet_v2_imagenet": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v2_imagenet.json",
                "target": 71.87,
                "metric_type": "Acc@1",
                "model_description": "MobileNet V2"
            },
            "mobilenet_v2_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v2_imagenet_int8.json",
                "reference": "mobilenet_v2_imagenet",
                "target": 71.07,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "mobilenet_v2_imagenet_int8_per_tensor": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v2_imagenet_int8_per_tensor.json",
                "reference": "mobilenet_v2_imagenet",
                "target": 71.24,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int8_per_tensor.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8 (per-tensor only)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "mobilenet_v2_imagenet_int4_int8": {
                "config": "examples/torch/classification/configs/mixed_precision/mobilenet_v2_imagenet_mixed_int_hawq.json",
                "reference": "mobilenet_v2_imagenet",
                "target": 70.95,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_int4_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "Mixed, 58.88% INT8 / 41.12% INT4",
                "diff_fp32_max": 0.4
            },
            "mobilenet_v2_imagenet_rb_sparsity_int8": {
                "config": "examples/torch/classification/configs/sparsity_quantization/mobilenet_v2_imagenet_rb_sparsity_int8.json",
                "reference": "mobilenet_v2_imagenet",
                "target": 71.09,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v2_imagenet_rb_sparsity_int8.pth",
                "model_description": "MobileNet V2",
                "compression_description": "INT8 + Sparsity 52% (RB)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "mobilenet_v3_small_imagenet": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v3_small_imagenet.json",
                "target": 67.66,
                "metric_type": "Acc@1",
                "model_description": "MobileNet V3 small"
            },
            "mobilenet_v3_small_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/mobilenet_v3_small_imagenet_int8.json",
                "reference": "mobilenet_v3_small_imagenet",
                "target": 66.98,
                "metric_type": "Acc@1",
                "resume": "mobilenet_v3_small_imagenet_int8.pth",
                "model_description": "MobileNet V3 small",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "squeezenet1_1_imagenet": {
                "config": "examples/torch/classification/configs/quantization/squeezenet1_1_imagenet.json",
                "target": 58.19,
                "metric_type": "Acc@1",
                "model_description": "SqueezeNet V1.1"
            },
            "squeezenet1_1_imagenet_int8": {
                "config": "examples/torch/classification/configs/quantization/squeezenet1_1_imagenet_int8.json",
                "reference": "squeezenet1_1_imagenet",
                "target": 58.22,
                "metric_type": "Acc@1",
                "resume": "squeezenet1_1_imagenet_int8.pth",
                "model_description": "SqueezeNet V1.1",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "squeezenet1_1_imagenet_int8_per_tensor": {
                "config": "examples/torch/classification/configs/quantization/squeezenet1_1_imagenet_int8_per_tensor.json",
                "reference": "squeezenet1_1_imagenet",
                "target": 58.11,
                "metric_type": "Acc@1",
                "resume": "squeezenet1_1_imagenet_int8_per_tensor.pth",
                "model_description": "SqueezeNet V1.1",
                "compression_description": "INT8 (per-tensor only)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.15
            },
            "squeezenet1_1_imagenet_int4_int8": {
                "config": "examples/torch/classification/configs/mixed_precision/squeezenet1_1_imagenet_mixed_int_hawq_old_eval.json",
                "reference": "squeezenet1_1_imagenet",
                "target": 57.57,
                "metric_type": "Acc@1",
                "resume": "squeezenet1_1_imagenet_int4_int8.pth",
                "model_description": "SqueezeNet V1.1",
                "compression_description": "Mixed, 52.83% INT8 / 47.17% INT4",
                "diff_fp32_min": -0.7,
                "diff_fp32_max": 0.7
            },
            "resnet18_imagenet": {
                "config": "examples/torch/classification/configs/binarization/resnet18_imagenet.json",
                "target": 69.76,
                "metric_type": "Acc@1",
                "model_description": "ResNet-18"
            },
            "resnet18_imagenet_binarization_xnor": {
                "config": "examples/torch/classification/configs/binarization/resnet18_imagenet_binarization_xnor.json",
                "reference": "resnet18_imagenet",
                "target": 61.67,
                "metric_type": "Acc@1",
                "resume": "resnet18_imagenet_binarization_xnor.pth",
                "model_description": "ResNet-18",
                "compression_description": "XNOR (weights), scale/threshold (activations)",
                "diff_fp32_min": -8,
                "diff_fp32_max": 0.1
            },
            "resnet18_imagenet_binarization_dorefa": {
                "config": "examples/torch/classification/configs/binarization/resnet18_imagenet_binarization_dorefa.json",
                "reference": "resnet18_imagenet",
                "target": 61.63,
                "metric_type": "Acc@1",
                "resume": "resnet18_imagenet_binarization_dorefa.pth",
                "model_description": "ResNet-18",
                "compression_description": "DoReFa (weights), scale/threshold (activations)",
                "diff_fp32_min": -8,
                "diff_fp32_max": 0.1
            },
            "resnet18_imagenet_pruning_magnitude": {
                "config": "examples/torch/classification/configs/pruning/resnet18_imagenet_pruning_magnitude.json",
                "reference": "resnet18_imagenet",
                "target": 69.27,
                "metric_type": "Acc@1",
                "resume": "resnet18_imagenet_pruning_magnitude.pth",
                "model_description": "ResNet-18",
                "compression_description": "Filter pruning, 40%, magnitude criterion"
            },
            "resnet18_imagenet_pruning_geometric_median": {
                "config": "examples/torch/classification/configs/pruning/resnet18_imagenet_pruning_geometric_median.json",
                "reference": "resnet18_imagenet",
                "target": 69.31,
                "metric_type": "Acc@1",
                "resume": "resnet18_imagenet_pruning_geometric_median.pth",
                "model_description": "ResNet-18",
                "compression_description": "Filter pruning, 40%, geometric median criterion"
            },
            "resnet34_imagenet": {
                "config": "examples/torch/classification/configs/pruning/resnet34_imagenet.json",
                "target": 73.3,
                "metric_type": "Acc@1",
                "model_description": "ResNet-34"
            },
            "resnet34_imagenet_pruning_geometric_median_kd": {
                "config": "examples/torch/classification/configs/pruning/resnet34_imagenet_pruning_geometric_median_kd.json",
                "reference": "resnet34_imagenet",
                "target": 73.11,
                "metric_type": "Acc@1",
                "resume": "resnet34_imagenet_pruning_geometric_median_kd.pth",
                "model_description": "ResNet-34",
                "compression_description": "Filter pruning, 50%, geometric median criterion + KD"
            },
            "googlenet_imagenet": {
                "config": "examples/torch/classification/configs/pruning/googlenet_imagenet.json",
                "target": 69.77,
                "metric_type": "Acc@1",
                "model_description": "GoogLeNet"
            },
            "googlenet_imagenet_pruning_geometric_median": {
                "config": "examples/torch/classification/configs/pruning/googlenet_imagenet_pruning_geometric_median.json",
                "reference": "googlenet_imagenet",
                "target": 69.47,
                "metric_type": "Acc@1",
                "resume": "googlenet_imagenet_pruning_geometric_median.pth",
                "model_description": "GoogLeNet",
                "compression_description": "Filter pruning, 40%, geometric median criterion"
            }
        }
    },
    "object_detection": {
        "voc": {
            "ssd300_mobilenet_voc": {
                "config": "examples/torch/object_detection/configs/ssd300_mobilenet_voc.json",
                "target": 62.23,
                "metric_type": "Mean AP",
                "resume": "ssd300_mobilenet_voc.pth",
                "batch": 120,
                "model_description": "SSD300-MobileNet"
            },
            "ssd300_mobilenet_voc_magnitude_sparsity_int8": {
                "config": "examples/torch/object_detection/configs/ssd300_mobilenet_voc_magnitude_int8.json",
                "reference": "ssd300_mobilenet_voc",
                "target": 62.95,
                "metric_type": "Mean AP",
                "resume": "ssd300_mobilenet_voc_magnitude_sparsity_int8.pth",
                "model_description": "SSD300-MobileNet",
                "compression_description": "INT8 + Sparsity 70% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.8,
                "diff_target_min": -0.2
            },
            "ssd300_vgg_voc": {
                "config": "examples/torch/object_detection/configs/ssd300_vgg_voc.json",
                "target": 78.28,
                "metric_type": "Mean AP",
                "resume": "ssd300_vgg_voc.pth",
                "batch": 120,
                "model_description": "SSD300-VGG-BN",
                "diff_target_max": 0.3
            },
            "ssd300_vgg_voc_int8": {
                "config": "examples/torch/object_detection/configs/ssd300_vgg_voc_int8.json",
                "reference": "ssd300_vgg_voc",
                "target": 77.81,
                "metric_type": "Mean AP",
                "resume": "ssd300_vgg_voc_int8.pth",
                "model_description": "SSD300-VGG-BN",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1
            },
            "ssd300_vgg_voc_magnitude_sparsity_int8": {
                "config": "examples/torch/object_detection/configs/ssd300_vgg_voc_magnitude_sparsity_int8.json",
                "reference": "ssd300_vgg_voc",
                "target": 77.66,
                "metric_type": "Mean AP",
                "resume": "ssd300_vgg_voc_magnitude_sparsity_int8.pth",
                "model_description": "SSD300-VGG-BN",
                "compression_description": "INT8 + Sparsity 70% (Magnitude)",
                "diff_fp32_max": 0.1
            },
            "ssd300_vgg_voc_pruning_geometric_median": {
                "config": "examples/torch/object_detection/configs/ssd300_vgg_voc_pruning_geometric_median.json",
                "reference": "ssd300_vgg_voc",
                "target": 78.35,
                "metric_type": "Mean AP",
                "resume": "ssd300_vgg_voc_pruning_geometric_median.pth",
                "batch": 32,
                "model_description": "SSD300-VGG-BN",
                "compression_description": "Filter pruning, 40%, geometric median criterion",
                "diff_fp32_max": 0.1
            },
            "ssd512_vgg_voc": {
                "config": "examples/torch/object_detection/configs/ssd512_vgg_voc.json",
                "target": 80.26,
                "metric_type": "Mean AP",
                "resume": "ssd512_vgg_voc.pth",
                "batch": 32,
                "model_description": "SSD512-VGG-BN",
                "diff_target_max": 0.4
            },
            "ssd512_vgg_voc_int8": {
                "config": "examples/torch/object_detection/configs/ssd512_vgg_voc_int8.json",
                "reference": "ssd512_vgg_voc",
                "target": 80.04,
                "metric_type": "Mean AP",
                "resume": "ssd512_vgg_voc_int8.pth",
                "batch": 32,
                "model_description": "SSD512-VGG-BN",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.2,
                "diff_target_max": 0.2
            },
            "ssd512_vgg_voc_magnitude_sparsity_int8": {
                "config": "examples/torch/object_detection/configs/ssd512_vgg_voc_magnitude_sparsity_int8.json",
                "reference": "ssd512_vgg_voc",
                "target": 79.68,
                "metric_type": "Mean AP",
                "resume": "ssd512_vgg_voc_magnitude_sparsity_int8.pth",
                "batch": 32,
                "model_description": "SSD512-VGG-BN",
                "compression_description": "INT8 + Sparsity 70% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "diff_target_min": -0.2
            }
        }
    },
    "semantic_segmentation": {
        "camvid": {
            "unet_camvid": {
                "config": "examples/torch/semantic_segmentation/configs/unet_camvid.json",
                "target": 71.95,
                "metric_type": "Mean IoU",
                "resume": "unet_camvid.pth",
                "mean_value": "[99.603,103.329,105.6567]",
                "scale_value": "[75.643,77.821,76.746]",
                "model_description": "UNet",
                "multiprocessing_distributed": true
            },
            "unet_camvid_int8": {
                "config": "examples/torch/semantic_segmentation/configs/unet_camvid_int8.json",
                "reference": "unet_camvid",
                "target": 71.89,
                "metric_type": "Mean IoU",
                "resume": "unet_camvid_int8.pth",
                "model_description": "UNet",
                "compression_description": "INT8",
                "mean_value": "[99.603,103.329,105.6567]",
                "scale_value": "[75.643,77.821,76.746]",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "diff_target_min": -0.2,
                "multiprocessing_distributed": true
            },
            "unet_camvid_magnitude_sparsity_int8": {
                "config": "examples/torch/semantic_segmentation/configs/unet_camvid_magnitude_sparsity_int8.json",
                "reference": "unet_camvid",
                "target": 72.46,
                "metric_type": "Mean IoU",
                "resume": "unet_camvid_magnitude_sparsity_int8.pth",
                "mean_value": "[99.603,103.329,105.6567]",
                "scale_value": "[75.643,77.821,76.746]",
                "model_description": "UNet",
                "compression_description": "INT8 + Sparsity 60% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.6,
                "multiprocessing_distributed": true
            },
            "icnet_camvid": {
                "config": "examples/torch/semantic_segmentation/configs/icnet_camvid.json",
                "target": 67.89,
                "metric_type": "Mean IoU",
                "resume": "icnet_camvid.pth",
                "mean_value": "[99.603,103.329,105.6567]",
                "scale_value": "[75.643,77.821,76.746]",
                "model_description": "ICNet",
                "multiprocessing_distributed": true
            },
            "icnet_camvid_int8": {
                "config": "examples/torch/semantic_segmentation/configs/icnet_camvid_int8.json",
                "reference": "icnet_camvid",
                "target": 67.89,
                "metric_type": "Mean IoU",
                "resume": "icnet_camvid_int8.pth",
                "mean_value": "[99.603,103.329,105.6567]",
                "scale_value": "[75.643,77.821,76.746]",
                "model_description": "ICNet",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true
            },
            "icnet_camvid_magnitude_sparsity_int8": {
                "config": "examples/torch/semantic_segmentation/configs/icnet_camvid_magnitude_sparsity_int8.json",
                "reference": "icnet_camvid",
                "target": 67.16,
                "metric_type": "Mean IoU",
                "resume": "icnet_camvid_magnitude_sparsity_int8.pth",
                "mean_value": "[99.603,103.329,105.6567]",
                "scale_value": "[75.643,77.821,76.746]",
                "model_description": "ICNet",
                "compression_description": "INT8 + Sparsity 60% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true
            }
        },
        "mapillary_vistas": {
            "unet_mapillary": {
                "config": "examples/torch/semantic_segmentation/configs/unet_mapillary.json",
                "target": 56.24,
                "metric_type": "Mean IoU",
                "resume": "unet_mapillary.pth",
                "model_description": "UNet",
                "multiprocessing_distributed": true
            },
            "unet_mapillary_int8": {
                "config": "examples/torch/semantic_segmentation/configs/unet_mapillary_int8.json",
                "reference": "unet_mapillary",
                "target": 56.09,
                "metric_type": "Mean IoU",
                "resume": "unet_mapillary_int8.pth",
                "model_description": "UNet",
                "compression_description": "INT8",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true
            },
            "unet_mapillary_magnitude_sparsity_int8": {
                "config": "examples/torch/semantic_segmentation/configs/unet_mapillary_magnitude_sparsity_int8.json",
                "reference": "unet_mapillary",
                "target": 55.69,
                "metric_type": "Mean IoU",
                "resume": "unet_mapillary_magnitude_sparsity_int8.pth",
                "model_description": "UNet",
                "compression_description": "INT8 + Sparsity 60% (Magnitude)",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "diff_target_max": 0.2,
                "multiprocessing_distributed": true
            },
            "unet_mapillary_pruning_geometric_median": {
                "config": "examples/torch/semantic_segmentation/configs/unet_mapillary_pruning_geometric_median.json",
                "reference": "unet_mapillary",
                "target": 55.64,
                "metric_type": "Mean IoU",
                "resume": "unet_mapillary_pruning_geometric_median.pth",
                "model_description": "UNet",
                "compression_description": "Filter pruning, 25%, geometric median criterion",
                "diff_fp32_min": -1,
                "diff_fp32_max": 0.1,
                "multiprocessing_distributed": true
            }
        }
    }
}