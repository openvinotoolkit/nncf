strict digraph  {
"0 QuantizeLinear_input.1_1" [id=0, type=QuantizeLinear];
"1 DequantizeLinear_input.1_1" [id=1, type=DequantizeLinear];
"2 QuantizeLinear_conv1.weight_1" [id=2, type=QuantizeLinear];
"3 DequantizeLinear_conv1.weight_1" [id=3, type=DequantizeLinear];
"4 Conv_0" [id=4, type=Conv];
"5 BatchNormalization_1" [id=5, type=BatchNormalization];
"6 Relu_2" [id=6, type=Relu];
"7 QuantizeLinear_onnx^^MaxPool_129_1" [id=7, label="7 QuantizeLinear_onnx::MaxPool_129_1", type=QuantizeLinear];
"8 DequantizeLinear_onnx^^MaxPool_129_1" [id=8, label="8 DequantizeLinear_onnx::MaxPool_129_1", type=DequantizeLinear];
"9 MaxPool_3" [id=9, type=MaxPool];
"10 QuantizeLinear_layer1.0.conv1.weight_1" [id=10, type=QuantizeLinear];
"11 DequantizeLinear_layer1.0.conv1.weight_1" [id=11, type=DequantizeLinear];
"12 Conv_4" [id=12, type=Conv];
"13 BatchNormalization_5" [id=13, type=BatchNormalization];
"14 Relu_6" [id=14, type=Relu];
"15 QuantizeLinear_onnx^^Conv_137_1" [id=15, label="15 QuantizeLinear_onnx::Conv_137_1", type=QuantizeLinear];
"16 DequantizeLinear_onnx^^Conv_137_1" [id=16, label="16 DequantizeLinear_onnx::Conv_137_1", type=DequantizeLinear];
"17 QuantizeLinear_layer1.0.conv2.weight_1" [id=17, type=QuantizeLinear];
"18 DequantizeLinear_layer1.0.conv2.weight_1" [id=18, type=DequantizeLinear];
"19 Conv_7" [id=19, type=Conv];
"20 BatchNormalization_8" [id=20, type=BatchNormalization];
"21 QuantizeLinear_onnx^^Add_139_1" [id=21, label="21 QuantizeLinear_onnx::Add_139_1", type=QuantizeLinear];
"22 DequantizeLinear_onnx^^Add_139_1" [id=22, label="22 DequantizeLinear_onnx::Add_139_1", type=DequantizeLinear];
"23 Add_9" [id=23, type=Add];
"24 Relu_10" [id=24, type=Relu];
"25 QuantizeLinear_input.24_1" [id=25, type=QuantizeLinear];
"26 DequantizeLinear_input.24_1" [id=26, type=DequantizeLinear];
"27 QuantizeLinear_layer1.1.conv1.weight_1" [id=27, type=QuantizeLinear];
"28 DequantizeLinear_layer1.1.conv1.weight_1" [id=28, type=DequantizeLinear];
"29 Conv_11" [id=29, type=Conv];
"30 BatchNormalization_12" [id=30, type=BatchNormalization];
"31 Relu_13" [id=31, type=Relu];
"32 QuantizeLinear_onnx^^Conv_152_1" [id=32, label="32 QuantizeLinear_onnx::Conv_152_1", type=QuantizeLinear];
"33 DequantizeLinear_onnx^^Conv_152_1" [id=33, label="33 DequantizeLinear_onnx::Conv_152_1", type=DequantizeLinear];
"34 QuantizeLinear_layer1.1.conv2.weight_1" [id=34, type=QuantizeLinear];
"35 DequantizeLinear_layer1.1.conv2.weight_1" [id=35, type=DequantizeLinear];
"36 Conv_14" [id=36, type=Conv];
"37 BatchNormalization_15" [id=37, type=BatchNormalization];
"38 QuantizeLinear_onnx^^Add_154_1" [id=38, label="38 QuantizeLinear_onnx::Add_154_1", type=QuantizeLinear];
"39 DequantizeLinear_onnx^^Add_154_1" [id=39, label="39 DequantizeLinear_onnx::Add_154_1", type=DequantizeLinear];
"40 Add_16" [id=40, type=Add];
"41 Relu_17" [id=41, type=Relu];
"42 QuantizeLinear_input.40_1" [id=42, type=QuantizeLinear];
"43 DequantizeLinear_input.40_1" [id=43, type=DequantizeLinear];
"44 QuantizeLinear_layer2.0.conv1.weight_1" [id=44, type=QuantizeLinear];
"45 DequantizeLinear_layer2.0.conv1.weight_1" [id=45, type=DequantizeLinear];
"46 Conv_18" [id=46, type=Conv];
"47 BatchNormalization_19" [id=47, type=BatchNormalization];
"48 Relu_20" [id=48, type=Relu];
"49 QuantizeLinear_onnx^^Conv_167_1" [id=49, label="49 QuantizeLinear_onnx::Conv_167_1", type=QuantizeLinear];
"50 DequantizeLinear_onnx^^Conv_167_1" [id=50, label="50 DequantizeLinear_onnx::Conv_167_1", type=DequantizeLinear];
"51 QuantizeLinear_layer2.0.conv2.weight_1" [id=51, type=QuantizeLinear];
"52 DequantizeLinear_layer2.0.conv2.weight_1" [id=52, type=DequantizeLinear];
"53 Conv_21" [id=53, type=Conv];
"54 BatchNormalization_22" [id=54, type=BatchNormalization];
"55 QuantizeLinear_layer2.0.downsample.0.weight_1" [id=55, type=QuantizeLinear];
"56 DequantizeLinear_layer2.0.downsample.0.weight_1" [id=56, type=DequantizeLinear];
"57 Conv_23" [id=57, type=Conv];
"58 BatchNormalization_24" [id=58, type=BatchNormalization];
"59 QuantizeLinear_onnx^^Add_169_1" [id=59, label="59 QuantizeLinear_onnx::Add_169_1", type=QuantizeLinear];
"60 DequantizeLinear_onnx^^Add_169_1" [id=60, label="60 DequantizeLinear_onnx::Add_169_1", type=DequantizeLinear];
"61 QuantizeLinear_onnx^^Add_175_1" [id=61, label="61 QuantizeLinear_onnx::Add_175_1", type=QuantizeLinear];
"62 DequantizeLinear_onnx^^Add_175_1" [id=62, label="62 DequantizeLinear_onnx::Add_175_1", type=DequantizeLinear];
"63 Add_25" [id=63, type=Add];
"64 Relu_26" [id=64, type=Relu];
"65 QuantizeLinear_input.60_1" [id=65, type=QuantizeLinear];
"66 DequantizeLinear_input.60_1" [id=66, type=DequantizeLinear];
"67 QuantizeLinear_layer2.1.conv1.weight_1" [id=67, type=QuantizeLinear];
"68 DequantizeLinear_layer2.1.conv1.weight_1" [id=68, type=DequantizeLinear];
"69 Conv_27" [id=69, type=Conv];
"70 BatchNormalization_28" [id=70, type=BatchNormalization];
"71 Relu_29" [id=71, type=Relu];
"72 QuantizeLinear_onnx^^Conv_188_1" [id=72, label="72 QuantizeLinear_onnx::Conv_188_1", type=QuantizeLinear];
"73 DequantizeLinear_onnx^^Conv_188_1" [id=73, label="73 DequantizeLinear_onnx::Conv_188_1", type=DequantizeLinear];
"74 QuantizeLinear_layer2.1.conv2.weight_1" [id=74, type=QuantizeLinear];
"75 DequantizeLinear_layer2.1.conv2.weight_1" [id=75, type=DequantizeLinear];
"76 Conv_30" [id=76, type=Conv];
"77 BatchNormalization_31" [id=77, type=BatchNormalization];
"78 QuantizeLinear_onnx^^Add_190_1" [id=78, label="78 QuantizeLinear_onnx::Add_190_1", type=QuantizeLinear];
"79 DequantizeLinear_onnx^^Add_190_1" [id=79, label="79 DequantizeLinear_onnx::Add_190_1", type=DequantizeLinear];
"80 Add_32" [id=80, type=Add];
"81 Relu_33" [id=81, type=Relu];
"82 QuantizeLinear_input.76_1" [id=82, type=QuantizeLinear];
"83 DequantizeLinear_input.76_1" [id=83, type=DequantizeLinear];
"84 QuantizeLinear_layer3.0.conv1.weight_1" [id=84, type=QuantizeLinear];
"85 DequantizeLinear_layer3.0.conv1.weight_1" [id=85, type=DequantizeLinear];
"86 Conv_34" [id=86, type=Conv];
"87 BatchNormalization_35" [id=87, type=BatchNormalization];
"88 Relu_36" [id=88, type=Relu];
"89 QuantizeLinear_onnx^^Conv_203_1" [id=89, label="89 QuantizeLinear_onnx::Conv_203_1", type=QuantizeLinear];
"90 DequantizeLinear_onnx^^Conv_203_1" [id=90, label="90 DequantizeLinear_onnx::Conv_203_1", type=DequantizeLinear];
"91 QuantizeLinear_layer3.0.conv2.weight_1" [id=91, type=QuantizeLinear];
"92 DequantizeLinear_layer3.0.conv2.weight_1" [id=92, type=DequantizeLinear];
"93 Conv_37" [id=93, type=Conv];
"94 BatchNormalization_38" [id=94, type=BatchNormalization];
"95 QuantizeLinear_layer3.0.downsample.0.weight_1" [id=95, type=QuantizeLinear];
"96 DequantizeLinear_layer3.0.downsample.0.weight_1" [id=96, type=DequantizeLinear];
"97 Conv_39" [id=97, type=Conv];
"98 BatchNormalization_40" [id=98, type=BatchNormalization];
"99 QuantizeLinear_onnx^^Add_205_1" [id=99, label="99 QuantizeLinear_onnx::Add_205_1", type=QuantizeLinear];
"100 DequantizeLinear_onnx^^Add_205_1" [id=100, label="100 DequantizeLinear_onnx::Add_205_1", type=DequantizeLinear];
"101 QuantizeLinear_onnx^^Add_211_1" [id=101, label="101 QuantizeLinear_onnx::Add_211_1", type=QuantizeLinear];
"102 DequantizeLinear_onnx^^Add_211_1" [id=102, label="102 DequantizeLinear_onnx::Add_211_1", type=DequantizeLinear];
"103 Add_41" [id=103, type=Add];
"104 Relu_42" [id=104, type=Relu];
"105 QuantizeLinear_input.96_1" [id=105, type=QuantizeLinear];
"106 DequantizeLinear_input.96_1" [id=106, type=DequantizeLinear];
"107 QuantizeLinear_layer3.1.conv1.weight_1" [id=107, type=QuantizeLinear];
"108 DequantizeLinear_layer3.1.conv1.weight_1" [id=108, type=DequantizeLinear];
"109 Conv_43" [id=109, type=Conv];
"110 BatchNormalization_44" [id=110, type=BatchNormalization];
"111 Relu_45" [id=111, type=Relu];
"112 QuantizeLinear_onnx^^Conv_224_1" [id=112, label="112 QuantizeLinear_onnx::Conv_224_1", type=QuantizeLinear];
"113 DequantizeLinear_onnx^^Conv_224_1" [id=113, label="113 DequantizeLinear_onnx::Conv_224_1", type=DequantizeLinear];
"114 QuantizeLinear_layer3.1.conv2.weight_1" [id=114, type=QuantizeLinear];
"115 DequantizeLinear_layer3.1.conv2.weight_1" [id=115, type=DequantizeLinear];
"116 Conv_46" [id=116, type=Conv];
"117 BatchNormalization_47" [id=117, type=BatchNormalization];
"118 QuantizeLinear_onnx^^Add_226_1" [id=118, label="118 QuantizeLinear_onnx::Add_226_1", type=QuantizeLinear];
"119 DequantizeLinear_onnx^^Add_226_1" [id=119, label="119 DequantizeLinear_onnx::Add_226_1", type=DequantizeLinear];
"120 Add_48" [id=120, type=Add];
"121 Relu_49" [id=121, type=Relu];
"122 QuantizeLinear_input.112_1" [id=122, type=QuantizeLinear];
"123 DequantizeLinear_input.112_1" [id=123, type=DequantizeLinear];
"124 QuantizeLinear_layer4.0.conv1.weight_1" [id=124, type=QuantizeLinear];
"125 DequantizeLinear_layer4.0.conv1.weight_1" [id=125, type=DequantizeLinear];
"126 Conv_50" [id=126, type=Conv];
"127 BatchNormalization_51" [id=127, type=BatchNormalization];
"128 Relu_52" [id=128, type=Relu];
"129 QuantizeLinear_onnx^^Conv_239_1" [id=129, label="129 QuantizeLinear_onnx::Conv_239_1", type=QuantizeLinear];
"130 DequantizeLinear_onnx^^Conv_239_1" [id=130, label="130 DequantizeLinear_onnx::Conv_239_1", type=DequantizeLinear];
"131 QuantizeLinear_layer4.0.conv2.weight_1" [id=131, type=QuantizeLinear];
"132 DequantizeLinear_layer4.0.conv2.weight_1" [id=132, type=DequantizeLinear];
"133 Conv_53" [id=133, type=Conv];
"134 BatchNormalization_54" [id=134, type=BatchNormalization];
"135 QuantizeLinear_layer4.0.downsample.0.weight_1" [id=135, type=QuantizeLinear];
"136 DequantizeLinear_layer4.0.downsample.0.weight_1" [id=136, type=DequantizeLinear];
"137 Conv_55" [id=137, type=Conv];
"138 BatchNormalization_56" [id=138, type=BatchNormalization];
"139 QuantizeLinear_onnx^^Add_241_1" [id=139, label="139 QuantizeLinear_onnx::Add_241_1", type=QuantizeLinear];
"140 DequantizeLinear_onnx^^Add_241_1" [id=140, label="140 DequantizeLinear_onnx::Add_241_1", type=DequantizeLinear];
"141 QuantizeLinear_onnx^^Add_247_1" [id=141, label="141 QuantizeLinear_onnx::Add_247_1", type=QuantizeLinear];
"142 DequantizeLinear_onnx^^Add_247_1" [id=142, label="142 DequantizeLinear_onnx::Add_247_1", type=DequantizeLinear];
"143 Add_57" [id=143, type=Add];
"144 Relu_58" [id=144, type=Relu];
"145 QuantizeLinear_input.132_1" [id=145, type=QuantizeLinear];
"146 DequantizeLinear_input.132_1" [id=146, type=DequantizeLinear];
"147 QuantizeLinear_layer4.1.conv1.weight_1" [id=147, type=QuantizeLinear];
"148 DequantizeLinear_layer4.1.conv1.weight_1" [id=148, type=DequantizeLinear];
"149 Conv_59" [id=149, type=Conv];
"150 BatchNormalization_60" [id=150, type=BatchNormalization];
"151 Relu_61" [id=151, type=Relu];
"152 QuantizeLinear_onnx^^Conv_260_1" [id=152, label="152 QuantizeLinear_onnx::Conv_260_1", type=QuantizeLinear];
"153 DequantizeLinear_onnx^^Conv_260_1" [id=153, label="153 DequantizeLinear_onnx::Conv_260_1", type=DequantizeLinear];
"154 QuantizeLinear_layer4.1.conv2.weight_1" [id=154, type=QuantizeLinear];
"155 DequantizeLinear_layer4.1.conv2.weight_1" [id=155, type=DequantizeLinear];
"156 Conv_62" [id=156, type=Conv];
"157 BatchNormalization_63" [id=157, type=BatchNormalization];
"158 QuantizeLinear_onnx^^Add_262_1" [id=158, label="158 QuantizeLinear_onnx::Add_262_1", type=QuantizeLinear];
"159 DequantizeLinear_onnx^^Add_262_1" [id=159, label="159 DequantizeLinear_onnx::Add_262_1", type=DequantizeLinear];
"160 Add_64" [id=160, type=Add];
"161 Relu_65" [id=161, type=Relu];
"162 QuantizeLinear_input.148_1" [id=162, type=QuantizeLinear];
"163 DequantizeLinear_input.148_1" [id=163, type=DequantizeLinear];
"164 GlobalAveragePool_66" [id=164, type=GlobalAveragePool];
"165 QuantizeLinear_onnx^^Flatten_269_1" [id=165, label="165 QuantizeLinear_onnx::Flatten_269_1", type=QuantizeLinear];
"166 DequantizeLinear_onnx^^Flatten_269_1" [id=166, label="166 DequantizeLinear_onnx::Flatten_269_1", type=DequantizeLinear];
"167 Flatten_67" [id=167, type=Flatten];
"168 QuantizeLinear_fc.weight_1" [id=168, type=QuantizeLinear];
"169 DequantizeLinear_fc.weight_1" [id=169, type=DequantizeLinear];
"170 Gemm_68" [id=170, type=Gemm];
"171 nncf_model_input_0" [id=171, type=nncf_model_input];
"172 nncf_model_output_0" [id=172, type=nncf_model_output];
"0 QuantizeLinear_input.1_1" -> "1 DequantizeLinear_input.1_1"  [label="[1, 3, 224, 224]", style=dashed];
"1 DequantizeLinear_input.1_1" -> "4 Conv_0"  [label="[1, 3, 224, 224]", style=solid];
"2 QuantizeLinear_conv1.weight_1" -> "3 DequantizeLinear_conv1.weight_1"  [label="[64, 3, 7, 7]", style=dashed];
"3 DequantizeLinear_conv1.weight_1" -> "4 Conv_0"  [label="[64, 3, 7, 7]", style=solid];
"4 Conv_0" -> "5 BatchNormalization_1"  [label="[1, 64, 112, 112]", style=solid];
"5 BatchNormalization_1" -> "6 Relu_2"  [label="[1, 64, 112, 112]", style=solid];
"6 Relu_2" -> "7 QuantizeLinear_onnx^^MaxPool_129_1"  [label="[1, 64, 112, 112]", style=solid];
"7 QuantizeLinear_onnx^^MaxPool_129_1" -> "8 DequantizeLinear_onnx^^MaxPool_129_1"  [label="[1, 64, 112, 112]", style=dashed];
"8 DequantizeLinear_onnx^^MaxPool_129_1" -> "9 MaxPool_3"  [label="[1, 64, 112, 112]", style=solid];
"9 MaxPool_3" -> "12 Conv_4"  [label="[1, 64, 56, 56]", style=solid];
"9 MaxPool_3" -> "23 Add_9"  [label="[1, 64, 56, 56]", style=solid];
"10 QuantizeLinear_layer1.0.conv1.weight_1" -> "11 DequantizeLinear_layer1.0.conv1.weight_1"  [label="[64, 64, 3, 3]", style=dashed];
"11 DequantizeLinear_layer1.0.conv1.weight_1" -> "12 Conv_4"  [label="[64, 64, 3, 3]", style=solid];
"12 Conv_4" -> "13 BatchNormalization_5"  [label="[1, 64, 56, 56]", style=solid];
"13 BatchNormalization_5" -> "14 Relu_6"  [label="[1, 64, 56, 56]", style=solid];
"14 Relu_6" -> "15 QuantizeLinear_onnx^^Conv_137_1"  [label="[1, 64, 56, 56]", style=solid];
"15 QuantizeLinear_onnx^^Conv_137_1" -> "16 DequantizeLinear_onnx^^Conv_137_1"  [label="[1, 64, 56, 56]", style=dashed];
"16 DequantizeLinear_onnx^^Conv_137_1" -> "19 Conv_7"  [label="[1, 64, 56, 56]", style=solid];
"17 QuantizeLinear_layer1.0.conv2.weight_1" -> "18 DequantizeLinear_layer1.0.conv2.weight_1"  [label="[64, 64, 3, 3]", style=dashed];
"18 DequantizeLinear_layer1.0.conv2.weight_1" -> "19 Conv_7"  [label="[64, 64, 3, 3]", style=solid];
"19 Conv_7" -> "20 BatchNormalization_8"  [label="[1, 64, 56, 56]", style=solid];
"20 BatchNormalization_8" -> "21 QuantizeLinear_onnx^^Add_139_1"  [label="[1, 64, 56, 56]", style=solid];
"21 QuantizeLinear_onnx^^Add_139_1" -> "22 DequantizeLinear_onnx^^Add_139_1"  [label="[1, 64, 56, 56]", style=dashed];
"22 DequantizeLinear_onnx^^Add_139_1" -> "23 Add_9"  [label="[1, 64, 56, 56]", style=solid];
"23 Add_9" -> "24 Relu_10"  [label="[1, 64, 56, 56]", style=solid];
"24 Relu_10" -> "25 QuantizeLinear_input.24_1"  [label="[1, 64, 56, 56]", style=solid];
"25 QuantizeLinear_input.24_1" -> "26 DequantizeLinear_input.24_1"  [label="[1, 64, 56, 56]", style=dashed];
"26 DequantizeLinear_input.24_1" -> "29 Conv_11"  [label="[1, 64, 56, 56]", style=solid];
"26 DequantizeLinear_input.24_1" -> "40 Add_16"  [label="[1, 64, 56, 56]", style=solid];
"27 QuantizeLinear_layer1.1.conv1.weight_1" -> "28 DequantizeLinear_layer1.1.conv1.weight_1"  [label="[64, 64, 3, 3]", style=dashed];
"28 DequantizeLinear_layer1.1.conv1.weight_1" -> "29 Conv_11"  [label="[64, 64, 3, 3]", style=solid];
"29 Conv_11" -> "30 BatchNormalization_12"  [label="[1, 64, 56, 56]", style=solid];
"30 BatchNormalization_12" -> "31 Relu_13"  [label="[1, 64, 56, 56]", style=solid];
"31 Relu_13" -> "32 QuantizeLinear_onnx^^Conv_152_1"  [label="[1, 64, 56, 56]", style=solid];
"32 QuantizeLinear_onnx^^Conv_152_1" -> "33 DequantizeLinear_onnx^^Conv_152_1"  [label="[1, 64, 56, 56]", style=dashed];
"33 DequantizeLinear_onnx^^Conv_152_1" -> "36 Conv_14"  [label="[1, 64, 56, 56]", style=solid];
"34 QuantizeLinear_layer1.1.conv2.weight_1" -> "35 DequantizeLinear_layer1.1.conv2.weight_1"  [label="[64, 64, 3, 3]", style=dashed];
"35 DequantizeLinear_layer1.1.conv2.weight_1" -> "36 Conv_14"  [label="[64, 64, 3, 3]", style=solid];
"36 Conv_14" -> "37 BatchNormalization_15"  [label="[1, 64, 56, 56]", style=solid];
"37 BatchNormalization_15" -> "38 QuantizeLinear_onnx^^Add_154_1"  [label="[1, 64, 56, 56]", style=solid];
"38 QuantizeLinear_onnx^^Add_154_1" -> "39 DequantizeLinear_onnx^^Add_154_1"  [label="[1, 64, 56, 56]", style=dashed];
"39 DequantizeLinear_onnx^^Add_154_1" -> "40 Add_16"  [label="[1, 64, 56, 56]", style=solid];
"40 Add_16" -> "41 Relu_17"  [label="[1, 64, 56, 56]", style=solid];
"41 Relu_17" -> "42 QuantizeLinear_input.40_1"  [label="[1, 64, 56, 56]", style=solid];
"42 QuantizeLinear_input.40_1" -> "43 DequantizeLinear_input.40_1"  [label="[1, 64, 56, 56]", style=dashed];
"43 DequantizeLinear_input.40_1" -> "46 Conv_18"  [label="[1, 64, 56, 56]", style=solid];
"43 DequantizeLinear_input.40_1" -> "57 Conv_23"  [label="[1, 64, 56, 56]", style=solid];
"44 QuantizeLinear_layer2.0.conv1.weight_1" -> "45 DequantizeLinear_layer2.0.conv1.weight_1"  [label="[128, 64, 3, 3]", style=dashed];
"45 DequantizeLinear_layer2.0.conv1.weight_1" -> "46 Conv_18"  [label="[128, 64, 3, 3]", style=solid];
"46 Conv_18" -> "47 BatchNormalization_19"  [label="[1, 128, 28, 28]", style=solid];
"47 BatchNormalization_19" -> "48 Relu_20"  [label="[1, 128, 28, 28]", style=solid];
"48 Relu_20" -> "49 QuantizeLinear_onnx^^Conv_167_1"  [label="[1, 128, 28, 28]", style=solid];
"49 QuantizeLinear_onnx^^Conv_167_1" -> "50 DequantizeLinear_onnx^^Conv_167_1"  [label="[1, 128, 28, 28]", style=dashed];
"50 DequantizeLinear_onnx^^Conv_167_1" -> "53 Conv_21"  [label="[1, 128, 28, 28]", style=solid];
"51 QuantizeLinear_layer2.0.conv2.weight_1" -> "52 DequantizeLinear_layer2.0.conv2.weight_1"  [label="[128, 128, 3, 3]", style=dashed];
"52 DequantizeLinear_layer2.0.conv2.weight_1" -> "53 Conv_21"  [label="[128, 128, 3, 3]", style=solid];
"53 Conv_21" -> "54 BatchNormalization_22"  [label="[1, 128, 28, 28]", style=solid];
"54 BatchNormalization_22" -> "59 QuantizeLinear_onnx^^Add_169_1"  [label="[1, 128, 28, 28]", style=solid];
"55 QuantizeLinear_layer2.0.downsample.0.weight_1" -> "56 DequantizeLinear_layer2.0.downsample.0.weight_1"  [label="[128, 64, 1, 1]", style=dashed];
"56 DequantizeLinear_layer2.0.downsample.0.weight_1" -> "57 Conv_23"  [label="[128, 64, 1, 1]", style=solid];
"57 Conv_23" -> "58 BatchNormalization_24"  [label="[1, 128, 28, 28]", style=solid];
"58 BatchNormalization_24" -> "61 QuantizeLinear_onnx^^Add_175_1"  [label="[1, 128, 28, 28]", style=solid];
"59 QuantizeLinear_onnx^^Add_169_1" -> "60 DequantizeLinear_onnx^^Add_169_1"  [label="[1, 128, 28, 28]", style=dashed];
"60 DequantizeLinear_onnx^^Add_169_1" -> "63 Add_25"  [label="[1, 128, 28, 28]", style=solid];
"61 QuantizeLinear_onnx^^Add_175_1" -> "62 DequantizeLinear_onnx^^Add_175_1"  [label="[1, 128, 28, 28]", style=dashed];
"62 DequantizeLinear_onnx^^Add_175_1" -> "63 Add_25"  [label="[1, 128, 28, 28]", style=solid];
"63 Add_25" -> "64 Relu_26"  [label="[1, 128, 28, 28]", style=solid];
"64 Relu_26" -> "65 QuantizeLinear_input.60_1"  [label="[1, 128, 28, 28]", style=solid];
"65 QuantizeLinear_input.60_1" -> "66 DequantizeLinear_input.60_1"  [label="[1, 128, 28, 28]", style=dashed];
"66 DequantizeLinear_input.60_1" -> "69 Conv_27"  [label="[1, 128, 28, 28]", style=solid];
"66 DequantizeLinear_input.60_1" -> "80 Add_32"  [label="[1, 128, 28, 28]", style=solid];
"67 QuantizeLinear_layer2.1.conv1.weight_1" -> "68 DequantizeLinear_layer2.1.conv1.weight_1"  [label="[128, 128, 3, 3]", style=dashed];
"68 DequantizeLinear_layer2.1.conv1.weight_1" -> "69 Conv_27"  [label="[128, 128, 3, 3]", style=solid];
"69 Conv_27" -> "70 BatchNormalization_28"  [label="[1, 128, 28, 28]", style=solid];
"70 BatchNormalization_28" -> "71 Relu_29"  [label="[1, 128, 28, 28]", style=solid];
"71 Relu_29" -> "72 QuantizeLinear_onnx^^Conv_188_1"  [label="[1, 128, 28, 28]", style=solid];
"72 QuantizeLinear_onnx^^Conv_188_1" -> "73 DequantizeLinear_onnx^^Conv_188_1"  [label="[1, 128, 28, 28]", style=dashed];
"73 DequantizeLinear_onnx^^Conv_188_1" -> "76 Conv_30"  [label="[1, 128, 28, 28]", style=solid];
"74 QuantizeLinear_layer2.1.conv2.weight_1" -> "75 DequantizeLinear_layer2.1.conv2.weight_1"  [label="[128, 128, 3, 3]", style=dashed];
"75 DequantizeLinear_layer2.1.conv2.weight_1" -> "76 Conv_30"  [label="[128, 128, 3, 3]", style=solid];
"76 Conv_30" -> "77 BatchNormalization_31"  [label="[1, 128, 28, 28]", style=solid];
"77 BatchNormalization_31" -> "78 QuantizeLinear_onnx^^Add_190_1"  [label="[1, 128, 28, 28]", style=solid];
"78 QuantizeLinear_onnx^^Add_190_1" -> "79 DequantizeLinear_onnx^^Add_190_1"  [label="[1, 128, 28, 28]", style=dashed];
"79 DequantizeLinear_onnx^^Add_190_1" -> "80 Add_32"  [label="[1, 128, 28, 28]", style=solid];
"80 Add_32" -> "81 Relu_33"  [label="[1, 128, 28, 28]", style=solid];
"81 Relu_33" -> "82 QuantizeLinear_input.76_1"  [label="[1, 128, 28, 28]", style=solid];
"82 QuantizeLinear_input.76_1" -> "83 DequantizeLinear_input.76_1"  [label="[1, 128, 28, 28]", style=dashed];
"83 DequantizeLinear_input.76_1" -> "86 Conv_34"  [label="[1, 128, 28, 28]", style=solid];
"83 DequantizeLinear_input.76_1" -> "97 Conv_39"  [label="[1, 128, 28, 28]", style=solid];
"84 QuantizeLinear_layer3.0.conv1.weight_1" -> "85 DequantizeLinear_layer3.0.conv1.weight_1"  [label="[256, 128, 3, 3]", style=dashed];
"85 DequantizeLinear_layer3.0.conv1.weight_1" -> "86 Conv_34"  [label="[256, 128, 3, 3]", style=solid];
"86 Conv_34" -> "87 BatchNormalization_35"  [label="[1, 256, 14, 14]", style=solid];
"87 BatchNormalization_35" -> "88 Relu_36"  [label="[1, 256, 14, 14]", style=solid];
"88 Relu_36" -> "89 QuantizeLinear_onnx^^Conv_203_1"  [label="[1, 256, 14, 14]", style=solid];
"89 QuantizeLinear_onnx^^Conv_203_1" -> "90 DequantizeLinear_onnx^^Conv_203_1"  [label="[1, 256, 14, 14]", style=dashed];
"90 DequantizeLinear_onnx^^Conv_203_1" -> "93 Conv_37"  [label="[1, 256, 14, 14]", style=solid];
"91 QuantizeLinear_layer3.0.conv2.weight_1" -> "92 DequantizeLinear_layer3.0.conv2.weight_1"  [label="[256, 256, 3, 3]", style=dashed];
"92 DequantizeLinear_layer3.0.conv2.weight_1" -> "93 Conv_37"  [label="[256, 256, 3, 3]", style=solid];
"93 Conv_37" -> "94 BatchNormalization_38"  [label="[1, 256, 14, 14]", style=solid];
"94 BatchNormalization_38" -> "99 QuantizeLinear_onnx^^Add_205_1"  [label="[1, 256, 14, 14]", style=solid];
"95 QuantizeLinear_layer3.0.downsample.0.weight_1" -> "96 DequantizeLinear_layer3.0.downsample.0.weight_1"  [label="[256, 128, 1, 1]", style=dashed];
"96 DequantizeLinear_layer3.0.downsample.0.weight_1" -> "97 Conv_39"  [label="[256, 128, 1, 1]", style=solid];
"97 Conv_39" -> "98 BatchNormalization_40"  [label="[1, 256, 14, 14]", style=solid];
"98 BatchNormalization_40" -> "101 QuantizeLinear_onnx^^Add_211_1"  [label="[1, 256, 14, 14]", style=solid];
"99 QuantizeLinear_onnx^^Add_205_1" -> "100 DequantizeLinear_onnx^^Add_205_1"  [label="[1, 256, 14, 14]", style=dashed];
"100 DequantizeLinear_onnx^^Add_205_1" -> "103 Add_41"  [label="[1, 256, 14, 14]", style=solid];
"101 QuantizeLinear_onnx^^Add_211_1" -> "102 DequantizeLinear_onnx^^Add_211_1"  [label="[1, 256, 14, 14]", style=dashed];
"102 DequantizeLinear_onnx^^Add_211_1" -> "103 Add_41"  [label="[1, 256, 14, 14]", style=solid];
"103 Add_41" -> "104 Relu_42"  [label="[1, 256, 14, 14]", style=solid];
"104 Relu_42" -> "105 QuantizeLinear_input.96_1"  [label="[1, 256, 14, 14]", style=solid];
"105 QuantizeLinear_input.96_1" -> "106 DequantizeLinear_input.96_1"  [label="[1, 256, 14, 14]", style=dashed];
"106 DequantizeLinear_input.96_1" -> "109 Conv_43"  [label="[1, 256, 14, 14]", style=solid];
"106 DequantizeLinear_input.96_1" -> "120 Add_48"  [label="[1, 256, 14, 14]", style=solid];
"107 QuantizeLinear_layer3.1.conv1.weight_1" -> "108 DequantizeLinear_layer3.1.conv1.weight_1"  [label="[256, 256, 3, 3]", style=dashed];
"108 DequantizeLinear_layer3.1.conv1.weight_1" -> "109 Conv_43"  [label="[256, 256, 3, 3]", style=solid];
"109 Conv_43" -> "110 BatchNormalization_44"  [label="[1, 256, 14, 14]", style=solid];
"110 BatchNormalization_44" -> "111 Relu_45"  [label="[1, 256, 14, 14]", style=solid];
"111 Relu_45" -> "112 QuantizeLinear_onnx^^Conv_224_1"  [label="[1, 256, 14, 14]", style=solid];
"112 QuantizeLinear_onnx^^Conv_224_1" -> "113 DequantizeLinear_onnx^^Conv_224_1"  [label="[1, 256, 14, 14]", style=dashed];
"113 DequantizeLinear_onnx^^Conv_224_1" -> "116 Conv_46"  [label="[1, 256, 14, 14]", style=solid];
"114 QuantizeLinear_layer3.1.conv2.weight_1" -> "115 DequantizeLinear_layer3.1.conv2.weight_1"  [label="[256, 256, 3, 3]", style=dashed];
"115 DequantizeLinear_layer3.1.conv2.weight_1" -> "116 Conv_46"  [label="[256, 256, 3, 3]", style=solid];
"116 Conv_46" -> "117 BatchNormalization_47"  [label="[1, 256, 14, 14]", style=solid];
"117 BatchNormalization_47" -> "118 QuantizeLinear_onnx^^Add_226_1"  [label="[1, 256, 14, 14]", style=solid];
"118 QuantizeLinear_onnx^^Add_226_1" -> "119 DequantizeLinear_onnx^^Add_226_1"  [label="[1, 256, 14, 14]", style=dashed];
"119 DequantizeLinear_onnx^^Add_226_1" -> "120 Add_48"  [label="[1, 256, 14, 14]", style=solid];
"120 Add_48" -> "121 Relu_49"  [label="[1, 256, 14, 14]", style=solid];
"121 Relu_49" -> "122 QuantizeLinear_input.112_1"  [label="[1, 256, 14, 14]", style=solid];
"122 QuantizeLinear_input.112_1" -> "123 DequantizeLinear_input.112_1"  [label="[1, 256, 14, 14]", style=dashed];
"123 DequantizeLinear_input.112_1" -> "126 Conv_50"  [label="[1, 256, 14, 14]", style=solid];
"123 DequantizeLinear_input.112_1" -> "137 Conv_55"  [label="[1, 256, 14, 14]", style=solid];
"124 QuantizeLinear_layer4.0.conv1.weight_1" -> "125 DequantizeLinear_layer4.0.conv1.weight_1"  [label="[512, 256, 3, 3]", style=dashed];
"125 DequantizeLinear_layer4.0.conv1.weight_1" -> "126 Conv_50"  [label="[512, 256, 3, 3]", style=solid];
"126 Conv_50" -> "127 BatchNormalization_51"  [label="[1, 512, 7, 7]", style=solid];
"127 BatchNormalization_51" -> "128 Relu_52"  [label="[1, 512, 7, 7]", style=solid];
"128 Relu_52" -> "129 QuantizeLinear_onnx^^Conv_239_1"  [label="[1, 512, 7, 7]", style=solid];
"129 QuantizeLinear_onnx^^Conv_239_1" -> "130 DequantizeLinear_onnx^^Conv_239_1"  [label="[1, 512, 7, 7]", style=dashed];
"130 DequantizeLinear_onnx^^Conv_239_1" -> "133 Conv_53"  [label="[1, 512, 7, 7]", style=solid];
"131 QuantizeLinear_layer4.0.conv2.weight_1" -> "132 DequantizeLinear_layer4.0.conv2.weight_1"  [label="[512, 512, 3, 3]", style=dashed];
"132 DequantizeLinear_layer4.0.conv2.weight_1" -> "133 Conv_53"  [label="[512, 512, 3, 3]", style=solid];
"133 Conv_53" -> "134 BatchNormalization_54"  [label="[1, 512, 7, 7]", style=solid];
"134 BatchNormalization_54" -> "139 QuantizeLinear_onnx^^Add_241_1"  [label="[1, 512, 7, 7]", style=solid];
"135 QuantizeLinear_layer4.0.downsample.0.weight_1" -> "136 DequantizeLinear_layer4.0.downsample.0.weight_1"  [label="[512, 256, 1, 1]", style=dashed];
"136 DequantizeLinear_layer4.0.downsample.0.weight_1" -> "137 Conv_55"  [label="[512, 256, 1, 1]", style=solid];
"137 Conv_55" -> "138 BatchNormalization_56"  [label="[1, 512, 7, 7]", style=solid];
"138 BatchNormalization_56" -> "141 QuantizeLinear_onnx^^Add_247_1"  [label="[1, 512, 7, 7]", style=solid];
"139 QuantizeLinear_onnx^^Add_241_1" -> "140 DequantizeLinear_onnx^^Add_241_1"  [label="[1, 512, 7, 7]", style=dashed];
"140 DequantizeLinear_onnx^^Add_241_1" -> "143 Add_57"  [label="[1, 512, 7, 7]", style=solid];
"141 QuantizeLinear_onnx^^Add_247_1" -> "142 DequantizeLinear_onnx^^Add_247_1"  [label="[1, 512, 7, 7]", style=dashed];
"142 DequantizeLinear_onnx^^Add_247_1" -> "143 Add_57"  [label="[1, 512, 7, 7]", style=solid];
"143 Add_57" -> "144 Relu_58"  [label="[1, 512, 7, 7]", style=solid];
"144 Relu_58" -> "145 QuantizeLinear_input.132_1"  [label="[1, 512, 7, 7]", style=solid];
"145 QuantizeLinear_input.132_1" -> "146 DequantizeLinear_input.132_1"  [label="[1, 512, 7, 7]", style=dashed];
"146 DequantizeLinear_input.132_1" -> "149 Conv_59"  [label="[1, 512, 7, 7]", style=solid];
"146 DequantizeLinear_input.132_1" -> "160 Add_64"  [label="[1, 512, 7, 7]", style=solid];
"147 QuantizeLinear_layer4.1.conv1.weight_1" -> "148 DequantizeLinear_layer4.1.conv1.weight_1"  [label="[512, 512, 3, 3]", style=dashed];
"148 DequantizeLinear_layer4.1.conv1.weight_1" -> "149 Conv_59"  [label="[512, 512, 3, 3]", style=solid];
"149 Conv_59" -> "150 BatchNormalization_60"  [label="[1, 512, 7, 7]", style=solid];
"150 BatchNormalization_60" -> "151 Relu_61"  [label="[1, 512, 7, 7]", style=solid];
"151 Relu_61" -> "152 QuantizeLinear_onnx^^Conv_260_1"  [label="[1, 512, 7, 7]", style=solid];
"152 QuantizeLinear_onnx^^Conv_260_1" -> "153 DequantizeLinear_onnx^^Conv_260_1"  [label="[1, 512, 7, 7]", style=dashed];
"153 DequantizeLinear_onnx^^Conv_260_1" -> "156 Conv_62"  [label="[1, 512, 7, 7]", style=solid];
"154 QuantizeLinear_layer4.1.conv2.weight_1" -> "155 DequantizeLinear_layer4.1.conv2.weight_1"  [label="[512, 512, 3, 3]", style=dashed];
"155 DequantizeLinear_layer4.1.conv2.weight_1" -> "156 Conv_62"  [label="[512, 512, 3, 3]", style=solid];
"156 Conv_62" -> "157 BatchNormalization_63"  [label="[1, 512, 7, 7]", style=solid];
"157 BatchNormalization_63" -> "158 QuantizeLinear_onnx^^Add_262_1"  [label="[1, 512, 7, 7]", style=solid];
"158 QuantizeLinear_onnx^^Add_262_1" -> "159 DequantizeLinear_onnx^^Add_262_1"  [label="[1, 512, 7, 7]", style=dashed];
"159 DequantizeLinear_onnx^^Add_262_1" -> "160 Add_64"  [label="[1, 512, 7, 7]", style=solid];
"160 Add_64" -> "161 Relu_65"  [label="[1, 512, 7, 7]", style=solid];
"161 Relu_65" -> "162 QuantizeLinear_input.148_1"  [label="[1, 512, 7, 7]", style=solid];
"162 QuantizeLinear_input.148_1" -> "163 DequantizeLinear_input.148_1"  [label="[1, 512, 7, 7]", style=dashed];
"163 DequantizeLinear_input.148_1" -> "164 GlobalAveragePool_66"  [label="[1, 512, 7, 7]", style=solid];
"164 GlobalAveragePool_66" -> "165 QuantizeLinear_onnx^^Flatten_269_1"  [label="[1, 512, 1, 1]", style=solid];
"165 QuantizeLinear_onnx^^Flatten_269_1" -> "166 DequantizeLinear_onnx^^Flatten_269_1"  [label="[1, 512, 1, 1]", style=dashed];
"166 DequantizeLinear_onnx^^Flatten_269_1" -> "167 Flatten_67"  [label="[1, 512, 1, 1]", style=solid];
"167 Flatten_67" -> "170 Gemm_68"  [label="[1, 512]", style=solid];
"168 QuantizeLinear_fc.weight_1" -> "169 DequantizeLinear_fc.weight_1"  [label="[1000, 512]", style=dashed];
"169 DequantizeLinear_fc.weight_1" -> "170 Gemm_68"  [label="[1000, 512]", style=solid];
"170 Gemm_68" -> "172 nncf_model_output_0"  [label="[1, 1000]", style=solid];
"171 nncf_model_input_0" -> "0 QuantizeLinear_input.1_1"  [label="[1, 3, 224, 224]", style=solid];
}
