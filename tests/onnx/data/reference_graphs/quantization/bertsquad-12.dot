strict digraph  {
"0 unique_ids_graph_outputs_Identity__10" [id=0, type=Identity];
"1 bert/encoder/ones/packed_Unsqueeze__20" [id=1, type=Unsqueeze];
"2 bert/encoder/ones/packed_Unsqueeze__19" [id=2, type=Unsqueeze];
"3 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" [id=3, type=Unsqueeze];
"4 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" [id=4, type=Unsqueeze];
"5 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" [id=5, type=Unsqueeze];
"6 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" [id=6, type=Unsqueeze];
"7 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" [id=7, type=Unsqueeze];
"8 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" [id=8, type=Unsqueeze];
"9 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" [id=9, type=Unsqueeze];
"10 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" [id=10, type=Unsqueeze];
"11 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" [id=11, type=Unsqueeze];
"12 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" [id=12, type=Unsqueeze];
"13 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" [id=13, type=Unsqueeze];
"14 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" [id=14, type=Unsqueeze];
"15 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" [id=15, type=Unsqueeze];
"16 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" [id=16, type=Unsqueeze];
"17 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" [id=17, type=Unsqueeze];
"18 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" [id=18, type=Unsqueeze];
"19 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" [id=19, type=Unsqueeze];
"20 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" [id=20, type=Unsqueeze];
"21 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" [id=21, type=Unsqueeze];
"22 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" [id=22, type=Unsqueeze];
"23 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" [id=23, type=Unsqueeze];
"24 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" [id=24, type=Unsqueeze];
"25 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" [id=25, type=Unsqueeze];
"26 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" [id=26, type=Unsqueeze];
"27 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" [id=27, type=Unsqueeze];
"28 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" [id=28, type=Unsqueeze];
"29 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" [id=29, type=Unsqueeze];
"30 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" [id=30, type=Unsqueeze];
"31 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" [id=31, type=Unsqueeze];
"32 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" [id=32, type=Unsqueeze];
"33 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" [id=33, type=Unsqueeze];
"34 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" [id=34, type=Unsqueeze];
"35 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" [id=35, type=Unsqueeze];
"36 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" [id=36, type=Unsqueeze];
"37 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" [id=37, type=Unsqueeze];
"38 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" [id=38, type=Unsqueeze];
"39 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" [id=39, type=Unsqueeze];
"40 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" [id=40, type=Unsqueeze];
"41 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" [id=41, type=Unsqueeze];
"42 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" [id=42, type=Unsqueeze];
"43 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" [id=43, type=Unsqueeze];
"44 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" [id=44, type=Unsqueeze];
"45 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" [id=45, type=Unsqueeze];
"46 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" [id=46, type=Unsqueeze];
"47 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" [id=47, type=Unsqueeze];
"48 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" [id=48, type=Unsqueeze];
"49 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" [id=49, type=Unsqueeze];
"50 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" [id=50, type=Unsqueeze];
"51 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" [id=51, type=Unsqueeze];
"52 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" [id=52, type=Unsqueeze];
"53 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" [id=53, type=Unsqueeze];
"54 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" [id=54, type=Unsqueeze];
"55 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" [id=55, type=Unsqueeze];
"56 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" [id=56, type=Unsqueeze];
"57 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" [id=57, type=Unsqueeze];
"58 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" [id=58, type=Unsqueeze];
"59 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" [id=59, type=Unsqueeze];
"60 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" [id=60, type=Unsqueeze];
"61 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" [id=61, type=Unsqueeze];
"62 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" [id=62, type=Unsqueeze];
"63 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" [id=63, type=Unsqueeze];
"64 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" [id=64, type=Unsqueeze];
"65 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" [id=65, type=Unsqueeze];
"66 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" [id=66, type=Unsqueeze];
"67 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" [id=67, type=Unsqueeze];
"68 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" [id=68, type=Unsqueeze];
"69 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" [id=69, type=Unsqueeze];
"70 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" [id=70, type=Unsqueeze];
"71 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" [id=71, type=Unsqueeze];
"72 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" [id=72, type=Unsqueeze];
"73 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" [id=73, type=Unsqueeze];
"74 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" [id=74, type=Unsqueeze];
"75 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" [id=75, type=Unsqueeze];
"76 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" [id=76, type=Unsqueeze];
"77 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" [id=77, type=Unsqueeze];
"78 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" [id=78, type=Unsqueeze];
"79 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" [id=79, type=Unsqueeze];
"80 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" [id=80, type=Unsqueeze];
"81 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" [id=81, type=Unsqueeze];
"82 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" [id=82, type=Unsqueeze];
"83 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" [id=83, type=Unsqueeze];
"84 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" [id=84, type=Unsqueeze];
"85 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" [id=85, type=Unsqueeze];
"86 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" [id=86, type=Unsqueeze];
"87 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" [id=87, type=Unsqueeze];
"88 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" [id=88, type=Unsqueeze];
"89 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" [id=89, type=Unsqueeze];
"90 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" [id=90, type=Unsqueeze];
"91 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" [id=91, type=Unsqueeze];
"92 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" [id=92, type=Unsqueeze];
"93 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" [id=93, type=Unsqueeze];
"94 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" [id=94, type=Unsqueeze];
"95 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" [id=95, type=Unsqueeze];
"96 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" [id=96, type=Unsqueeze];
"97 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" [id=97, type=Unsqueeze];
"98 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" [id=98, type=Unsqueeze];
"99 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" [id=99, type=Unsqueeze];
"100 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" [id=100, type=Unsqueeze];
"101 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" [id=101, type=Unsqueeze];
"102 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" [id=102, type=Unsqueeze];
"103 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" [id=103, type=Unsqueeze];
"104 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" [id=104, type=Unsqueeze];
"105 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" [id=105, type=Unsqueeze];
"106 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" [id=106, type=Unsqueeze];
"107 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" [id=107, type=Unsqueeze];
"108 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" [id=108, type=Unsqueeze];
"109 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" [id=109, type=Unsqueeze];
"110 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" [id=110, type=Unsqueeze];
"111 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" [id=111, type=Unsqueeze];
"112 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" [id=112, type=Unsqueeze];
"113 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" [id=113, type=Unsqueeze];
"114 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" [id=114, type=Unsqueeze];
"115 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" [id=115, type=Unsqueeze];
"116 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" [id=116, type=Unsqueeze];
"117 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" [id=117, type=Unsqueeze];
"118 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" [id=118, type=Unsqueeze];
"119 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" [id=119, type=Unsqueeze];
"120 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" [id=120, type=Unsqueeze];
"121 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" [id=121, type=Unsqueeze];
"122 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" [id=122, type=Unsqueeze];
"123 bert/encoder/Shape" [id=123, type=Shape];
"124 bert/encoder/Shape__12" [id=124, type=Cast];
"125 bert/encoder/strided_slice" [id=125, type=Slice];
"126 bert/encoder/strided_slice__16" [id=126, type=Squeeze];
"127 bert/encoder/strided_slice__17" [id=127, type=Cast];
"128 bert/encoder/ones/packed_Unsqueeze__18" [id=128, type=Unsqueeze];
"129 bert/encoder/ones/packed_Concat__21" [id=129, type=Concat];
"130 bert/encoder/ones__22" [id=130, type=Cast];
"131 bert/encoder/ones" [id=131, type=ConstantOfShape];
"132 bert/encoder/Reshape_13/shape_Unsqueeze__300" [id=132, type=Unsqueeze];
"133 bert/encoder/Reshape_13/shape_Unsqueeze__299" [id=133, type=Unsqueeze];
"134 bert/encoder/Reshape_1__302" [id=134, type=Cast];
"135 bert/encoder/Reshape/shape_Unsqueeze__23" [id=135, type=Unsqueeze];
"136 bert/encoder/Reshape/shape_Unsqueeze__25" [id=136, type=Unsqueeze];
"137 bert/encoder/Reshape/shape_Unsqueeze__24" [id=137, type=Unsqueeze];
"138 bert/encoder/Reshape/shape_Concat__26" [id=138, type=Concat];
"139 bert/encoder/Reshape__27" [id=139, type=Cast];
"140 bert/encoder/Reshape" [id=140, type=Reshape];
"141 bert/encoder/Cast" [id=141, type=Cast];
"142 bert/encoder/mul" [id=142, type=Mul];
"143 bert/encoder/layer_9/attention/self/ExpandDims" [id=143, type=Reshape];
"144 bert/encoder/layer_9/attention/self/sub" [id=144, type=Sub];
"145 bert/encoder/layer_9/attention/self/mul_1" [id=145, type=Mul];
"146 bert/encoder/layer_8/attention/self/ExpandDims" [id=146, type=Reshape];
"147 bert/encoder/layer_8/attention/self/sub" [id=147, type=Sub];
"148 bert/encoder/layer_8/attention/self/mul_1" [id=148, type=Mul];
"149 bert/encoder/layer_7/attention/self/ExpandDims" [id=149, type=Reshape];
"150 bert/encoder/layer_7/attention/self/sub" [id=150, type=Sub];
"151 bert/encoder/layer_7/attention/self/mul_1" [id=151, type=Mul];
"152 bert/encoder/layer_6/attention/self/ExpandDims" [id=152, type=Reshape];
"153 bert/encoder/layer_6/attention/self/sub" [id=153, type=Sub];
"154 bert/encoder/layer_6/attention/self/mul_1" [id=154, type=Mul];
"155 bert/encoder/layer_5/attention/self/ExpandDims" [id=155, type=Reshape];
"156 bert/encoder/layer_5/attention/self/sub" [id=156, type=Sub];
"157 bert/encoder/layer_5/attention/self/mul_1" [id=157, type=Mul];
"158 bert/encoder/layer_4/attention/self/ExpandDims" [id=158, type=Reshape];
"159 bert/encoder/layer_4/attention/self/sub" [id=159, type=Sub];
"160 bert/encoder/layer_4/attention/self/mul_1" [id=160, type=Mul];
"161 bert/encoder/layer_3/attention/self/ExpandDims" [id=161, type=Reshape];
"162 bert/encoder/layer_3/attention/self/sub" [id=162, type=Sub];
"163 bert/encoder/layer_3/attention/self/mul_1" [id=163, type=Mul];
"164 bert/encoder/layer_2/attention/self/ExpandDims" [id=164, type=Reshape];
"165 bert/encoder/layer_2/attention/self/sub" [id=165, type=Sub];
"166 bert/encoder/layer_2/attention/self/mul_1" [id=166, type=Mul];
"167 bert/encoder/layer_11/attention/self/ExpandDims" [id=167, type=Reshape];
"168 bert/encoder/layer_11/attention/self/sub" [id=168, type=Sub];
"169 bert/encoder/layer_11/attention/self/mul_1" [id=169, type=Mul];
"170 bert/encoder/layer_10/attention/self/ExpandDims" [id=170, type=Reshape];
"171 bert/encoder/layer_10/attention/self/sub" [id=171, type=Sub];
"172 bert/encoder/layer_10/attention/self/mul_1" [id=172, type=Mul];
"173 bert/encoder/layer_1/attention/self/ExpandDims" [id=173, type=Reshape];
"174 bert/encoder/layer_1/attention/self/sub" [id=174, type=Sub];
"175 bert/encoder/layer_1/attention/self/mul_1" [id=175, type=Mul];
"176 bert/encoder/layer_0/attention/self/ExpandDims" [id=176, type=Reshape];
"177 bert/encoder/layer_0/attention/self/sub" [id=177, type=Sub];
"178 bert/encoder/layer_0/attention/self/mul_1" [id=178, type=Mul];
"179 bert/embeddings/Slice" [id=179, type=Slice];
"180 bert/embeddings/Reshape_4__42" [id=180, type=Cast];
"181 bert/embeddings/Reshape_4" [id=181, type=Reshape];
"182 bert/embeddings/Reshape_3/shape_Unsqueeze__69" [id=182, type=Unsqueeze];
"183 bert/embeddings/Reshape_3/shape_Unsqueeze__68" [id=183, type=Unsqueeze];
"184 bert/embeddings/Reshape_2__43" [id=184, type=Cast];
"185 bert/embeddings/Reshape_2" [id=185, type=Reshape];
"186 bert/embeddings/Reshape_1/shape_Unsqueeze__57" [id=186, type=Unsqueeze];
"187 bert/embeddings/Reshape_1/shape_Unsqueeze__56" [id=187, type=Unsqueeze];
"188 bert/embeddings/Reshape__59" [id=188, type=Cast];
"189 bert/embeddings/ExpandDims" [id=189, type=Reshape];
"190 bert/embeddings/Shape" [id=190, type=Shape];
"191 bert/embeddings/Shape__49" [id=191, type=Cast];
"192 bert/embeddings/strided_slice" [id=192, type=Slice];
"193 bert/embeddings/strided_slice__53" [id=193, type=Squeeze];
"194 bert/embeddings/strided_slice__54" [id=194, type=Cast];
"195 bert/embeddings/Reshape_1/shape_Unsqueeze__55" [id=195, type=Unsqueeze];
"196 bert/embeddings/Reshape_1/shape_Concat__58" [id=196, type=Concat];
"197 bert/embeddings/Reshape_1__60" [id=197, type=Cast];
"198 bert/embeddings/Reshape" [id=198, type=Reshape];
"199 bert/embeddings/GatherV2" [id=199, type=Gather];
"200 bert/embeddings/Reshape_1" [id=200, type=Reshape];
"201 bert/embeddings/Shape_1" [id=201, type=Shape];
"202 bert/embeddings/Shape_1__61" [id=202, type=Cast];
"203 bert/embeddings/strided_slice_1" [id=203, type=Slice];
"204 bert/embeddings/strided_slice_1__65" [id=204, type=Squeeze];
"205 bert/embeddings/strided_slice_1__66" [id=205, type=Cast];
"206 bert/embeddings/Reshape_3/shape_Unsqueeze__67" [id=206, type=Unsqueeze];
"207 bert/embeddings/Reshape_3/shape_Concat__70" [id=207, type=Concat];
"208 bert/embeddings/Reshape_3__71" [id=208, type=Cast];
"209 Unsqueeze__46" [id=209, type=Unsqueeze];
"210 Unsqueeze__45" [id=210, type=Unsqueeze];
"211 Unsqueeze__44" [id=211, type=Unsqueeze];
"212 Reshape_1/shape_Unsqueeze__480" [id=212, type=Unsqueeze];
"213 Reshape_1/shape_Unsqueeze__479" [id=213, type=Unsqueeze];
"214 Reshape/shape_Unsqueeze__483" [id=214, type=Unsqueeze];
"215 MatMul__486" [id=215, type=Transpose];
"216 Concat__47" [id=216, type=Concat];
"217 bert/embeddings/one_hot" [id=217, type=OneHot];
"218 QuantizeLinear_bert/embeddings/one_hot^0_1" [id=218, label="218 QuantizeLinear_bert/embeddings/one_hot:0_1", type=QuantizeLinear];
"219 DequantizeLinear_bert/embeddings/one_hot^0_1" [id=219, label="219 DequantizeLinear_bert/embeddings/one_hot:0_1", type=DequantizeLinear];
"220 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=220, label="220 QuantizeLinear_bert/embeddings/token_type_embeddings:0_1", type=QuantizeLinear];
"221 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=221, label="221 DequantizeLinear_bert/embeddings/token_type_embeddings:0_1", type=DequantizeLinear];
"222 bert/embeddings/MatMul" [id=222, type=MatMul];
"223 bert/embeddings/Reshape_3" [id=223, type=Reshape];
"224 bert/embeddings/add" [id=224, type=Add];
"225 bert/embeddings/add_1" [id=225, type=Add];
"226 bert/embeddings/LayerNorm/moments/mean" [id=226, type=ReduceMean];
"227 bert/embeddings/LayerNorm/moments/StopGradient" [id=227, type=Identity];
"228 bert/embeddings/LayerNorm/moments/SquaredDifference" [id=228, type=Sub];
"229 bert/embeddings/LayerNorm/moments/SquaredDifference__72" [id=229, type=Mul];
"230 bert/embeddings/LayerNorm/moments/variance" [id=230, type=ReduceMean];
"231 bert/embeddings/LayerNorm/batchnorm/add" [id=231, type=Add];
"232 bert/embeddings/LayerNorm/batchnorm/Rsqrt" [id=232, type=Sqrt];
"233 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" [id=233, type=Reciprocal];
"234 bert/embeddings/LayerNorm/batchnorm/mul" [id=234, type=Mul];
"235 bert/embeddings/LayerNorm/batchnorm/mul_2" [id=235, type=Mul];
"236 bert/embeddings/LayerNorm/batchnorm/sub" [id=236, type=Sub];
"237 bert/embeddings/LayerNorm/batchnorm/mul_1" [id=237, type=Mul];
"238 bert/embeddings/LayerNorm/batchnorm/add_1" [id=238, type=Add];
"239 bert/encoder/Shape_2" [id=239, type=Shape];
"240 bert/encoder/Shape_2__76" [id=240, type=Cast];
"241 bert/encoder/strided_slice_2" [id=241, type=Slice];
"242 bert/encoder/strided_slice_2__80" [id=242, type=Squeeze];
"243 bert/encoder/strided_slice_2__81" [id=243, type=Cast];
"244 bert/encoder/layer_9/attention/self/mul_2" [id=244, type=Mul];
"245 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" [id=245, type=Unsqueeze];
"246 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" [id=246, type=Concat];
"247 bert/encoder/layer_9/attention/self/Reshape_3__434" [id=247, type=Cast];
"248 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" [id=248, type=Unsqueeze];
"249 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [id=249, type=Concat];
"250 bert/encoder/layer_9/attention/self/Reshape_2__429" [id=250, type=Cast];
"251 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" [id=251, type=Unsqueeze];
"252 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [id=252, type=Concat];
"253 bert/encoder/layer_9/attention/self/Reshape_1__431" [id=253, type=Cast];
"254 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" [id=254, type=Unsqueeze];
"255 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [id=255, type=Concat];
"256 bert/encoder/layer_9/attention/self/Reshape__430" [id=256, type=Cast];
"257 bert/encoder/layer_8/attention/self/mul_2" [id=257, type=Mul];
"258 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" [id=258, type=Unsqueeze];
"259 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" [id=259, type=Concat];
"260 bert/encoder/layer_8/attention/self/Reshape_3__420" [id=260, type=Cast];
"261 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" [id=261, type=Unsqueeze];
"262 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [id=262, type=Concat];
"263 bert/encoder/layer_8/attention/self/Reshape_2__415" [id=263, type=Cast];
"264 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" [id=264, type=Unsqueeze];
"265 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [id=265, type=Concat];
"266 bert/encoder/layer_8/attention/self/Reshape_1__417" [id=266, type=Cast];
"267 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" [id=267, type=Unsqueeze];
"268 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [id=268, type=Concat];
"269 bert/encoder/layer_8/attention/self/Reshape__416" [id=269, type=Cast];
"270 bert/encoder/layer_7/attention/self/mul_2" [id=270, type=Mul];
"271 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" [id=271, type=Unsqueeze];
"272 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" [id=272, type=Concat];
"273 bert/encoder/layer_7/attention/self/Reshape_3__406" [id=273, type=Cast];
"274 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" [id=274, type=Unsqueeze];
"275 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [id=275, type=Concat];
"276 bert/encoder/layer_7/attention/self/Reshape_2__401" [id=276, type=Cast];
"277 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" [id=277, type=Unsqueeze];
"278 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [id=278, type=Concat];
"279 bert/encoder/layer_7/attention/self/Reshape_1__403" [id=279, type=Cast];
"280 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" [id=280, type=Unsqueeze];
"281 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [id=281, type=Concat];
"282 bert/encoder/layer_7/attention/self/Reshape__402" [id=282, type=Cast];
"283 bert/encoder/layer_6/attention/self/mul_2" [id=283, type=Mul];
"284 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" [id=284, type=Unsqueeze];
"285 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" [id=285, type=Concat];
"286 bert/encoder/layer_6/attention/self/Reshape_3__392" [id=286, type=Cast];
"287 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" [id=287, type=Unsqueeze];
"288 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [id=288, type=Concat];
"289 bert/encoder/layer_6/attention/self/Reshape_2__387" [id=289, type=Cast];
"290 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" [id=290, type=Unsqueeze];
"291 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [id=291, type=Concat];
"292 bert/encoder/layer_6/attention/self/Reshape_1__389" [id=292, type=Cast];
"293 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" [id=293, type=Unsqueeze];
"294 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [id=294, type=Concat];
"295 bert/encoder/layer_6/attention/self/Reshape__388" [id=295, type=Cast];
"296 bert/encoder/layer_5/attention/self/mul_2" [id=296, type=Mul];
"297 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" [id=297, type=Unsqueeze];
"298 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" [id=298, type=Concat];
"299 bert/encoder/layer_5/attention/self/Reshape_3__378" [id=299, type=Cast];
"300 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" [id=300, type=Unsqueeze];
"301 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [id=301, type=Concat];
"302 bert/encoder/layer_5/attention/self/Reshape_2__373" [id=302, type=Cast];
"303 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" [id=303, type=Unsqueeze];
"304 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [id=304, type=Concat];
"305 bert/encoder/layer_5/attention/self/Reshape_1__375" [id=305, type=Cast];
"306 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" [id=306, type=Unsqueeze];
"307 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [id=307, type=Concat];
"308 bert/encoder/layer_5/attention/self/Reshape__374" [id=308, type=Cast];
"309 bert/encoder/layer_4/attention/self/mul_2" [id=309, type=Mul];
"310 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" [id=310, type=Unsqueeze];
"311 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" [id=311, type=Concat];
"312 bert/encoder/layer_4/attention/self/Reshape_3__364" [id=312, type=Cast];
"313 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" [id=313, type=Unsqueeze];
"314 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [id=314, type=Concat];
"315 bert/encoder/layer_4/attention/self/Reshape_2__359" [id=315, type=Cast];
"316 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" [id=316, type=Unsqueeze];
"317 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [id=317, type=Concat];
"318 bert/encoder/layer_4/attention/self/Reshape_1__361" [id=318, type=Cast];
"319 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" [id=319, type=Unsqueeze];
"320 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [id=320, type=Concat];
"321 bert/encoder/layer_4/attention/self/Reshape__360" [id=321, type=Cast];
"322 bert/encoder/layer_3/attention/self/mul_2" [id=322, type=Mul];
"323 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" [id=323, type=Unsqueeze];
"324 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" [id=324, type=Concat];
"325 bert/encoder/layer_3/attention/self/Reshape_3__350" [id=325, type=Cast];
"326 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" [id=326, type=Unsqueeze];
"327 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [id=327, type=Concat];
"328 bert/encoder/layer_3/attention/self/Reshape_2__345" [id=328, type=Cast];
"329 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" [id=329, type=Unsqueeze];
"330 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [id=330, type=Concat];
"331 bert/encoder/layer_3/attention/self/Reshape_1__347" [id=331, type=Cast];
"332 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" [id=332, type=Unsqueeze];
"333 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [id=333, type=Concat];
"334 bert/encoder/layer_3/attention/self/Reshape__346" [id=334, type=Cast];
"335 bert/encoder/layer_2/attention/self/mul_2" [id=335, type=Mul];
"336 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" [id=336, type=Unsqueeze];
"337 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" [id=337, type=Concat];
"338 bert/encoder/layer_2/attention/self/Reshape_3__336" [id=338, type=Cast];
"339 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" [id=339, type=Unsqueeze];
"340 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [id=340, type=Concat];
"341 bert/encoder/layer_2/attention/self/Reshape_2__331" [id=341, type=Cast];
"342 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" [id=342, type=Unsqueeze];
"343 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [id=343, type=Concat];
"344 bert/encoder/layer_2/attention/self/Reshape_1__333" [id=344, type=Cast];
"345 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" [id=345, type=Unsqueeze];
"346 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [id=346, type=Concat];
"347 bert/encoder/layer_2/attention/self/Reshape__332" [id=347, type=Cast];
"348 bert/encoder/layer_11/attention/self/mul_2" [id=348, type=Mul];
"349 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" [id=349, type=Unsqueeze];
"350 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" [id=350, type=Concat];
"351 bert/encoder/layer_11/attention/self/Reshape_3__462" [id=351, type=Cast];
"352 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" [id=352, type=Unsqueeze];
"353 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [id=353, type=Concat];
"354 bert/encoder/layer_11/attention/self/Reshape_2__457" [id=354, type=Cast];
"355 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" [id=355, type=Unsqueeze];
"356 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [id=356, type=Concat];
"357 bert/encoder/layer_11/attention/self/Reshape_1__459" [id=357, type=Cast];
"358 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" [id=358, type=Unsqueeze];
"359 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [id=359, type=Concat];
"360 bert/encoder/layer_11/attention/self/Reshape__458" [id=360, type=Cast];
"361 bert/encoder/layer_10/attention/self/mul_2" [id=361, type=Mul];
"362 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" [id=362, type=Unsqueeze];
"363 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" [id=363, type=Concat];
"364 bert/encoder/layer_10/attention/self/Reshape_3__448" [id=364, type=Cast];
"365 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" [id=365, type=Unsqueeze];
"366 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [id=366, type=Concat];
"367 bert/encoder/layer_10/attention/self/Reshape_2__443" [id=367, type=Cast];
"368 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" [id=368, type=Unsqueeze];
"369 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [id=369, type=Concat];
"370 bert/encoder/layer_10/attention/self/Reshape_1__445" [id=370, type=Cast];
"371 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" [id=371, type=Unsqueeze];
"372 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [id=372, type=Concat];
"373 bert/encoder/layer_10/attention/self/Reshape__444" [id=373, type=Cast];
"374 bert/encoder/layer_1/attention/self/mul_2" [id=374, type=Mul];
"375 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" [id=375, type=Unsqueeze];
"376 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" [id=376, type=Concat];
"377 bert/encoder/layer_1/attention/self/Reshape_3__322" [id=377, type=Cast];
"378 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" [id=378, type=Unsqueeze];
"379 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [id=379, type=Concat];
"380 bert/encoder/layer_1/attention/self/Reshape_2__317" [id=380, type=Cast];
"381 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" [id=381, type=Unsqueeze];
"382 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [id=382, type=Concat];
"383 bert/encoder/layer_1/attention/self/Reshape_1__319" [id=383, type=Cast];
"384 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" [id=384, type=Unsqueeze];
"385 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [id=385, type=Concat];
"386 bert/encoder/layer_1/attention/self/Reshape__318" [id=386, type=Cast];
"387 bert/encoder/layer_0/attention/self/mul_2" [id=387, type=Mul];
"388 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" [id=388, type=Unsqueeze];
"389 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" [id=389, type=Concat];
"390 bert/encoder/layer_0/attention/self/Reshape_3__308" [id=390, type=Cast];
"391 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" [id=391, type=Unsqueeze];
"392 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [id=392, type=Concat];
"393 bert/encoder/layer_0/attention/self/Reshape_2__303" [id=393, type=Cast];
"394 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" [id=394, type=Unsqueeze];
"395 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [id=395, type=Concat];
"396 bert/encoder/layer_0/attention/self/Reshape_1__305" [id=396, type=Cast];
"397 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" [id=397, type=Unsqueeze];
"398 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [id=398, type=Concat];
"399 bert/encoder/layer_0/attention/self/Reshape__304" [id=399, type=Cast];
"400 bert/encoder/Reshape_13/shape_Unsqueeze__298" [id=400, type=Unsqueeze];
"401 bert/encoder/Reshape_13/shape_Concat__301" [id=401, type=Concat];
"402 bert/encoder/Reshape_13__471" [id=402, type=Cast];
"403 bert/encoder/Reshape_1" [id=403, type=Reshape];
"404 QuantizeLinear_bert/encoder/Reshape_1^0_3" [id=404, label="404 QuantizeLinear_bert/encoder/Reshape_1:0_3", type=QuantizeLinear];
"405 DequantizeLinear_bert/encoder/Reshape_1^0_3" [id=405, label="405 DequantizeLinear_bert/encoder/Reshape_1:0_3", type=DequantizeLinear];
"406 QuantizeLinear_bert/encoder/Reshape_1^0_2" [id=406, label="406 QuantizeLinear_bert/encoder/Reshape_1:0_2", type=QuantizeLinear];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_2" [id=407, label="407 DequantizeLinear_bert/encoder/Reshape_1:0_2", type=DequantizeLinear];
"408 QuantizeLinear_bert/encoder/Reshape_1^0_1" [id=408, label="408 QuantizeLinear_bert/encoder/Reshape_1:0_1", type=QuantizeLinear];
"409 DequantizeLinear_bert/encoder/Reshape_1^0_1" [id=409, label="409 DequantizeLinear_bert/encoder/Reshape_1:0_1", type=DequantizeLinear];
"410 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=410, label="410 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1", type=QuantizeLinear];
"411 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=411, label="411 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1", type=DequantizeLinear];
"412 bert/encoder/layer_0/attention/self/value/MatMul" [id=412, type=MatMul];
"413 bert/encoder/layer_0/attention/self/value/BiasAdd" [id=413, type=Add];
"414 bert/encoder/layer_0/attention/self/Reshape_2" [id=414, type=Reshape];
"415 bert/encoder/layer_0/attention/self/transpose_2" [id=415, type=Transpose];
"416 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=416, label="416 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1", type=QuantizeLinear];
"417 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=417, label="417 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1", type=DequantizeLinear];
"418 bert/encoder/layer_0/attention/self/query/MatMul" [id=418, type=MatMul];
"419 bert/encoder/layer_0/attention/self/query/BiasAdd" [id=419, type=Add];
"420 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=420, label="420 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"421 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=421, label="421 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"422 bert/encoder/layer_0/attention/self/Reshape" [id=422, type=Reshape];
"423 bert/encoder/layer_0/attention/self/transpose" [id=423, type=Transpose];
"424 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=424, label="424 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1", type=QuantizeLinear];
"425 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=425, label="425 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1", type=DequantizeLinear];
"426 bert/encoder/layer_0/attention/self/key/MatMul" [id=426, type=MatMul];
"427 bert/encoder/layer_0/attention/self/key/BiasAdd" [id=427, type=Add];
"428 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=428, label="428 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"429 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=429, label="429 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"430 bert/encoder/layer_0/attention/self/Reshape_1" [id=430, type=Reshape];
"431 bert/encoder/layer_0/attention/self/transpose_1" [id=431, type=Transpose];
"432 bert/encoder/layer_0/attention/self/MatMul__306" [id=432, type=Transpose];
"433 bert/encoder/layer_0/attention/self/MatMul" [id=433, type=MatMul];
"434 bert/encoder/layer_0/attention/self/Mul" [id=434, type=Mul];
"435 bert/encoder/layer_0/attention/self/add" [id=435, type=Add];
"436 bert/encoder/layer_0/attention/self/Softmax" [id=436, type=Softmax];
"437 bert/encoder/layer_0/attention/self/MatMul_1" [id=437, type=MatMul];
"438 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=438, label="438 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"439 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=439, label="439 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"440 bert/encoder/layer_0/attention/self/transpose_3" [id=440, type=Transpose];
"441 bert/encoder/layer_0/attention/self/Reshape_3" [id=441, type=Reshape];
"442 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=442, label="442 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"443 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=443, label="443 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"444 bert/encoder/layer_0/attention/output/dense/MatMul" [id=444, type=MatMul];
"445 bert/encoder/layer_0/attention/output/dense/BiasAdd" [id=445, type=Add];
"446 bert/encoder/layer_0/attention/output/add" [id=446, type=Add];
"447 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" [id=447, type=ReduceMean];
"448 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" [id=448, type=Identity];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" [id=449, type=Sub];
"450 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" [id=450, type=Mul];
"451 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" [id=451, type=ReduceMean];
"452 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" [id=452, type=Add];
"453 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" [id=453, type=Sqrt];
"454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" [id=454, type=Reciprocal];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" [id=455, type=Mul];
"456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" [id=456, type=Mul];
"457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" [id=457, type=Sub];
"458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" [id=458, type=Mul];
"459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" [id=459, type=Add];
"460 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=460, label="460 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"461 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=461, label="461 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"462 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=462, label="462 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"463 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=463, label="463 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"464 bert/encoder/layer_0/intermediate/dense/MatMul" [id=464, type=MatMul];
"465 bert/encoder/layer_0/intermediate/dense/BiasAdd" [id=465, type=Add];
"466 bert/encoder/layer_0/intermediate/dense/Pow" [id=466, type=Pow];
"467 bert/encoder/layer_0/intermediate/dense/mul" [id=467, type=Mul];
"468 bert/encoder/layer_0/intermediate/dense/add" [id=468, type=Add];
"469 bert/encoder/layer_0/intermediate/dense/mul_1" [id=469, type=Mul];
"470 bert/encoder/layer_0/intermediate/dense/Tanh" [id=470, type=Tanh];
"471 bert/encoder/layer_0/intermediate/dense/add_1" [id=471, type=Add];
"472 bert/encoder/layer_0/intermediate/dense/mul_2" [id=472, type=Mul];
"473 bert/encoder/layer_0/intermediate/dense/mul_3" [id=473, type=Mul];
"474 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=474, label="474 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"475 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=475, label="475 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"476 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=476, label="476 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1", type=QuantizeLinear];
"477 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=477, label="477 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1", type=DequantizeLinear];
"478 bert/encoder/layer_0/output/dense/MatMul" [id=478, type=MatMul];
"479 bert/encoder/layer_0/output/dense/BiasAdd" [id=479, type=Add];
"480 bert/encoder/layer_0/output/add" [id=480, type=Add];
"481 bert/encoder/layer_0/output/LayerNorm/moments/mean" [id=481, type=ReduceMean];
"482 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" [id=482, type=Identity];
"483 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" [id=483, type=Sub];
"484 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" [id=484, type=Mul];
"485 bert/encoder/layer_0/output/LayerNorm/moments/variance" [id=485, type=ReduceMean];
"486 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" [id=486, type=Add];
"487 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" [id=487, type=Sqrt];
"488 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" [id=488, type=Reciprocal];
"489 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" [id=489, type=Mul];
"490 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" [id=490, type=Mul];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" [id=491, type=Sub];
"492 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" [id=492, type=Mul];
"493 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" [id=493, type=Add];
"494 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=494, label="494 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"495 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=495, label="495 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=496, label="496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=497, label="497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"498 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=498, label="498 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"499 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=499, label="499 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"500 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=500, label="500 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1", type=QuantizeLinear];
"501 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=501, label="501 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1", type=DequantizeLinear];
"502 bert/encoder/layer_1/attention/self/value/MatMul" [id=502, type=MatMul];
"503 bert/encoder/layer_1/attention/self/value/BiasAdd" [id=503, type=Add];
"504 bert/encoder/layer_1/attention/self/Reshape_2" [id=504, type=Reshape];
"505 bert/encoder/layer_1/attention/self/transpose_2" [id=505, type=Transpose];
"506 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=506, label="506 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1", type=QuantizeLinear];
"507 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=507, label="507 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1", type=DequantizeLinear];
"508 bert/encoder/layer_1/attention/self/query/MatMul" [id=508, type=MatMul];
"509 bert/encoder/layer_1/attention/self/query/BiasAdd" [id=509, type=Add];
"510 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=510, label="510 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"511 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=511, label="511 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"512 bert/encoder/layer_1/attention/self/Reshape" [id=512, type=Reshape];
"513 bert/encoder/layer_1/attention/self/transpose" [id=513, type=Transpose];
"514 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=514, label="514 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1", type=QuantizeLinear];
"515 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=515, label="515 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1", type=DequantizeLinear];
"516 bert/encoder/layer_1/attention/self/key/MatMul" [id=516, type=MatMul];
"517 bert/encoder/layer_1/attention/self/key/BiasAdd" [id=517, type=Add];
"518 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=518, label="518 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"519 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=519, label="519 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"520 bert/encoder/layer_1/attention/self/Reshape_1" [id=520, type=Reshape];
"521 bert/encoder/layer_1/attention/self/transpose_1" [id=521, type=Transpose];
"522 bert/encoder/layer_1/attention/self/MatMul__320" [id=522, type=Transpose];
"523 bert/encoder/layer_1/attention/self/MatMul" [id=523, type=MatMul];
"524 bert/encoder/layer_1/attention/self/Mul" [id=524, type=Mul];
"525 bert/encoder/layer_1/attention/self/add" [id=525, type=Add];
"526 bert/encoder/layer_1/attention/self/Softmax" [id=526, type=Softmax];
"527 bert/encoder/layer_1/attention/self/MatMul_1" [id=527, type=MatMul];
"528 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=528, label="528 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"529 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=529, label="529 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"530 bert/encoder/layer_1/attention/self/transpose_3" [id=530, type=Transpose];
"531 bert/encoder/layer_1/attention/self/Reshape_3" [id=531, type=Reshape];
"532 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=532, label="532 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"533 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=533, label="533 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"534 bert/encoder/layer_1/attention/output/dense/MatMul" [id=534, type=MatMul];
"535 bert/encoder/layer_1/attention/output/dense/BiasAdd" [id=535, type=Add];
"536 bert/encoder/layer_1/attention/output/add" [id=536, type=Add];
"537 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" [id=537, type=ReduceMean];
"538 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" [id=538, type=Identity];
"539 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" [id=539, type=Sub];
"540 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" [id=540, type=Mul];
"541 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" [id=541, type=ReduceMean];
"542 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" [id=542, type=Add];
"543 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" [id=543, type=Sqrt];
"544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" [id=544, type=Reciprocal];
"545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" [id=545, type=Mul];
"546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" [id=546, type=Mul];
"547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" [id=547, type=Sub];
"548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" [id=548, type=Mul];
"549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" [id=549, type=Add];
"550 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=550, label="550 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"551 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=551, label="551 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"552 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=552, label="552 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"553 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=553, label="553 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"554 bert/encoder/layer_1/intermediate/dense/MatMul" [id=554, type=MatMul];
"555 bert/encoder/layer_1/intermediate/dense/BiasAdd" [id=555, type=Add];
"556 bert/encoder/layer_1/intermediate/dense/Pow" [id=556, type=Pow];
"557 bert/encoder/layer_1/intermediate/dense/mul" [id=557, type=Mul];
"558 bert/encoder/layer_1/intermediate/dense/add" [id=558, type=Add];
"559 bert/encoder/layer_1/intermediate/dense/mul_1" [id=559, type=Mul];
"560 bert/encoder/layer_1/intermediate/dense/Tanh" [id=560, type=Tanh];
"561 bert/encoder/layer_1/intermediate/dense/add_1" [id=561, type=Add];
"562 bert/encoder/layer_1/intermediate/dense/mul_2" [id=562, type=Mul];
"563 bert/encoder/layer_1/intermediate/dense/mul_3" [id=563, type=Mul];
"564 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=564, label="564 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"565 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=565, label="565 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"566 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=566, label="566 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1", type=QuantizeLinear];
"567 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=567, label="567 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1", type=DequantizeLinear];
"568 bert/encoder/layer_1/output/dense/MatMul" [id=568, type=MatMul];
"569 bert/encoder/layer_1/output/dense/BiasAdd" [id=569, type=Add];
"570 bert/encoder/layer_1/output/add" [id=570, type=Add];
"571 bert/encoder/layer_1/output/LayerNorm/moments/mean" [id=571, type=ReduceMean];
"572 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" [id=572, type=Identity];
"573 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" [id=573, type=Sub];
"574 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" [id=574, type=Mul];
"575 bert/encoder/layer_1/output/LayerNorm/moments/variance" [id=575, type=ReduceMean];
"576 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" [id=576, type=Add];
"577 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" [id=577, type=Sqrt];
"578 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" [id=578, type=Reciprocal];
"579 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" [id=579, type=Mul];
"580 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" [id=580, type=Mul];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" [id=581, type=Sub];
"582 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" [id=582, type=Mul];
"583 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" [id=583, type=Add];
"584 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=584, label="584 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"585 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=585, label="585 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=586, label="586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=587, label="587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"588 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=588, label="588 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"589 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=589, label="589 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"590 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=590, label="590 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1", type=QuantizeLinear];
"591 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=591, label="591 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1", type=DequantizeLinear];
"592 bert/encoder/layer_2/attention/self/value/MatMul" [id=592, type=MatMul];
"593 bert/encoder/layer_2/attention/self/value/BiasAdd" [id=593, type=Add];
"594 bert/encoder/layer_2/attention/self/Reshape_2" [id=594, type=Reshape];
"595 bert/encoder/layer_2/attention/self/transpose_2" [id=595, type=Transpose];
"596 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=596, label="596 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1", type=QuantizeLinear];
"597 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=597, label="597 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1", type=DequantizeLinear];
"598 bert/encoder/layer_2/attention/self/query/MatMul" [id=598, type=MatMul];
"599 bert/encoder/layer_2/attention/self/query/BiasAdd" [id=599, type=Add];
"600 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=600, label="600 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"601 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=601, label="601 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"602 bert/encoder/layer_2/attention/self/Reshape" [id=602, type=Reshape];
"603 bert/encoder/layer_2/attention/self/transpose" [id=603, type=Transpose];
"604 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=604, label="604 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1", type=QuantizeLinear];
"605 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=605, label="605 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1", type=DequantizeLinear];
"606 bert/encoder/layer_2/attention/self/key/MatMul" [id=606, type=MatMul];
"607 bert/encoder/layer_2/attention/self/key/BiasAdd" [id=607, type=Add];
"608 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=608, label="608 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"609 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=609, label="609 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"610 bert/encoder/layer_2/attention/self/Reshape_1" [id=610, type=Reshape];
"611 bert/encoder/layer_2/attention/self/transpose_1" [id=611, type=Transpose];
"612 bert/encoder/layer_2/attention/self/MatMul__334" [id=612, type=Transpose];
"613 bert/encoder/layer_2/attention/self/MatMul" [id=613, type=MatMul];
"614 bert/encoder/layer_2/attention/self/Mul" [id=614, type=Mul];
"615 bert/encoder/layer_2/attention/self/add" [id=615, type=Add];
"616 bert/encoder/layer_2/attention/self/Softmax" [id=616, type=Softmax];
"617 bert/encoder/layer_2/attention/self/MatMul_1" [id=617, type=MatMul];
"618 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=618, label="618 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"619 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=619, label="619 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"620 bert/encoder/layer_2/attention/self/transpose_3" [id=620, type=Transpose];
"621 bert/encoder/layer_2/attention/self/Reshape_3" [id=621, type=Reshape];
"622 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=622, label="622 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"623 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=623, label="623 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"624 bert/encoder/layer_2/attention/output/dense/MatMul" [id=624, type=MatMul];
"625 bert/encoder/layer_2/attention/output/dense/BiasAdd" [id=625, type=Add];
"626 bert/encoder/layer_2/attention/output/add" [id=626, type=Add];
"627 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" [id=627, type=ReduceMean];
"628 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" [id=628, type=Identity];
"629 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" [id=629, type=Sub];
"630 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" [id=630, type=Mul];
"631 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" [id=631, type=ReduceMean];
"632 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" [id=632, type=Add];
"633 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" [id=633, type=Sqrt];
"634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" [id=634, type=Reciprocal];
"635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" [id=635, type=Mul];
"636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" [id=636, type=Mul];
"637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" [id=637, type=Sub];
"638 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" [id=638, type=Mul];
"639 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" [id=639, type=Add];
"640 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=640, label="640 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"641 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=641, label="641 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"642 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=642, label="642 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"643 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=643, label="643 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"644 bert/encoder/layer_2/intermediate/dense/MatMul" [id=644, type=MatMul];
"645 bert/encoder/layer_2/intermediate/dense/BiasAdd" [id=645, type=Add];
"646 bert/encoder/layer_2/intermediate/dense/Pow" [id=646, type=Pow];
"647 bert/encoder/layer_2/intermediate/dense/mul" [id=647, type=Mul];
"648 bert/encoder/layer_2/intermediate/dense/add" [id=648, type=Add];
"649 bert/encoder/layer_2/intermediate/dense/mul_1" [id=649, type=Mul];
"650 bert/encoder/layer_2/intermediate/dense/Tanh" [id=650, type=Tanh];
"651 bert/encoder/layer_2/intermediate/dense/add_1" [id=651, type=Add];
"652 bert/encoder/layer_2/intermediate/dense/mul_2" [id=652, type=Mul];
"653 bert/encoder/layer_2/intermediate/dense/mul_3" [id=653, type=Mul];
"654 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=654, label="654 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"655 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=655, label="655 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"656 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=656, label="656 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1", type=QuantizeLinear];
"657 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=657, label="657 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1", type=DequantizeLinear];
"658 bert/encoder/layer_2/output/dense/MatMul" [id=658, type=MatMul];
"659 bert/encoder/layer_2/output/dense/BiasAdd" [id=659, type=Add];
"660 bert/encoder/layer_2/output/add" [id=660, type=Add];
"661 bert/encoder/layer_2/output/LayerNorm/moments/mean" [id=661, type=ReduceMean];
"662 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" [id=662, type=Identity];
"663 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" [id=663, type=Sub];
"664 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" [id=664, type=Mul];
"665 bert/encoder/layer_2/output/LayerNorm/moments/variance" [id=665, type=ReduceMean];
"666 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" [id=666, type=Add];
"667 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" [id=667, type=Sqrt];
"668 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" [id=668, type=Reciprocal];
"669 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" [id=669, type=Mul];
"670 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" [id=670, type=Mul];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" [id=671, type=Sub];
"672 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" [id=672, type=Mul];
"673 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" [id=673, type=Add];
"674 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=674, label="674 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"675 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=675, label="675 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=676, label="676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=677, label="677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"678 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=678, label="678 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"679 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=679, label="679 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"680 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=680, label="680 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1", type=QuantizeLinear];
"681 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=681, label="681 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1", type=DequantizeLinear];
"682 bert/encoder/layer_3/attention/self/value/MatMul" [id=682, type=MatMul];
"683 bert/encoder/layer_3/attention/self/value/BiasAdd" [id=683, type=Add];
"684 bert/encoder/layer_3/attention/self/Reshape_2" [id=684, type=Reshape];
"685 bert/encoder/layer_3/attention/self/transpose_2" [id=685, type=Transpose];
"686 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=686, label="686 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1", type=QuantizeLinear];
"687 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=687, label="687 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1", type=DequantizeLinear];
"688 bert/encoder/layer_3/attention/self/query/MatMul" [id=688, type=MatMul];
"689 bert/encoder/layer_3/attention/self/query/BiasAdd" [id=689, type=Add];
"690 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=690, label="690 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"691 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=691, label="691 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"692 bert/encoder/layer_3/attention/self/Reshape" [id=692, type=Reshape];
"693 bert/encoder/layer_3/attention/self/transpose" [id=693, type=Transpose];
"694 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=694, label="694 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1", type=QuantizeLinear];
"695 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=695, label="695 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1", type=DequantizeLinear];
"696 bert/encoder/layer_3/attention/self/key/MatMul" [id=696, type=MatMul];
"697 bert/encoder/layer_3/attention/self/key/BiasAdd" [id=697, type=Add];
"698 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=698, label="698 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"699 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=699, label="699 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"700 bert/encoder/layer_3/attention/self/Reshape_1" [id=700, type=Reshape];
"701 bert/encoder/layer_3/attention/self/transpose_1" [id=701, type=Transpose];
"702 bert/encoder/layer_3/attention/self/MatMul__348" [id=702, type=Transpose];
"703 bert/encoder/layer_3/attention/self/MatMul" [id=703, type=MatMul];
"704 bert/encoder/layer_3/attention/self/Mul" [id=704, type=Mul];
"705 bert/encoder/layer_3/attention/self/add" [id=705, type=Add];
"706 bert/encoder/layer_3/attention/self/Softmax" [id=706, type=Softmax];
"707 bert/encoder/layer_3/attention/self/MatMul_1" [id=707, type=MatMul];
"708 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=708, label="708 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"709 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=709, label="709 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"710 bert/encoder/layer_3/attention/self/transpose_3" [id=710, type=Transpose];
"711 bert/encoder/layer_3/attention/self/Reshape_3" [id=711, type=Reshape];
"712 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=712, label="712 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"713 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=713, label="713 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"714 bert/encoder/layer_3/attention/output/dense/MatMul" [id=714, type=MatMul];
"715 bert/encoder/layer_3/attention/output/dense/BiasAdd" [id=715, type=Add];
"716 bert/encoder/layer_3/attention/output/add" [id=716, type=Add];
"717 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" [id=717, type=ReduceMean];
"718 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" [id=718, type=Identity];
"719 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" [id=719, type=Sub];
"720 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" [id=720, type=Mul];
"721 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" [id=721, type=ReduceMean];
"722 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" [id=722, type=Add];
"723 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" [id=723, type=Sqrt];
"724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" [id=724, type=Reciprocal];
"725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" [id=725, type=Mul];
"726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" [id=726, type=Mul];
"727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" [id=727, type=Sub];
"728 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" [id=728, type=Mul];
"729 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" [id=729, type=Add];
"730 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=730, label="730 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"731 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=731, label="731 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"732 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=732, label="732 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"733 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=733, label="733 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"734 bert/encoder/layer_3/intermediate/dense/MatMul" [id=734, type=MatMul];
"735 bert/encoder/layer_3/intermediate/dense/BiasAdd" [id=735, type=Add];
"736 bert/encoder/layer_3/intermediate/dense/Pow" [id=736, type=Pow];
"737 bert/encoder/layer_3/intermediate/dense/mul" [id=737, type=Mul];
"738 bert/encoder/layer_3/intermediate/dense/add" [id=738, type=Add];
"739 bert/encoder/layer_3/intermediate/dense/mul_1" [id=739, type=Mul];
"740 bert/encoder/layer_3/intermediate/dense/Tanh" [id=740, type=Tanh];
"741 bert/encoder/layer_3/intermediate/dense/add_1" [id=741, type=Add];
"742 bert/encoder/layer_3/intermediate/dense/mul_2" [id=742, type=Mul];
"743 bert/encoder/layer_3/intermediate/dense/mul_3" [id=743, type=Mul];
"744 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=744, label="744 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"745 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=745, label="745 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"746 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=746, label="746 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1", type=QuantizeLinear];
"747 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=747, label="747 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1", type=DequantizeLinear];
"748 bert/encoder/layer_3/output/dense/MatMul" [id=748, type=MatMul];
"749 bert/encoder/layer_3/output/dense/BiasAdd" [id=749, type=Add];
"750 bert/encoder/layer_3/output/add" [id=750, type=Add];
"751 bert/encoder/layer_3/output/LayerNorm/moments/mean" [id=751, type=ReduceMean];
"752 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" [id=752, type=Identity];
"753 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" [id=753, type=Sub];
"754 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" [id=754, type=Mul];
"755 bert/encoder/layer_3/output/LayerNorm/moments/variance" [id=755, type=ReduceMean];
"756 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" [id=756, type=Add];
"757 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" [id=757, type=Sqrt];
"758 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" [id=758, type=Reciprocal];
"759 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" [id=759, type=Mul];
"760 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" [id=760, type=Mul];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" [id=761, type=Sub];
"762 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" [id=762, type=Mul];
"763 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" [id=763, type=Add];
"764 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=764, label="764 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"765 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=765, label="765 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=766, label="766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=767, label="767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"768 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=768, label="768 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"769 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=769, label="769 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"770 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=770, label="770 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1", type=QuantizeLinear];
"771 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=771, label="771 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1", type=DequantizeLinear];
"772 bert/encoder/layer_4/attention/self/value/MatMul" [id=772, type=MatMul];
"773 bert/encoder/layer_4/attention/self/value/BiasAdd" [id=773, type=Add];
"774 bert/encoder/layer_4/attention/self/Reshape_2" [id=774, type=Reshape];
"775 bert/encoder/layer_4/attention/self/transpose_2" [id=775, type=Transpose];
"776 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=776, label="776 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1", type=QuantizeLinear];
"777 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=777, label="777 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1", type=DequantizeLinear];
"778 bert/encoder/layer_4/attention/self/query/MatMul" [id=778, type=MatMul];
"779 bert/encoder/layer_4/attention/self/query/BiasAdd" [id=779, type=Add];
"780 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=780, label="780 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"781 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=781, label="781 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"782 bert/encoder/layer_4/attention/self/Reshape" [id=782, type=Reshape];
"783 bert/encoder/layer_4/attention/self/transpose" [id=783, type=Transpose];
"784 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=784, label="784 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1", type=QuantizeLinear];
"785 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=785, label="785 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1", type=DequantizeLinear];
"786 bert/encoder/layer_4/attention/self/key/MatMul" [id=786, type=MatMul];
"787 bert/encoder/layer_4/attention/self/key/BiasAdd" [id=787, type=Add];
"788 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=788, label="788 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"789 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=789, label="789 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"790 bert/encoder/layer_4/attention/self/Reshape_1" [id=790, type=Reshape];
"791 bert/encoder/layer_4/attention/self/transpose_1" [id=791, type=Transpose];
"792 bert/encoder/layer_4/attention/self/MatMul__362" [id=792, type=Transpose];
"793 bert/encoder/layer_4/attention/self/MatMul" [id=793, type=MatMul];
"794 bert/encoder/layer_4/attention/self/Mul" [id=794, type=Mul];
"795 bert/encoder/layer_4/attention/self/add" [id=795, type=Add];
"796 bert/encoder/layer_4/attention/self/Softmax" [id=796, type=Softmax];
"797 bert/encoder/layer_4/attention/self/MatMul_1" [id=797, type=MatMul];
"798 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=798, label="798 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"799 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=799, label="799 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"800 bert/encoder/layer_4/attention/self/transpose_3" [id=800, type=Transpose];
"801 bert/encoder/layer_4/attention/self/Reshape_3" [id=801, type=Reshape];
"802 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=802, label="802 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"803 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=803, label="803 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"804 bert/encoder/layer_4/attention/output/dense/MatMul" [id=804, type=MatMul];
"805 bert/encoder/layer_4/attention/output/dense/BiasAdd" [id=805, type=Add];
"806 bert/encoder/layer_4/attention/output/add" [id=806, type=Add];
"807 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" [id=807, type=ReduceMean];
"808 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" [id=808, type=Identity];
"809 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" [id=809, type=Sub];
"810 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" [id=810, type=Mul];
"811 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" [id=811, type=ReduceMean];
"812 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" [id=812, type=Add];
"813 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" [id=813, type=Sqrt];
"814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" [id=814, type=Reciprocal];
"815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" [id=815, type=Mul];
"816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" [id=816, type=Mul];
"817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" [id=817, type=Sub];
"818 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" [id=818, type=Mul];
"819 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" [id=819, type=Add];
"820 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=820, label="820 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"821 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=821, label="821 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"822 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=822, label="822 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"823 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=823, label="823 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"824 bert/encoder/layer_4/intermediate/dense/MatMul" [id=824, type=MatMul];
"825 bert/encoder/layer_4/intermediate/dense/BiasAdd" [id=825, type=Add];
"826 bert/encoder/layer_4/intermediate/dense/Pow" [id=826, type=Pow];
"827 bert/encoder/layer_4/intermediate/dense/mul" [id=827, type=Mul];
"828 bert/encoder/layer_4/intermediate/dense/add" [id=828, type=Add];
"829 bert/encoder/layer_4/intermediate/dense/mul_1" [id=829, type=Mul];
"830 bert/encoder/layer_4/intermediate/dense/Tanh" [id=830, type=Tanh];
"831 bert/encoder/layer_4/intermediate/dense/add_1" [id=831, type=Add];
"832 bert/encoder/layer_4/intermediate/dense/mul_2" [id=832, type=Mul];
"833 bert/encoder/layer_4/intermediate/dense/mul_3" [id=833, type=Mul];
"834 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=834, label="834 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"835 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=835, label="835 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"836 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=836, label="836 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1", type=QuantizeLinear];
"837 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=837, label="837 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1", type=DequantizeLinear];
"838 bert/encoder/layer_4/output/dense/MatMul" [id=838, type=MatMul];
"839 bert/encoder/layer_4/output/dense/BiasAdd" [id=839, type=Add];
"840 bert/encoder/layer_4/output/add" [id=840, type=Add];
"841 bert/encoder/layer_4/output/LayerNorm/moments/mean" [id=841, type=ReduceMean];
"842 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" [id=842, type=Identity];
"843 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" [id=843, type=Sub];
"844 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" [id=844, type=Mul];
"845 bert/encoder/layer_4/output/LayerNorm/moments/variance" [id=845, type=ReduceMean];
"846 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" [id=846, type=Add];
"847 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" [id=847, type=Sqrt];
"848 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" [id=848, type=Reciprocal];
"849 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" [id=849, type=Mul];
"850 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" [id=850, type=Mul];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" [id=851, type=Sub];
"852 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" [id=852, type=Mul];
"853 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" [id=853, type=Add];
"854 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=854, label="854 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"855 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=855, label="855 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=856, label="856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=857, label="857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"858 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=858, label="858 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"859 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=859, label="859 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"860 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=860, label="860 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1", type=QuantizeLinear];
"861 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=861, label="861 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1", type=DequantizeLinear];
"862 bert/encoder/layer_5/attention/self/value/MatMul" [id=862, type=MatMul];
"863 bert/encoder/layer_5/attention/self/value/BiasAdd" [id=863, type=Add];
"864 bert/encoder/layer_5/attention/self/Reshape_2" [id=864, type=Reshape];
"865 bert/encoder/layer_5/attention/self/transpose_2" [id=865, type=Transpose];
"866 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=866, label="866 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1", type=QuantizeLinear];
"867 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=867, label="867 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1", type=DequantizeLinear];
"868 bert/encoder/layer_5/attention/self/query/MatMul" [id=868, type=MatMul];
"869 bert/encoder/layer_5/attention/self/query/BiasAdd" [id=869, type=Add];
"870 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=870, label="870 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"871 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=871, label="871 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"872 bert/encoder/layer_5/attention/self/Reshape" [id=872, type=Reshape];
"873 bert/encoder/layer_5/attention/self/transpose" [id=873, type=Transpose];
"874 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=874, label="874 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1", type=QuantizeLinear];
"875 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=875, label="875 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1", type=DequantizeLinear];
"876 bert/encoder/layer_5/attention/self/key/MatMul" [id=876, type=MatMul];
"877 bert/encoder/layer_5/attention/self/key/BiasAdd" [id=877, type=Add];
"878 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=878, label="878 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"879 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=879, label="879 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"880 bert/encoder/layer_5/attention/self/Reshape_1" [id=880, type=Reshape];
"881 bert/encoder/layer_5/attention/self/transpose_1" [id=881, type=Transpose];
"882 bert/encoder/layer_5/attention/self/MatMul__376" [id=882, type=Transpose];
"883 bert/encoder/layer_5/attention/self/MatMul" [id=883, type=MatMul];
"884 bert/encoder/layer_5/attention/self/Mul" [id=884, type=Mul];
"885 bert/encoder/layer_5/attention/self/add" [id=885, type=Add];
"886 bert/encoder/layer_5/attention/self/Softmax" [id=886, type=Softmax];
"887 bert/encoder/layer_5/attention/self/MatMul_1" [id=887, type=MatMul];
"888 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=888, label="888 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"889 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=889, label="889 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"890 bert/encoder/layer_5/attention/self/transpose_3" [id=890, type=Transpose];
"891 bert/encoder/layer_5/attention/self/Reshape_3" [id=891, type=Reshape];
"892 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=892, label="892 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"893 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=893, label="893 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"894 bert/encoder/layer_5/attention/output/dense/MatMul" [id=894, type=MatMul];
"895 bert/encoder/layer_5/attention/output/dense/BiasAdd" [id=895, type=Add];
"896 bert/encoder/layer_5/attention/output/add" [id=896, type=Add];
"897 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" [id=897, type=ReduceMean];
"898 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" [id=898, type=Identity];
"899 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" [id=899, type=Sub];
"900 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" [id=900, type=Mul];
"901 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" [id=901, type=ReduceMean];
"902 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" [id=902, type=Add];
"903 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" [id=903, type=Sqrt];
"904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" [id=904, type=Reciprocal];
"905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" [id=905, type=Mul];
"906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" [id=906, type=Mul];
"907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" [id=907, type=Sub];
"908 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" [id=908, type=Mul];
"909 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" [id=909, type=Add];
"910 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=910, label="910 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"911 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=911, label="911 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"912 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=912, label="912 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"913 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=913, label="913 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"914 bert/encoder/layer_5/intermediate/dense/MatMul" [id=914, type=MatMul];
"915 bert/encoder/layer_5/intermediate/dense/BiasAdd" [id=915, type=Add];
"916 bert/encoder/layer_5/intermediate/dense/Pow" [id=916, type=Pow];
"917 bert/encoder/layer_5/intermediate/dense/mul" [id=917, type=Mul];
"918 bert/encoder/layer_5/intermediate/dense/add" [id=918, type=Add];
"919 bert/encoder/layer_5/intermediate/dense/mul_1" [id=919, type=Mul];
"920 bert/encoder/layer_5/intermediate/dense/Tanh" [id=920, type=Tanh];
"921 bert/encoder/layer_5/intermediate/dense/add_1" [id=921, type=Add];
"922 bert/encoder/layer_5/intermediate/dense/mul_2" [id=922, type=Mul];
"923 bert/encoder/layer_5/intermediate/dense/mul_3" [id=923, type=Mul];
"924 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=924, label="924 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"925 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=925, label="925 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"926 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=926, label="926 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1", type=QuantizeLinear];
"927 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=927, label="927 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1", type=DequantizeLinear];
"928 bert/encoder/layer_5/output/dense/MatMul" [id=928, type=MatMul];
"929 bert/encoder/layer_5/output/dense/BiasAdd" [id=929, type=Add];
"930 bert/encoder/layer_5/output/add" [id=930, type=Add];
"931 bert/encoder/layer_5/output/LayerNorm/moments/mean" [id=931, type=ReduceMean];
"932 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" [id=932, type=Identity];
"933 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" [id=933, type=Sub];
"934 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" [id=934, type=Mul];
"935 bert/encoder/layer_5/output/LayerNorm/moments/variance" [id=935, type=ReduceMean];
"936 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" [id=936, type=Add];
"937 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" [id=937, type=Sqrt];
"938 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" [id=938, type=Reciprocal];
"939 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" [id=939, type=Mul];
"940 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" [id=940, type=Mul];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" [id=941, type=Sub];
"942 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" [id=942, type=Mul];
"943 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" [id=943, type=Add];
"944 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=944, label="944 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"945 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=945, label="945 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=946, label="946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=947, label="947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"948 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=948, label="948 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"949 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=949, label="949 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"950 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=950, label="950 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1", type=QuantizeLinear];
"951 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=951, label="951 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1", type=DequantizeLinear];
"952 bert/encoder/layer_6/attention/self/value/MatMul" [id=952, type=MatMul];
"953 bert/encoder/layer_6/attention/self/value/BiasAdd" [id=953, type=Add];
"954 bert/encoder/layer_6/attention/self/Reshape_2" [id=954, type=Reshape];
"955 bert/encoder/layer_6/attention/self/transpose_2" [id=955, type=Transpose];
"956 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=956, label="956 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1", type=QuantizeLinear];
"957 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=957, label="957 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1", type=DequantizeLinear];
"958 bert/encoder/layer_6/attention/self/query/MatMul" [id=958, type=MatMul];
"959 bert/encoder/layer_6/attention/self/query/BiasAdd" [id=959, type=Add];
"960 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=960, label="960 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"961 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=961, label="961 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"962 bert/encoder/layer_6/attention/self/Reshape" [id=962, type=Reshape];
"963 bert/encoder/layer_6/attention/self/transpose" [id=963, type=Transpose];
"964 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=964, label="964 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1", type=QuantizeLinear];
"965 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=965, label="965 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1", type=DequantizeLinear];
"966 bert/encoder/layer_6/attention/self/key/MatMul" [id=966, type=MatMul];
"967 bert/encoder/layer_6/attention/self/key/BiasAdd" [id=967, type=Add];
"968 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=968, label="968 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"969 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=969, label="969 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"970 bert/encoder/layer_6/attention/self/Reshape_1" [id=970, type=Reshape];
"971 bert/encoder/layer_6/attention/self/transpose_1" [id=971, type=Transpose];
"972 bert/encoder/layer_6/attention/self/MatMul__390" [id=972, type=Transpose];
"973 bert/encoder/layer_6/attention/self/MatMul" [id=973, type=MatMul];
"974 bert/encoder/layer_6/attention/self/Mul" [id=974, type=Mul];
"975 bert/encoder/layer_6/attention/self/add" [id=975, type=Add];
"976 bert/encoder/layer_6/attention/self/Softmax" [id=976, type=Softmax];
"977 bert/encoder/layer_6/attention/self/MatMul_1" [id=977, type=MatMul];
"978 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=978, label="978 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"979 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=979, label="979 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"980 bert/encoder/layer_6/attention/self/transpose_3" [id=980, type=Transpose];
"981 bert/encoder/layer_6/attention/self/Reshape_3" [id=981, type=Reshape];
"982 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=982, label="982 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"983 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=983, label="983 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"984 bert/encoder/layer_6/attention/output/dense/MatMul" [id=984, type=MatMul];
"985 bert/encoder/layer_6/attention/output/dense/BiasAdd" [id=985, type=Add];
"986 bert/encoder/layer_6/attention/output/add" [id=986, type=Add];
"987 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" [id=987, type=ReduceMean];
"988 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" [id=988, type=Identity];
"989 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" [id=989, type=Sub];
"990 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" [id=990, type=Mul];
"991 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" [id=991, type=ReduceMean];
"992 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" [id=992, type=Add];
"993 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" [id=993, type=Sqrt];
"994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" [id=994, type=Reciprocal];
"995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" [id=995, type=Mul];
"996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" [id=996, type=Mul];
"997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" [id=997, type=Sub];
"998 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" [id=998, type=Mul];
"999 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" [id=999, type=Add];
"1000 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1000, label="1000 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1001 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1001, label="1001 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1002 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1002, label="1002 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1003 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1003, label="1003 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1004 bert/encoder/layer_6/intermediate/dense/MatMul" [id=1004, type=MatMul];
"1005 bert/encoder/layer_6/intermediate/dense/BiasAdd" [id=1005, type=Add];
"1006 bert/encoder/layer_6/intermediate/dense/Pow" [id=1006, type=Pow];
"1007 bert/encoder/layer_6/intermediate/dense/mul" [id=1007, type=Mul];
"1008 bert/encoder/layer_6/intermediate/dense/add" [id=1008, type=Add];
"1009 bert/encoder/layer_6/intermediate/dense/mul_1" [id=1009, type=Mul];
"1010 bert/encoder/layer_6/intermediate/dense/Tanh" [id=1010, type=Tanh];
"1011 bert/encoder/layer_6/intermediate/dense/add_1" [id=1011, type=Add];
"1012 bert/encoder/layer_6/intermediate/dense/mul_2" [id=1012, type=Mul];
"1013 bert/encoder/layer_6/intermediate/dense/mul_3" [id=1013, type=Mul];
"1014 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1014, label="1014 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1015 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1015, label="1015 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1016 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1016, label="1016 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1", type=QuantizeLinear];
"1017 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1017, label="1017 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1", type=DequantizeLinear];
"1018 bert/encoder/layer_6/output/dense/MatMul" [id=1018, type=MatMul];
"1019 bert/encoder/layer_6/output/dense/BiasAdd" [id=1019, type=Add];
"1020 bert/encoder/layer_6/output/add" [id=1020, type=Add];
"1021 bert/encoder/layer_6/output/LayerNorm/moments/mean" [id=1021, type=ReduceMean];
"1022 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" [id=1022, type=Identity];
"1023 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" [id=1023, type=Sub];
"1024 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" [id=1024, type=Mul];
"1025 bert/encoder/layer_6/output/LayerNorm/moments/variance" [id=1025, type=ReduceMean];
"1026 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" [id=1026, type=Add];
"1027 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" [id=1027, type=Sqrt];
"1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" [id=1028, type=Reciprocal];
"1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" [id=1029, type=Mul];
"1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" [id=1030, type=Mul];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" [id=1031, type=Sub];
"1032 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" [id=1032, type=Mul];
"1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" [id=1033, type=Add];
"1034 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1034, label="1034 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1035 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1035, label="1035 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1036, label="1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1037, label="1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1038 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1038, label="1038 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1039 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1039, label="1039 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1040 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1040, label="1040 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1041 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1041, label="1041 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1042 bert/encoder/layer_7/attention/self/value/MatMul" [id=1042, type=MatMul];
"1043 bert/encoder/layer_7/attention/self/value/BiasAdd" [id=1043, type=Add];
"1044 bert/encoder/layer_7/attention/self/Reshape_2" [id=1044, type=Reshape];
"1045 bert/encoder/layer_7/attention/self/transpose_2" [id=1045, type=Transpose];
"1046 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1046, label="1046 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1047 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1047, label="1047 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1048 bert/encoder/layer_7/attention/self/query/MatMul" [id=1048, type=MatMul];
"1049 bert/encoder/layer_7/attention/self/query/BiasAdd" [id=1049, type=Add];
"1050 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1050, label="1050 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1051 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1051, label="1051 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1052 bert/encoder/layer_7/attention/self/Reshape" [id=1052, type=Reshape];
"1053 bert/encoder/layer_7/attention/self/transpose" [id=1053, type=Transpose];
"1054 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1054, label="1054 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1055 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1055, label="1055 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1056 bert/encoder/layer_7/attention/self/key/MatMul" [id=1056, type=MatMul];
"1057 bert/encoder/layer_7/attention/self/key/BiasAdd" [id=1057, type=Add];
"1058 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1058, label="1058 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1059 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1059, label="1059 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1060 bert/encoder/layer_7/attention/self/Reshape_1" [id=1060, type=Reshape];
"1061 bert/encoder/layer_7/attention/self/transpose_1" [id=1061, type=Transpose];
"1062 bert/encoder/layer_7/attention/self/MatMul__404" [id=1062, type=Transpose];
"1063 bert/encoder/layer_7/attention/self/MatMul" [id=1063, type=MatMul];
"1064 bert/encoder/layer_7/attention/self/Mul" [id=1064, type=Mul];
"1065 bert/encoder/layer_7/attention/self/add" [id=1065, type=Add];
"1066 bert/encoder/layer_7/attention/self/Softmax" [id=1066, type=Softmax];
"1067 bert/encoder/layer_7/attention/self/MatMul_1" [id=1067, type=MatMul];
"1068 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1068, label="1068 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1069 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1069, label="1069 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1070 bert/encoder/layer_7/attention/self/transpose_3" [id=1070, type=Transpose];
"1071 bert/encoder/layer_7/attention/self/Reshape_3" [id=1071, type=Reshape];
"1072 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1072, label="1072 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1073 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1073, label="1073 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1074 bert/encoder/layer_7/attention/output/dense/MatMul" [id=1074, type=MatMul];
"1075 bert/encoder/layer_7/attention/output/dense/BiasAdd" [id=1075, type=Add];
"1076 bert/encoder/layer_7/attention/output/add" [id=1076, type=Add];
"1077 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" [id=1077, type=ReduceMean];
"1078 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" [id=1078, type=Identity];
"1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" [id=1079, type=Sub];
"1080 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" [id=1080, type=Mul];
"1081 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" [id=1081, type=ReduceMean];
"1082 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" [id=1082, type=Add];
"1083 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1083, type=Sqrt];
"1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" [id=1084, type=Reciprocal];
"1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" [id=1085, type=Mul];
"1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" [id=1086, type=Mul];
"1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" [id=1087, type=Sub];
"1088 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" [id=1088, type=Mul];
"1089 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" [id=1089, type=Add];
"1090 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1090, label="1090 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1091 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1091, label="1091 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1092 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1092, label="1092 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1093 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1093, label="1093 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1094 bert/encoder/layer_7/intermediate/dense/MatMul" [id=1094, type=MatMul];
"1095 bert/encoder/layer_7/intermediate/dense/BiasAdd" [id=1095, type=Add];
"1096 bert/encoder/layer_7/intermediate/dense/Pow" [id=1096, type=Pow];
"1097 bert/encoder/layer_7/intermediate/dense/mul" [id=1097, type=Mul];
"1098 bert/encoder/layer_7/intermediate/dense/add" [id=1098, type=Add];
"1099 bert/encoder/layer_7/intermediate/dense/mul_1" [id=1099, type=Mul];
"1100 bert/encoder/layer_7/intermediate/dense/Tanh" [id=1100, type=Tanh];
"1101 bert/encoder/layer_7/intermediate/dense/add_1" [id=1101, type=Add];
"1102 bert/encoder/layer_7/intermediate/dense/mul_2" [id=1102, type=Mul];
"1103 bert/encoder/layer_7/intermediate/dense/mul_3" [id=1103, type=Mul];
"1104 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1104, label="1104 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1105 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1105, label="1105 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1106 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1106, label="1106 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1", type=QuantizeLinear];
"1107 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1107, label="1107 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1", type=DequantizeLinear];
"1108 bert/encoder/layer_7/output/dense/MatMul" [id=1108, type=MatMul];
"1109 bert/encoder/layer_7/output/dense/BiasAdd" [id=1109, type=Add];
"1110 bert/encoder/layer_7/output/add" [id=1110, type=Add];
"1111 bert/encoder/layer_7/output/LayerNorm/moments/mean" [id=1111, type=ReduceMean];
"1112 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" [id=1112, type=Identity];
"1113 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" [id=1113, type=Sub];
"1114 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" [id=1114, type=Mul];
"1115 bert/encoder/layer_7/output/LayerNorm/moments/variance" [id=1115, type=ReduceMean];
"1116 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" [id=1116, type=Add];
"1117 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" [id=1117, type=Sqrt];
"1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" [id=1118, type=Reciprocal];
"1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" [id=1119, type=Mul];
"1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" [id=1120, type=Mul];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" [id=1121, type=Sub];
"1122 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" [id=1122, type=Mul];
"1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" [id=1123, type=Add];
"1124 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1124, label="1124 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1125 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1125, label="1125 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1126, label="1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1127, label="1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1128 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1128, label="1128 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1129 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1129, label="1129 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1130 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1130, label="1130 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1131 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1131, label="1131 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1132 bert/encoder/layer_8/attention/self/value/MatMul" [id=1132, type=MatMul];
"1133 bert/encoder/layer_8/attention/self/value/BiasAdd" [id=1133, type=Add];
"1134 bert/encoder/layer_8/attention/self/Reshape_2" [id=1134, type=Reshape];
"1135 bert/encoder/layer_8/attention/self/transpose_2" [id=1135, type=Transpose];
"1136 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1136, label="1136 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1137 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1137, label="1137 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1138 bert/encoder/layer_8/attention/self/query/MatMul" [id=1138, type=MatMul];
"1139 bert/encoder/layer_8/attention/self/query/BiasAdd" [id=1139, type=Add];
"1140 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1140, label="1140 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1141 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1141, label="1141 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1142 bert/encoder/layer_8/attention/self/Reshape" [id=1142, type=Reshape];
"1143 bert/encoder/layer_8/attention/self/transpose" [id=1143, type=Transpose];
"1144 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1144, label="1144 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1145 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1145, label="1145 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1146 bert/encoder/layer_8/attention/self/key/MatMul" [id=1146, type=MatMul];
"1147 bert/encoder/layer_8/attention/self/key/BiasAdd" [id=1147, type=Add];
"1148 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1148, label="1148 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1149 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1149, label="1149 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1150 bert/encoder/layer_8/attention/self/Reshape_1" [id=1150, type=Reshape];
"1151 bert/encoder/layer_8/attention/self/transpose_1" [id=1151, type=Transpose];
"1152 bert/encoder/layer_8/attention/self/MatMul__418" [id=1152, type=Transpose];
"1153 bert/encoder/layer_8/attention/self/MatMul" [id=1153, type=MatMul];
"1154 bert/encoder/layer_8/attention/self/Mul" [id=1154, type=Mul];
"1155 bert/encoder/layer_8/attention/self/add" [id=1155, type=Add];
"1156 bert/encoder/layer_8/attention/self/Softmax" [id=1156, type=Softmax];
"1157 bert/encoder/layer_8/attention/self/MatMul_1" [id=1157, type=MatMul];
"1158 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1158, label="1158 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1159 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1159, label="1159 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1160 bert/encoder/layer_8/attention/self/transpose_3" [id=1160, type=Transpose];
"1161 bert/encoder/layer_8/attention/self/Reshape_3" [id=1161, type=Reshape];
"1162 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1162, label="1162 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1163 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1163, label="1163 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1164 bert/encoder/layer_8/attention/output/dense/MatMul" [id=1164, type=MatMul];
"1165 bert/encoder/layer_8/attention/output/dense/BiasAdd" [id=1165, type=Add];
"1166 bert/encoder/layer_8/attention/output/add" [id=1166, type=Add];
"1167 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" [id=1167, type=ReduceMean];
"1168 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" [id=1168, type=Identity];
"1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" [id=1169, type=Sub];
"1170 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" [id=1170, type=Mul];
"1171 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" [id=1171, type=ReduceMean];
"1172 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" [id=1172, type=Add];
"1173 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1173, type=Sqrt];
"1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" [id=1174, type=Reciprocal];
"1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" [id=1175, type=Mul];
"1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" [id=1176, type=Mul];
"1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" [id=1177, type=Sub];
"1178 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" [id=1178, type=Mul];
"1179 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" [id=1179, type=Add];
"1180 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1180, label="1180 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1181 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1181, label="1181 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1182 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1182, label="1182 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1183 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1183, label="1183 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1184 bert/encoder/layer_8/intermediate/dense/MatMul" [id=1184, type=MatMul];
"1185 bert/encoder/layer_8/intermediate/dense/BiasAdd" [id=1185, type=Add];
"1186 bert/encoder/layer_8/intermediate/dense/Pow" [id=1186, type=Pow];
"1187 bert/encoder/layer_8/intermediate/dense/mul" [id=1187, type=Mul];
"1188 bert/encoder/layer_8/intermediate/dense/add" [id=1188, type=Add];
"1189 bert/encoder/layer_8/intermediate/dense/mul_1" [id=1189, type=Mul];
"1190 bert/encoder/layer_8/intermediate/dense/Tanh" [id=1190, type=Tanh];
"1191 bert/encoder/layer_8/intermediate/dense/add_1" [id=1191, type=Add];
"1192 bert/encoder/layer_8/intermediate/dense/mul_2" [id=1192, type=Mul];
"1193 bert/encoder/layer_8/intermediate/dense/mul_3" [id=1193, type=Mul];
"1194 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1194, label="1194 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1195 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1195, label="1195 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1196 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1196, label="1196 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1", type=QuantizeLinear];
"1197 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1197, label="1197 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1", type=DequantizeLinear];
"1198 bert/encoder/layer_8/output/dense/MatMul" [id=1198, type=MatMul];
"1199 bert/encoder/layer_8/output/dense/BiasAdd" [id=1199, type=Add];
"1200 bert/encoder/layer_8/output/add" [id=1200, type=Add];
"1201 bert/encoder/layer_8/output/LayerNorm/moments/mean" [id=1201, type=ReduceMean];
"1202 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" [id=1202, type=Identity];
"1203 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" [id=1203, type=Sub];
"1204 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" [id=1204, type=Mul];
"1205 bert/encoder/layer_8/output/LayerNorm/moments/variance" [id=1205, type=ReduceMean];
"1206 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" [id=1206, type=Add];
"1207 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" [id=1207, type=Sqrt];
"1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" [id=1208, type=Reciprocal];
"1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" [id=1209, type=Mul];
"1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" [id=1210, type=Mul];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" [id=1211, type=Sub];
"1212 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" [id=1212, type=Mul];
"1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" [id=1213, type=Add];
"1214 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1214, label="1214 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1215 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1215, label="1215 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1216, label="1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1217, label="1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1218 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1218, label="1218 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1219 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1219, label="1219 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1220 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1220, label="1220 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1221 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1221, label="1221 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1222 bert/encoder/layer_9/attention/self/value/MatMul" [id=1222, type=MatMul];
"1223 bert/encoder/layer_9/attention/self/value/BiasAdd" [id=1223, type=Add];
"1224 bert/encoder/layer_9/attention/self/Reshape_2" [id=1224, type=Reshape];
"1225 bert/encoder/layer_9/attention/self/transpose_2" [id=1225, type=Transpose];
"1226 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1226, label="1226 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1227 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1227, label="1227 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1228 bert/encoder/layer_9/attention/self/query/MatMul" [id=1228, type=MatMul];
"1229 bert/encoder/layer_9/attention/self/query/BiasAdd" [id=1229, type=Add];
"1230 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1230, label="1230 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1231 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1231, label="1231 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1232 bert/encoder/layer_9/attention/self/Reshape" [id=1232, type=Reshape];
"1233 bert/encoder/layer_9/attention/self/transpose" [id=1233, type=Transpose];
"1234 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1234, label="1234 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1235 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1235, label="1235 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1236 bert/encoder/layer_9/attention/self/key/MatMul" [id=1236, type=MatMul];
"1237 bert/encoder/layer_9/attention/self/key/BiasAdd" [id=1237, type=Add];
"1238 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1238, label="1238 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1239 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1239, label="1239 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1240 bert/encoder/layer_9/attention/self/Reshape_1" [id=1240, type=Reshape];
"1241 bert/encoder/layer_9/attention/self/transpose_1" [id=1241, type=Transpose];
"1242 bert/encoder/layer_9/attention/self/MatMul__432" [id=1242, type=Transpose];
"1243 bert/encoder/layer_9/attention/self/MatMul" [id=1243, type=MatMul];
"1244 bert/encoder/layer_9/attention/self/Mul" [id=1244, type=Mul];
"1245 bert/encoder/layer_9/attention/self/add" [id=1245, type=Add];
"1246 bert/encoder/layer_9/attention/self/Softmax" [id=1246, type=Softmax];
"1247 bert/encoder/layer_9/attention/self/MatMul_1" [id=1247, type=MatMul];
"1248 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1248, label="1248 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1249 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1249, label="1249 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1250 bert/encoder/layer_9/attention/self/transpose_3" [id=1250, type=Transpose];
"1251 bert/encoder/layer_9/attention/self/Reshape_3" [id=1251, type=Reshape];
"1252 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1252, label="1252 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1253 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1253, label="1253 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1254 bert/encoder/layer_9/attention/output/dense/MatMul" [id=1254, type=MatMul];
"1255 bert/encoder/layer_9/attention/output/dense/BiasAdd" [id=1255, type=Add];
"1256 bert/encoder/layer_9/attention/output/add" [id=1256, type=Add];
"1257 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" [id=1257, type=ReduceMean];
"1258 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" [id=1258, type=Identity];
"1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" [id=1259, type=Sub];
"1260 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" [id=1260, type=Mul];
"1261 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" [id=1261, type=ReduceMean];
"1262 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" [id=1262, type=Add];
"1263 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1263, type=Sqrt];
"1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" [id=1264, type=Reciprocal];
"1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" [id=1265, type=Mul];
"1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" [id=1266, type=Mul];
"1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" [id=1267, type=Sub];
"1268 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" [id=1268, type=Mul];
"1269 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" [id=1269, type=Add];
"1270 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1270, label="1270 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1271 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1271, label="1271 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1272 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1272, label="1272 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1273 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1273, label="1273 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1274 bert/encoder/layer_9/intermediate/dense/MatMul" [id=1274, type=MatMul];
"1275 bert/encoder/layer_9/intermediate/dense/BiasAdd" [id=1275, type=Add];
"1276 bert/encoder/layer_9/intermediate/dense/Pow" [id=1276, type=Pow];
"1277 bert/encoder/layer_9/intermediate/dense/mul" [id=1277, type=Mul];
"1278 bert/encoder/layer_9/intermediate/dense/add" [id=1278, type=Add];
"1279 bert/encoder/layer_9/intermediate/dense/mul_1" [id=1279, type=Mul];
"1280 bert/encoder/layer_9/intermediate/dense/Tanh" [id=1280, type=Tanh];
"1281 bert/encoder/layer_9/intermediate/dense/add_1" [id=1281, type=Add];
"1282 bert/encoder/layer_9/intermediate/dense/mul_2" [id=1282, type=Mul];
"1283 bert/encoder/layer_9/intermediate/dense/mul_3" [id=1283, type=Mul];
"1284 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1284, label="1284 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1285 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1285, label="1285 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1286 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1286, label="1286 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1", type=QuantizeLinear];
"1287 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1287, label="1287 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1", type=DequantizeLinear];
"1288 bert/encoder/layer_9/output/dense/MatMul" [id=1288, type=MatMul];
"1289 bert/encoder/layer_9/output/dense/BiasAdd" [id=1289, type=Add];
"1290 bert/encoder/layer_9/output/add" [id=1290, type=Add];
"1291 bert/encoder/layer_9/output/LayerNorm/moments/mean" [id=1291, type=ReduceMean];
"1292 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" [id=1292, type=Identity];
"1293 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" [id=1293, type=Sub];
"1294 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" [id=1294, type=Mul];
"1295 bert/encoder/layer_9/output/LayerNorm/moments/variance" [id=1295, type=ReduceMean];
"1296 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" [id=1296, type=Add];
"1297 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" [id=1297, type=Sqrt];
"1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" [id=1298, type=Reciprocal];
"1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" [id=1299, type=Mul];
"1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" [id=1300, type=Mul];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" [id=1301, type=Sub];
"1302 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" [id=1302, type=Mul];
"1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" [id=1303, type=Add];
"1304 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1304, label="1304 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1305 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1305, label="1305 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1306, label="1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1307, label="1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1308 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1308, label="1308 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1309 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1309, label="1309 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1310 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1310, label="1310 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1311 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1311, label="1311 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1312 bert/encoder/layer_10/attention/self/value/MatMul" [id=1312, type=MatMul];
"1313 bert/encoder/layer_10/attention/self/value/BiasAdd" [id=1313, type=Add];
"1314 bert/encoder/layer_10/attention/self/Reshape_2" [id=1314, type=Reshape];
"1315 bert/encoder/layer_10/attention/self/transpose_2" [id=1315, type=Transpose];
"1316 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1316, label="1316 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1317 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1317, label="1317 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1318 bert/encoder/layer_10/attention/self/query/MatMul" [id=1318, type=MatMul];
"1319 bert/encoder/layer_10/attention/self/query/BiasAdd" [id=1319, type=Add];
"1320 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1320, label="1320 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1321 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1321, label="1321 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1322 bert/encoder/layer_10/attention/self/Reshape" [id=1322, type=Reshape];
"1323 bert/encoder/layer_10/attention/self/transpose" [id=1323, type=Transpose];
"1324 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1324, label="1324 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1325 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1325, label="1325 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1326 bert/encoder/layer_10/attention/self/key/MatMul" [id=1326, type=MatMul];
"1327 bert/encoder/layer_10/attention/self/key/BiasAdd" [id=1327, type=Add];
"1328 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1328, label="1328 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1329 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1329, label="1329 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1330 bert/encoder/layer_10/attention/self/Reshape_1" [id=1330, type=Reshape];
"1331 bert/encoder/layer_10/attention/self/transpose_1" [id=1331, type=Transpose];
"1332 bert/encoder/layer_10/attention/self/MatMul__446" [id=1332, type=Transpose];
"1333 bert/encoder/layer_10/attention/self/MatMul" [id=1333, type=MatMul];
"1334 bert/encoder/layer_10/attention/self/Mul" [id=1334, type=Mul];
"1335 bert/encoder/layer_10/attention/self/add" [id=1335, type=Add];
"1336 bert/encoder/layer_10/attention/self/Softmax" [id=1336, type=Softmax];
"1337 bert/encoder/layer_10/attention/self/MatMul_1" [id=1337, type=MatMul];
"1338 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1338, label="1338 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1339 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1339, label="1339 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1340 bert/encoder/layer_10/attention/self/transpose_3" [id=1340, type=Transpose];
"1341 bert/encoder/layer_10/attention/self/Reshape_3" [id=1341, type=Reshape];
"1342 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1342, label="1342 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1343 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1343, label="1343 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1344 bert/encoder/layer_10/attention/output/dense/MatMul" [id=1344, type=MatMul];
"1345 bert/encoder/layer_10/attention/output/dense/BiasAdd" [id=1345, type=Add];
"1346 bert/encoder/layer_10/attention/output/add" [id=1346, type=Add];
"1347 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" [id=1347, type=ReduceMean];
"1348 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" [id=1348, type=Identity];
"1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" [id=1349, type=Sub];
"1350 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" [id=1350, type=Mul];
"1351 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" [id=1351, type=ReduceMean];
"1352 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" [id=1352, type=Add];
"1353 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1353, type=Sqrt];
"1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" [id=1354, type=Reciprocal];
"1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" [id=1355, type=Mul];
"1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" [id=1356, type=Mul];
"1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" [id=1357, type=Sub];
"1358 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" [id=1358, type=Mul];
"1359 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" [id=1359, type=Add];
"1360 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1360, label="1360 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1361 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1361, label="1361 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1362 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1362, label="1362 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1363 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1363, label="1363 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1364 bert/encoder/layer_10/intermediate/dense/MatMul" [id=1364, type=MatMul];
"1365 bert/encoder/layer_10/intermediate/dense/BiasAdd" [id=1365, type=Add];
"1366 bert/encoder/layer_10/intermediate/dense/Pow" [id=1366, type=Pow];
"1367 bert/encoder/layer_10/intermediate/dense/mul" [id=1367, type=Mul];
"1368 bert/encoder/layer_10/intermediate/dense/add" [id=1368, type=Add];
"1369 bert/encoder/layer_10/intermediate/dense/mul_1" [id=1369, type=Mul];
"1370 bert/encoder/layer_10/intermediate/dense/Tanh" [id=1370, type=Tanh];
"1371 bert/encoder/layer_10/intermediate/dense/add_1" [id=1371, type=Add];
"1372 bert/encoder/layer_10/intermediate/dense/mul_2" [id=1372, type=Mul];
"1373 bert/encoder/layer_10/intermediate/dense/mul_3" [id=1373, type=Mul];
"1374 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1374, label="1374 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1375 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1375, label="1375 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1376 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1376, label="1376 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1", type=QuantizeLinear];
"1377 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1377, label="1377 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1", type=DequantizeLinear];
"1378 bert/encoder/layer_10/output/dense/MatMul" [id=1378, type=MatMul];
"1379 bert/encoder/layer_10/output/dense/BiasAdd" [id=1379, type=Add];
"1380 bert/encoder/layer_10/output/add" [id=1380, type=Add];
"1381 bert/encoder/layer_10/output/LayerNorm/moments/mean" [id=1381, type=ReduceMean];
"1382 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" [id=1382, type=Identity];
"1383 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" [id=1383, type=Sub];
"1384 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" [id=1384, type=Mul];
"1385 bert/encoder/layer_10/output/LayerNorm/moments/variance" [id=1385, type=ReduceMean];
"1386 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" [id=1386, type=Add];
"1387 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" [id=1387, type=Sqrt];
"1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" [id=1388, type=Reciprocal];
"1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" [id=1389, type=Mul];
"1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" [id=1390, type=Mul];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" [id=1391, type=Sub];
"1392 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" [id=1392, type=Mul];
"1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" [id=1393, type=Add];
"1394 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1394, label="1394 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1395 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1395, label="1395 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1396, label="1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1397, label="1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1398 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1398, label="1398 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1399 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1399, label="1399 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1400 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1400, label="1400 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1401 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1401, label="1401 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1402 bert/encoder/layer_11/attention/self/value/MatMul" [id=1402, type=MatMul];
"1403 bert/encoder/layer_11/attention/self/value/BiasAdd" [id=1403, type=Add];
"1404 bert/encoder/layer_11/attention/self/Reshape_2" [id=1404, type=Reshape];
"1405 bert/encoder/layer_11/attention/self/transpose_2" [id=1405, type=Transpose];
"1406 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1406, label="1406 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1407 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1407, label="1407 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1408 bert/encoder/layer_11/attention/self/query/MatMul" [id=1408, type=MatMul];
"1409 bert/encoder/layer_11/attention/self/query/BiasAdd" [id=1409, type=Add];
"1410 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1410, label="1410 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1411 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1411, label="1411 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1412 bert/encoder/layer_11/attention/self/Reshape" [id=1412, type=Reshape];
"1413 bert/encoder/layer_11/attention/self/transpose" [id=1413, type=Transpose];
"1414 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1414, label="1414 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1415 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1415, label="1415 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1416 bert/encoder/layer_11/attention/self/key/MatMul" [id=1416, type=MatMul];
"1417 bert/encoder/layer_11/attention/self/key/BiasAdd" [id=1417, type=Add];
"1418 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1418, label="1418 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1419 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1419, label="1419 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1420 bert/encoder/layer_11/attention/self/Reshape_1" [id=1420, type=Reshape];
"1421 bert/encoder/layer_11/attention/self/transpose_1" [id=1421, type=Transpose];
"1422 bert/encoder/layer_11/attention/self/MatMul__460" [id=1422, type=Transpose];
"1423 bert/encoder/layer_11/attention/self/MatMul" [id=1423, type=MatMul];
"1424 bert/encoder/layer_11/attention/self/Mul" [id=1424, type=Mul];
"1425 bert/encoder/layer_11/attention/self/add" [id=1425, type=Add];
"1426 bert/encoder/layer_11/attention/self/Softmax" [id=1426, type=Softmax];
"1427 bert/encoder/layer_11/attention/self/MatMul_1" [id=1427, type=MatMul];
"1428 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1428, label="1428 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1429 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1429, label="1429 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1430 bert/encoder/layer_11/attention/self/transpose_3" [id=1430, type=Transpose];
"1431 bert/encoder/layer_11/attention/self/Reshape_3" [id=1431, type=Reshape];
"1432 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1432, label="1432 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1433 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1433, label="1433 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1434 bert/encoder/layer_11/attention/output/dense/MatMul" [id=1434, type=MatMul];
"1435 bert/encoder/layer_11/attention/output/dense/BiasAdd" [id=1435, type=Add];
"1436 bert/encoder/layer_11/attention/output/add" [id=1436, type=Add];
"1437 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" [id=1437, type=ReduceMean];
"1438 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" [id=1438, type=Identity];
"1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" [id=1439, type=Sub];
"1440 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" [id=1440, type=Mul];
"1441 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" [id=1441, type=ReduceMean];
"1442 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" [id=1442, type=Add];
"1443 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1443, type=Sqrt];
"1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" [id=1444, type=Reciprocal];
"1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" [id=1445, type=Mul];
"1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" [id=1446, type=Mul];
"1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" [id=1447, type=Sub];
"1448 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" [id=1448, type=Mul];
"1449 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" [id=1449, type=Add];
"1450 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1450, label="1450 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1451 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1451, label="1451 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1452 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1452, label="1452 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1453 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1453, label="1453 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1454 bert/encoder/layer_11/intermediate/dense/MatMul" [id=1454, type=MatMul];
"1455 bert/encoder/layer_11/intermediate/dense/BiasAdd" [id=1455, type=Add];
"1456 bert/encoder/layer_11/intermediate/dense/Pow" [id=1456, type=Pow];
"1457 bert/encoder/layer_11/intermediate/dense/mul" [id=1457, type=Mul];
"1458 bert/encoder/layer_11/intermediate/dense/add" [id=1458, type=Add];
"1459 bert/encoder/layer_11/intermediate/dense/mul_1" [id=1459, type=Mul];
"1460 bert/encoder/layer_11/intermediate/dense/Tanh" [id=1460, type=Tanh];
"1461 bert/encoder/layer_11/intermediate/dense/add_1" [id=1461, type=Add];
"1462 bert/encoder/layer_11/intermediate/dense/mul_2" [id=1462, type=Mul];
"1463 bert/encoder/layer_11/intermediate/dense/mul_3" [id=1463, type=Mul];
"1464 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1464, label="1464 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1465 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1465, label="1465 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1466 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1466, label="1466 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1", type=QuantizeLinear];
"1467 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1467, label="1467 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1", type=DequantizeLinear];
"1468 bert/encoder/layer_11/output/dense/MatMul" [id=1468, type=MatMul];
"1469 bert/encoder/layer_11/output/dense/BiasAdd" [id=1469, type=Add];
"1470 bert/encoder/layer_11/output/add" [id=1470, type=Add];
"1471 bert/encoder/layer_11/output/LayerNorm/moments/mean" [id=1471, type=ReduceMean];
"1472 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" [id=1472, type=Identity];
"1473 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" [id=1473, type=Sub];
"1474 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" [id=1474, type=Mul];
"1475 bert/encoder/layer_11/output/LayerNorm/moments/variance" [id=1475, type=ReduceMean];
"1476 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" [id=1476, type=Add];
"1477 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" [id=1477, type=Sqrt];
"1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" [id=1478, type=Reciprocal];
"1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" [id=1479, type=Mul];
"1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" [id=1480, type=Mul];
"1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" [id=1481, type=Sub];
"1482 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" [id=1482, type=Mul];
"1483 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" [id=1483, type=Add];
"1484 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1484, label="1484 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1485 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1485, label="1485 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1486 bert/encoder/Reshape_13" [id=1486, type=Reshape];
"1487 Shape_1" [id=1487, type=Shape];
"1488 Shape_1__472" [id=1488, type=Cast];
"1489 strided_slice_1" [id=1489, type=Slice];
"1490 strided_slice_1__476" [id=1490, type=Squeeze];
"1491 strided_slice_1__477" [id=1491, type=Cast];
"1492 mul" [id=1492, type=Mul];
"1493 Reshape/shape_Unsqueeze__482" [id=1493, type=Unsqueeze];
"1494 Reshape/shape_Concat__484" [id=1494, type=Concat];
"1495 Reshape__485" [id=1495, type=Cast];
"1496 Reshape_1/shape_Unsqueeze__478" [id=1496, type=Unsqueeze];
"1497 Reshape_1/shape_Concat__481" [id=1497, type=Concat];
"1498 Reshape_1__487" [id=1498, type=Cast];
"1499 Reshape" [id=1499, type=Reshape];
"1500 QuantizeLinear_MatMul__486^0_1" [id=1500, label="1500 QuantizeLinear_MatMul__486:0_1", type=QuantizeLinear];
"1501 DequantizeLinear_MatMul__486^0_1" [id=1501, label="1501 DequantizeLinear_MatMul__486:0_1", type=DequantizeLinear];
"1502 MatMul" [id=1502, type=MatMul];
"1503 BiasAdd" [id=1503, type=Add];
"1504 Reshape_1" [id=1504, type=Reshape];
"1505 transpose" [id=1505, type=Transpose];
"1506 unstack" [id=1506, type=Split];
"1507 unstack__490" [id=1507, type=Squeeze];
"1508 unstack_graph_outputs_Identity__4" [id=1508, type=Identity];
"1509 unstack__488" [id=1509, type=Squeeze];
"1510 unstack_graph_outputs_Identity__7" [id=1510, type=Identity];
"1511 nncf_model_input_0" [id=1511, type=nncf_model_input];
"1512 nncf_model_input_1" [id=1512, type=nncf_model_input];
"1513 nncf_model_input_2" [id=1513, type=nncf_model_input];
"1514 nncf_model_input_3" [id=1514, type=nncf_model_input];
"1515 nncf_model_output_0" [id=1515, type=nncf_model_output];
"1516 nncf_model_output_1" [id=1516, type=nncf_model_output];
"1517 nncf_model_output_2" [id=1517, type=nncf_model_output];
"0 unique_ids_graph_outputs_Identity__10" -> "1517 nncf_model_output_2"  [label="[-1]", style=dashed];
"1 bert/encoder/ones/packed_Unsqueeze__20" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"2 bert/encoder/ones/packed_Unsqueeze__19" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"3 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" -> "246 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84"  [label="[1]", style=dashed];
"4 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" -> "249 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"5 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" -> "249 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"6 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" -> "249 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"7 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" -> "252 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"8 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" -> "252 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"9 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" -> "252 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"10 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" -> "255 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"11 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" -> "255 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"12 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" -> "255 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"13 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" -> "259 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102"  [label="[1]", style=dashed];
"14 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" -> "262 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"15 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" -> "262 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"16 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" -> "262 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"17 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" -> "265 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"18 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" -> "265 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"19 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" -> "265 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"20 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" -> "268 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"21 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" -> "268 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"22 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" -> "268 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"23 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" -> "272 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120"  [label="[1]", style=dashed];
"24 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" -> "275 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"25 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" -> "275 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"26 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" -> "275 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"27 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" -> "278 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"28 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" -> "278 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"29 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" -> "278 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"30 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" -> "281 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"31 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" -> "281 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"32 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" -> "281 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"33 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" -> "285 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138"  [label="[1]", style=dashed];
"34 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" -> "288 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"35 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" -> "288 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"36 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" -> "288 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"37 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" -> "291 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"38 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" -> "291 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"39 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" -> "291 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"40 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" -> "294 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"41 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" -> "294 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"42 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" -> "294 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"43 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" -> "298 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156"  [label="[1]", style=dashed];
"44 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" -> "301 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"45 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" -> "301 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"46 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" -> "301 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"47 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" -> "304 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"48 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" -> "304 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"49 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" -> "304 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"50 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" -> "307 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"51 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" -> "307 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"52 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" -> "307 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"53 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" -> "311 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174"  [label="[1]", style=dashed];
"54 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" -> "314 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"55 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" -> "314 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"56 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" -> "314 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"57 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" -> "317 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"58 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" -> "317 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"59 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" -> "317 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"60 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" -> "320 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"61 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" -> "320 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"62 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" -> "320 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"63 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" -> "324 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192"  [label="[1]", style=dashed];
"64 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" -> "327 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"65 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" -> "327 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"66 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" -> "327 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"67 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" -> "330 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"68 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" -> "330 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"69 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" -> "330 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"70 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" -> "333 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"71 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" -> "333 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"72 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" -> "333 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"73 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" -> "337 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210"  [label="[1]", style=dashed];
"74 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" -> "340 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"75 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" -> "340 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"76 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" -> "340 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"77 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" -> "343 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"78 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" -> "343 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"79 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" -> "343 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"80 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" -> "346 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"81 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" -> "346 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"82 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" -> "346 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"83 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" -> "350 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228"  [label="[1]", style=dashed];
"84 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" -> "353 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"85 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" -> "353 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"86 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" -> "353 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"87 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" -> "356 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"88 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" -> "356 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"89 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" -> "356 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"90 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" -> "359 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"91 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" -> "359 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"92 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" -> "359 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"93 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" -> "363 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246"  [label="[1]", style=dashed];
"94 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" -> "366 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"95 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" -> "366 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"96 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" -> "366 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"97 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" -> "369 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"98 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" -> "369 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"99 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" -> "369 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"100 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" -> "372 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"101 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" -> "372 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"102 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" -> "372 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"103 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" -> "376 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264"  [label="[1]", style=dashed];
"104 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" -> "379 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"105 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" -> "379 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"106 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" -> "379 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"107 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" -> "382 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"108 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" -> "382 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"109 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" -> "382 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"110 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" -> "385 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"111 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" -> "385 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"112 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" -> "385 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"113 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" -> "389 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282"  [label="[1]", style=dashed];
"114 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" -> "392 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"115 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" -> "392 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"116 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" -> "392 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"117 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" -> "395 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"118 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" -> "395 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"119 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" -> "395 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"120 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" -> "398 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"121 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" -> "398 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"122 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" -> "398 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"123 bert/encoder/Shape" -> "124 bert/encoder/Shape__12"  [label="[2]", style=dashed];
"124 bert/encoder/Shape__12" -> "125 bert/encoder/strided_slice"  [label="[2]", style=solid];
"125 bert/encoder/strided_slice" -> "126 bert/encoder/strided_slice__16"  [label="[1]", style=solid];
"126 bert/encoder/strided_slice__16" -> "127 bert/encoder/strided_slice__17"  [label="[]", style=solid];
"127 bert/encoder/strided_slice__17" -> "128 bert/encoder/ones/packed_Unsqueeze__18"  [label="[]", style=dashed];
"127 bert/encoder/strided_slice__17" -> "135 bert/encoder/Reshape/shape_Unsqueeze__23"  [label="[]", style=dashed];
"128 bert/encoder/ones/packed_Unsqueeze__18" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"129 bert/encoder/ones/packed_Concat__21" -> "130 bert/encoder/ones__22"  [label="[3]", style=dashed];
"130 bert/encoder/ones__22" -> "131 bert/encoder/ones"  [label="[3]", style=dashed];
"131 bert/encoder/ones" -> "142 bert/encoder/mul"  [label="[-1, -1, -1]", style=solid];
"132 bert/encoder/Reshape_13/shape_Unsqueeze__300" -> "401 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"133 bert/encoder/Reshape_13/shape_Unsqueeze__299" -> "401 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"134 bert/encoder/Reshape_1__302" -> "403 bert/encoder/Reshape_1"  [label="[2]", style=dashed];
"135 bert/encoder/Reshape/shape_Unsqueeze__23" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"136 bert/encoder/Reshape/shape_Unsqueeze__25" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"137 bert/encoder/Reshape/shape_Unsqueeze__24" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"138 bert/encoder/Reshape/shape_Concat__26" -> "139 bert/encoder/Reshape__27"  [label="[3]", style=dashed];
"139 bert/encoder/Reshape__27" -> "140 bert/encoder/Reshape"  [label="[3]", style=dashed];
"140 bert/encoder/Reshape" -> "141 bert/encoder/Cast"  [label="[]", style=dashed];
"141 bert/encoder/Cast" -> "142 bert/encoder/mul"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "143 bert/encoder/layer_9/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "146 bert/encoder/layer_8/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "149 bert/encoder/layer_7/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "152 bert/encoder/layer_6/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "155 bert/encoder/layer_5/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "158 bert/encoder/layer_4/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "161 bert/encoder/layer_3/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "164 bert/encoder/layer_2/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "167 bert/encoder/layer_11/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "170 bert/encoder/layer_10/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "173 bert/encoder/layer_1/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "176 bert/encoder/layer_0/attention/self/ExpandDims"  [label="[]", style=solid];
"143 bert/encoder/layer_9/attention/self/ExpandDims" -> "144 bert/encoder/layer_9/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"144 bert/encoder/layer_9/attention/self/sub" -> "145 bert/encoder/layer_9/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"145 bert/encoder/layer_9/attention/self/mul_1" -> "1245 bert/encoder/layer_9/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"146 bert/encoder/layer_8/attention/self/ExpandDims" -> "147 bert/encoder/layer_8/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"147 bert/encoder/layer_8/attention/self/sub" -> "148 bert/encoder/layer_8/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"148 bert/encoder/layer_8/attention/self/mul_1" -> "1155 bert/encoder/layer_8/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"149 bert/encoder/layer_7/attention/self/ExpandDims" -> "150 bert/encoder/layer_7/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"150 bert/encoder/layer_7/attention/self/sub" -> "151 bert/encoder/layer_7/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"151 bert/encoder/layer_7/attention/self/mul_1" -> "1065 bert/encoder/layer_7/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"152 bert/encoder/layer_6/attention/self/ExpandDims" -> "153 bert/encoder/layer_6/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"153 bert/encoder/layer_6/attention/self/sub" -> "154 bert/encoder/layer_6/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"154 bert/encoder/layer_6/attention/self/mul_1" -> "975 bert/encoder/layer_6/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"155 bert/encoder/layer_5/attention/self/ExpandDims" -> "156 bert/encoder/layer_5/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"156 bert/encoder/layer_5/attention/self/sub" -> "157 bert/encoder/layer_5/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"157 bert/encoder/layer_5/attention/self/mul_1" -> "885 bert/encoder/layer_5/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"158 bert/encoder/layer_4/attention/self/ExpandDims" -> "159 bert/encoder/layer_4/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"159 bert/encoder/layer_4/attention/self/sub" -> "160 bert/encoder/layer_4/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"160 bert/encoder/layer_4/attention/self/mul_1" -> "795 bert/encoder/layer_4/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"161 bert/encoder/layer_3/attention/self/ExpandDims" -> "162 bert/encoder/layer_3/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"162 bert/encoder/layer_3/attention/self/sub" -> "163 bert/encoder/layer_3/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"163 bert/encoder/layer_3/attention/self/mul_1" -> "705 bert/encoder/layer_3/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"164 bert/encoder/layer_2/attention/self/ExpandDims" -> "165 bert/encoder/layer_2/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"165 bert/encoder/layer_2/attention/self/sub" -> "166 bert/encoder/layer_2/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"166 bert/encoder/layer_2/attention/self/mul_1" -> "615 bert/encoder/layer_2/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"167 bert/encoder/layer_11/attention/self/ExpandDims" -> "168 bert/encoder/layer_11/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"168 bert/encoder/layer_11/attention/self/sub" -> "169 bert/encoder/layer_11/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"169 bert/encoder/layer_11/attention/self/mul_1" -> "1425 bert/encoder/layer_11/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"170 bert/encoder/layer_10/attention/self/ExpandDims" -> "171 bert/encoder/layer_10/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"171 bert/encoder/layer_10/attention/self/sub" -> "172 bert/encoder/layer_10/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"172 bert/encoder/layer_10/attention/self/mul_1" -> "1335 bert/encoder/layer_10/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"173 bert/encoder/layer_1/attention/self/ExpandDims" -> "174 bert/encoder/layer_1/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"174 bert/encoder/layer_1/attention/self/sub" -> "175 bert/encoder/layer_1/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"175 bert/encoder/layer_1/attention/self/mul_1" -> "525 bert/encoder/layer_1/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"176 bert/encoder/layer_0/attention/self/ExpandDims" -> "177 bert/encoder/layer_0/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"177 bert/encoder/layer_0/attention/self/sub" -> "178 bert/encoder/layer_0/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"178 bert/encoder/layer_0/attention/self/mul_1" -> "435 bert/encoder/layer_0/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"179 bert/embeddings/Slice" -> "181 bert/embeddings/Reshape_4"  [label="[256, 768]", style=solid];
"180 bert/embeddings/Reshape_4__42" -> "181 bert/embeddings/Reshape_4"  [label="[3]", style=dashed];
"181 bert/embeddings/Reshape_4" -> "225 bert/embeddings/add_1"  [label="[]", style=solid];
"182 bert/embeddings/Reshape_3/shape_Unsqueeze__69" -> "207 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"183 bert/embeddings/Reshape_3/shape_Unsqueeze__68" -> "207 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"184 bert/embeddings/Reshape_2__43" -> "185 bert/embeddings/Reshape_2"  [label="[1]", style=dashed];
"185 bert/embeddings/Reshape_2" -> "217 bert/embeddings/one_hot"  [label="[]", style=dashed];
"186 bert/embeddings/Reshape_1/shape_Unsqueeze__57" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"187 bert/embeddings/Reshape_1/shape_Unsqueeze__56" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"188 bert/embeddings/Reshape__59" -> "198 bert/embeddings/Reshape"  [label="[1]", style=dashed];
"189 bert/embeddings/ExpandDims" -> "190 bert/embeddings/Shape"  [label="[-1, 256, 1]", style=dashed];
"189 bert/embeddings/ExpandDims" -> "198 bert/embeddings/Reshape"  [label="[-1, 256, 1]", style=dashed];
"190 bert/embeddings/Shape" -> "191 bert/embeddings/Shape__49"  [label="[3]", style=dashed];
"191 bert/embeddings/Shape__49" -> "192 bert/embeddings/strided_slice"  [label="[3]", style=solid];
"192 bert/embeddings/strided_slice" -> "193 bert/embeddings/strided_slice__53"  [label="[1]", style=solid];
"193 bert/embeddings/strided_slice__53" -> "194 bert/embeddings/strided_slice__54"  [label="[]", style=solid];
"194 bert/embeddings/strided_slice__54" -> "195 bert/embeddings/Reshape_1/shape_Unsqueeze__55"  [label="[]", style=dashed];
"195 bert/embeddings/Reshape_1/shape_Unsqueeze__55" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"196 bert/embeddings/Reshape_1/shape_Concat__58" -> "197 bert/embeddings/Reshape_1__60"  [label="[3]", style=dashed];
"197 bert/embeddings/Reshape_1__60" -> "200 bert/embeddings/Reshape_1"  [label="[3]", style=dashed];
"198 bert/embeddings/Reshape" -> "199 bert/embeddings/GatherV2"  [label="[]", style=dashed];
"199 bert/embeddings/GatherV2" -> "200 bert/embeddings/Reshape_1"  [label="[]", style=solid];
"200 bert/embeddings/Reshape_1" -> "201 bert/embeddings/Shape_1"  [label="[]", style=solid];
"200 bert/embeddings/Reshape_1" -> "224 bert/embeddings/add"  [label="[]", style=solid];
"201 bert/embeddings/Shape_1" -> "202 bert/embeddings/Shape_1__61"  [label="[-1]", style=dashed];
"202 bert/embeddings/Shape_1__61" -> "203 bert/embeddings/strided_slice_1"  [label="[-1]", style=solid];
"203 bert/embeddings/strided_slice_1" -> "204 bert/embeddings/strided_slice_1__65"  [label="[-1]", style=solid];
"204 bert/embeddings/strided_slice_1__65" -> "205 bert/embeddings/strided_slice_1__66"  [label="[]", style=solid];
"205 bert/embeddings/strided_slice_1__66" -> "206 bert/embeddings/Reshape_3/shape_Unsqueeze__67"  [label="[]", style=dashed];
"206 bert/embeddings/Reshape_3/shape_Unsqueeze__67" -> "207 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"207 bert/embeddings/Reshape_3/shape_Concat__70" -> "208 bert/embeddings/Reshape_3__71"  [label="[3]", style=dashed];
"208 bert/embeddings/Reshape_3__71" -> "223 bert/embeddings/Reshape_3"  [label="[3]", style=dashed];
"209 Unsqueeze__46" -> "216 Concat__47"  [label="[1]", style=solid];
"210 Unsqueeze__45" -> "216 Concat__47"  [label="[1]", style=solid];
"211 Unsqueeze__44" -> "217 bert/embeddings/one_hot"  [label="[1]", style=dashed];
"212 Reshape_1/shape_Unsqueeze__480" -> "1497 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"213 Reshape_1/shape_Unsqueeze__479" -> "1497 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"214 Reshape/shape_Unsqueeze__483" -> "1494 Reshape/shape_Concat__484"  [label="[1]", style=dashed];
"215 MatMul__486" -> "1500 QuantizeLinear_MatMul__486^0_1"  [label="[768, 2]", style=solid];
"216 Concat__47" -> "217 bert/embeddings/one_hot"  [label="[2]", style=solid];
"217 bert/embeddings/one_hot" -> "218 QuantizeLinear_bert/embeddings/one_hot^0_1"  [label="[]", style=solid];
"218 QuantizeLinear_bert/embeddings/one_hot^0_1" -> "219 DequantizeLinear_bert/embeddings/one_hot^0_1"  [label="[]", style=dashed];
"219 DequantizeLinear_bert/embeddings/one_hot^0_1" -> "222 bert/embeddings/MatMul"  [label="[]", style=solid];
"220 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "221 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1"  [label="[2, 768]", style=dashed];
"221 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "222 bert/embeddings/MatMul"  [label="[2, 768]", style=solid];
"222 bert/embeddings/MatMul" -> "223 bert/embeddings/Reshape_3"  [label="[]", style=solid];
"223 bert/embeddings/Reshape_3" -> "224 bert/embeddings/add"  [label="[]", style=solid];
"224 bert/embeddings/add" -> "225 bert/embeddings/add_1"  [label="[]", style=solid];
"225 bert/embeddings/add_1" -> "226 bert/embeddings/LayerNorm/moments/mean"  [label="[]", style=solid];
"225 bert/embeddings/add_1" -> "228 bert/embeddings/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"225 bert/embeddings/add_1" -> "237 bert/embeddings/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"226 bert/embeddings/LayerNorm/moments/mean" -> "227 bert/embeddings/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"226 bert/embeddings/LayerNorm/moments/mean" -> "235 bert/embeddings/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"227 bert/embeddings/LayerNorm/moments/StopGradient" -> "228 bert/embeddings/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"228 bert/embeddings/LayerNorm/moments/SquaredDifference" -> "229 bert/embeddings/LayerNorm/moments/SquaredDifference__72"  [label="[]", style=solid];
"229 bert/embeddings/LayerNorm/moments/SquaredDifference__72" -> "230 bert/embeddings/LayerNorm/moments/variance"  [label="[]", style=solid];
"230 bert/embeddings/LayerNorm/moments/variance" -> "231 bert/embeddings/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"231 bert/embeddings/LayerNorm/batchnorm/add" -> "232 bert/embeddings/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"232 bert/embeddings/LayerNorm/batchnorm/Rsqrt" -> "233 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74"  [label="[]", style=solid];
"233 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" -> "234 bert/embeddings/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"234 bert/embeddings/LayerNorm/batchnorm/mul" -> "235 bert/embeddings/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"234 bert/embeddings/LayerNorm/batchnorm/mul" -> "237 bert/embeddings/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"235 bert/embeddings/LayerNorm/batchnorm/mul_2" -> "236 bert/embeddings/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"236 bert/embeddings/LayerNorm/batchnorm/sub" -> "238 bert/embeddings/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"237 bert/embeddings/LayerNorm/batchnorm/mul_1" -> "238 bert/embeddings/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"238 bert/embeddings/LayerNorm/batchnorm/add_1" -> "239 bert/encoder/Shape_2"  [label="[]", style=solid];
"238 bert/embeddings/LayerNorm/batchnorm/add_1" -> "403 bert/encoder/Reshape_1"  [label="[]", style=solid];
"239 bert/encoder/Shape_2" -> "240 bert/encoder/Shape_2__76"  [label="[-1]", style=dashed];
"240 bert/encoder/Shape_2__76" -> "241 bert/encoder/strided_slice_2"  [label="[-1]", style=solid];
"241 bert/encoder/strided_slice_2" -> "242 bert/encoder/strided_slice_2__80"  [label="[-1]", style=solid];
"242 bert/encoder/strided_slice_2__80" -> "243 bert/encoder/strided_slice_2__81"  [label="[]", style=solid];
"243 bert/encoder/strided_slice_2__81" -> "244 bert/encoder/layer_9/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "248 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "251 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "254 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "257 bert/encoder/layer_8/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "261 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "264 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "267 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "270 bert/encoder/layer_7/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "274 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "277 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "280 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "283 bert/encoder/layer_6/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "287 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "290 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "293 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "296 bert/encoder/layer_5/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "300 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "303 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "306 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "309 bert/encoder/layer_4/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "313 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "316 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "319 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "322 bert/encoder/layer_3/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "326 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "329 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "332 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "335 bert/encoder/layer_2/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "339 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "342 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "345 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "348 bert/encoder/layer_11/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "352 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "355 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "358 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "361 bert/encoder/layer_10/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "365 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "368 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "371 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "374 bert/encoder/layer_1/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "378 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "381 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "384 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "387 bert/encoder/layer_0/attention/self/mul_2"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "391 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "394 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "397 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293"  [label="[]", style=dashed];
"243 bert/encoder/strided_slice_2__81" -> "400 bert/encoder/Reshape_13/shape_Unsqueeze__298"  [label="[]", style=dashed];
"244 bert/encoder/layer_9/attention/self/mul_2" -> "245 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82"  [label="[]", style=dashed];
"245 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" -> "246 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84"  [label="[1]", style=dashed];
"246 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" -> "247 bert/encoder/layer_9/attention/self/Reshape_3__434"  [label="[2]", style=dashed];
"247 bert/encoder/layer_9/attention/self/Reshape_3__434" -> "1251 bert/encoder/layer_9/attention/self/Reshape_3"  [label="[2]", style=dashed];
"248 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" -> "249 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"249 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" -> "250 bert/encoder/layer_9/attention/self/Reshape_2__429"  [label="[4]", style=dashed];
"250 bert/encoder/layer_9/attention/self/Reshape_2__429" -> "1224 bert/encoder/layer_9/attention/self/Reshape_2"  [label="[4]", style=dashed];
"251 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" -> "252 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"252 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" -> "253 bert/encoder/layer_9/attention/self/Reshape_1__431"  [label="[4]", style=dashed];
"253 bert/encoder/layer_9/attention/self/Reshape_1__431" -> "1240 bert/encoder/layer_9/attention/self/Reshape_1"  [label="[4]", style=dashed];
"254 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" -> "255 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"255 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" -> "256 bert/encoder/layer_9/attention/self/Reshape__430"  [label="[4]", style=dashed];
"256 bert/encoder/layer_9/attention/self/Reshape__430" -> "1232 bert/encoder/layer_9/attention/self/Reshape"  [label="[4]", style=dashed];
"257 bert/encoder/layer_8/attention/self/mul_2" -> "258 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100"  [label="[]", style=dashed];
"258 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" -> "259 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102"  [label="[1]", style=dashed];
"259 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" -> "260 bert/encoder/layer_8/attention/self/Reshape_3__420"  [label="[2]", style=dashed];
"260 bert/encoder/layer_8/attention/self/Reshape_3__420" -> "1161 bert/encoder/layer_8/attention/self/Reshape_3"  [label="[2]", style=dashed];
"261 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" -> "262 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"262 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" -> "263 bert/encoder/layer_8/attention/self/Reshape_2__415"  [label="[4]", style=dashed];
"263 bert/encoder/layer_8/attention/self/Reshape_2__415" -> "1134 bert/encoder/layer_8/attention/self/Reshape_2"  [label="[4]", style=dashed];
"264 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" -> "265 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"265 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" -> "266 bert/encoder/layer_8/attention/self/Reshape_1__417"  [label="[4]", style=dashed];
"266 bert/encoder/layer_8/attention/self/Reshape_1__417" -> "1150 bert/encoder/layer_8/attention/self/Reshape_1"  [label="[4]", style=dashed];
"267 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" -> "268 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"268 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" -> "269 bert/encoder/layer_8/attention/self/Reshape__416"  [label="[4]", style=dashed];
"269 bert/encoder/layer_8/attention/self/Reshape__416" -> "1142 bert/encoder/layer_8/attention/self/Reshape"  [label="[4]", style=dashed];
"270 bert/encoder/layer_7/attention/self/mul_2" -> "271 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118"  [label="[]", style=dashed];
"271 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" -> "272 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120"  [label="[1]", style=dashed];
"272 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" -> "273 bert/encoder/layer_7/attention/self/Reshape_3__406"  [label="[2]", style=dashed];
"273 bert/encoder/layer_7/attention/self/Reshape_3__406" -> "1071 bert/encoder/layer_7/attention/self/Reshape_3"  [label="[2]", style=dashed];
"274 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" -> "275 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"275 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" -> "276 bert/encoder/layer_7/attention/self/Reshape_2__401"  [label="[4]", style=dashed];
"276 bert/encoder/layer_7/attention/self/Reshape_2__401" -> "1044 bert/encoder/layer_7/attention/self/Reshape_2"  [label="[4]", style=dashed];
"277 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" -> "278 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"278 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" -> "279 bert/encoder/layer_7/attention/self/Reshape_1__403"  [label="[4]", style=dashed];
"279 bert/encoder/layer_7/attention/self/Reshape_1__403" -> "1060 bert/encoder/layer_7/attention/self/Reshape_1"  [label="[4]", style=dashed];
"280 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" -> "281 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"281 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" -> "282 bert/encoder/layer_7/attention/self/Reshape__402"  [label="[4]", style=dashed];
"282 bert/encoder/layer_7/attention/self/Reshape__402" -> "1052 bert/encoder/layer_7/attention/self/Reshape"  [label="[4]", style=dashed];
"283 bert/encoder/layer_6/attention/self/mul_2" -> "284 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136"  [label="[]", style=dashed];
"284 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" -> "285 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138"  [label="[1]", style=dashed];
"285 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" -> "286 bert/encoder/layer_6/attention/self/Reshape_3__392"  [label="[2]", style=dashed];
"286 bert/encoder/layer_6/attention/self/Reshape_3__392" -> "981 bert/encoder/layer_6/attention/self/Reshape_3"  [label="[2]", style=dashed];
"287 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" -> "288 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"288 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" -> "289 bert/encoder/layer_6/attention/self/Reshape_2__387"  [label="[4]", style=dashed];
"289 bert/encoder/layer_6/attention/self/Reshape_2__387" -> "954 bert/encoder/layer_6/attention/self/Reshape_2"  [label="[4]", style=dashed];
"290 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" -> "291 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"291 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" -> "292 bert/encoder/layer_6/attention/self/Reshape_1__389"  [label="[4]", style=dashed];
"292 bert/encoder/layer_6/attention/self/Reshape_1__389" -> "970 bert/encoder/layer_6/attention/self/Reshape_1"  [label="[4]", style=dashed];
"293 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" -> "294 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"294 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" -> "295 bert/encoder/layer_6/attention/self/Reshape__388"  [label="[4]", style=dashed];
"295 bert/encoder/layer_6/attention/self/Reshape__388" -> "962 bert/encoder/layer_6/attention/self/Reshape"  [label="[4]", style=dashed];
"296 bert/encoder/layer_5/attention/self/mul_2" -> "297 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154"  [label="[]", style=dashed];
"297 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" -> "298 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156"  [label="[1]", style=dashed];
"298 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" -> "299 bert/encoder/layer_5/attention/self/Reshape_3__378"  [label="[2]", style=dashed];
"299 bert/encoder/layer_5/attention/self/Reshape_3__378" -> "891 bert/encoder/layer_5/attention/self/Reshape_3"  [label="[2]", style=dashed];
"300 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" -> "301 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"301 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" -> "302 bert/encoder/layer_5/attention/self/Reshape_2__373"  [label="[4]", style=dashed];
"302 bert/encoder/layer_5/attention/self/Reshape_2__373" -> "864 bert/encoder/layer_5/attention/self/Reshape_2"  [label="[4]", style=dashed];
"303 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" -> "304 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"304 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" -> "305 bert/encoder/layer_5/attention/self/Reshape_1__375"  [label="[4]", style=dashed];
"305 bert/encoder/layer_5/attention/self/Reshape_1__375" -> "880 bert/encoder/layer_5/attention/self/Reshape_1"  [label="[4]", style=dashed];
"306 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" -> "307 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"307 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" -> "308 bert/encoder/layer_5/attention/self/Reshape__374"  [label="[4]", style=dashed];
"308 bert/encoder/layer_5/attention/self/Reshape__374" -> "872 bert/encoder/layer_5/attention/self/Reshape"  [label="[4]", style=dashed];
"309 bert/encoder/layer_4/attention/self/mul_2" -> "310 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172"  [label="[]", style=dashed];
"310 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" -> "311 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174"  [label="[1]", style=dashed];
"311 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" -> "312 bert/encoder/layer_4/attention/self/Reshape_3__364"  [label="[2]", style=dashed];
"312 bert/encoder/layer_4/attention/self/Reshape_3__364" -> "801 bert/encoder/layer_4/attention/self/Reshape_3"  [label="[2]", style=dashed];
"313 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" -> "314 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"314 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" -> "315 bert/encoder/layer_4/attention/self/Reshape_2__359"  [label="[4]", style=dashed];
"315 bert/encoder/layer_4/attention/self/Reshape_2__359" -> "774 bert/encoder/layer_4/attention/self/Reshape_2"  [label="[4]", style=dashed];
"316 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" -> "317 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"317 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" -> "318 bert/encoder/layer_4/attention/self/Reshape_1__361"  [label="[4]", style=dashed];
"318 bert/encoder/layer_4/attention/self/Reshape_1__361" -> "790 bert/encoder/layer_4/attention/self/Reshape_1"  [label="[4]", style=dashed];
"319 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" -> "320 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"320 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" -> "321 bert/encoder/layer_4/attention/self/Reshape__360"  [label="[4]", style=dashed];
"321 bert/encoder/layer_4/attention/self/Reshape__360" -> "782 bert/encoder/layer_4/attention/self/Reshape"  [label="[4]", style=dashed];
"322 bert/encoder/layer_3/attention/self/mul_2" -> "323 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190"  [label="[]", style=dashed];
"323 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" -> "324 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192"  [label="[1]", style=dashed];
"324 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" -> "325 bert/encoder/layer_3/attention/self/Reshape_3__350"  [label="[2]", style=dashed];
"325 bert/encoder/layer_3/attention/self/Reshape_3__350" -> "711 bert/encoder/layer_3/attention/self/Reshape_3"  [label="[2]", style=dashed];
"326 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" -> "327 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"327 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" -> "328 bert/encoder/layer_3/attention/self/Reshape_2__345"  [label="[4]", style=dashed];
"328 bert/encoder/layer_3/attention/self/Reshape_2__345" -> "684 bert/encoder/layer_3/attention/self/Reshape_2"  [label="[4]", style=dashed];
"329 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" -> "330 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"330 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" -> "331 bert/encoder/layer_3/attention/self/Reshape_1__347"  [label="[4]", style=dashed];
"331 bert/encoder/layer_3/attention/self/Reshape_1__347" -> "700 bert/encoder/layer_3/attention/self/Reshape_1"  [label="[4]", style=dashed];
"332 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" -> "333 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"333 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" -> "334 bert/encoder/layer_3/attention/self/Reshape__346"  [label="[4]", style=dashed];
"334 bert/encoder/layer_3/attention/self/Reshape__346" -> "692 bert/encoder/layer_3/attention/self/Reshape"  [label="[4]", style=dashed];
"335 bert/encoder/layer_2/attention/self/mul_2" -> "336 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208"  [label="[]", style=dashed];
"336 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" -> "337 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210"  [label="[1]", style=dashed];
"337 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" -> "338 bert/encoder/layer_2/attention/self/Reshape_3__336"  [label="[2]", style=dashed];
"338 bert/encoder/layer_2/attention/self/Reshape_3__336" -> "621 bert/encoder/layer_2/attention/self/Reshape_3"  [label="[2]", style=dashed];
"339 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" -> "340 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"340 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" -> "341 bert/encoder/layer_2/attention/self/Reshape_2__331"  [label="[4]", style=dashed];
"341 bert/encoder/layer_2/attention/self/Reshape_2__331" -> "594 bert/encoder/layer_2/attention/self/Reshape_2"  [label="[4]", style=dashed];
"342 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" -> "343 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"343 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" -> "344 bert/encoder/layer_2/attention/self/Reshape_1__333"  [label="[4]", style=dashed];
"344 bert/encoder/layer_2/attention/self/Reshape_1__333" -> "610 bert/encoder/layer_2/attention/self/Reshape_1"  [label="[4]", style=dashed];
"345 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" -> "346 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"346 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" -> "347 bert/encoder/layer_2/attention/self/Reshape__332"  [label="[4]", style=dashed];
"347 bert/encoder/layer_2/attention/self/Reshape__332" -> "602 bert/encoder/layer_2/attention/self/Reshape"  [label="[4]", style=dashed];
"348 bert/encoder/layer_11/attention/self/mul_2" -> "349 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226"  [label="[]", style=dashed];
"349 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" -> "350 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228"  [label="[1]", style=dashed];
"350 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" -> "351 bert/encoder/layer_11/attention/self/Reshape_3__462"  [label="[2]", style=dashed];
"351 bert/encoder/layer_11/attention/self/Reshape_3__462" -> "1431 bert/encoder/layer_11/attention/self/Reshape_3"  [label="[2]", style=dashed];
"352 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" -> "353 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"353 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" -> "354 bert/encoder/layer_11/attention/self/Reshape_2__457"  [label="[4]", style=dashed];
"354 bert/encoder/layer_11/attention/self/Reshape_2__457" -> "1404 bert/encoder/layer_11/attention/self/Reshape_2"  [label="[4]", style=dashed];
"355 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" -> "356 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"356 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" -> "357 bert/encoder/layer_11/attention/self/Reshape_1__459"  [label="[4]", style=dashed];
"357 bert/encoder/layer_11/attention/self/Reshape_1__459" -> "1420 bert/encoder/layer_11/attention/self/Reshape_1"  [label="[4]", style=dashed];
"358 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" -> "359 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"359 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" -> "360 bert/encoder/layer_11/attention/self/Reshape__458"  [label="[4]", style=dashed];
"360 bert/encoder/layer_11/attention/self/Reshape__458" -> "1412 bert/encoder/layer_11/attention/self/Reshape"  [label="[4]", style=dashed];
"361 bert/encoder/layer_10/attention/self/mul_2" -> "362 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244"  [label="[]", style=dashed];
"362 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" -> "363 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246"  [label="[1]", style=dashed];
"363 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" -> "364 bert/encoder/layer_10/attention/self/Reshape_3__448"  [label="[2]", style=dashed];
"364 bert/encoder/layer_10/attention/self/Reshape_3__448" -> "1341 bert/encoder/layer_10/attention/self/Reshape_3"  [label="[2]", style=dashed];
"365 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" -> "366 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"366 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" -> "367 bert/encoder/layer_10/attention/self/Reshape_2__443"  [label="[4]", style=dashed];
"367 bert/encoder/layer_10/attention/self/Reshape_2__443" -> "1314 bert/encoder/layer_10/attention/self/Reshape_2"  [label="[4]", style=dashed];
"368 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" -> "369 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"369 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" -> "370 bert/encoder/layer_10/attention/self/Reshape_1__445"  [label="[4]", style=dashed];
"370 bert/encoder/layer_10/attention/self/Reshape_1__445" -> "1330 bert/encoder/layer_10/attention/self/Reshape_1"  [label="[4]", style=dashed];
"371 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" -> "372 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"372 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" -> "373 bert/encoder/layer_10/attention/self/Reshape__444"  [label="[4]", style=dashed];
"373 bert/encoder/layer_10/attention/self/Reshape__444" -> "1322 bert/encoder/layer_10/attention/self/Reshape"  [label="[4]", style=dashed];
"374 bert/encoder/layer_1/attention/self/mul_2" -> "375 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262"  [label="[]", style=dashed];
"375 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" -> "376 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264"  [label="[1]", style=dashed];
"376 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" -> "377 bert/encoder/layer_1/attention/self/Reshape_3__322"  [label="[2]", style=dashed];
"377 bert/encoder/layer_1/attention/self/Reshape_3__322" -> "531 bert/encoder/layer_1/attention/self/Reshape_3"  [label="[2]", style=dashed];
"378 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" -> "379 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"379 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" -> "380 bert/encoder/layer_1/attention/self/Reshape_2__317"  [label="[4]", style=dashed];
"380 bert/encoder/layer_1/attention/self/Reshape_2__317" -> "504 bert/encoder/layer_1/attention/self/Reshape_2"  [label="[4]", style=dashed];
"381 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" -> "382 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"382 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" -> "383 bert/encoder/layer_1/attention/self/Reshape_1__319"  [label="[4]", style=dashed];
"383 bert/encoder/layer_1/attention/self/Reshape_1__319" -> "520 bert/encoder/layer_1/attention/self/Reshape_1"  [label="[4]", style=dashed];
"384 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" -> "385 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"385 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" -> "386 bert/encoder/layer_1/attention/self/Reshape__318"  [label="[4]", style=dashed];
"386 bert/encoder/layer_1/attention/self/Reshape__318" -> "512 bert/encoder/layer_1/attention/self/Reshape"  [label="[4]", style=dashed];
"387 bert/encoder/layer_0/attention/self/mul_2" -> "388 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280"  [label="[]", style=dashed];
"388 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" -> "389 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282"  [label="[1]", style=dashed];
"389 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" -> "390 bert/encoder/layer_0/attention/self/Reshape_3__308"  [label="[2]", style=dashed];
"390 bert/encoder/layer_0/attention/self/Reshape_3__308" -> "441 bert/encoder/layer_0/attention/self/Reshape_3"  [label="[2]", style=dashed];
"391 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" -> "392 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"392 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" -> "393 bert/encoder/layer_0/attention/self/Reshape_2__303"  [label="[4]", style=dashed];
"393 bert/encoder/layer_0/attention/self/Reshape_2__303" -> "414 bert/encoder/layer_0/attention/self/Reshape_2"  [label="[4]", style=dashed];
"394 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" -> "395 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"395 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" -> "396 bert/encoder/layer_0/attention/self/Reshape_1__305"  [label="[4]", style=dashed];
"396 bert/encoder/layer_0/attention/self/Reshape_1__305" -> "430 bert/encoder/layer_0/attention/self/Reshape_1"  [label="[4]", style=dashed];
"397 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" -> "398 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"398 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" -> "399 bert/encoder/layer_0/attention/self/Reshape__304"  [label="[4]", style=dashed];
"399 bert/encoder/layer_0/attention/self/Reshape__304" -> "422 bert/encoder/layer_0/attention/self/Reshape"  [label="[4]", style=dashed];
"400 bert/encoder/Reshape_13/shape_Unsqueeze__298" -> "401 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"401 bert/encoder/Reshape_13/shape_Concat__301" -> "402 bert/encoder/Reshape_13__471"  [label="[3]", style=dashed];
"402 bert/encoder/Reshape_13__471" -> "1486 bert/encoder/Reshape_13"  [label="[3]", style=dashed];
"403 bert/encoder/Reshape_1" -> "404 QuantizeLinear_bert/encoder/Reshape_1^0_3"  [label="[]", style=solid];
"403 bert/encoder/Reshape_1" -> "406 QuantizeLinear_bert/encoder/Reshape_1^0_2"  [label="[]", style=solid];
"403 bert/encoder/Reshape_1" -> "408 QuantizeLinear_bert/encoder/Reshape_1^0_1"  [label="[]", style=solid];
"403 bert/encoder/Reshape_1" -> "446 bert/encoder/layer_0/attention/output/add"  [label="[]", style=solid];
"404 QuantizeLinear_bert/encoder/Reshape_1^0_3" -> "405 DequantizeLinear_bert/encoder/Reshape_1^0_3"  [label="[]", style=dashed];
"405 DequantizeLinear_bert/encoder/Reshape_1^0_3" -> "426 bert/encoder/layer_0/attention/self/key/MatMul"  [label="[]", style=solid];
"406 QuantizeLinear_bert/encoder/Reshape_1^0_2" -> "407 DequantizeLinear_bert/encoder/Reshape_1^0_2"  [label="[]", style=dashed];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_2" -> "418 bert/encoder/layer_0/attention/self/query/MatMul"  [label="[]", style=solid];
"408 QuantizeLinear_bert/encoder/Reshape_1^0_1" -> "409 DequantizeLinear_bert/encoder/Reshape_1^0_1"  [label="[]", style=dashed];
"409 DequantizeLinear_bert/encoder/Reshape_1^0_1" -> "412 bert/encoder/layer_0/attention/self/value/MatMul"  [label="[]", style=solid];
"410 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "411 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"411 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "412 bert/encoder/layer_0/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"412 bert/encoder/layer_0/attention/self/value/MatMul" -> "413 bert/encoder/layer_0/attention/self/value/BiasAdd"  [label="[]", style=solid];
"413 bert/encoder/layer_0/attention/self/value/BiasAdd" -> "414 bert/encoder/layer_0/attention/self/Reshape_2"  [label="[]", style=solid];
"414 bert/encoder/layer_0/attention/self/Reshape_2" -> "415 bert/encoder/layer_0/attention/self/transpose_2"  [label="[]", style=solid];
"415 bert/encoder/layer_0/attention/self/transpose_2" -> "437 bert/encoder/layer_0/attention/self/MatMul_1"  [label="[]", style=solid];
"416 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "417 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"417 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "418 bert/encoder/layer_0/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"418 bert/encoder/layer_0/attention/self/query/MatMul" -> "419 bert/encoder/layer_0/attention/self/query/BiasAdd"  [label="[]", style=solid];
"419 bert/encoder/layer_0/attention/self/query/BiasAdd" -> "420 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"420 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "421 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"421 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "422 bert/encoder/layer_0/attention/self/Reshape"  [label="[]", style=solid];
"422 bert/encoder/layer_0/attention/self/Reshape" -> "423 bert/encoder/layer_0/attention/self/transpose"  [label="[]", style=solid];
"423 bert/encoder/layer_0/attention/self/transpose" -> "433 bert/encoder/layer_0/attention/self/MatMul"  [label="[]", style=solid];
"424 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "425 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"425 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "426 bert/encoder/layer_0/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"426 bert/encoder/layer_0/attention/self/key/MatMul" -> "427 bert/encoder/layer_0/attention/self/key/BiasAdd"  [label="[]", style=solid];
"427 bert/encoder/layer_0/attention/self/key/BiasAdd" -> "428 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"428 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "429 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"429 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "430 bert/encoder/layer_0/attention/self/Reshape_1"  [label="[]", style=solid];
"430 bert/encoder/layer_0/attention/self/Reshape_1" -> "431 bert/encoder/layer_0/attention/self/transpose_1"  [label="[]", style=solid];
"431 bert/encoder/layer_0/attention/self/transpose_1" -> "432 bert/encoder/layer_0/attention/self/MatMul__306"  [label="[]", style=solid];
"432 bert/encoder/layer_0/attention/self/MatMul__306" -> "433 bert/encoder/layer_0/attention/self/MatMul"  [label="[]", style=solid];
"433 bert/encoder/layer_0/attention/self/MatMul" -> "434 bert/encoder/layer_0/attention/self/Mul"  [label="[]", style=solid];
"434 bert/encoder/layer_0/attention/self/Mul" -> "435 bert/encoder/layer_0/attention/self/add"  [label="[]", style=solid];
"435 bert/encoder/layer_0/attention/self/add" -> "436 bert/encoder/layer_0/attention/self/Softmax"  [label="[]", style=solid];
"436 bert/encoder/layer_0/attention/self/Softmax" -> "437 bert/encoder/layer_0/attention/self/MatMul_1"  [label="[]", style=solid];
"437 bert/encoder/layer_0/attention/self/MatMul_1" -> "438 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"438 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "439 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"439 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "440 bert/encoder/layer_0/attention/self/transpose_3"  [label="[]", style=solid];
"440 bert/encoder/layer_0/attention/self/transpose_3" -> "441 bert/encoder/layer_0/attention/self/Reshape_3"  [label="[]", style=solid];
"441 bert/encoder/layer_0/attention/self/Reshape_3" -> "444 bert/encoder/layer_0/attention/output/dense/MatMul"  [label="[]", style=solid];
"442 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "443 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"443 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "444 bert/encoder/layer_0/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"444 bert/encoder/layer_0/attention/output/dense/MatMul" -> "445 bert/encoder/layer_0/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"445 bert/encoder/layer_0/attention/output/dense/BiasAdd" -> "446 bert/encoder/layer_0/attention/output/add"  [label="[]", style=solid];
"446 bert/encoder/layer_0/attention/output/add" -> "447 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"446 bert/encoder/layer_0/attention/output/add" -> "449 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"446 bert/encoder/layer_0/attention/output/add" -> "458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"447 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "448 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"447 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"448 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" -> "449 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" -> "450 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309"  [label="[]", style=solid];
"450 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" -> "451 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"451 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" -> "452 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"452 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" -> "453 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"453 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" -> "454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311"  [label="[]", style=solid];
"454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" -> "455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" -> "457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" -> "459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" -> "459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "460 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "480 bert/encoder/layer_0/output/add"  [label="[]", style=solid];
"460 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "461 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"461 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "464 bert/encoder/layer_0/intermediate/dense/MatMul"  [label="[]", style=solid];
"462 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "463 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"463 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "464 bert/encoder/layer_0/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"464 bert/encoder/layer_0/intermediate/dense/MatMul" -> "465 bert/encoder/layer_0/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"465 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "466 bert/encoder/layer_0/intermediate/dense/Pow"  [label="[]", style=solid];
"465 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "468 bert/encoder/layer_0/intermediate/dense/add"  [label="[]", style=solid];
"465 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "473 bert/encoder/layer_0/intermediate/dense/mul_3"  [label="[]", style=solid];
"466 bert/encoder/layer_0/intermediate/dense/Pow" -> "467 bert/encoder/layer_0/intermediate/dense/mul"  [label="[]", style=solid];
"467 bert/encoder/layer_0/intermediate/dense/mul" -> "468 bert/encoder/layer_0/intermediate/dense/add"  [label="[]", style=solid];
"468 bert/encoder/layer_0/intermediate/dense/add" -> "469 bert/encoder/layer_0/intermediate/dense/mul_1"  [label="[]", style=solid];
"469 bert/encoder/layer_0/intermediate/dense/mul_1" -> "470 bert/encoder/layer_0/intermediate/dense/Tanh"  [label="[]", style=solid];
"470 bert/encoder/layer_0/intermediate/dense/Tanh" -> "471 bert/encoder/layer_0/intermediate/dense/add_1"  [label="[]", style=solid];
"471 bert/encoder/layer_0/intermediate/dense/add_1" -> "472 bert/encoder/layer_0/intermediate/dense/mul_2"  [label="[]", style=solid];
"472 bert/encoder/layer_0/intermediate/dense/mul_2" -> "473 bert/encoder/layer_0/intermediate/dense/mul_3"  [label="[]", style=solid];
"473 bert/encoder/layer_0/intermediate/dense/mul_3" -> "474 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"474 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "475 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"475 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "478 bert/encoder/layer_0/output/dense/MatMul"  [label="[]", style=solid];
"476 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "477 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"477 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "478 bert/encoder/layer_0/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"478 bert/encoder/layer_0/output/dense/MatMul" -> "479 bert/encoder/layer_0/output/dense/BiasAdd"  [label="[]", style=solid];
"479 bert/encoder/layer_0/output/dense/BiasAdd" -> "480 bert/encoder/layer_0/output/add"  [label="[]", style=solid];
"480 bert/encoder/layer_0/output/add" -> "481 bert/encoder/layer_0/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"480 bert/encoder/layer_0/output/add" -> "483 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"480 bert/encoder/layer_0/output/add" -> "492 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"481 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "482 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"481 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "490 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"482 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" -> "483 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"483 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" -> "484 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313"  [label="[]", style=solid];
"484 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" -> "485 bert/encoder/layer_0/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"485 bert/encoder/layer_0/output/LayerNorm/moments/variance" -> "486 bert/encoder/layer_0/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"486 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" -> "487 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"487 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" -> "488 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315"  [label="[]", style=solid];
"488 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" -> "489 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"489 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "490 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"489 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "492 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"490 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" -> "491 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" -> "493 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"492 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" -> "493 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"493 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "494 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"493 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"493 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "498 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"493 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "536 bert/encoder/layer_1/attention/output/add"  [label="[]", style=solid];
"494 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "495 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"495 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "516 bert/encoder/layer_1/attention/self/key/MatMul"  [label="[]", style=solid];
"496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "508 bert/encoder/layer_1/attention/self/query/MatMul"  [label="[]", style=solid];
"498 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "499 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"499 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "502 bert/encoder/layer_1/attention/self/value/MatMul"  [label="[]", style=solid];
"500 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "501 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"501 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "502 bert/encoder/layer_1/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"502 bert/encoder/layer_1/attention/self/value/MatMul" -> "503 bert/encoder/layer_1/attention/self/value/BiasAdd"  [label="[]", style=solid];
"503 bert/encoder/layer_1/attention/self/value/BiasAdd" -> "504 bert/encoder/layer_1/attention/self/Reshape_2"  [label="[]", style=solid];
"504 bert/encoder/layer_1/attention/self/Reshape_2" -> "505 bert/encoder/layer_1/attention/self/transpose_2"  [label="[]", style=solid];
"505 bert/encoder/layer_1/attention/self/transpose_2" -> "527 bert/encoder/layer_1/attention/self/MatMul_1"  [label="[]", style=solid];
"506 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "507 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"507 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "508 bert/encoder/layer_1/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"508 bert/encoder/layer_1/attention/self/query/MatMul" -> "509 bert/encoder/layer_1/attention/self/query/BiasAdd"  [label="[]", style=solid];
"509 bert/encoder/layer_1/attention/self/query/BiasAdd" -> "510 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"510 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "511 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"511 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "512 bert/encoder/layer_1/attention/self/Reshape"  [label="[]", style=solid];
"512 bert/encoder/layer_1/attention/self/Reshape" -> "513 bert/encoder/layer_1/attention/self/transpose"  [label="[]", style=solid];
"513 bert/encoder/layer_1/attention/self/transpose" -> "523 bert/encoder/layer_1/attention/self/MatMul"  [label="[]", style=solid];
"514 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "515 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"515 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "516 bert/encoder/layer_1/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"516 bert/encoder/layer_1/attention/self/key/MatMul" -> "517 bert/encoder/layer_1/attention/self/key/BiasAdd"  [label="[]", style=solid];
"517 bert/encoder/layer_1/attention/self/key/BiasAdd" -> "518 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"518 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "519 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"519 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "520 bert/encoder/layer_1/attention/self/Reshape_1"  [label="[]", style=solid];
"520 bert/encoder/layer_1/attention/self/Reshape_1" -> "521 bert/encoder/layer_1/attention/self/transpose_1"  [label="[]", style=solid];
"521 bert/encoder/layer_1/attention/self/transpose_1" -> "522 bert/encoder/layer_1/attention/self/MatMul__320"  [label="[]", style=solid];
"522 bert/encoder/layer_1/attention/self/MatMul__320" -> "523 bert/encoder/layer_1/attention/self/MatMul"  [label="[]", style=solid];
"523 bert/encoder/layer_1/attention/self/MatMul" -> "524 bert/encoder/layer_1/attention/self/Mul"  [label="[]", style=solid];
"524 bert/encoder/layer_1/attention/self/Mul" -> "525 bert/encoder/layer_1/attention/self/add"  [label="[]", style=solid];
"525 bert/encoder/layer_1/attention/self/add" -> "526 bert/encoder/layer_1/attention/self/Softmax"  [label="[]", style=solid];
"526 bert/encoder/layer_1/attention/self/Softmax" -> "527 bert/encoder/layer_1/attention/self/MatMul_1"  [label="[]", style=solid];
"527 bert/encoder/layer_1/attention/self/MatMul_1" -> "528 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"528 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "529 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"529 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "530 bert/encoder/layer_1/attention/self/transpose_3"  [label="[]", style=solid];
"530 bert/encoder/layer_1/attention/self/transpose_3" -> "531 bert/encoder/layer_1/attention/self/Reshape_3"  [label="[]", style=solid];
"531 bert/encoder/layer_1/attention/self/Reshape_3" -> "534 bert/encoder/layer_1/attention/output/dense/MatMul"  [label="[]", style=solid];
"532 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "533 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"533 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "534 bert/encoder/layer_1/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"534 bert/encoder/layer_1/attention/output/dense/MatMul" -> "535 bert/encoder/layer_1/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"535 bert/encoder/layer_1/attention/output/dense/BiasAdd" -> "536 bert/encoder/layer_1/attention/output/add"  [label="[]", style=solid];
"536 bert/encoder/layer_1/attention/output/add" -> "537 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"536 bert/encoder/layer_1/attention/output/add" -> "539 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"536 bert/encoder/layer_1/attention/output/add" -> "548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"537 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "538 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"537 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"538 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" -> "539 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"539 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" -> "540 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323"  [label="[]", style=solid];
"540 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" -> "541 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"541 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" -> "542 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"542 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" -> "543 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"543 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" -> "544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325"  [label="[]", style=solid];
"544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" -> "545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" -> "547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" -> "549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" -> "549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "550 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "570 bert/encoder/layer_1/output/add"  [label="[]", style=solid];
"550 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "551 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"551 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "554 bert/encoder/layer_1/intermediate/dense/MatMul"  [label="[]", style=solid];
"552 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "553 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"553 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "554 bert/encoder/layer_1/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"554 bert/encoder/layer_1/intermediate/dense/MatMul" -> "555 bert/encoder/layer_1/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"555 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "556 bert/encoder/layer_1/intermediate/dense/Pow"  [label="[]", style=solid];
"555 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "558 bert/encoder/layer_1/intermediate/dense/add"  [label="[]", style=solid];
"555 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "563 bert/encoder/layer_1/intermediate/dense/mul_3"  [label="[]", style=solid];
"556 bert/encoder/layer_1/intermediate/dense/Pow" -> "557 bert/encoder/layer_1/intermediate/dense/mul"  [label="[]", style=solid];
"557 bert/encoder/layer_1/intermediate/dense/mul" -> "558 bert/encoder/layer_1/intermediate/dense/add"  [label="[]", style=solid];
"558 bert/encoder/layer_1/intermediate/dense/add" -> "559 bert/encoder/layer_1/intermediate/dense/mul_1"  [label="[]", style=solid];
"559 bert/encoder/layer_1/intermediate/dense/mul_1" -> "560 bert/encoder/layer_1/intermediate/dense/Tanh"  [label="[]", style=solid];
"560 bert/encoder/layer_1/intermediate/dense/Tanh" -> "561 bert/encoder/layer_1/intermediate/dense/add_1"  [label="[]", style=solid];
"561 bert/encoder/layer_1/intermediate/dense/add_1" -> "562 bert/encoder/layer_1/intermediate/dense/mul_2"  [label="[]", style=solid];
"562 bert/encoder/layer_1/intermediate/dense/mul_2" -> "563 bert/encoder/layer_1/intermediate/dense/mul_3"  [label="[]", style=solid];
"563 bert/encoder/layer_1/intermediate/dense/mul_3" -> "564 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"564 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "565 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"565 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "568 bert/encoder/layer_1/output/dense/MatMul"  [label="[]", style=solid];
"566 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "567 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"567 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "568 bert/encoder/layer_1/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"568 bert/encoder/layer_1/output/dense/MatMul" -> "569 bert/encoder/layer_1/output/dense/BiasAdd"  [label="[]", style=solid];
"569 bert/encoder/layer_1/output/dense/BiasAdd" -> "570 bert/encoder/layer_1/output/add"  [label="[]", style=solid];
"570 bert/encoder/layer_1/output/add" -> "571 bert/encoder/layer_1/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"570 bert/encoder/layer_1/output/add" -> "573 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"570 bert/encoder/layer_1/output/add" -> "582 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"571 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "572 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"571 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "580 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"572 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" -> "573 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"573 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" -> "574 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327"  [label="[]", style=solid];
"574 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" -> "575 bert/encoder/layer_1/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"575 bert/encoder/layer_1/output/LayerNorm/moments/variance" -> "576 bert/encoder/layer_1/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"576 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" -> "577 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"577 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" -> "578 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329"  [label="[]", style=solid];
"578 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" -> "579 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"579 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "580 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"579 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "582 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"580 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" -> "581 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" -> "583 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"582 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" -> "583 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"583 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "584 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"583 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"583 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "588 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"583 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "626 bert/encoder/layer_2/attention/output/add"  [label="[]", style=solid];
"584 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "585 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"585 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "606 bert/encoder/layer_2/attention/self/key/MatMul"  [label="[]", style=solid];
"586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "598 bert/encoder/layer_2/attention/self/query/MatMul"  [label="[]", style=solid];
"588 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "589 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"589 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "592 bert/encoder/layer_2/attention/self/value/MatMul"  [label="[]", style=solid];
"590 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "591 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"591 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "592 bert/encoder/layer_2/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"592 bert/encoder/layer_2/attention/self/value/MatMul" -> "593 bert/encoder/layer_2/attention/self/value/BiasAdd"  [label="[]", style=solid];
"593 bert/encoder/layer_2/attention/self/value/BiasAdd" -> "594 bert/encoder/layer_2/attention/self/Reshape_2"  [label="[]", style=solid];
"594 bert/encoder/layer_2/attention/self/Reshape_2" -> "595 bert/encoder/layer_2/attention/self/transpose_2"  [label="[]", style=solid];
"595 bert/encoder/layer_2/attention/self/transpose_2" -> "617 bert/encoder/layer_2/attention/self/MatMul_1"  [label="[]", style=solid];
"596 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "597 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"597 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "598 bert/encoder/layer_2/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"598 bert/encoder/layer_2/attention/self/query/MatMul" -> "599 bert/encoder/layer_2/attention/self/query/BiasAdd"  [label="[]", style=solid];
"599 bert/encoder/layer_2/attention/self/query/BiasAdd" -> "600 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"600 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "601 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"601 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "602 bert/encoder/layer_2/attention/self/Reshape"  [label="[]", style=solid];
"602 bert/encoder/layer_2/attention/self/Reshape" -> "603 bert/encoder/layer_2/attention/self/transpose"  [label="[]", style=solid];
"603 bert/encoder/layer_2/attention/self/transpose" -> "613 bert/encoder/layer_2/attention/self/MatMul"  [label="[]", style=solid];
"604 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "605 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"605 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "606 bert/encoder/layer_2/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"606 bert/encoder/layer_2/attention/self/key/MatMul" -> "607 bert/encoder/layer_2/attention/self/key/BiasAdd"  [label="[]", style=solid];
"607 bert/encoder/layer_2/attention/self/key/BiasAdd" -> "608 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"608 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "609 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"609 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "610 bert/encoder/layer_2/attention/self/Reshape_1"  [label="[]", style=solid];
"610 bert/encoder/layer_2/attention/self/Reshape_1" -> "611 bert/encoder/layer_2/attention/self/transpose_1"  [label="[]", style=solid];
"611 bert/encoder/layer_2/attention/self/transpose_1" -> "612 bert/encoder/layer_2/attention/self/MatMul__334"  [label="[]", style=solid];
"612 bert/encoder/layer_2/attention/self/MatMul__334" -> "613 bert/encoder/layer_2/attention/self/MatMul"  [label="[]", style=solid];
"613 bert/encoder/layer_2/attention/self/MatMul" -> "614 bert/encoder/layer_2/attention/self/Mul"  [label="[]", style=solid];
"614 bert/encoder/layer_2/attention/self/Mul" -> "615 bert/encoder/layer_2/attention/self/add"  [label="[]", style=solid];
"615 bert/encoder/layer_2/attention/self/add" -> "616 bert/encoder/layer_2/attention/self/Softmax"  [label="[]", style=solid];
"616 bert/encoder/layer_2/attention/self/Softmax" -> "617 bert/encoder/layer_2/attention/self/MatMul_1"  [label="[]", style=solid];
"617 bert/encoder/layer_2/attention/self/MatMul_1" -> "618 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"618 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "619 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"619 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "620 bert/encoder/layer_2/attention/self/transpose_3"  [label="[]", style=solid];
"620 bert/encoder/layer_2/attention/self/transpose_3" -> "621 bert/encoder/layer_2/attention/self/Reshape_3"  [label="[]", style=solid];
"621 bert/encoder/layer_2/attention/self/Reshape_3" -> "624 bert/encoder/layer_2/attention/output/dense/MatMul"  [label="[]", style=solid];
"622 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "623 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"623 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "624 bert/encoder/layer_2/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"624 bert/encoder/layer_2/attention/output/dense/MatMul" -> "625 bert/encoder/layer_2/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"625 bert/encoder/layer_2/attention/output/dense/BiasAdd" -> "626 bert/encoder/layer_2/attention/output/add"  [label="[]", style=solid];
"626 bert/encoder/layer_2/attention/output/add" -> "627 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"626 bert/encoder/layer_2/attention/output/add" -> "629 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"626 bert/encoder/layer_2/attention/output/add" -> "638 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"627 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "628 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"627 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"628 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" -> "629 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"629 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" -> "630 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337"  [label="[]", style=solid];
"630 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" -> "631 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"631 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" -> "632 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"632 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" -> "633 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"633 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" -> "634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339"  [label="[]", style=solid];
"634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" -> "635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "638 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" -> "637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" -> "639 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"638 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" -> "639 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"639 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "640 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"639 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "660 bert/encoder/layer_2/output/add"  [label="[]", style=solid];
"640 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "641 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"641 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "644 bert/encoder/layer_2/intermediate/dense/MatMul"  [label="[]", style=solid];
"642 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "643 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"643 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "644 bert/encoder/layer_2/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"644 bert/encoder/layer_2/intermediate/dense/MatMul" -> "645 bert/encoder/layer_2/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"645 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "646 bert/encoder/layer_2/intermediate/dense/Pow"  [label="[]", style=solid];
"645 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "648 bert/encoder/layer_2/intermediate/dense/add"  [label="[]", style=solid];
"645 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "653 bert/encoder/layer_2/intermediate/dense/mul_3"  [label="[]", style=solid];
"646 bert/encoder/layer_2/intermediate/dense/Pow" -> "647 bert/encoder/layer_2/intermediate/dense/mul"  [label="[]", style=solid];
"647 bert/encoder/layer_2/intermediate/dense/mul" -> "648 bert/encoder/layer_2/intermediate/dense/add"  [label="[]", style=solid];
"648 bert/encoder/layer_2/intermediate/dense/add" -> "649 bert/encoder/layer_2/intermediate/dense/mul_1"  [label="[]", style=solid];
"649 bert/encoder/layer_2/intermediate/dense/mul_1" -> "650 bert/encoder/layer_2/intermediate/dense/Tanh"  [label="[]", style=solid];
"650 bert/encoder/layer_2/intermediate/dense/Tanh" -> "651 bert/encoder/layer_2/intermediate/dense/add_1"  [label="[]", style=solid];
"651 bert/encoder/layer_2/intermediate/dense/add_1" -> "652 bert/encoder/layer_2/intermediate/dense/mul_2"  [label="[]", style=solid];
"652 bert/encoder/layer_2/intermediate/dense/mul_2" -> "653 bert/encoder/layer_2/intermediate/dense/mul_3"  [label="[]", style=solid];
"653 bert/encoder/layer_2/intermediate/dense/mul_3" -> "654 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"654 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "655 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"655 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "658 bert/encoder/layer_2/output/dense/MatMul"  [label="[]", style=solid];
"656 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "657 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"657 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "658 bert/encoder/layer_2/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"658 bert/encoder/layer_2/output/dense/MatMul" -> "659 bert/encoder/layer_2/output/dense/BiasAdd"  [label="[]", style=solid];
"659 bert/encoder/layer_2/output/dense/BiasAdd" -> "660 bert/encoder/layer_2/output/add"  [label="[]", style=solid];
"660 bert/encoder/layer_2/output/add" -> "661 bert/encoder/layer_2/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"660 bert/encoder/layer_2/output/add" -> "663 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"660 bert/encoder/layer_2/output/add" -> "672 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"661 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "662 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"661 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "670 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"662 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" -> "663 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"663 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" -> "664 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341"  [label="[]", style=solid];
"664 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" -> "665 bert/encoder/layer_2/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"665 bert/encoder/layer_2/output/LayerNorm/moments/variance" -> "666 bert/encoder/layer_2/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"666 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" -> "667 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"667 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" -> "668 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343"  [label="[]", style=solid];
"668 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" -> "669 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"669 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "670 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"669 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "672 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"670 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" -> "671 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" -> "673 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"672 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" -> "673 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"673 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "674 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"673 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"673 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "678 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"673 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "716 bert/encoder/layer_3/attention/output/add"  [label="[]", style=solid];
"674 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "675 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"675 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "696 bert/encoder/layer_3/attention/self/key/MatMul"  [label="[]", style=solid];
"676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "688 bert/encoder/layer_3/attention/self/query/MatMul"  [label="[]", style=solid];
"678 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "679 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"679 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "682 bert/encoder/layer_3/attention/self/value/MatMul"  [label="[]", style=solid];
"680 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "681 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"681 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "682 bert/encoder/layer_3/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"682 bert/encoder/layer_3/attention/self/value/MatMul" -> "683 bert/encoder/layer_3/attention/self/value/BiasAdd"  [label="[]", style=solid];
"683 bert/encoder/layer_3/attention/self/value/BiasAdd" -> "684 bert/encoder/layer_3/attention/self/Reshape_2"  [label="[]", style=solid];
"684 bert/encoder/layer_3/attention/self/Reshape_2" -> "685 bert/encoder/layer_3/attention/self/transpose_2"  [label="[]", style=solid];
"685 bert/encoder/layer_3/attention/self/transpose_2" -> "707 bert/encoder/layer_3/attention/self/MatMul_1"  [label="[]", style=solid];
"686 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "687 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"687 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "688 bert/encoder/layer_3/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"688 bert/encoder/layer_3/attention/self/query/MatMul" -> "689 bert/encoder/layer_3/attention/self/query/BiasAdd"  [label="[]", style=solid];
"689 bert/encoder/layer_3/attention/self/query/BiasAdd" -> "690 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"690 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "691 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"691 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "692 bert/encoder/layer_3/attention/self/Reshape"  [label="[]", style=solid];
"692 bert/encoder/layer_3/attention/self/Reshape" -> "693 bert/encoder/layer_3/attention/self/transpose"  [label="[]", style=solid];
"693 bert/encoder/layer_3/attention/self/transpose" -> "703 bert/encoder/layer_3/attention/self/MatMul"  [label="[]", style=solid];
"694 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "695 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"695 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "696 bert/encoder/layer_3/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"696 bert/encoder/layer_3/attention/self/key/MatMul" -> "697 bert/encoder/layer_3/attention/self/key/BiasAdd"  [label="[]", style=solid];
"697 bert/encoder/layer_3/attention/self/key/BiasAdd" -> "698 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"698 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "699 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"699 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "700 bert/encoder/layer_3/attention/self/Reshape_1"  [label="[]", style=solid];
"700 bert/encoder/layer_3/attention/self/Reshape_1" -> "701 bert/encoder/layer_3/attention/self/transpose_1"  [label="[]", style=solid];
"701 bert/encoder/layer_3/attention/self/transpose_1" -> "702 bert/encoder/layer_3/attention/self/MatMul__348"  [label="[]", style=solid];
"702 bert/encoder/layer_3/attention/self/MatMul__348" -> "703 bert/encoder/layer_3/attention/self/MatMul"  [label="[]", style=solid];
"703 bert/encoder/layer_3/attention/self/MatMul" -> "704 bert/encoder/layer_3/attention/self/Mul"  [label="[]", style=solid];
"704 bert/encoder/layer_3/attention/self/Mul" -> "705 bert/encoder/layer_3/attention/self/add"  [label="[]", style=solid];
"705 bert/encoder/layer_3/attention/self/add" -> "706 bert/encoder/layer_3/attention/self/Softmax"  [label="[]", style=solid];
"706 bert/encoder/layer_3/attention/self/Softmax" -> "707 bert/encoder/layer_3/attention/self/MatMul_1"  [label="[]", style=solid];
"707 bert/encoder/layer_3/attention/self/MatMul_1" -> "708 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"708 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "709 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"709 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "710 bert/encoder/layer_3/attention/self/transpose_3"  [label="[]", style=solid];
"710 bert/encoder/layer_3/attention/self/transpose_3" -> "711 bert/encoder/layer_3/attention/self/Reshape_3"  [label="[]", style=solid];
"711 bert/encoder/layer_3/attention/self/Reshape_3" -> "714 bert/encoder/layer_3/attention/output/dense/MatMul"  [label="[]", style=solid];
"712 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "713 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"713 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "714 bert/encoder/layer_3/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"714 bert/encoder/layer_3/attention/output/dense/MatMul" -> "715 bert/encoder/layer_3/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"715 bert/encoder/layer_3/attention/output/dense/BiasAdd" -> "716 bert/encoder/layer_3/attention/output/add"  [label="[]", style=solid];
"716 bert/encoder/layer_3/attention/output/add" -> "717 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"716 bert/encoder/layer_3/attention/output/add" -> "719 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"716 bert/encoder/layer_3/attention/output/add" -> "728 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"717 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "718 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"717 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"718 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" -> "719 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"719 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" -> "720 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351"  [label="[]", style=solid];
"720 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" -> "721 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"721 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" -> "722 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"722 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" -> "723 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"723 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" -> "724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353"  [label="[]", style=solid];
"724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" -> "725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "728 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" -> "727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" -> "729 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"728 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" -> "729 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"729 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "730 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"729 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "750 bert/encoder/layer_3/output/add"  [label="[]", style=solid];
"730 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "731 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"731 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "734 bert/encoder/layer_3/intermediate/dense/MatMul"  [label="[]", style=solid];
"732 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "733 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"733 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "734 bert/encoder/layer_3/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"734 bert/encoder/layer_3/intermediate/dense/MatMul" -> "735 bert/encoder/layer_3/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"735 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "736 bert/encoder/layer_3/intermediate/dense/Pow"  [label="[]", style=solid];
"735 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "738 bert/encoder/layer_3/intermediate/dense/add"  [label="[]", style=solid];
"735 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "743 bert/encoder/layer_3/intermediate/dense/mul_3"  [label="[]", style=solid];
"736 bert/encoder/layer_3/intermediate/dense/Pow" -> "737 bert/encoder/layer_3/intermediate/dense/mul"  [label="[]", style=solid];
"737 bert/encoder/layer_3/intermediate/dense/mul" -> "738 bert/encoder/layer_3/intermediate/dense/add"  [label="[]", style=solid];
"738 bert/encoder/layer_3/intermediate/dense/add" -> "739 bert/encoder/layer_3/intermediate/dense/mul_1"  [label="[]", style=solid];
"739 bert/encoder/layer_3/intermediate/dense/mul_1" -> "740 bert/encoder/layer_3/intermediate/dense/Tanh"  [label="[]", style=solid];
"740 bert/encoder/layer_3/intermediate/dense/Tanh" -> "741 bert/encoder/layer_3/intermediate/dense/add_1"  [label="[]", style=solid];
"741 bert/encoder/layer_3/intermediate/dense/add_1" -> "742 bert/encoder/layer_3/intermediate/dense/mul_2"  [label="[]", style=solid];
"742 bert/encoder/layer_3/intermediate/dense/mul_2" -> "743 bert/encoder/layer_3/intermediate/dense/mul_3"  [label="[]", style=solid];
"743 bert/encoder/layer_3/intermediate/dense/mul_3" -> "744 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"744 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "745 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"745 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "748 bert/encoder/layer_3/output/dense/MatMul"  [label="[]", style=solid];
"746 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "747 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"747 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "748 bert/encoder/layer_3/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"748 bert/encoder/layer_3/output/dense/MatMul" -> "749 bert/encoder/layer_3/output/dense/BiasAdd"  [label="[]", style=solid];
"749 bert/encoder/layer_3/output/dense/BiasAdd" -> "750 bert/encoder/layer_3/output/add"  [label="[]", style=solid];
"750 bert/encoder/layer_3/output/add" -> "751 bert/encoder/layer_3/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"750 bert/encoder/layer_3/output/add" -> "753 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"750 bert/encoder/layer_3/output/add" -> "762 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"751 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "752 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"751 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "760 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"752 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" -> "753 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"753 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" -> "754 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355"  [label="[]", style=solid];
"754 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" -> "755 bert/encoder/layer_3/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"755 bert/encoder/layer_3/output/LayerNorm/moments/variance" -> "756 bert/encoder/layer_3/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"756 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" -> "757 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"757 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" -> "758 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357"  [label="[]", style=solid];
"758 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" -> "759 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"759 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "760 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"759 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "762 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"760 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" -> "761 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" -> "763 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"762 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" -> "763 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"763 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "764 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"763 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"763 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "768 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"763 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "806 bert/encoder/layer_4/attention/output/add"  [label="[]", style=solid];
"764 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "765 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"765 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "786 bert/encoder/layer_4/attention/self/key/MatMul"  [label="[]", style=solid];
"766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "778 bert/encoder/layer_4/attention/self/query/MatMul"  [label="[]", style=solid];
"768 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "769 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"769 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "772 bert/encoder/layer_4/attention/self/value/MatMul"  [label="[]", style=solid];
"770 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "771 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"771 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "772 bert/encoder/layer_4/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"772 bert/encoder/layer_4/attention/self/value/MatMul" -> "773 bert/encoder/layer_4/attention/self/value/BiasAdd"  [label="[]", style=solid];
"773 bert/encoder/layer_4/attention/self/value/BiasAdd" -> "774 bert/encoder/layer_4/attention/self/Reshape_2"  [label="[]", style=solid];
"774 bert/encoder/layer_4/attention/self/Reshape_2" -> "775 bert/encoder/layer_4/attention/self/transpose_2"  [label="[]", style=solid];
"775 bert/encoder/layer_4/attention/self/transpose_2" -> "797 bert/encoder/layer_4/attention/self/MatMul_1"  [label="[]", style=solid];
"776 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "777 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"777 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "778 bert/encoder/layer_4/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"778 bert/encoder/layer_4/attention/self/query/MatMul" -> "779 bert/encoder/layer_4/attention/self/query/BiasAdd"  [label="[]", style=solid];
"779 bert/encoder/layer_4/attention/self/query/BiasAdd" -> "780 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"780 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "781 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"781 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "782 bert/encoder/layer_4/attention/self/Reshape"  [label="[]", style=solid];
"782 bert/encoder/layer_4/attention/self/Reshape" -> "783 bert/encoder/layer_4/attention/self/transpose"  [label="[]", style=solid];
"783 bert/encoder/layer_4/attention/self/transpose" -> "793 bert/encoder/layer_4/attention/self/MatMul"  [label="[]", style=solid];
"784 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "785 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"785 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "786 bert/encoder/layer_4/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"786 bert/encoder/layer_4/attention/self/key/MatMul" -> "787 bert/encoder/layer_4/attention/self/key/BiasAdd"  [label="[]", style=solid];
"787 bert/encoder/layer_4/attention/self/key/BiasAdd" -> "788 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"788 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "789 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"789 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "790 bert/encoder/layer_4/attention/self/Reshape_1"  [label="[]", style=solid];
"790 bert/encoder/layer_4/attention/self/Reshape_1" -> "791 bert/encoder/layer_4/attention/self/transpose_1"  [label="[]", style=solid];
"791 bert/encoder/layer_4/attention/self/transpose_1" -> "792 bert/encoder/layer_4/attention/self/MatMul__362"  [label="[]", style=solid];
"792 bert/encoder/layer_4/attention/self/MatMul__362" -> "793 bert/encoder/layer_4/attention/self/MatMul"  [label="[]", style=solid];
"793 bert/encoder/layer_4/attention/self/MatMul" -> "794 bert/encoder/layer_4/attention/self/Mul"  [label="[]", style=solid];
"794 bert/encoder/layer_4/attention/self/Mul" -> "795 bert/encoder/layer_4/attention/self/add"  [label="[]", style=solid];
"795 bert/encoder/layer_4/attention/self/add" -> "796 bert/encoder/layer_4/attention/self/Softmax"  [label="[]", style=solid];
"796 bert/encoder/layer_4/attention/self/Softmax" -> "797 bert/encoder/layer_4/attention/self/MatMul_1"  [label="[]", style=solid];
"797 bert/encoder/layer_4/attention/self/MatMul_1" -> "798 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"798 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "799 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"799 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "800 bert/encoder/layer_4/attention/self/transpose_3"  [label="[]", style=solid];
"800 bert/encoder/layer_4/attention/self/transpose_3" -> "801 bert/encoder/layer_4/attention/self/Reshape_3"  [label="[]", style=solid];
"801 bert/encoder/layer_4/attention/self/Reshape_3" -> "804 bert/encoder/layer_4/attention/output/dense/MatMul"  [label="[]", style=solid];
"802 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "803 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"803 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "804 bert/encoder/layer_4/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"804 bert/encoder/layer_4/attention/output/dense/MatMul" -> "805 bert/encoder/layer_4/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"805 bert/encoder/layer_4/attention/output/dense/BiasAdd" -> "806 bert/encoder/layer_4/attention/output/add"  [label="[]", style=solid];
"806 bert/encoder/layer_4/attention/output/add" -> "807 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"806 bert/encoder/layer_4/attention/output/add" -> "809 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"806 bert/encoder/layer_4/attention/output/add" -> "818 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"807 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "808 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"807 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"808 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" -> "809 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"809 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" -> "810 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365"  [label="[]", style=solid];
"810 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" -> "811 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"811 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" -> "812 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"812 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" -> "813 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"813 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" -> "814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367"  [label="[]", style=solid];
"814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" -> "815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "818 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" -> "817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" -> "819 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"818 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" -> "819 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"819 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "820 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"819 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "840 bert/encoder/layer_4/output/add"  [label="[]", style=solid];
"820 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "821 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"821 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "824 bert/encoder/layer_4/intermediate/dense/MatMul"  [label="[]", style=solid];
"822 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "823 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"823 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "824 bert/encoder/layer_4/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"824 bert/encoder/layer_4/intermediate/dense/MatMul" -> "825 bert/encoder/layer_4/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"825 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "826 bert/encoder/layer_4/intermediate/dense/Pow"  [label="[]", style=solid];
"825 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "828 bert/encoder/layer_4/intermediate/dense/add"  [label="[]", style=solid];
"825 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "833 bert/encoder/layer_4/intermediate/dense/mul_3"  [label="[]", style=solid];
"826 bert/encoder/layer_4/intermediate/dense/Pow" -> "827 bert/encoder/layer_4/intermediate/dense/mul"  [label="[]", style=solid];
"827 bert/encoder/layer_4/intermediate/dense/mul" -> "828 bert/encoder/layer_4/intermediate/dense/add"  [label="[]", style=solid];
"828 bert/encoder/layer_4/intermediate/dense/add" -> "829 bert/encoder/layer_4/intermediate/dense/mul_1"  [label="[]", style=solid];
"829 bert/encoder/layer_4/intermediate/dense/mul_1" -> "830 bert/encoder/layer_4/intermediate/dense/Tanh"  [label="[]", style=solid];
"830 bert/encoder/layer_4/intermediate/dense/Tanh" -> "831 bert/encoder/layer_4/intermediate/dense/add_1"  [label="[]", style=solid];
"831 bert/encoder/layer_4/intermediate/dense/add_1" -> "832 bert/encoder/layer_4/intermediate/dense/mul_2"  [label="[]", style=solid];
"832 bert/encoder/layer_4/intermediate/dense/mul_2" -> "833 bert/encoder/layer_4/intermediate/dense/mul_3"  [label="[]", style=solid];
"833 bert/encoder/layer_4/intermediate/dense/mul_3" -> "834 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"834 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "835 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"835 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "838 bert/encoder/layer_4/output/dense/MatMul"  [label="[]", style=solid];
"836 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "837 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"837 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "838 bert/encoder/layer_4/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"838 bert/encoder/layer_4/output/dense/MatMul" -> "839 bert/encoder/layer_4/output/dense/BiasAdd"  [label="[]", style=solid];
"839 bert/encoder/layer_4/output/dense/BiasAdd" -> "840 bert/encoder/layer_4/output/add"  [label="[]", style=solid];
"840 bert/encoder/layer_4/output/add" -> "841 bert/encoder/layer_4/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"840 bert/encoder/layer_4/output/add" -> "843 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"840 bert/encoder/layer_4/output/add" -> "852 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"841 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "842 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"841 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "850 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"842 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" -> "843 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"843 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" -> "844 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369"  [label="[]", style=solid];
"844 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" -> "845 bert/encoder/layer_4/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"845 bert/encoder/layer_4/output/LayerNorm/moments/variance" -> "846 bert/encoder/layer_4/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"846 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" -> "847 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"847 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" -> "848 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371"  [label="[]", style=solid];
"848 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" -> "849 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"849 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "850 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"849 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "852 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"850 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" -> "851 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" -> "853 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"852 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" -> "853 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"853 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "854 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"853 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"853 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "858 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"853 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "896 bert/encoder/layer_5/attention/output/add"  [label="[]", style=solid];
"854 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "855 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"855 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "876 bert/encoder/layer_5/attention/self/key/MatMul"  [label="[]", style=solid];
"856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "868 bert/encoder/layer_5/attention/self/query/MatMul"  [label="[]", style=solid];
"858 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "859 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"859 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "862 bert/encoder/layer_5/attention/self/value/MatMul"  [label="[]", style=solid];
"860 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "861 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"861 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "862 bert/encoder/layer_5/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"862 bert/encoder/layer_5/attention/self/value/MatMul" -> "863 bert/encoder/layer_5/attention/self/value/BiasAdd"  [label="[]", style=solid];
"863 bert/encoder/layer_5/attention/self/value/BiasAdd" -> "864 bert/encoder/layer_5/attention/self/Reshape_2"  [label="[]", style=solid];
"864 bert/encoder/layer_5/attention/self/Reshape_2" -> "865 bert/encoder/layer_5/attention/self/transpose_2"  [label="[]", style=solid];
"865 bert/encoder/layer_5/attention/self/transpose_2" -> "887 bert/encoder/layer_5/attention/self/MatMul_1"  [label="[]", style=solid];
"866 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "867 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"867 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "868 bert/encoder/layer_5/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"868 bert/encoder/layer_5/attention/self/query/MatMul" -> "869 bert/encoder/layer_5/attention/self/query/BiasAdd"  [label="[]", style=solid];
"869 bert/encoder/layer_5/attention/self/query/BiasAdd" -> "870 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"870 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "871 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"871 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "872 bert/encoder/layer_5/attention/self/Reshape"  [label="[]", style=solid];
"872 bert/encoder/layer_5/attention/self/Reshape" -> "873 bert/encoder/layer_5/attention/self/transpose"  [label="[]", style=solid];
"873 bert/encoder/layer_5/attention/self/transpose" -> "883 bert/encoder/layer_5/attention/self/MatMul"  [label="[]", style=solid];
"874 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "875 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"875 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "876 bert/encoder/layer_5/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"876 bert/encoder/layer_5/attention/self/key/MatMul" -> "877 bert/encoder/layer_5/attention/self/key/BiasAdd"  [label="[]", style=solid];
"877 bert/encoder/layer_5/attention/self/key/BiasAdd" -> "878 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"878 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "879 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"879 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "880 bert/encoder/layer_5/attention/self/Reshape_1"  [label="[]", style=solid];
"880 bert/encoder/layer_5/attention/self/Reshape_1" -> "881 bert/encoder/layer_5/attention/self/transpose_1"  [label="[]", style=solid];
"881 bert/encoder/layer_5/attention/self/transpose_1" -> "882 bert/encoder/layer_5/attention/self/MatMul__376"  [label="[]", style=solid];
"882 bert/encoder/layer_5/attention/self/MatMul__376" -> "883 bert/encoder/layer_5/attention/self/MatMul"  [label="[]", style=solid];
"883 bert/encoder/layer_5/attention/self/MatMul" -> "884 bert/encoder/layer_5/attention/self/Mul"  [label="[]", style=solid];
"884 bert/encoder/layer_5/attention/self/Mul" -> "885 bert/encoder/layer_5/attention/self/add"  [label="[]", style=solid];
"885 bert/encoder/layer_5/attention/self/add" -> "886 bert/encoder/layer_5/attention/self/Softmax"  [label="[]", style=solid];
"886 bert/encoder/layer_5/attention/self/Softmax" -> "887 bert/encoder/layer_5/attention/self/MatMul_1"  [label="[]", style=solid];
"887 bert/encoder/layer_5/attention/self/MatMul_1" -> "888 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"888 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "889 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"889 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "890 bert/encoder/layer_5/attention/self/transpose_3"  [label="[]", style=solid];
"890 bert/encoder/layer_5/attention/self/transpose_3" -> "891 bert/encoder/layer_5/attention/self/Reshape_3"  [label="[]", style=solid];
"891 bert/encoder/layer_5/attention/self/Reshape_3" -> "894 bert/encoder/layer_5/attention/output/dense/MatMul"  [label="[]", style=solid];
"892 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "893 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"893 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "894 bert/encoder/layer_5/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"894 bert/encoder/layer_5/attention/output/dense/MatMul" -> "895 bert/encoder/layer_5/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"895 bert/encoder/layer_5/attention/output/dense/BiasAdd" -> "896 bert/encoder/layer_5/attention/output/add"  [label="[]", style=solid];
"896 bert/encoder/layer_5/attention/output/add" -> "897 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"896 bert/encoder/layer_5/attention/output/add" -> "899 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"896 bert/encoder/layer_5/attention/output/add" -> "908 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"897 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "898 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"897 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"898 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" -> "899 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"899 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" -> "900 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379"  [label="[]", style=solid];
"900 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" -> "901 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"901 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" -> "902 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"902 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" -> "903 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"903 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" -> "904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381"  [label="[]", style=solid];
"904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" -> "905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "908 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" -> "907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" -> "909 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"908 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" -> "909 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"909 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "910 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"909 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "930 bert/encoder/layer_5/output/add"  [label="[]", style=solid];
"910 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "911 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"911 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "914 bert/encoder/layer_5/intermediate/dense/MatMul"  [label="[]", style=solid];
"912 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "913 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"913 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "914 bert/encoder/layer_5/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"914 bert/encoder/layer_5/intermediate/dense/MatMul" -> "915 bert/encoder/layer_5/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"915 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "916 bert/encoder/layer_5/intermediate/dense/Pow"  [label="[]", style=solid];
"915 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "918 bert/encoder/layer_5/intermediate/dense/add"  [label="[]", style=solid];
"915 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "923 bert/encoder/layer_5/intermediate/dense/mul_3"  [label="[]", style=solid];
"916 bert/encoder/layer_5/intermediate/dense/Pow" -> "917 bert/encoder/layer_5/intermediate/dense/mul"  [label="[]", style=solid];
"917 bert/encoder/layer_5/intermediate/dense/mul" -> "918 bert/encoder/layer_5/intermediate/dense/add"  [label="[]", style=solid];
"918 bert/encoder/layer_5/intermediate/dense/add" -> "919 bert/encoder/layer_5/intermediate/dense/mul_1"  [label="[]", style=solid];
"919 bert/encoder/layer_5/intermediate/dense/mul_1" -> "920 bert/encoder/layer_5/intermediate/dense/Tanh"  [label="[]", style=solid];
"920 bert/encoder/layer_5/intermediate/dense/Tanh" -> "921 bert/encoder/layer_5/intermediate/dense/add_1"  [label="[]", style=solid];
"921 bert/encoder/layer_5/intermediate/dense/add_1" -> "922 bert/encoder/layer_5/intermediate/dense/mul_2"  [label="[]", style=solid];
"922 bert/encoder/layer_5/intermediate/dense/mul_2" -> "923 bert/encoder/layer_5/intermediate/dense/mul_3"  [label="[]", style=solid];
"923 bert/encoder/layer_5/intermediate/dense/mul_3" -> "924 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"924 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "925 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"925 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "928 bert/encoder/layer_5/output/dense/MatMul"  [label="[]", style=solid];
"926 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "927 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"927 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "928 bert/encoder/layer_5/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"928 bert/encoder/layer_5/output/dense/MatMul" -> "929 bert/encoder/layer_5/output/dense/BiasAdd"  [label="[]", style=solid];
"929 bert/encoder/layer_5/output/dense/BiasAdd" -> "930 bert/encoder/layer_5/output/add"  [label="[]", style=solid];
"930 bert/encoder/layer_5/output/add" -> "931 bert/encoder/layer_5/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"930 bert/encoder/layer_5/output/add" -> "933 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"930 bert/encoder/layer_5/output/add" -> "942 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"931 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "932 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"931 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "940 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"932 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" -> "933 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"933 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" -> "934 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383"  [label="[]", style=solid];
"934 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" -> "935 bert/encoder/layer_5/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"935 bert/encoder/layer_5/output/LayerNorm/moments/variance" -> "936 bert/encoder/layer_5/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"936 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" -> "937 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"937 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" -> "938 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385"  [label="[]", style=solid];
"938 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" -> "939 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"939 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "940 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"939 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "942 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"940 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" -> "941 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" -> "943 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"942 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" -> "943 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"943 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "944 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"943 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"943 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "948 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"943 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "986 bert/encoder/layer_6/attention/output/add"  [label="[]", style=solid];
"944 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "945 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"945 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "966 bert/encoder/layer_6/attention/self/key/MatMul"  [label="[]", style=solid];
"946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "958 bert/encoder/layer_6/attention/self/query/MatMul"  [label="[]", style=solid];
"948 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "949 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"949 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "952 bert/encoder/layer_6/attention/self/value/MatMul"  [label="[]", style=solid];
"950 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "951 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"951 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "952 bert/encoder/layer_6/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"952 bert/encoder/layer_6/attention/self/value/MatMul" -> "953 bert/encoder/layer_6/attention/self/value/BiasAdd"  [label="[]", style=solid];
"953 bert/encoder/layer_6/attention/self/value/BiasAdd" -> "954 bert/encoder/layer_6/attention/self/Reshape_2"  [label="[]", style=solid];
"954 bert/encoder/layer_6/attention/self/Reshape_2" -> "955 bert/encoder/layer_6/attention/self/transpose_2"  [label="[]", style=solid];
"955 bert/encoder/layer_6/attention/self/transpose_2" -> "977 bert/encoder/layer_6/attention/self/MatMul_1"  [label="[]", style=solid];
"956 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "957 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"957 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "958 bert/encoder/layer_6/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"958 bert/encoder/layer_6/attention/self/query/MatMul" -> "959 bert/encoder/layer_6/attention/self/query/BiasAdd"  [label="[]", style=solid];
"959 bert/encoder/layer_6/attention/self/query/BiasAdd" -> "960 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"960 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "961 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"961 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "962 bert/encoder/layer_6/attention/self/Reshape"  [label="[]", style=solid];
"962 bert/encoder/layer_6/attention/self/Reshape" -> "963 bert/encoder/layer_6/attention/self/transpose"  [label="[]", style=solid];
"963 bert/encoder/layer_6/attention/self/transpose" -> "973 bert/encoder/layer_6/attention/self/MatMul"  [label="[]", style=solid];
"964 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "965 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"965 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "966 bert/encoder/layer_6/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"966 bert/encoder/layer_6/attention/self/key/MatMul" -> "967 bert/encoder/layer_6/attention/self/key/BiasAdd"  [label="[]", style=solid];
"967 bert/encoder/layer_6/attention/self/key/BiasAdd" -> "968 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"968 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "969 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"969 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "970 bert/encoder/layer_6/attention/self/Reshape_1"  [label="[]", style=solid];
"970 bert/encoder/layer_6/attention/self/Reshape_1" -> "971 bert/encoder/layer_6/attention/self/transpose_1"  [label="[]", style=solid];
"971 bert/encoder/layer_6/attention/self/transpose_1" -> "972 bert/encoder/layer_6/attention/self/MatMul__390"  [label="[]", style=solid];
"972 bert/encoder/layer_6/attention/self/MatMul__390" -> "973 bert/encoder/layer_6/attention/self/MatMul"  [label="[]", style=solid];
"973 bert/encoder/layer_6/attention/self/MatMul" -> "974 bert/encoder/layer_6/attention/self/Mul"  [label="[]", style=solid];
"974 bert/encoder/layer_6/attention/self/Mul" -> "975 bert/encoder/layer_6/attention/self/add"  [label="[]", style=solid];
"975 bert/encoder/layer_6/attention/self/add" -> "976 bert/encoder/layer_6/attention/self/Softmax"  [label="[]", style=solid];
"976 bert/encoder/layer_6/attention/self/Softmax" -> "977 bert/encoder/layer_6/attention/self/MatMul_1"  [label="[]", style=solid];
"977 bert/encoder/layer_6/attention/self/MatMul_1" -> "978 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"978 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "979 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"979 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "980 bert/encoder/layer_6/attention/self/transpose_3"  [label="[]", style=solid];
"980 bert/encoder/layer_6/attention/self/transpose_3" -> "981 bert/encoder/layer_6/attention/self/Reshape_3"  [label="[]", style=solid];
"981 bert/encoder/layer_6/attention/self/Reshape_3" -> "984 bert/encoder/layer_6/attention/output/dense/MatMul"  [label="[]", style=solid];
"982 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "983 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"983 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "984 bert/encoder/layer_6/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"984 bert/encoder/layer_6/attention/output/dense/MatMul" -> "985 bert/encoder/layer_6/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"985 bert/encoder/layer_6/attention/output/dense/BiasAdd" -> "986 bert/encoder/layer_6/attention/output/add"  [label="[]", style=solid];
"986 bert/encoder/layer_6/attention/output/add" -> "987 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"986 bert/encoder/layer_6/attention/output/add" -> "989 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"986 bert/encoder/layer_6/attention/output/add" -> "998 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"987 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "988 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"987 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"988 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" -> "989 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"989 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" -> "990 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393"  [label="[]", style=solid];
"990 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" -> "991 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"991 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" -> "992 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"992 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" -> "993 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"993 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" -> "994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395"  [label="[]", style=solid];
"994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" -> "995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "998 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" -> "997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" -> "999 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"998 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" -> "999 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"999 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1000 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"999 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1020 bert/encoder/layer_6/output/add"  [label="[]", style=solid];
"1000 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1001 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1001 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1004 bert/encoder/layer_6/intermediate/dense/MatMul"  [label="[]", style=solid];
"1002 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1003 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1003 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1004 bert/encoder/layer_6/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1004 bert/encoder/layer_6/intermediate/dense/MatMul" -> "1005 bert/encoder/layer_6/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1005 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1006 bert/encoder/layer_6/intermediate/dense/Pow"  [label="[]", style=solid];
"1005 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1008 bert/encoder/layer_6/intermediate/dense/add"  [label="[]", style=solid];
"1005 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1013 bert/encoder/layer_6/intermediate/dense/mul_3"  [label="[]", style=solid];
"1006 bert/encoder/layer_6/intermediate/dense/Pow" -> "1007 bert/encoder/layer_6/intermediate/dense/mul"  [label="[]", style=solid];
"1007 bert/encoder/layer_6/intermediate/dense/mul" -> "1008 bert/encoder/layer_6/intermediate/dense/add"  [label="[]", style=solid];
"1008 bert/encoder/layer_6/intermediate/dense/add" -> "1009 bert/encoder/layer_6/intermediate/dense/mul_1"  [label="[]", style=solid];
"1009 bert/encoder/layer_6/intermediate/dense/mul_1" -> "1010 bert/encoder/layer_6/intermediate/dense/Tanh"  [label="[]", style=solid];
"1010 bert/encoder/layer_6/intermediate/dense/Tanh" -> "1011 bert/encoder/layer_6/intermediate/dense/add_1"  [label="[]", style=solid];
"1011 bert/encoder/layer_6/intermediate/dense/add_1" -> "1012 bert/encoder/layer_6/intermediate/dense/mul_2"  [label="[]", style=solid];
"1012 bert/encoder/layer_6/intermediate/dense/mul_2" -> "1013 bert/encoder/layer_6/intermediate/dense/mul_3"  [label="[]", style=solid];
"1013 bert/encoder/layer_6/intermediate/dense/mul_3" -> "1014 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1014 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1015 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1015 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1018 bert/encoder/layer_6/output/dense/MatMul"  [label="[]", style=solid];
"1016 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1017 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1017 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1018 bert/encoder/layer_6/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1018 bert/encoder/layer_6/output/dense/MatMul" -> "1019 bert/encoder/layer_6/output/dense/BiasAdd"  [label="[]", style=solid];
"1019 bert/encoder/layer_6/output/dense/BiasAdd" -> "1020 bert/encoder/layer_6/output/add"  [label="[]", style=solid];
"1020 bert/encoder/layer_6/output/add" -> "1021 bert/encoder/layer_6/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1020 bert/encoder/layer_6/output/add" -> "1023 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1020 bert/encoder/layer_6/output/add" -> "1032 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1021 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1022 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1021 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1022 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" -> "1023 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1023 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" -> "1024 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397"  [label="[]", style=solid];
"1024 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" -> "1025 bert/encoder/layer_6/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1025 bert/encoder/layer_6/output/LayerNorm/moments/variance" -> "1026 bert/encoder/layer_6/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1026 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" -> "1027 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1027 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" -> "1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399"  [label="[]", style=solid];
"1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" -> "1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1032 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" -> "1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" -> "1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1032 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" -> "1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1034 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1038 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1076 bert/encoder/layer_7/attention/output/add"  [label="[]", style=solid];
"1034 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1035 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1035 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1056 bert/encoder/layer_7/attention/self/key/MatMul"  [label="[]", style=solid];
"1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1048 bert/encoder/layer_7/attention/self/query/MatMul"  [label="[]", style=solid];
"1038 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1039 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1039 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1042 bert/encoder/layer_7/attention/self/value/MatMul"  [label="[]", style=solid];
"1040 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1041 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1041 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1042 bert/encoder/layer_7/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1042 bert/encoder/layer_7/attention/self/value/MatMul" -> "1043 bert/encoder/layer_7/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1043 bert/encoder/layer_7/attention/self/value/BiasAdd" -> "1044 bert/encoder/layer_7/attention/self/Reshape_2"  [label="[]", style=solid];
"1044 bert/encoder/layer_7/attention/self/Reshape_2" -> "1045 bert/encoder/layer_7/attention/self/transpose_2"  [label="[]", style=solid];
"1045 bert/encoder/layer_7/attention/self/transpose_2" -> "1067 bert/encoder/layer_7/attention/self/MatMul_1"  [label="[]", style=solid];
"1046 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1047 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1047 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1048 bert/encoder/layer_7/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1048 bert/encoder/layer_7/attention/self/query/MatMul" -> "1049 bert/encoder/layer_7/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1049 bert/encoder/layer_7/attention/self/query/BiasAdd" -> "1050 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1050 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1051 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1051 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1052 bert/encoder/layer_7/attention/self/Reshape"  [label="[]", style=solid];
"1052 bert/encoder/layer_7/attention/self/Reshape" -> "1053 bert/encoder/layer_7/attention/self/transpose"  [label="[]", style=solid];
"1053 bert/encoder/layer_7/attention/self/transpose" -> "1063 bert/encoder/layer_7/attention/self/MatMul"  [label="[]", style=solid];
"1054 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1055 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1055 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1056 bert/encoder/layer_7/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1056 bert/encoder/layer_7/attention/self/key/MatMul" -> "1057 bert/encoder/layer_7/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1057 bert/encoder/layer_7/attention/self/key/BiasAdd" -> "1058 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1058 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1059 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1059 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1060 bert/encoder/layer_7/attention/self/Reshape_1"  [label="[]", style=solid];
"1060 bert/encoder/layer_7/attention/self/Reshape_1" -> "1061 bert/encoder/layer_7/attention/self/transpose_1"  [label="[]", style=solid];
"1061 bert/encoder/layer_7/attention/self/transpose_1" -> "1062 bert/encoder/layer_7/attention/self/MatMul__404"  [label="[]", style=solid];
"1062 bert/encoder/layer_7/attention/self/MatMul__404" -> "1063 bert/encoder/layer_7/attention/self/MatMul"  [label="[]", style=solid];
"1063 bert/encoder/layer_7/attention/self/MatMul" -> "1064 bert/encoder/layer_7/attention/self/Mul"  [label="[]", style=solid];
"1064 bert/encoder/layer_7/attention/self/Mul" -> "1065 bert/encoder/layer_7/attention/self/add"  [label="[]", style=solid];
"1065 bert/encoder/layer_7/attention/self/add" -> "1066 bert/encoder/layer_7/attention/self/Softmax"  [label="[]", style=solid];
"1066 bert/encoder/layer_7/attention/self/Softmax" -> "1067 bert/encoder/layer_7/attention/self/MatMul_1"  [label="[]", style=solid];
"1067 bert/encoder/layer_7/attention/self/MatMul_1" -> "1068 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1068 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1069 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1069 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1070 bert/encoder/layer_7/attention/self/transpose_3"  [label="[]", style=solid];
"1070 bert/encoder/layer_7/attention/self/transpose_3" -> "1071 bert/encoder/layer_7/attention/self/Reshape_3"  [label="[]", style=solid];
"1071 bert/encoder/layer_7/attention/self/Reshape_3" -> "1074 bert/encoder/layer_7/attention/output/dense/MatMul"  [label="[]", style=solid];
"1072 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1073 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1073 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1074 bert/encoder/layer_7/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1074 bert/encoder/layer_7/attention/output/dense/MatMul" -> "1075 bert/encoder/layer_7/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1075 bert/encoder/layer_7/attention/output/dense/BiasAdd" -> "1076 bert/encoder/layer_7/attention/output/add"  [label="[]", style=solid];
"1076 bert/encoder/layer_7/attention/output/add" -> "1077 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1076 bert/encoder/layer_7/attention/output/add" -> "1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1076 bert/encoder/layer_7/attention/output/add" -> "1088 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1077 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1078 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1077 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1078 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" -> "1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" -> "1080 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407"  [label="[]", style=solid];
"1080 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" -> "1081 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1081 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" -> "1082 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1082 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" -> "1083 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1083 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409"  [label="[]", style=solid];
"1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" -> "1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1088 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" -> "1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" -> "1089 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1088 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" -> "1089 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1089 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1090 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1089 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1110 bert/encoder/layer_7/output/add"  [label="[]", style=solid];
"1090 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1091 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1091 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1094 bert/encoder/layer_7/intermediate/dense/MatMul"  [label="[]", style=solid];
"1092 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1093 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1093 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1094 bert/encoder/layer_7/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1094 bert/encoder/layer_7/intermediate/dense/MatMul" -> "1095 bert/encoder/layer_7/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1095 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1096 bert/encoder/layer_7/intermediate/dense/Pow"  [label="[]", style=solid];
"1095 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1098 bert/encoder/layer_7/intermediate/dense/add"  [label="[]", style=solid];
"1095 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1103 bert/encoder/layer_7/intermediate/dense/mul_3"  [label="[]", style=solid];
"1096 bert/encoder/layer_7/intermediate/dense/Pow" -> "1097 bert/encoder/layer_7/intermediate/dense/mul"  [label="[]", style=solid];
"1097 bert/encoder/layer_7/intermediate/dense/mul" -> "1098 bert/encoder/layer_7/intermediate/dense/add"  [label="[]", style=solid];
"1098 bert/encoder/layer_7/intermediate/dense/add" -> "1099 bert/encoder/layer_7/intermediate/dense/mul_1"  [label="[]", style=solid];
"1099 bert/encoder/layer_7/intermediate/dense/mul_1" -> "1100 bert/encoder/layer_7/intermediate/dense/Tanh"  [label="[]", style=solid];
"1100 bert/encoder/layer_7/intermediate/dense/Tanh" -> "1101 bert/encoder/layer_7/intermediate/dense/add_1"  [label="[]", style=solid];
"1101 bert/encoder/layer_7/intermediate/dense/add_1" -> "1102 bert/encoder/layer_7/intermediate/dense/mul_2"  [label="[]", style=solid];
"1102 bert/encoder/layer_7/intermediate/dense/mul_2" -> "1103 bert/encoder/layer_7/intermediate/dense/mul_3"  [label="[]", style=solid];
"1103 bert/encoder/layer_7/intermediate/dense/mul_3" -> "1104 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1104 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1105 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1105 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1108 bert/encoder/layer_7/output/dense/MatMul"  [label="[]", style=solid];
"1106 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1107 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1107 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1108 bert/encoder/layer_7/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1108 bert/encoder/layer_7/output/dense/MatMul" -> "1109 bert/encoder/layer_7/output/dense/BiasAdd"  [label="[]", style=solid];
"1109 bert/encoder/layer_7/output/dense/BiasAdd" -> "1110 bert/encoder/layer_7/output/add"  [label="[]", style=solid];
"1110 bert/encoder/layer_7/output/add" -> "1111 bert/encoder/layer_7/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1110 bert/encoder/layer_7/output/add" -> "1113 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1110 bert/encoder/layer_7/output/add" -> "1122 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1111 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1112 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1111 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1112 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" -> "1113 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1113 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" -> "1114 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411"  [label="[]", style=solid];
"1114 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" -> "1115 bert/encoder/layer_7/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1115 bert/encoder/layer_7/output/LayerNorm/moments/variance" -> "1116 bert/encoder/layer_7/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1116 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" -> "1117 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1117 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" -> "1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413"  [label="[]", style=solid];
"1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" -> "1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1122 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" -> "1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" -> "1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1122 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" -> "1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1124 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1128 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1166 bert/encoder/layer_8/attention/output/add"  [label="[]", style=solid];
"1124 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1125 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1125 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1146 bert/encoder/layer_8/attention/self/key/MatMul"  [label="[]", style=solid];
"1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1138 bert/encoder/layer_8/attention/self/query/MatMul"  [label="[]", style=solid];
"1128 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1129 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1129 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1132 bert/encoder/layer_8/attention/self/value/MatMul"  [label="[]", style=solid];
"1130 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1131 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1131 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1132 bert/encoder/layer_8/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1132 bert/encoder/layer_8/attention/self/value/MatMul" -> "1133 bert/encoder/layer_8/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1133 bert/encoder/layer_8/attention/self/value/BiasAdd" -> "1134 bert/encoder/layer_8/attention/self/Reshape_2"  [label="[]", style=solid];
"1134 bert/encoder/layer_8/attention/self/Reshape_2" -> "1135 bert/encoder/layer_8/attention/self/transpose_2"  [label="[]", style=solid];
"1135 bert/encoder/layer_8/attention/self/transpose_2" -> "1157 bert/encoder/layer_8/attention/self/MatMul_1"  [label="[]", style=solid];
"1136 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1137 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1137 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1138 bert/encoder/layer_8/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1138 bert/encoder/layer_8/attention/self/query/MatMul" -> "1139 bert/encoder/layer_8/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1139 bert/encoder/layer_8/attention/self/query/BiasAdd" -> "1140 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1140 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1141 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1141 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1142 bert/encoder/layer_8/attention/self/Reshape"  [label="[]", style=solid];
"1142 bert/encoder/layer_8/attention/self/Reshape" -> "1143 bert/encoder/layer_8/attention/self/transpose"  [label="[]", style=solid];
"1143 bert/encoder/layer_8/attention/self/transpose" -> "1153 bert/encoder/layer_8/attention/self/MatMul"  [label="[]", style=solid];
"1144 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1145 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1145 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1146 bert/encoder/layer_8/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1146 bert/encoder/layer_8/attention/self/key/MatMul" -> "1147 bert/encoder/layer_8/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1147 bert/encoder/layer_8/attention/self/key/BiasAdd" -> "1148 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1148 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1149 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1149 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1150 bert/encoder/layer_8/attention/self/Reshape_1"  [label="[]", style=solid];
"1150 bert/encoder/layer_8/attention/self/Reshape_1" -> "1151 bert/encoder/layer_8/attention/self/transpose_1"  [label="[]", style=solid];
"1151 bert/encoder/layer_8/attention/self/transpose_1" -> "1152 bert/encoder/layer_8/attention/self/MatMul__418"  [label="[]", style=solid];
"1152 bert/encoder/layer_8/attention/self/MatMul__418" -> "1153 bert/encoder/layer_8/attention/self/MatMul"  [label="[]", style=solid];
"1153 bert/encoder/layer_8/attention/self/MatMul" -> "1154 bert/encoder/layer_8/attention/self/Mul"  [label="[]", style=solid];
"1154 bert/encoder/layer_8/attention/self/Mul" -> "1155 bert/encoder/layer_8/attention/self/add"  [label="[]", style=solid];
"1155 bert/encoder/layer_8/attention/self/add" -> "1156 bert/encoder/layer_8/attention/self/Softmax"  [label="[]", style=solid];
"1156 bert/encoder/layer_8/attention/self/Softmax" -> "1157 bert/encoder/layer_8/attention/self/MatMul_1"  [label="[]", style=solid];
"1157 bert/encoder/layer_8/attention/self/MatMul_1" -> "1158 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1158 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1159 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1159 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1160 bert/encoder/layer_8/attention/self/transpose_3"  [label="[]", style=solid];
"1160 bert/encoder/layer_8/attention/self/transpose_3" -> "1161 bert/encoder/layer_8/attention/self/Reshape_3"  [label="[]", style=solid];
"1161 bert/encoder/layer_8/attention/self/Reshape_3" -> "1164 bert/encoder/layer_8/attention/output/dense/MatMul"  [label="[]", style=solid];
"1162 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1163 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1163 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1164 bert/encoder/layer_8/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1164 bert/encoder/layer_8/attention/output/dense/MatMul" -> "1165 bert/encoder/layer_8/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1165 bert/encoder/layer_8/attention/output/dense/BiasAdd" -> "1166 bert/encoder/layer_8/attention/output/add"  [label="[]", style=solid];
"1166 bert/encoder/layer_8/attention/output/add" -> "1167 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1166 bert/encoder/layer_8/attention/output/add" -> "1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1166 bert/encoder/layer_8/attention/output/add" -> "1178 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1167 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1168 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1167 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1168 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" -> "1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" -> "1170 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421"  [label="[]", style=solid];
"1170 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" -> "1171 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1171 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" -> "1172 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1172 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" -> "1173 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1173 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423"  [label="[]", style=solid];
"1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" -> "1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1178 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" -> "1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" -> "1179 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1178 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" -> "1179 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1179 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1180 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1179 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1200 bert/encoder/layer_8/output/add"  [label="[]", style=solid];
"1180 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1181 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1181 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1184 bert/encoder/layer_8/intermediate/dense/MatMul"  [label="[]", style=solid];
"1182 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1183 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1183 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1184 bert/encoder/layer_8/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1184 bert/encoder/layer_8/intermediate/dense/MatMul" -> "1185 bert/encoder/layer_8/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1185 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1186 bert/encoder/layer_8/intermediate/dense/Pow"  [label="[]", style=solid];
"1185 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1188 bert/encoder/layer_8/intermediate/dense/add"  [label="[]", style=solid];
"1185 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1193 bert/encoder/layer_8/intermediate/dense/mul_3"  [label="[]", style=solid];
"1186 bert/encoder/layer_8/intermediate/dense/Pow" -> "1187 bert/encoder/layer_8/intermediate/dense/mul"  [label="[]", style=solid];
"1187 bert/encoder/layer_8/intermediate/dense/mul" -> "1188 bert/encoder/layer_8/intermediate/dense/add"  [label="[]", style=solid];
"1188 bert/encoder/layer_8/intermediate/dense/add" -> "1189 bert/encoder/layer_8/intermediate/dense/mul_1"  [label="[]", style=solid];
"1189 bert/encoder/layer_8/intermediate/dense/mul_1" -> "1190 bert/encoder/layer_8/intermediate/dense/Tanh"  [label="[]", style=solid];
"1190 bert/encoder/layer_8/intermediate/dense/Tanh" -> "1191 bert/encoder/layer_8/intermediate/dense/add_1"  [label="[]", style=solid];
"1191 bert/encoder/layer_8/intermediate/dense/add_1" -> "1192 bert/encoder/layer_8/intermediate/dense/mul_2"  [label="[]", style=solid];
"1192 bert/encoder/layer_8/intermediate/dense/mul_2" -> "1193 bert/encoder/layer_8/intermediate/dense/mul_3"  [label="[]", style=solid];
"1193 bert/encoder/layer_8/intermediate/dense/mul_3" -> "1194 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1194 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1195 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1195 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1198 bert/encoder/layer_8/output/dense/MatMul"  [label="[]", style=solid];
"1196 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1197 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1197 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1198 bert/encoder/layer_8/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1198 bert/encoder/layer_8/output/dense/MatMul" -> "1199 bert/encoder/layer_8/output/dense/BiasAdd"  [label="[]", style=solid];
"1199 bert/encoder/layer_8/output/dense/BiasAdd" -> "1200 bert/encoder/layer_8/output/add"  [label="[]", style=solid];
"1200 bert/encoder/layer_8/output/add" -> "1201 bert/encoder/layer_8/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1200 bert/encoder/layer_8/output/add" -> "1203 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1200 bert/encoder/layer_8/output/add" -> "1212 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1201 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1202 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1201 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1202 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" -> "1203 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1203 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" -> "1204 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425"  [label="[]", style=solid];
"1204 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" -> "1205 bert/encoder/layer_8/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1205 bert/encoder/layer_8/output/LayerNorm/moments/variance" -> "1206 bert/encoder/layer_8/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1206 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" -> "1207 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1207 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" -> "1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427"  [label="[]", style=solid];
"1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" -> "1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1212 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" -> "1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" -> "1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1212 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" -> "1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1214 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1218 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1256 bert/encoder/layer_9/attention/output/add"  [label="[]", style=solid];
"1214 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1215 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1215 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1236 bert/encoder/layer_9/attention/self/key/MatMul"  [label="[]", style=solid];
"1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1228 bert/encoder/layer_9/attention/self/query/MatMul"  [label="[]", style=solid];
"1218 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1219 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1219 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1222 bert/encoder/layer_9/attention/self/value/MatMul"  [label="[]", style=solid];
"1220 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1221 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1221 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1222 bert/encoder/layer_9/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1222 bert/encoder/layer_9/attention/self/value/MatMul" -> "1223 bert/encoder/layer_9/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1223 bert/encoder/layer_9/attention/self/value/BiasAdd" -> "1224 bert/encoder/layer_9/attention/self/Reshape_2"  [label="[]", style=solid];
"1224 bert/encoder/layer_9/attention/self/Reshape_2" -> "1225 bert/encoder/layer_9/attention/self/transpose_2"  [label="[]", style=solid];
"1225 bert/encoder/layer_9/attention/self/transpose_2" -> "1247 bert/encoder/layer_9/attention/self/MatMul_1"  [label="[]", style=solid];
"1226 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1227 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1227 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1228 bert/encoder/layer_9/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1228 bert/encoder/layer_9/attention/self/query/MatMul" -> "1229 bert/encoder/layer_9/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1229 bert/encoder/layer_9/attention/self/query/BiasAdd" -> "1230 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1230 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1231 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1231 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1232 bert/encoder/layer_9/attention/self/Reshape"  [label="[]", style=solid];
"1232 bert/encoder/layer_9/attention/self/Reshape" -> "1233 bert/encoder/layer_9/attention/self/transpose"  [label="[]", style=solid];
"1233 bert/encoder/layer_9/attention/self/transpose" -> "1243 bert/encoder/layer_9/attention/self/MatMul"  [label="[]", style=solid];
"1234 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1235 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1235 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1236 bert/encoder/layer_9/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1236 bert/encoder/layer_9/attention/self/key/MatMul" -> "1237 bert/encoder/layer_9/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1237 bert/encoder/layer_9/attention/self/key/BiasAdd" -> "1238 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1238 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1239 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1239 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1240 bert/encoder/layer_9/attention/self/Reshape_1"  [label="[]", style=solid];
"1240 bert/encoder/layer_9/attention/self/Reshape_1" -> "1241 bert/encoder/layer_9/attention/self/transpose_1"  [label="[]", style=solid];
"1241 bert/encoder/layer_9/attention/self/transpose_1" -> "1242 bert/encoder/layer_9/attention/self/MatMul__432"  [label="[]", style=solid];
"1242 bert/encoder/layer_9/attention/self/MatMul__432" -> "1243 bert/encoder/layer_9/attention/self/MatMul"  [label="[]", style=solid];
"1243 bert/encoder/layer_9/attention/self/MatMul" -> "1244 bert/encoder/layer_9/attention/self/Mul"  [label="[]", style=solid];
"1244 bert/encoder/layer_9/attention/self/Mul" -> "1245 bert/encoder/layer_9/attention/self/add"  [label="[]", style=solid];
"1245 bert/encoder/layer_9/attention/self/add" -> "1246 bert/encoder/layer_9/attention/self/Softmax"  [label="[]", style=solid];
"1246 bert/encoder/layer_9/attention/self/Softmax" -> "1247 bert/encoder/layer_9/attention/self/MatMul_1"  [label="[]", style=solid];
"1247 bert/encoder/layer_9/attention/self/MatMul_1" -> "1248 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1248 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1249 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1249 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1250 bert/encoder/layer_9/attention/self/transpose_3"  [label="[]", style=solid];
"1250 bert/encoder/layer_9/attention/self/transpose_3" -> "1251 bert/encoder/layer_9/attention/self/Reshape_3"  [label="[]", style=solid];
"1251 bert/encoder/layer_9/attention/self/Reshape_3" -> "1254 bert/encoder/layer_9/attention/output/dense/MatMul"  [label="[]", style=solid];
"1252 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1253 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1253 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1254 bert/encoder/layer_9/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1254 bert/encoder/layer_9/attention/output/dense/MatMul" -> "1255 bert/encoder/layer_9/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1255 bert/encoder/layer_9/attention/output/dense/BiasAdd" -> "1256 bert/encoder/layer_9/attention/output/add"  [label="[]", style=solid];
"1256 bert/encoder/layer_9/attention/output/add" -> "1257 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1256 bert/encoder/layer_9/attention/output/add" -> "1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1256 bert/encoder/layer_9/attention/output/add" -> "1268 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1257 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1258 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1257 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1258 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" -> "1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" -> "1260 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435"  [label="[]", style=solid];
"1260 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" -> "1261 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1261 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" -> "1262 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1262 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" -> "1263 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1263 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437"  [label="[]", style=solid];
"1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" -> "1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1268 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" -> "1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" -> "1269 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1268 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" -> "1269 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1269 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1270 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1269 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1290 bert/encoder/layer_9/output/add"  [label="[]", style=solid];
"1270 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1271 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1271 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1274 bert/encoder/layer_9/intermediate/dense/MatMul"  [label="[]", style=solid];
"1272 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1273 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1273 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1274 bert/encoder/layer_9/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1274 bert/encoder/layer_9/intermediate/dense/MatMul" -> "1275 bert/encoder/layer_9/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1275 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1276 bert/encoder/layer_9/intermediate/dense/Pow"  [label="[]", style=solid];
"1275 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1278 bert/encoder/layer_9/intermediate/dense/add"  [label="[]", style=solid];
"1275 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1283 bert/encoder/layer_9/intermediate/dense/mul_3"  [label="[]", style=solid];
"1276 bert/encoder/layer_9/intermediate/dense/Pow" -> "1277 bert/encoder/layer_9/intermediate/dense/mul"  [label="[]", style=solid];
"1277 bert/encoder/layer_9/intermediate/dense/mul" -> "1278 bert/encoder/layer_9/intermediate/dense/add"  [label="[]", style=solid];
"1278 bert/encoder/layer_9/intermediate/dense/add" -> "1279 bert/encoder/layer_9/intermediate/dense/mul_1"  [label="[]", style=solid];
"1279 bert/encoder/layer_9/intermediate/dense/mul_1" -> "1280 bert/encoder/layer_9/intermediate/dense/Tanh"  [label="[]", style=solid];
"1280 bert/encoder/layer_9/intermediate/dense/Tanh" -> "1281 bert/encoder/layer_9/intermediate/dense/add_1"  [label="[]", style=solid];
"1281 bert/encoder/layer_9/intermediate/dense/add_1" -> "1282 bert/encoder/layer_9/intermediate/dense/mul_2"  [label="[]", style=solid];
"1282 bert/encoder/layer_9/intermediate/dense/mul_2" -> "1283 bert/encoder/layer_9/intermediate/dense/mul_3"  [label="[]", style=solid];
"1283 bert/encoder/layer_9/intermediate/dense/mul_3" -> "1284 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1284 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1285 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1285 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1288 bert/encoder/layer_9/output/dense/MatMul"  [label="[]", style=solid];
"1286 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1287 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1287 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1288 bert/encoder/layer_9/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1288 bert/encoder/layer_9/output/dense/MatMul" -> "1289 bert/encoder/layer_9/output/dense/BiasAdd"  [label="[]", style=solid];
"1289 bert/encoder/layer_9/output/dense/BiasAdd" -> "1290 bert/encoder/layer_9/output/add"  [label="[]", style=solid];
"1290 bert/encoder/layer_9/output/add" -> "1291 bert/encoder/layer_9/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1290 bert/encoder/layer_9/output/add" -> "1293 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1290 bert/encoder/layer_9/output/add" -> "1302 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1291 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1292 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1291 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1292 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" -> "1293 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1293 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" -> "1294 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439"  [label="[]", style=solid];
"1294 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" -> "1295 bert/encoder/layer_9/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1295 bert/encoder/layer_9/output/LayerNorm/moments/variance" -> "1296 bert/encoder/layer_9/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1296 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" -> "1297 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1297 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" -> "1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441"  [label="[]", style=solid];
"1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" -> "1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1302 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" -> "1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" -> "1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1302 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" -> "1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1304 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1308 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1346 bert/encoder/layer_10/attention/output/add"  [label="[]", style=solid];
"1304 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1305 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1305 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1326 bert/encoder/layer_10/attention/self/key/MatMul"  [label="[]", style=solid];
"1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1318 bert/encoder/layer_10/attention/self/query/MatMul"  [label="[]", style=solid];
"1308 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1309 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1309 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1312 bert/encoder/layer_10/attention/self/value/MatMul"  [label="[]", style=solid];
"1310 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1311 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1311 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1312 bert/encoder/layer_10/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1312 bert/encoder/layer_10/attention/self/value/MatMul" -> "1313 bert/encoder/layer_10/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1313 bert/encoder/layer_10/attention/self/value/BiasAdd" -> "1314 bert/encoder/layer_10/attention/self/Reshape_2"  [label="[]", style=solid];
"1314 bert/encoder/layer_10/attention/self/Reshape_2" -> "1315 bert/encoder/layer_10/attention/self/transpose_2"  [label="[]", style=solid];
"1315 bert/encoder/layer_10/attention/self/transpose_2" -> "1337 bert/encoder/layer_10/attention/self/MatMul_1"  [label="[]", style=solid];
"1316 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1317 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1317 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1318 bert/encoder/layer_10/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1318 bert/encoder/layer_10/attention/self/query/MatMul" -> "1319 bert/encoder/layer_10/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1319 bert/encoder/layer_10/attention/self/query/BiasAdd" -> "1320 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1320 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1321 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1321 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1322 bert/encoder/layer_10/attention/self/Reshape"  [label="[]", style=solid];
"1322 bert/encoder/layer_10/attention/self/Reshape" -> "1323 bert/encoder/layer_10/attention/self/transpose"  [label="[]", style=solid];
"1323 bert/encoder/layer_10/attention/self/transpose" -> "1333 bert/encoder/layer_10/attention/self/MatMul"  [label="[]", style=solid];
"1324 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1325 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1325 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1326 bert/encoder/layer_10/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1326 bert/encoder/layer_10/attention/self/key/MatMul" -> "1327 bert/encoder/layer_10/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1327 bert/encoder/layer_10/attention/self/key/BiasAdd" -> "1328 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1328 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1329 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1329 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1330 bert/encoder/layer_10/attention/self/Reshape_1"  [label="[]", style=solid];
"1330 bert/encoder/layer_10/attention/self/Reshape_1" -> "1331 bert/encoder/layer_10/attention/self/transpose_1"  [label="[]", style=solid];
"1331 bert/encoder/layer_10/attention/self/transpose_1" -> "1332 bert/encoder/layer_10/attention/self/MatMul__446"  [label="[]", style=solid];
"1332 bert/encoder/layer_10/attention/self/MatMul__446" -> "1333 bert/encoder/layer_10/attention/self/MatMul"  [label="[]", style=solid];
"1333 bert/encoder/layer_10/attention/self/MatMul" -> "1334 bert/encoder/layer_10/attention/self/Mul"  [label="[]", style=solid];
"1334 bert/encoder/layer_10/attention/self/Mul" -> "1335 bert/encoder/layer_10/attention/self/add"  [label="[]", style=solid];
"1335 bert/encoder/layer_10/attention/self/add" -> "1336 bert/encoder/layer_10/attention/self/Softmax"  [label="[]", style=solid];
"1336 bert/encoder/layer_10/attention/self/Softmax" -> "1337 bert/encoder/layer_10/attention/self/MatMul_1"  [label="[]", style=solid];
"1337 bert/encoder/layer_10/attention/self/MatMul_1" -> "1338 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1338 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1339 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1339 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1340 bert/encoder/layer_10/attention/self/transpose_3"  [label="[]", style=solid];
"1340 bert/encoder/layer_10/attention/self/transpose_3" -> "1341 bert/encoder/layer_10/attention/self/Reshape_3"  [label="[]", style=solid];
"1341 bert/encoder/layer_10/attention/self/Reshape_3" -> "1344 bert/encoder/layer_10/attention/output/dense/MatMul"  [label="[]", style=solid];
"1342 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1343 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1343 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1344 bert/encoder/layer_10/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1344 bert/encoder/layer_10/attention/output/dense/MatMul" -> "1345 bert/encoder/layer_10/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1345 bert/encoder/layer_10/attention/output/dense/BiasAdd" -> "1346 bert/encoder/layer_10/attention/output/add"  [label="[]", style=solid];
"1346 bert/encoder/layer_10/attention/output/add" -> "1347 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1346 bert/encoder/layer_10/attention/output/add" -> "1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1346 bert/encoder/layer_10/attention/output/add" -> "1358 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1347 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1348 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1347 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1348 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" -> "1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" -> "1350 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449"  [label="[]", style=solid];
"1350 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" -> "1351 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1351 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" -> "1352 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1352 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" -> "1353 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1353 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451"  [label="[]", style=solid];
"1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" -> "1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1358 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" -> "1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" -> "1359 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1358 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" -> "1359 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1359 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1360 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1359 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1380 bert/encoder/layer_10/output/add"  [label="[]", style=solid];
"1360 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1361 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1361 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1364 bert/encoder/layer_10/intermediate/dense/MatMul"  [label="[]", style=solid];
"1362 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1363 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1363 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1364 bert/encoder/layer_10/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1364 bert/encoder/layer_10/intermediate/dense/MatMul" -> "1365 bert/encoder/layer_10/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1365 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1366 bert/encoder/layer_10/intermediate/dense/Pow"  [label="[]", style=solid];
"1365 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1368 bert/encoder/layer_10/intermediate/dense/add"  [label="[]", style=solid];
"1365 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1373 bert/encoder/layer_10/intermediate/dense/mul_3"  [label="[]", style=solid];
"1366 bert/encoder/layer_10/intermediate/dense/Pow" -> "1367 bert/encoder/layer_10/intermediate/dense/mul"  [label="[]", style=solid];
"1367 bert/encoder/layer_10/intermediate/dense/mul" -> "1368 bert/encoder/layer_10/intermediate/dense/add"  [label="[]", style=solid];
"1368 bert/encoder/layer_10/intermediate/dense/add" -> "1369 bert/encoder/layer_10/intermediate/dense/mul_1"  [label="[]", style=solid];
"1369 bert/encoder/layer_10/intermediate/dense/mul_1" -> "1370 bert/encoder/layer_10/intermediate/dense/Tanh"  [label="[]", style=solid];
"1370 bert/encoder/layer_10/intermediate/dense/Tanh" -> "1371 bert/encoder/layer_10/intermediate/dense/add_1"  [label="[]", style=solid];
"1371 bert/encoder/layer_10/intermediate/dense/add_1" -> "1372 bert/encoder/layer_10/intermediate/dense/mul_2"  [label="[]", style=solid];
"1372 bert/encoder/layer_10/intermediate/dense/mul_2" -> "1373 bert/encoder/layer_10/intermediate/dense/mul_3"  [label="[]", style=solid];
"1373 bert/encoder/layer_10/intermediate/dense/mul_3" -> "1374 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1374 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1375 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1375 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1378 bert/encoder/layer_10/output/dense/MatMul"  [label="[]", style=solid];
"1376 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1377 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1377 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1378 bert/encoder/layer_10/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1378 bert/encoder/layer_10/output/dense/MatMul" -> "1379 bert/encoder/layer_10/output/dense/BiasAdd"  [label="[]", style=solid];
"1379 bert/encoder/layer_10/output/dense/BiasAdd" -> "1380 bert/encoder/layer_10/output/add"  [label="[]", style=solid];
"1380 bert/encoder/layer_10/output/add" -> "1381 bert/encoder/layer_10/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1380 bert/encoder/layer_10/output/add" -> "1383 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1380 bert/encoder/layer_10/output/add" -> "1392 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1381 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1382 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1381 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1382 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" -> "1383 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1383 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" -> "1384 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453"  [label="[]", style=solid];
"1384 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" -> "1385 bert/encoder/layer_10/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1385 bert/encoder/layer_10/output/LayerNorm/moments/variance" -> "1386 bert/encoder/layer_10/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1386 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" -> "1387 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1387 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" -> "1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455"  [label="[]", style=solid];
"1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" -> "1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1392 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" -> "1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" -> "1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1392 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" -> "1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1394 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1398 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1436 bert/encoder/layer_11/attention/output/add"  [label="[]", style=solid];
"1394 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1395 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1395 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1416 bert/encoder/layer_11/attention/self/key/MatMul"  [label="[]", style=solid];
"1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1408 bert/encoder/layer_11/attention/self/query/MatMul"  [label="[]", style=solid];
"1398 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1399 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1399 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1402 bert/encoder/layer_11/attention/self/value/MatMul"  [label="[]", style=solid];
"1400 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1401 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1401 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1402 bert/encoder/layer_11/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1402 bert/encoder/layer_11/attention/self/value/MatMul" -> "1403 bert/encoder/layer_11/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1403 bert/encoder/layer_11/attention/self/value/BiasAdd" -> "1404 bert/encoder/layer_11/attention/self/Reshape_2"  [label="[]", style=solid];
"1404 bert/encoder/layer_11/attention/self/Reshape_2" -> "1405 bert/encoder/layer_11/attention/self/transpose_2"  [label="[]", style=solid];
"1405 bert/encoder/layer_11/attention/self/transpose_2" -> "1427 bert/encoder/layer_11/attention/self/MatMul_1"  [label="[]", style=solid];
"1406 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1407 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1407 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1408 bert/encoder/layer_11/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1408 bert/encoder/layer_11/attention/self/query/MatMul" -> "1409 bert/encoder/layer_11/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1409 bert/encoder/layer_11/attention/self/query/BiasAdd" -> "1410 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1410 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1411 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1411 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1412 bert/encoder/layer_11/attention/self/Reshape"  [label="[]", style=solid];
"1412 bert/encoder/layer_11/attention/self/Reshape" -> "1413 bert/encoder/layer_11/attention/self/transpose"  [label="[]", style=solid];
"1413 bert/encoder/layer_11/attention/self/transpose" -> "1423 bert/encoder/layer_11/attention/self/MatMul"  [label="[]", style=solid];
"1414 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1415 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1415 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1416 bert/encoder/layer_11/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1416 bert/encoder/layer_11/attention/self/key/MatMul" -> "1417 bert/encoder/layer_11/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1417 bert/encoder/layer_11/attention/self/key/BiasAdd" -> "1418 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1418 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1419 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1419 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1420 bert/encoder/layer_11/attention/self/Reshape_1"  [label="[]", style=solid];
"1420 bert/encoder/layer_11/attention/self/Reshape_1" -> "1421 bert/encoder/layer_11/attention/self/transpose_1"  [label="[]", style=solid];
"1421 bert/encoder/layer_11/attention/self/transpose_1" -> "1422 bert/encoder/layer_11/attention/self/MatMul__460"  [label="[]", style=solid];
"1422 bert/encoder/layer_11/attention/self/MatMul__460" -> "1423 bert/encoder/layer_11/attention/self/MatMul"  [label="[]", style=solid];
"1423 bert/encoder/layer_11/attention/self/MatMul" -> "1424 bert/encoder/layer_11/attention/self/Mul"  [label="[]", style=solid];
"1424 bert/encoder/layer_11/attention/self/Mul" -> "1425 bert/encoder/layer_11/attention/self/add"  [label="[]", style=solid];
"1425 bert/encoder/layer_11/attention/self/add" -> "1426 bert/encoder/layer_11/attention/self/Softmax"  [label="[]", style=solid];
"1426 bert/encoder/layer_11/attention/self/Softmax" -> "1427 bert/encoder/layer_11/attention/self/MatMul_1"  [label="[]", style=solid];
"1427 bert/encoder/layer_11/attention/self/MatMul_1" -> "1428 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1428 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1429 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1429 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1430 bert/encoder/layer_11/attention/self/transpose_3"  [label="[]", style=solid];
"1430 bert/encoder/layer_11/attention/self/transpose_3" -> "1431 bert/encoder/layer_11/attention/self/Reshape_3"  [label="[]", style=solid];
"1431 bert/encoder/layer_11/attention/self/Reshape_3" -> "1434 bert/encoder/layer_11/attention/output/dense/MatMul"  [label="[]", style=solid];
"1432 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1433 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1433 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1434 bert/encoder/layer_11/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1434 bert/encoder/layer_11/attention/output/dense/MatMul" -> "1435 bert/encoder/layer_11/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1435 bert/encoder/layer_11/attention/output/dense/BiasAdd" -> "1436 bert/encoder/layer_11/attention/output/add"  [label="[]", style=solid];
"1436 bert/encoder/layer_11/attention/output/add" -> "1437 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1436 bert/encoder/layer_11/attention/output/add" -> "1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1436 bert/encoder/layer_11/attention/output/add" -> "1448 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1437 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1438 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1437 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1438 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" -> "1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" -> "1440 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463"  [label="[]", style=solid];
"1440 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" -> "1441 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1441 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" -> "1442 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1442 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" -> "1443 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1443 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465"  [label="[]", style=solid];
"1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" -> "1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1448 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" -> "1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" -> "1449 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1448 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" -> "1449 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1449 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1450 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1449 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1470 bert/encoder/layer_11/output/add"  [label="[]", style=solid];
"1450 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1451 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1451 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1454 bert/encoder/layer_11/intermediate/dense/MatMul"  [label="[]", style=solid];
"1452 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1453 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1453 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1454 bert/encoder/layer_11/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1454 bert/encoder/layer_11/intermediate/dense/MatMul" -> "1455 bert/encoder/layer_11/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1455 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1456 bert/encoder/layer_11/intermediate/dense/Pow"  [label="[]", style=solid];
"1455 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1458 bert/encoder/layer_11/intermediate/dense/add"  [label="[]", style=solid];
"1455 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1463 bert/encoder/layer_11/intermediate/dense/mul_3"  [label="[]", style=solid];
"1456 bert/encoder/layer_11/intermediate/dense/Pow" -> "1457 bert/encoder/layer_11/intermediate/dense/mul"  [label="[]", style=solid];
"1457 bert/encoder/layer_11/intermediate/dense/mul" -> "1458 bert/encoder/layer_11/intermediate/dense/add"  [label="[]", style=solid];
"1458 bert/encoder/layer_11/intermediate/dense/add" -> "1459 bert/encoder/layer_11/intermediate/dense/mul_1"  [label="[]", style=solid];
"1459 bert/encoder/layer_11/intermediate/dense/mul_1" -> "1460 bert/encoder/layer_11/intermediate/dense/Tanh"  [label="[]", style=solid];
"1460 bert/encoder/layer_11/intermediate/dense/Tanh" -> "1461 bert/encoder/layer_11/intermediate/dense/add_1"  [label="[]", style=solid];
"1461 bert/encoder/layer_11/intermediate/dense/add_1" -> "1462 bert/encoder/layer_11/intermediate/dense/mul_2"  [label="[]", style=solid];
"1462 bert/encoder/layer_11/intermediate/dense/mul_2" -> "1463 bert/encoder/layer_11/intermediate/dense/mul_3"  [label="[]", style=solid];
"1463 bert/encoder/layer_11/intermediate/dense/mul_3" -> "1464 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1464 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1465 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1465 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1468 bert/encoder/layer_11/output/dense/MatMul"  [label="[]", style=solid];
"1466 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1467 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1467 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1468 bert/encoder/layer_11/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1468 bert/encoder/layer_11/output/dense/MatMul" -> "1469 bert/encoder/layer_11/output/dense/BiasAdd"  [label="[]", style=solid];
"1469 bert/encoder/layer_11/output/dense/BiasAdd" -> "1470 bert/encoder/layer_11/output/add"  [label="[]", style=solid];
"1470 bert/encoder/layer_11/output/add" -> "1471 bert/encoder/layer_11/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1470 bert/encoder/layer_11/output/add" -> "1473 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1470 bert/encoder/layer_11/output/add" -> "1482 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1471 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1472 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1471 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1472 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" -> "1473 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1473 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" -> "1474 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467"  [label="[]", style=solid];
"1474 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" -> "1475 bert/encoder/layer_11/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1475 bert/encoder/layer_11/output/LayerNorm/moments/variance" -> "1476 bert/encoder/layer_11/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1476 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" -> "1477 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1477 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" -> "1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469"  [label="[]", style=solid];
"1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" -> "1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1482 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" -> "1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" -> "1483 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1482 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" -> "1483 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1483 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" -> "1484 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1484 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1485 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1485 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1486 bert/encoder/Reshape_13"  [label="[]", style=solid];
"1486 bert/encoder/Reshape_13" -> "1487 Shape_1"  [label="[]", style=solid];
"1486 bert/encoder/Reshape_13" -> "1499 Reshape"  [label="[]", style=solid];
"1487 Shape_1" -> "1488 Shape_1__472"  [label="[-1]", style=dashed];
"1488 Shape_1__472" -> "1489 strided_slice_1"  [label="[-1]", style=solid];
"1489 strided_slice_1" -> "1490 strided_slice_1__476"  [label="[-1]", style=solid];
"1490 strided_slice_1__476" -> "1491 strided_slice_1__477"  [label="[]", style=solid];
"1491 strided_slice_1__477" -> "1492 mul"  [label="[]", style=dashed];
"1491 strided_slice_1__477" -> "1496 Reshape_1/shape_Unsqueeze__478"  [label="[]", style=dashed];
"1492 mul" -> "1493 Reshape/shape_Unsqueeze__482"  [label="[]", style=dashed];
"1493 Reshape/shape_Unsqueeze__482" -> "1494 Reshape/shape_Concat__484"  [label="[1]", style=dashed];
"1494 Reshape/shape_Concat__484" -> "1495 Reshape__485"  [label="[2]", style=dashed];
"1495 Reshape__485" -> "1499 Reshape"  [label="[2]", style=dashed];
"1496 Reshape_1/shape_Unsqueeze__478" -> "1497 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"1497 Reshape_1/shape_Concat__481" -> "1498 Reshape_1__487"  [label="[3]", style=dashed];
"1498 Reshape_1__487" -> "1504 Reshape_1"  [label="[3]", style=dashed];
"1499 Reshape" -> "1502 MatMul"  [label="[]", style=solid];
"1500 QuantizeLinear_MatMul__486^0_1" -> "1501 DequantizeLinear_MatMul__486^0_1"  [label="[768, 2]", style=dashed];
"1501 DequantizeLinear_MatMul__486^0_1" -> "1502 MatMul"  [label="[768, 2]", style=solid];
"1502 MatMul" -> "1503 BiasAdd"  [label="[]", style=solid];
"1503 BiasAdd" -> "1504 Reshape_1"  [label="[]", style=solid];
"1504 Reshape_1" -> "1505 transpose"  [label="[]", style=solid];
"1505 transpose" -> "1506 unstack"  [label="[]", style=solid];
"1506 unstack" -> "1507 unstack__490"  [label="[]", style=solid];
"1506 unstack" -> "1509 unstack__488"  [label="[]", style=solid];
"1507 unstack__490" -> "1508 unstack_graph_outputs_Identity__4"  [label="[]", style=solid];
"1508 unstack_graph_outputs_Identity__4" -> "1515 nncf_model_output_0"  [label="[-1, 256]", style=solid];
"1509 unstack__488" -> "1510 unstack_graph_outputs_Identity__7"  [label="[]", style=solid];
"1510 unstack_graph_outputs_Identity__7" -> "1516 nncf_model_output_1"  [label="[-1, 256]", style=solid];
"1511 nncf_model_input_0" -> "0 unique_ids_graph_outputs_Identity__10"  [label="[-1]", style=dashed];
"1512 nncf_model_input_1" -> "185 bert/embeddings/Reshape_2"  [label="[-1, 256]", style=dashed];
"1513 nncf_model_input_2" -> "140 bert/encoder/Reshape"  [label="[-1, 256]", style=dashed];
"1514 nncf_model_input_3" -> "123 bert/encoder/Shape"  [label="[-1, 256]", style=dashed];
"1514 nncf_model_input_3" -> "189 bert/embeddings/ExpandDims"  [label="[-1, 256]", style=dashed];
}
