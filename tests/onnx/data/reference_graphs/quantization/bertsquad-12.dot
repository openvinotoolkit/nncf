digraph {
"0 unique_ids_graph_outputs_Identity__10" [id=0, type=Identity];
"1 Constant_nncf_1" [id=1, type=Constant];
"2 bert/encoder/ones/packed_Unsqueeze__20" [id=2, type=Unsqueeze];
"3 Constant_nncf_3" [id=3, type=Constant];
"4 bert/encoder/ones/packed_Unsqueeze__19" [id=4, type=Unsqueeze];
"5 Constant_nncf_5" [id=5, type=Constant];
"6 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" [id=6, type=Unsqueeze];
"7 Constant_nncf_7" [id=7, type=Constant];
"8 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" [id=8, type=Unsqueeze];
"9 Constant_nncf_9" [id=9, type=Constant];
"10 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" [id=10, type=Unsqueeze];
"11 Constant_nncf_11" [id=11, type=Constant];
"12 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" [id=12, type=Unsqueeze];
"13 Constant_nncf_13" [id=13, type=Constant];
"14 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" [id=14, type=Unsqueeze];
"15 Constant_nncf_15" [id=15, type=Constant];
"16 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" [id=16, type=Unsqueeze];
"17 Constant_nncf_17" [id=17, type=Constant];
"18 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" [id=18, type=Unsqueeze];
"19 Constant_nncf_19" [id=19, type=Constant];
"20 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" [id=20, type=Unsqueeze];
"21 Constant_nncf_21" [id=21, type=Constant];
"22 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" [id=22, type=Unsqueeze];
"23 Constant_nncf_23" [id=23, type=Constant];
"24 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" [id=24, type=Unsqueeze];
"25 Constant_nncf_25" [id=25, type=Constant];
"26 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" [id=26, type=Unsqueeze];
"27 Constant_nncf_27" [id=27, type=Constant];
"28 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" [id=28, type=Unsqueeze];
"29 Constant_nncf_29" [id=29, type=Constant];
"30 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" [id=30, type=Unsqueeze];
"31 Constant_nncf_31" [id=31, type=Constant];
"32 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" [id=32, type=Unsqueeze];
"33 Constant_nncf_33" [id=33, type=Constant];
"34 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" [id=34, type=Unsqueeze];
"35 Constant_nncf_35" [id=35, type=Constant];
"36 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" [id=36, type=Unsqueeze];
"37 Constant_nncf_37" [id=37, type=Constant];
"38 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" [id=38, type=Unsqueeze];
"39 Constant_nncf_39" [id=39, type=Constant];
"40 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" [id=40, type=Unsqueeze];
"41 Constant_nncf_41" [id=41, type=Constant];
"42 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" [id=42, type=Unsqueeze];
"43 Constant_nncf_43" [id=43, type=Constant];
"44 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" [id=44, type=Unsqueeze];
"45 Constant_nncf_45" [id=45, type=Constant];
"46 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" [id=46, type=Unsqueeze];
"47 Constant_nncf_47" [id=47, type=Constant];
"48 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" [id=48, type=Unsqueeze];
"49 Constant_nncf_49" [id=49, type=Constant];
"50 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" [id=50, type=Unsqueeze];
"51 Constant_nncf_51" [id=51, type=Constant];
"52 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" [id=52, type=Unsqueeze];
"53 Constant_nncf_53" [id=53, type=Constant];
"54 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" [id=54, type=Unsqueeze];
"55 Constant_nncf_55" [id=55, type=Constant];
"56 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" [id=56, type=Unsqueeze];
"57 Constant_nncf_57" [id=57, type=Constant];
"58 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" [id=58, type=Unsqueeze];
"59 Constant_nncf_59" [id=59, type=Constant];
"60 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" [id=60, type=Unsqueeze];
"61 Constant_nncf_61" [id=61, type=Constant];
"62 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" [id=62, type=Unsqueeze];
"63 Constant_nncf_63" [id=63, type=Constant];
"64 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" [id=64, type=Unsqueeze];
"65 Constant_nncf_65" [id=65, type=Constant];
"66 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" [id=66, type=Unsqueeze];
"67 Constant_nncf_67" [id=67, type=Constant];
"68 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" [id=68, type=Unsqueeze];
"69 Constant_nncf_69" [id=69, type=Constant];
"70 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" [id=70, type=Unsqueeze];
"71 Constant_nncf_71" [id=71, type=Constant];
"72 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" [id=72, type=Unsqueeze];
"73 Constant_nncf_73" [id=73, type=Constant];
"74 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" [id=74, type=Unsqueeze];
"75 Constant_nncf_75" [id=75, type=Constant];
"76 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" [id=76, type=Unsqueeze];
"77 Constant_nncf_77" [id=77, type=Constant];
"78 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" [id=78, type=Unsqueeze];
"79 Constant_nncf_79" [id=79, type=Constant];
"80 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" [id=80, type=Unsqueeze];
"81 Constant_nncf_81" [id=81, type=Constant];
"82 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" [id=82, type=Unsqueeze];
"83 Constant_nncf_83" [id=83, type=Constant];
"84 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" [id=84, type=Unsqueeze];
"85 Constant_nncf_85" [id=85, type=Constant];
"86 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" [id=86, type=Unsqueeze];
"87 Constant_nncf_87" [id=87, type=Constant];
"88 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" [id=88, type=Unsqueeze];
"89 Constant_nncf_89" [id=89, type=Constant];
"90 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" [id=90, type=Unsqueeze];
"91 Constant_nncf_91" [id=91, type=Constant];
"92 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" [id=92, type=Unsqueeze];
"93 Constant_nncf_93" [id=93, type=Constant];
"94 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" [id=94, type=Unsqueeze];
"95 Constant_nncf_95" [id=95, type=Constant];
"96 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" [id=96, type=Unsqueeze];
"97 Constant_nncf_97" [id=97, type=Constant];
"98 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" [id=98, type=Unsqueeze];
"99 Constant_nncf_99" [id=99, type=Constant];
"100 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" [id=100, type=Unsqueeze];
"101 Constant_nncf_101" [id=101, type=Constant];
"102 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" [id=102, type=Unsqueeze];
"103 Constant_nncf_103" [id=103, type=Constant];
"104 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" [id=104, type=Unsqueeze];
"105 Constant_nncf_105" [id=105, type=Constant];
"106 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" [id=106, type=Unsqueeze];
"107 Constant_nncf_107" [id=107, type=Constant];
"108 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" [id=108, type=Unsqueeze];
"109 Constant_nncf_109" [id=109, type=Constant];
"110 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" [id=110, type=Unsqueeze];
"111 Constant_nncf_111" [id=111, type=Constant];
"112 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" [id=112, type=Unsqueeze];
"113 Constant_nncf_113" [id=113, type=Constant];
"114 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" [id=114, type=Unsqueeze];
"115 Constant_nncf_115" [id=115, type=Constant];
"116 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" [id=116, type=Unsqueeze];
"117 Constant_nncf_117" [id=117, type=Constant];
"118 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" [id=118, type=Unsqueeze];
"119 Constant_nncf_119" [id=119, type=Constant];
"120 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" [id=120, type=Unsqueeze];
"121 Constant_nncf_121" [id=121, type=Constant];
"122 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" [id=122, type=Unsqueeze];
"123 Constant_nncf_123" [id=123, type=Constant];
"124 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" [id=124, type=Unsqueeze];
"125 Constant_nncf_125" [id=125, type=Constant];
"126 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" [id=126, type=Unsqueeze];
"127 Constant_nncf_127" [id=127, type=Constant];
"128 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" [id=128, type=Unsqueeze];
"129 Constant_nncf_129" [id=129, type=Constant];
"130 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" [id=130, type=Unsqueeze];
"131 Constant_nncf_131" [id=131, type=Constant];
"132 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" [id=132, type=Unsqueeze];
"133 Constant_nncf_133" [id=133, type=Constant];
"134 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" [id=134, type=Unsqueeze];
"135 Constant_nncf_135" [id=135, type=Constant];
"136 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" [id=136, type=Unsqueeze];
"137 Constant_nncf_137" [id=137, type=Constant];
"138 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" [id=138, type=Unsqueeze];
"139 Constant_nncf_139" [id=139, type=Constant];
"140 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" [id=140, type=Unsqueeze];
"141 Constant_nncf_141" [id=141, type=Constant];
"142 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" [id=142, type=Unsqueeze];
"143 Constant_nncf_143" [id=143, type=Constant];
"144 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" [id=144, type=Unsqueeze];
"145 Constant_nncf_145" [id=145, type=Constant];
"146 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" [id=146, type=Unsqueeze];
"147 Constant_nncf_147" [id=147, type=Constant];
"148 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" [id=148, type=Unsqueeze];
"149 Constant_nncf_149" [id=149, type=Constant];
"150 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" [id=150, type=Unsqueeze];
"151 Constant_nncf_151" [id=151, type=Constant];
"152 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" [id=152, type=Unsqueeze];
"153 Constant_nncf_153" [id=153, type=Constant];
"154 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" [id=154, type=Unsqueeze];
"155 Constant_nncf_155" [id=155, type=Constant];
"156 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" [id=156, type=Unsqueeze];
"157 Constant_nncf_157" [id=157, type=Constant];
"158 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" [id=158, type=Unsqueeze];
"159 Constant_nncf_159" [id=159, type=Constant];
"160 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" [id=160, type=Unsqueeze];
"161 Constant_nncf_161" [id=161, type=Constant];
"162 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" [id=162, type=Unsqueeze];
"163 Constant_nncf_163" [id=163, type=Constant];
"164 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" [id=164, type=Unsqueeze];
"165 Constant_nncf_165" [id=165, type=Constant];
"166 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" [id=166, type=Unsqueeze];
"167 Constant_nncf_167" [id=167, type=Constant];
"168 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" [id=168, type=Unsqueeze];
"169 Constant_nncf_169" [id=169, type=Constant];
"170 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" [id=170, type=Unsqueeze];
"171 Constant_nncf_171" [id=171, type=Constant];
"172 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" [id=172, type=Unsqueeze];
"173 Constant_nncf_173" [id=173, type=Constant];
"174 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" [id=174, type=Unsqueeze];
"175 Constant_nncf_175" [id=175, type=Constant];
"176 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" [id=176, type=Unsqueeze];
"177 Constant_nncf_177" [id=177, type=Constant];
"178 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" [id=178, type=Unsqueeze];
"179 Constant_nncf_179" [id=179, type=Constant];
"180 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" [id=180, type=Unsqueeze];
"181 Constant_nncf_181" [id=181, type=Constant];
"182 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" [id=182, type=Unsqueeze];
"183 Constant_nncf_183" [id=183, type=Constant];
"184 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" [id=184, type=Unsqueeze];
"185 Constant_nncf_185" [id=185, type=Constant];
"186 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" [id=186, type=Unsqueeze];
"187 Constant_nncf_187" [id=187, type=Constant];
"188 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" [id=188, type=Unsqueeze];
"189 Constant_nncf_189" [id=189, type=Constant];
"190 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" [id=190, type=Unsqueeze];
"191 Constant_nncf_191" [id=191, type=Constant];
"192 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" [id=192, type=Unsqueeze];
"193 Constant_nncf_193" [id=193, type=Constant];
"194 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" [id=194, type=Unsqueeze];
"195 Constant_nncf_195" [id=195, type=Constant];
"196 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" [id=196, type=Unsqueeze];
"197 Constant_nncf_197" [id=197, type=Constant];
"198 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" [id=198, type=Unsqueeze];
"199 Constant_nncf_199" [id=199, type=Constant];
"200 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" [id=200, type=Unsqueeze];
"201 Constant_nncf_201" [id=201, type=Constant];
"202 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" [id=202, type=Unsqueeze];
"203 Constant_nncf_203" [id=203, type=Constant];
"204 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" [id=204, type=Unsqueeze];
"205 Constant_nncf_205" [id=205, type=Constant];
"206 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" [id=206, type=Unsqueeze];
"207 Constant_nncf_207" [id=207, type=Constant];
"208 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" [id=208, type=Unsqueeze];
"209 Constant_nncf_209" [id=209, type=Constant];
"210 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" [id=210, type=Unsqueeze];
"211 Constant_nncf_211" [id=211, type=Constant];
"212 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" [id=212, type=Unsqueeze];
"213 Constant_nncf_213" [id=213, type=Constant];
"214 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" [id=214, type=Unsqueeze];
"215 Constant_nncf_215" [id=215, type=Constant];
"216 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" [id=216, type=Unsqueeze];
"217 Constant_nncf_217" [id=217, type=Constant];
"218 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" [id=218, type=Unsqueeze];
"219 Constant_nncf_219" [id=219, type=Constant];
"220 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" [id=220, type=Unsqueeze];
"221 Constant_nncf_221" [id=221, type=Constant];
"222 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" [id=222, type=Unsqueeze];
"223 Constant_nncf_223" [id=223, type=Constant];
"224 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" [id=224, type=Unsqueeze];
"225 Constant_nncf_225" [id=225, type=Constant];
"226 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" [id=226, type=Unsqueeze];
"227 Constant_nncf_227" [id=227, type=Constant];
"228 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" [id=228, type=Unsqueeze];
"229 Constant_nncf_229" [id=229, type=Constant];
"230 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" [id=230, type=Unsqueeze];
"231 Constant_nncf_231" [id=231, type=Constant];
"232 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" [id=232, type=Unsqueeze];
"233 Constant_nncf_233" [id=233, type=Constant];
"234 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" [id=234, type=Unsqueeze];
"235 Constant_nncf_235" [id=235, type=Constant];
"236 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" [id=236, type=Unsqueeze];
"237 Constant_nncf_237" [id=237, type=Constant];
"238 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" [id=238, type=Unsqueeze];
"239 Constant_nncf_239" [id=239, type=Constant];
"240 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" [id=240, type=Unsqueeze];
"241 Constant_nncf_241" [id=241, type=Constant];
"242 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" [id=242, type=Unsqueeze];
"243 Constant_nncf_243" [id=243, type=Constant];
"244 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" [id=244, type=Unsqueeze];
"245 bert/encoder/Shape" [id=245, type=Shape];
"246 bert/encoder/Shape__12" [id=246, type=Cast];
"247 bert/encoder/strided_slice" [id=247, type=Slice];
"248 Constant_nncf_248" [id=248, type=Constant];
"249 bert/encoder/strided_slice__16" [id=249, type=Squeeze];
"250 bert/encoder/strided_slice__17" [id=250, type=Cast];
"251 Constant_nncf_251" [id=251, type=Constant];
"252 bert/encoder/ones/packed_Unsqueeze__18" [id=252, type=Unsqueeze];
"253 bert/encoder/ones/packed_Concat__21" [id=253, type=Concat];
"254 bert/encoder/ones__22" [id=254, type=Cast];
"255 bert/encoder/ones" [id=255, type=ConstantOfShape];
"256 Constant_nncf_256" [id=256, type=Constant];
"257 bert/encoder/Reshape_13/shape_Unsqueeze__300" [id=257, type=Unsqueeze];
"258 Constant_nncf_258" [id=258, type=Constant];
"259 bert/encoder/Reshape_13/shape_Unsqueeze__299" [id=259, type=Unsqueeze];
"260 bert/encoder/Reshape_1__302" [id=260, type=Cast];
"261 Constant_nncf_261" [id=261, type=Constant];
"262 bert/encoder/Reshape/shape_Unsqueeze__23" [id=262, type=Unsqueeze];
"263 Constant_nncf_263" [id=263, type=Constant];
"264 bert/encoder/Reshape/shape_Unsqueeze__25" [id=264, type=Unsqueeze];
"265 Constant_nncf_265" [id=265, type=Constant];
"266 bert/encoder/Reshape/shape_Unsqueeze__24" [id=266, type=Unsqueeze];
"267 bert/encoder/Reshape/shape_Concat__26" [id=267, type=Concat];
"268 bert/encoder/Reshape__27" [id=268, type=Cast];
"269 bert/encoder/Reshape" [id=269, type=Reshape];
"270 bert/encoder/Cast" [id=270, type=Cast];
"271 bert/encoder/mul" [id=271, type=Mul];
"272 bert/encoder/layer_9/attention/self/ExpandDims" [id=272, type=Reshape];
"273 bert/encoder/layer_9/attention/self/sub" [id=273, type=Sub];
"274 bert/encoder/layer_9/attention/self/mul_1" [id=274, type=Mul];
"275 bert/encoder/layer_8/attention/self/ExpandDims" [id=275, type=Reshape];
"276 bert/encoder/layer_8/attention/self/sub" [id=276, type=Sub];
"277 bert/encoder/layer_8/attention/self/mul_1" [id=277, type=Mul];
"278 bert/encoder/layer_7/attention/self/ExpandDims" [id=278, type=Reshape];
"279 bert/encoder/layer_7/attention/self/sub" [id=279, type=Sub];
"280 bert/encoder/layer_7/attention/self/mul_1" [id=280, type=Mul];
"281 bert/encoder/layer_6/attention/self/ExpandDims" [id=281, type=Reshape];
"282 bert/encoder/layer_6/attention/self/sub" [id=282, type=Sub];
"283 bert/encoder/layer_6/attention/self/mul_1" [id=283, type=Mul];
"284 bert/encoder/layer_5/attention/self/ExpandDims" [id=284, type=Reshape];
"285 bert/encoder/layer_5/attention/self/sub" [id=285, type=Sub];
"286 bert/encoder/layer_5/attention/self/mul_1" [id=286, type=Mul];
"287 bert/encoder/layer_4/attention/self/ExpandDims" [id=287, type=Reshape];
"288 bert/encoder/layer_4/attention/self/sub" [id=288, type=Sub];
"289 bert/encoder/layer_4/attention/self/mul_1" [id=289, type=Mul];
"290 bert/encoder/layer_3/attention/self/ExpandDims" [id=290, type=Reshape];
"291 bert/encoder/layer_3/attention/self/sub" [id=291, type=Sub];
"292 bert/encoder/layer_3/attention/self/mul_1" [id=292, type=Mul];
"293 bert/encoder/layer_2/attention/self/ExpandDims" [id=293, type=Reshape];
"294 bert/encoder/layer_2/attention/self/sub" [id=294, type=Sub];
"295 bert/encoder/layer_2/attention/self/mul_1" [id=295, type=Mul];
"296 bert/encoder/layer_11/attention/self/ExpandDims" [id=296, type=Reshape];
"297 bert/encoder/layer_11/attention/self/sub" [id=297, type=Sub];
"298 bert/encoder/layer_11/attention/self/mul_1" [id=298, type=Mul];
"299 bert/encoder/layer_10/attention/self/ExpandDims" [id=299, type=Reshape];
"300 bert/encoder/layer_10/attention/self/sub" [id=300, type=Sub];
"301 bert/encoder/layer_10/attention/self/mul_1" [id=301, type=Mul];
"302 bert/encoder/layer_1/attention/self/ExpandDims" [id=302, type=Reshape];
"303 bert/encoder/layer_1/attention/self/sub" [id=303, type=Sub];
"304 bert/encoder/layer_1/attention/self/mul_1" [id=304, type=Mul];
"305 bert/encoder/layer_0/attention/self/ExpandDims" [id=305, type=Reshape];
"306 bert/encoder/layer_0/attention/self/sub" [id=306, type=Sub];
"307 bert/encoder/layer_0/attention/self/mul_1" [id=307, type=Mul];
"308 bert/embeddings/Slice" [id=308, type=Slice];
"309 bert/embeddings/Reshape_4__42" [id=309, type=Cast];
"310 bert/embeddings/Reshape_4" [id=310, type=Reshape];
"311 Constant_nncf_311" [id=311, type=Constant];
"312 bert/embeddings/Reshape_3/shape_Unsqueeze__69" [id=312, type=Unsqueeze];
"313 Constant_nncf_313" [id=313, type=Constant];
"314 bert/embeddings/Reshape_3/shape_Unsqueeze__68" [id=314, type=Unsqueeze];
"315 bert/embeddings/Reshape_2__43" [id=315, type=Cast];
"316 bert/embeddings/Reshape_2" [id=316, type=Reshape];
"317 Constant_nncf_317" [id=317, type=Constant];
"318 bert/embeddings/Reshape_1/shape_Unsqueeze__57" [id=318, type=Unsqueeze];
"319 Constant_nncf_319" [id=319, type=Constant];
"320 bert/embeddings/Reshape_1/shape_Unsqueeze__56" [id=320, type=Unsqueeze];
"321 bert/embeddings/Reshape__59" [id=321, type=Cast];
"322 bert/embeddings/ExpandDims" [id=322, type=Reshape];
"323 bert/embeddings/Shape" [id=323, type=Shape];
"324 bert/embeddings/Shape__49" [id=324, type=Cast];
"325 bert/embeddings/strided_slice" [id=325, type=Slice];
"326 Constant_nncf_326" [id=326, type=Constant];
"327 bert/embeddings/strided_slice__53" [id=327, type=Squeeze];
"328 bert/embeddings/strided_slice__54" [id=328, type=Cast];
"329 Constant_nncf_329" [id=329, type=Constant];
"330 bert/embeddings/Reshape_1/shape_Unsqueeze__55" [id=330, type=Unsqueeze];
"331 bert/embeddings/Reshape_1/shape_Concat__58" [id=331, type=Concat];
"332 bert/embeddings/Reshape_1__60" [id=332, type=Cast];
"333 bert/embeddings/Reshape" [id=333, type=Reshape];
"334 QuantizeLinear_bert/embeddings/word_embeddings^0_1" [id=334, type=QuantizeLinear, label="334 QuantizeLinear_bert/embeddings/word_embeddings:0_1"];
"335 DequantizeLinear_bert/embeddings/word_embeddings^0_1" [id=335, type=DequantizeLinear, label="335 DequantizeLinear_bert/embeddings/word_embeddings:0_1"];
"336 bert/embeddings/GatherV2" [id=336, type=Gather];
"337 bert/embeddings/Reshape_1" [id=337, type=Reshape];
"338 bert/embeddings/Shape_1" [id=338, type=Shape];
"339 bert/embeddings/Shape_1__61" [id=339, type=Cast];
"340 bert/embeddings/strided_slice_1" [id=340, type=Slice];
"341 Constant_nncf_339" [id=341, type=Constant];
"342 bert/embeddings/strided_slice_1__65" [id=342, type=Squeeze];
"343 bert/embeddings/strided_slice_1__66" [id=343, type=Cast];
"344 Constant_nncf_342" [id=344, type=Constant];
"345 bert/embeddings/Reshape_3/shape_Unsqueeze__67" [id=345, type=Unsqueeze];
"346 bert/embeddings/Reshape_3/shape_Concat__70" [id=346, type=Concat];
"347 bert/embeddings/Reshape_3__71" [id=347, type=Cast];
"348 Constant_nncf_346" [id=348, type=Constant];
"349 Unsqueeze__46" [id=349, type=Unsqueeze];
"350 Constant_nncf_348" [id=350, type=Constant];
"351 Unsqueeze__45" [id=351, type=Unsqueeze];
"352 Constant_nncf_350" [id=352, type=Constant];
"353 Unsqueeze__44" [id=353, type=Unsqueeze];
"354 Constant_nncf_352" [id=354, type=Constant];
"355 Reshape_1/shape_Unsqueeze__480" [id=355, type=Unsqueeze];
"356 Constant_nncf_354" [id=356, type=Constant];
"357 Reshape_1/shape_Unsqueeze__479" [id=357, type=Unsqueeze];
"358 Constant_nncf_356" [id=358, type=Constant];
"359 Reshape/shape_Unsqueeze__483" [id=359, type=Unsqueeze];
"360 MatMul__486" [id=360, type=Transpose];
"361 Concat__47" [id=361, type=Concat];
"362 bert/embeddings/one_hot" [id=362, type=OneHot];
"363 QuantizeLinear_bert/embeddings/one_hot^0_1" [id=363, type=QuantizeLinear, label="363 QuantizeLinear_bert/embeddings/one_hot:0_1"];
"364 DequantizeLinear_bert/embeddings/one_hot^0_1" [id=364, type=DequantizeLinear, label="364 DequantizeLinear_bert/embeddings/one_hot:0_1"];
"365 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=365, type=QuantizeLinear, label="365 QuantizeLinear_bert/embeddings/token_type_embeddings:0_1"];
"366 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=366, type=DequantizeLinear, label="366 DequantizeLinear_bert/embeddings/token_type_embeddings:0_1"];
"367 bert/embeddings/MatMul" [id=367, type=MatMul];
"368 bert/embeddings/Reshape_3" [id=368, type=Reshape];
"369 bert/embeddings/add" [id=369, type=Add];
"370 bert/embeddings/add_1" [id=370, type=Add];
"371 bert/embeddings/LayerNorm/moments/mean" [id=371, type=ReduceMean];
"372 bert/embeddings/LayerNorm/moments/StopGradient" [id=372, type=Identity];
"373 bert/embeddings/LayerNorm/moments/SquaredDifference" [id=373, type=Sub];
"374 bert/embeddings/LayerNorm/moments/SquaredDifference__72" [id=374, type=Mul];
"375 bert/embeddings/LayerNorm/moments/variance" [id=375, type=ReduceMean];
"376 bert/embeddings/LayerNorm/batchnorm/add" [id=376, type=Add];
"377 bert/embeddings/LayerNorm/batchnorm/Rsqrt" [id=377, type=Sqrt];
"378 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" [id=378, type=Reciprocal];
"379 bert/embeddings/LayerNorm/batchnorm/mul" [id=379, type=Mul];
"380 bert/embeddings/LayerNorm/batchnorm/mul_2" [id=380, type=Mul];
"381 bert/embeddings/LayerNorm/batchnorm/sub" [id=381, type=Sub];
"382 bert/embeddings/LayerNorm/batchnorm/mul_1" [id=382, type=Mul];
"383 bert/embeddings/LayerNorm/batchnorm/add_1" [id=383, type=Add];
"384 bert/encoder/Shape_2" [id=384, type=Shape];
"385 bert/encoder/Shape_2__76" [id=385, type=Cast];
"386 bert/encoder/strided_slice_2" [id=386, type=Slice];
"387 Constant_nncf_381" [id=387, type=Constant];
"388 bert/encoder/strided_slice_2__80" [id=388, type=Squeeze];
"389 bert/encoder/strided_slice_2__81" [id=389, type=Cast];
"390 bert/encoder/layer_9/attention/self/mul_2" [id=390, type=Mul];
"391 Constant_nncf_385" [id=391, type=Constant];
"392 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" [id=392, type=Unsqueeze];
"393 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" [id=393, type=Concat];
"394 bert/encoder/layer_9/attention/self/Reshape_3__434" [id=394, type=Cast];
"395 Constant_nncf_389" [id=395, type=Constant];
"396 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" [id=396, type=Unsqueeze];
"397 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [id=397, type=Concat];
"398 bert/encoder/layer_9/attention/self/Reshape_2__429" [id=398, type=Cast];
"399 Constant_nncf_393" [id=399, type=Constant];
"400 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" [id=400, type=Unsqueeze];
"401 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [id=401, type=Concat];
"402 bert/encoder/layer_9/attention/self/Reshape_1__431" [id=402, type=Cast];
"403 Constant_nncf_397" [id=403, type=Constant];
"404 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" [id=404, type=Unsqueeze];
"405 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [id=405, type=Concat];
"406 bert/encoder/layer_9/attention/self/Reshape__430" [id=406, type=Cast];
"407 bert/encoder/layer_8/attention/self/mul_2" [id=407, type=Mul];
"408 Constant_nncf_402" [id=408, type=Constant];
"409 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" [id=409, type=Unsqueeze];
"410 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" [id=410, type=Concat];
"411 bert/encoder/layer_8/attention/self/Reshape_3__420" [id=411, type=Cast];
"412 Constant_nncf_406" [id=412, type=Constant];
"413 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" [id=413, type=Unsqueeze];
"414 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [id=414, type=Concat];
"415 bert/encoder/layer_8/attention/self/Reshape_2__415" [id=415, type=Cast];
"416 Constant_nncf_410" [id=416, type=Constant];
"417 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" [id=417, type=Unsqueeze];
"418 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [id=418, type=Concat];
"419 bert/encoder/layer_8/attention/self/Reshape_1__417" [id=419, type=Cast];
"420 Constant_nncf_414" [id=420, type=Constant];
"421 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" [id=421, type=Unsqueeze];
"422 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [id=422, type=Concat];
"423 bert/encoder/layer_8/attention/self/Reshape__416" [id=423, type=Cast];
"424 bert/encoder/layer_7/attention/self/mul_2" [id=424, type=Mul];
"425 Constant_nncf_419" [id=425, type=Constant];
"426 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" [id=426, type=Unsqueeze];
"427 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" [id=427, type=Concat];
"428 bert/encoder/layer_7/attention/self/Reshape_3__406" [id=428, type=Cast];
"429 Constant_nncf_423" [id=429, type=Constant];
"430 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" [id=430, type=Unsqueeze];
"431 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [id=431, type=Concat];
"432 bert/encoder/layer_7/attention/self/Reshape_2__401" [id=432, type=Cast];
"433 Constant_nncf_427" [id=433, type=Constant];
"434 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" [id=434, type=Unsqueeze];
"435 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [id=435, type=Concat];
"436 bert/encoder/layer_7/attention/self/Reshape_1__403" [id=436, type=Cast];
"437 Constant_nncf_431" [id=437, type=Constant];
"438 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" [id=438, type=Unsqueeze];
"439 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [id=439, type=Concat];
"440 bert/encoder/layer_7/attention/self/Reshape__402" [id=440, type=Cast];
"441 bert/encoder/layer_6/attention/self/mul_2" [id=441, type=Mul];
"442 Constant_nncf_436" [id=442, type=Constant];
"443 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" [id=443, type=Unsqueeze];
"444 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" [id=444, type=Concat];
"445 bert/encoder/layer_6/attention/self/Reshape_3__392" [id=445, type=Cast];
"446 Constant_nncf_440" [id=446, type=Constant];
"447 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" [id=447, type=Unsqueeze];
"448 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [id=448, type=Concat];
"449 bert/encoder/layer_6/attention/self/Reshape_2__387" [id=449, type=Cast];
"450 Constant_nncf_444" [id=450, type=Constant];
"451 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" [id=451, type=Unsqueeze];
"452 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [id=452, type=Concat];
"453 bert/encoder/layer_6/attention/self/Reshape_1__389" [id=453, type=Cast];
"454 Constant_nncf_448" [id=454, type=Constant];
"455 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" [id=455, type=Unsqueeze];
"456 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [id=456, type=Concat];
"457 bert/encoder/layer_6/attention/self/Reshape__388" [id=457, type=Cast];
"458 bert/encoder/layer_5/attention/self/mul_2" [id=458, type=Mul];
"459 Constant_nncf_453" [id=459, type=Constant];
"460 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" [id=460, type=Unsqueeze];
"461 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" [id=461, type=Concat];
"462 bert/encoder/layer_5/attention/self/Reshape_3__378" [id=462, type=Cast];
"463 Constant_nncf_457" [id=463, type=Constant];
"464 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" [id=464, type=Unsqueeze];
"465 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [id=465, type=Concat];
"466 bert/encoder/layer_5/attention/self/Reshape_2__373" [id=466, type=Cast];
"467 Constant_nncf_461" [id=467, type=Constant];
"468 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" [id=468, type=Unsqueeze];
"469 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [id=469, type=Concat];
"470 bert/encoder/layer_5/attention/self/Reshape_1__375" [id=470, type=Cast];
"471 Constant_nncf_465" [id=471, type=Constant];
"472 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" [id=472, type=Unsqueeze];
"473 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [id=473, type=Concat];
"474 bert/encoder/layer_5/attention/self/Reshape__374" [id=474, type=Cast];
"475 bert/encoder/layer_4/attention/self/mul_2" [id=475, type=Mul];
"476 Constant_nncf_470" [id=476, type=Constant];
"477 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" [id=477, type=Unsqueeze];
"478 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" [id=478, type=Concat];
"479 bert/encoder/layer_4/attention/self/Reshape_3__364" [id=479, type=Cast];
"480 Constant_nncf_474" [id=480, type=Constant];
"481 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" [id=481, type=Unsqueeze];
"482 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [id=482, type=Concat];
"483 bert/encoder/layer_4/attention/self/Reshape_2__359" [id=483, type=Cast];
"484 Constant_nncf_478" [id=484, type=Constant];
"485 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" [id=485, type=Unsqueeze];
"486 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [id=486, type=Concat];
"487 bert/encoder/layer_4/attention/self/Reshape_1__361" [id=487, type=Cast];
"488 Constant_nncf_482" [id=488, type=Constant];
"489 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" [id=489, type=Unsqueeze];
"490 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [id=490, type=Concat];
"491 bert/encoder/layer_4/attention/self/Reshape__360" [id=491, type=Cast];
"492 bert/encoder/layer_3/attention/self/mul_2" [id=492, type=Mul];
"493 Constant_nncf_487" [id=493, type=Constant];
"494 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" [id=494, type=Unsqueeze];
"495 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" [id=495, type=Concat];
"496 bert/encoder/layer_3/attention/self/Reshape_3__350" [id=496, type=Cast];
"497 Constant_nncf_491" [id=497, type=Constant];
"498 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" [id=498, type=Unsqueeze];
"499 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [id=499, type=Concat];
"500 bert/encoder/layer_3/attention/self/Reshape_2__345" [id=500, type=Cast];
"501 Constant_nncf_495" [id=501, type=Constant];
"502 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" [id=502, type=Unsqueeze];
"503 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [id=503, type=Concat];
"504 bert/encoder/layer_3/attention/self/Reshape_1__347" [id=504, type=Cast];
"505 Constant_nncf_499" [id=505, type=Constant];
"506 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" [id=506, type=Unsqueeze];
"507 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [id=507, type=Concat];
"508 bert/encoder/layer_3/attention/self/Reshape__346" [id=508, type=Cast];
"509 bert/encoder/layer_2/attention/self/mul_2" [id=509, type=Mul];
"510 Constant_nncf_504" [id=510, type=Constant];
"511 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" [id=511, type=Unsqueeze];
"512 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" [id=512, type=Concat];
"513 bert/encoder/layer_2/attention/self/Reshape_3__336" [id=513, type=Cast];
"514 Constant_nncf_508" [id=514, type=Constant];
"515 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" [id=515, type=Unsqueeze];
"516 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [id=516, type=Concat];
"517 bert/encoder/layer_2/attention/self/Reshape_2__331" [id=517, type=Cast];
"518 Constant_nncf_512" [id=518, type=Constant];
"519 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" [id=519, type=Unsqueeze];
"520 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [id=520, type=Concat];
"521 bert/encoder/layer_2/attention/self/Reshape_1__333" [id=521, type=Cast];
"522 Constant_nncf_516" [id=522, type=Constant];
"523 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" [id=523, type=Unsqueeze];
"524 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [id=524, type=Concat];
"525 bert/encoder/layer_2/attention/self/Reshape__332" [id=525, type=Cast];
"526 bert/encoder/layer_11/attention/self/mul_2" [id=526, type=Mul];
"527 Constant_nncf_521" [id=527, type=Constant];
"528 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" [id=528, type=Unsqueeze];
"529 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" [id=529, type=Concat];
"530 bert/encoder/layer_11/attention/self/Reshape_3__462" [id=530, type=Cast];
"531 Constant_nncf_525" [id=531, type=Constant];
"532 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" [id=532, type=Unsqueeze];
"533 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [id=533, type=Concat];
"534 bert/encoder/layer_11/attention/self/Reshape_2__457" [id=534, type=Cast];
"535 Constant_nncf_529" [id=535, type=Constant];
"536 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" [id=536, type=Unsqueeze];
"537 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [id=537, type=Concat];
"538 bert/encoder/layer_11/attention/self/Reshape_1__459" [id=538, type=Cast];
"539 Constant_nncf_533" [id=539, type=Constant];
"540 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" [id=540, type=Unsqueeze];
"541 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [id=541, type=Concat];
"542 bert/encoder/layer_11/attention/self/Reshape__458" [id=542, type=Cast];
"543 bert/encoder/layer_10/attention/self/mul_2" [id=543, type=Mul];
"544 Constant_nncf_538" [id=544, type=Constant];
"545 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" [id=545, type=Unsqueeze];
"546 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" [id=546, type=Concat];
"547 bert/encoder/layer_10/attention/self/Reshape_3__448" [id=547, type=Cast];
"548 Constant_nncf_542" [id=548, type=Constant];
"549 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" [id=549, type=Unsqueeze];
"550 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [id=550, type=Concat];
"551 bert/encoder/layer_10/attention/self/Reshape_2__443" [id=551, type=Cast];
"552 Constant_nncf_546" [id=552, type=Constant];
"553 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" [id=553, type=Unsqueeze];
"554 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [id=554, type=Concat];
"555 bert/encoder/layer_10/attention/self/Reshape_1__445" [id=555, type=Cast];
"556 Constant_nncf_550" [id=556, type=Constant];
"557 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" [id=557, type=Unsqueeze];
"558 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [id=558, type=Concat];
"559 bert/encoder/layer_10/attention/self/Reshape__444" [id=559, type=Cast];
"560 bert/encoder/layer_1/attention/self/mul_2" [id=560, type=Mul];
"561 Constant_nncf_555" [id=561, type=Constant];
"562 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" [id=562, type=Unsqueeze];
"563 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" [id=563, type=Concat];
"564 bert/encoder/layer_1/attention/self/Reshape_3__322" [id=564, type=Cast];
"565 Constant_nncf_559" [id=565, type=Constant];
"566 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" [id=566, type=Unsqueeze];
"567 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [id=567, type=Concat];
"568 bert/encoder/layer_1/attention/self/Reshape_2__317" [id=568, type=Cast];
"569 Constant_nncf_563" [id=569, type=Constant];
"570 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" [id=570, type=Unsqueeze];
"571 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [id=571, type=Concat];
"572 bert/encoder/layer_1/attention/self/Reshape_1__319" [id=572, type=Cast];
"573 Constant_nncf_567" [id=573, type=Constant];
"574 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" [id=574, type=Unsqueeze];
"575 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [id=575, type=Concat];
"576 bert/encoder/layer_1/attention/self/Reshape__318" [id=576, type=Cast];
"577 bert/encoder/layer_0/attention/self/mul_2" [id=577, type=Mul];
"578 Constant_nncf_572" [id=578, type=Constant];
"579 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" [id=579, type=Unsqueeze];
"580 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" [id=580, type=Concat];
"581 bert/encoder/layer_0/attention/self/Reshape_3__308" [id=581, type=Cast];
"582 Constant_nncf_576" [id=582, type=Constant];
"583 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" [id=583, type=Unsqueeze];
"584 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [id=584, type=Concat];
"585 bert/encoder/layer_0/attention/self/Reshape_2__303" [id=585, type=Cast];
"586 Constant_nncf_580" [id=586, type=Constant];
"587 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" [id=587, type=Unsqueeze];
"588 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [id=588, type=Concat];
"589 bert/encoder/layer_0/attention/self/Reshape_1__305" [id=589, type=Cast];
"590 Constant_nncf_584" [id=590, type=Constant];
"591 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" [id=591, type=Unsqueeze];
"592 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [id=592, type=Concat];
"593 bert/encoder/layer_0/attention/self/Reshape__304" [id=593, type=Cast];
"594 Constant_nncf_588" [id=594, type=Constant];
"595 bert/encoder/Reshape_13/shape_Unsqueeze__298" [id=595, type=Unsqueeze];
"596 bert/encoder/Reshape_13/shape_Concat__301" [id=596, type=Concat];
"597 bert/encoder/Reshape_13__471" [id=597, type=Cast];
"598 bert/encoder/Reshape_1" [id=598, type=Reshape];
"599 QuantizeLinear_bert/encoder/Reshape_1^0_1" [id=599, type=QuantizeLinear, label="599 QuantizeLinear_bert/encoder/Reshape_1:0_1"];
"600 DequantizeLinear_bert/encoder/Reshape_1^0_1" [id=600, type=DequantizeLinear, label="600 DequantizeLinear_bert/encoder/Reshape_1:0_1"];
"601 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=601, type=QuantizeLinear, label="601 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1"];
"602 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=602, type=DequantizeLinear, label="602 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1"];
"603 QuantizeLinear_bert/encoder/Reshape_1^0_2" [id=603, type=QuantizeLinear, label="603 QuantizeLinear_bert/encoder/Reshape_1:0_2"];
"604 DequantizeLinear_bert/encoder/Reshape_1^0_2" [id=604, type=DequantizeLinear, label="604 DequantizeLinear_bert/encoder/Reshape_1:0_2"];
"605 QuantizeLinear_bert/encoder/Reshape_1^0_3" [id=605, type=QuantizeLinear, label="605 QuantizeLinear_bert/encoder/Reshape_1:0_3"];
"606 DequantizeLinear_bert/encoder/Reshape_1^0_3" [id=606, type=DequantizeLinear, label="606 DequantizeLinear_bert/encoder/Reshape_1:0_3"];
"607 bert/encoder/layer_0/attention/self/value/MatMul" [id=607, type=MatMul];
"608 bert/encoder/layer_0/attention/self/value/BiasAdd" [id=608, type=Add];
"609 bert/encoder/layer_0/attention/self/Reshape_2" [id=609, type=Reshape];
"610 bert/encoder/layer_0/attention/self/transpose_2" [id=610, type=Transpose];
"611 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=611, type=QuantizeLinear, label="611 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1"];
"612 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=612, type=DequantizeLinear, label="612 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1"];
"613 bert/encoder/layer_0/attention/self/query/MatMul" [id=613, type=MatMul];
"614 bert/encoder/layer_0/attention/self/query/BiasAdd" [id=614, type=Add];
"615 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=615, type=QuantizeLinear, label="615 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1"];
"616 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=616, type=DequantizeLinear, label="616 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1"];
"617 bert/encoder/layer_0/attention/self/Reshape" [id=617, type=Reshape];
"618 bert/encoder/layer_0/attention/self/transpose" [id=618, type=Transpose];
"619 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=619, type=QuantizeLinear, label="619 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1"];
"620 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=620, type=DequantizeLinear, label="620 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1"];
"621 bert/encoder/layer_0/attention/self/key/MatMul" [id=621, type=MatMul];
"622 bert/encoder/layer_0/attention/self/key/BiasAdd" [id=622, type=Add];
"623 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=623, type=QuantizeLinear, label="623 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1"];
"624 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=624, type=DequantizeLinear, label="624 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1"];
"625 bert/encoder/layer_0/attention/self/Reshape_1" [id=625, type=Reshape];
"626 bert/encoder/layer_0/attention/self/transpose_1" [id=626, type=Transpose];
"627 bert/encoder/layer_0/attention/self/MatMul__306" [id=627, type=Transpose];
"628 bert/encoder/layer_0/attention/self/MatMul" [id=628, type=MatMul];
"629 bert/encoder/layer_0/attention/self/Mul" [id=629, type=Mul];
"630 bert/encoder/layer_0/attention/self/add" [id=630, type=Add];
"631 Shape_nncf_609" [id=631, type=Shape];
"632 Flatten_nncf_610" [id=632, type=Flatten];
"633 bert/encoder/layer_0/attention/self/Softmax" [id=633, type=Softmax];
"634 Reshape_nncf_612" [id=634, type=Reshape];
"635 bert/encoder/layer_0/attention/self/MatMul_1" [id=635, type=MatMul];
"636 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=636, type=QuantizeLinear, label="636 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1"];
"637 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=637, type=DequantizeLinear, label="637 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1"];
"638 bert/encoder/layer_0/attention/self/transpose_3" [id=638, type=Transpose];
"639 bert/encoder/layer_0/attention/self/Reshape_3" [id=639, type=Reshape];
"640 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=640, type=QuantizeLinear, label="640 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1"];
"641 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=641, type=DequantizeLinear, label="641 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1"];
"642 bert/encoder/layer_0/attention/output/dense/MatMul" [id=642, type=MatMul];
"643 bert/encoder/layer_0/attention/output/dense/BiasAdd" [id=643, type=Add];
"644 bert/encoder/layer_0/attention/output/add" [id=644, type=Add];
"645 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" [id=645, type=ReduceMean];
"646 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" [id=646, type=Identity];
"647 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" [id=647, type=Sub];
"648 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" [id=648, type=Mul];
"649 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" [id=649, type=ReduceMean];
"650 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" [id=650, type=Add];
"651 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" [id=651, type=Sqrt];
"652 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" [id=652, type=Reciprocal];
"653 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" [id=653, type=Mul];
"654 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" [id=654, type=Mul];
"655 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" [id=655, type=Sub];
"656 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" [id=656, type=Mul];
"657 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" [id=657, type=Add];
"658 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=658, type=QuantizeLinear, label="658 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"659 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=659, type=DequantizeLinear, label="659 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"660 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=660, type=QuantizeLinear, label="660 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1"];
"661 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=661, type=DequantizeLinear, label="661 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1"];
"662 bert/encoder/layer_0/intermediate/dense/MatMul" [id=662, type=MatMul];
"663 bert/encoder/layer_0/intermediate/dense/BiasAdd" [id=663, type=Add];
"664 bert/encoder/layer_0/intermediate/dense/Pow" [id=664, type=Pow];
"665 bert/encoder/layer_0/intermediate/dense/mul" [id=665, type=Mul];
"666 bert/encoder/layer_0/intermediate/dense/add" [id=666, type=Add];
"667 bert/encoder/layer_0/intermediate/dense/mul_1" [id=667, type=Mul];
"668 bert/encoder/layer_0/intermediate/dense/Tanh" [id=668, type=Tanh];
"669 bert/encoder/layer_0/intermediate/dense/add_1" [id=669, type=Add];
"670 bert/encoder/layer_0/intermediate/dense/mul_2" [id=670, type=Mul];
"671 bert/encoder/layer_0/intermediate/dense/mul_3" [id=671, type=Mul];
"672 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=672, type=QuantizeLinear, label="672 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1"];
"673 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=673, type=DequantizeLinear, label="673 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1"];
"674 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=674, type=QuantizeLinear, label="674 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1"];
"675 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=675, type=DequantizeLinear, label="675 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1"];
"676 bert/encoder/layer_0/output/dense/MatMul" [id=676, type=MatMul];
"677 bert/encoder/layer_0/output/dense/BiasAdd" [id=677, type=Add];
"678 bert/encoder/layer_0/output/add" [id=678, type=Add];
"679 bert/encoder/layer_0/output/LayerNorm/moments/mean" [id=679, type=ReduceMean];
"680 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" [id=680, type=Identity];
"681 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" [id=681, type=Sub];
"682 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" [id=682, type=Mul];
"683 bert/encoder/layer_0/output/LayerNorm/moments/variance" [id=683, type=ReduceMean];
"684 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" [id=684, type=Add];
"685 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" [id=685, type=Sqrt];
"686 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" [id=686, type=Reciprocal];
"687 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" [id=687, type=Mul];
"688 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" [id=688, type=Mul];
"689 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" [id=689, type=Sub];
"690 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" [id=690, type=Mul];
"691 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" [id=691, type=Add];
"692 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=692, type=QuantizeLinear, label="692 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1"];
"693 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=693, type=DequantizeLinear, label="693 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1"];
"694 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=694, type=QuantizeLinear, label="694 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1"];
"695 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=695, type=DequantizeLinear, label="695 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1"];
"696 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=696, type=QuantizeLinear, label="696 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2"];
"697 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=697, type=DequantizeLinear, label="697 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2"];
"698 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=698, type=QuantizeLinear, label="698 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3"];
"699 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=699, type=DequantizeLinear, label="699 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3"];
"700 bert/encoder/layer_1/attention/self/value/MatMul" [id=700, type=MatMul];
"701 bert/encoder/layer_1/attention/self/value/BiasAdd" [id=701, type=Add];
"702 bert/encoder/layer_1/attention/self/Reshape_2" [id=702, type=Reshape];
"703 bert/encoder/layer_1/attention/self/transpose_2" [id=703, type=Transpose];
"704 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=704, type=QuantizeLinear, label="704 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1"];
"705 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=705, type=DequantizeLinear, label="705 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1"];
"706 bert/encoder/layer_1/attention/self/query/MatMul" [id=706, type=MatMul];
"707 bert/encoder/layer_1/attention/self/query/BiasAdd" [id=707, type=Add];
"708 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=708, type=QuantizeLinear, label="708 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1"];
"709 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=709, type=DequantizeLinear, label="709 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1"];
"710 bert/encoder/layer_1/attention/self/Reshape" [id=710, type=Reshape];
"711 bert/encoder/layer_1/attention/self/transpose" [id=711, type=Transpose];
"712 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=712, type=QuantizeLinear, label="712 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1"];
"713 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=713, type=DequantizeLinear, label="713 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1"];
"714 bert/encoder/layer_1/attention/self/key/MatMul" [id=714, type=MatMul];
"715 bert/encoder/layer_1/attention/self/key/BiasAdd" [id=715, type=Add];
"716 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=716, type=QuantizeLinear, label="716 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1"];
"717 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=717, type=DequantizeLinear, label="717 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1"];
"718 bert/encoder/layer_1/attention/self/Reshape_1" [id=718, type=Reshape];
"719 bert/encoder/layer_1/attention/self/transpose_1" [id=719, type=Transpose];
"720 bert/encoder/layer_1/attention/self/MatMul__320" [id=720, type=Transpose];
"721 bert/encoder/layer_1/attention/self/MatMul" [id=721, type=MatMul];
"722 bert/encoder/layer_1/attention/self/Mul" [id=722, type=Mul];
"723 bert/encoder/layer_1/attention/self/add" [id=723, type=Add];
"724 Shape_nncf_674" [id=724, type=Shape];
"725 Flatten_nncf_675" [id=725, type=Flatten];
"726 bert/encoder/layer_1/attention/self/Softmax" [id=726, type=Softmax];
"727 Reshape_nncf_677" [id=727, type=Reshape];
"728 bert/encoder/layer_1/attention/self/MatMul_1" [id=728, type=MatMul];
"729 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=729, type=QuantizeLinear, label="729 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1"];
"730 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=730, type=DequantizeLinear, label="730 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1"];
"731 bert/encoder/layer_1/attention/self/transpose_3" [id=731, type=Transpose];
"732 bert/encoder/layer_1/attention/self/Reshape_3" [id=732, type=Reshape];
"733 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=733, type=QuantizeLinear, label="733 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1"];
"734 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=734, type=DequantizeLinear, label="734 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1"];
"735 bert/encoder/layer_1/attention/output/dense/MatMul" [id=735, type=MatMul];
"736 bert/encoder/layer_1/attention/output/dense/BiasAdd" [id=736, type=Add];
"737 bert/encoder/layer_1/attention/output/add" [id=737, type=Add];
"738 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" [id=738, type=ReduceMean];
"739 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" [id=739, type=Identity];
"740 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" [id=740, type=Sub];
"741 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" [id=741, type=Mul];
"742 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" [id=742, type=ReduceMean];
"743 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" [id=743, type=Add];
"744 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" [id=744, type=Sqrt];
"745 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" [id=745, type=Reciprocal];
"746 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" [id=746, type=Mul];
"747 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" [id=747, type=Mul];
"748 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" [id=748, type=Sub];
"749 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" [id=749, type=Mul];
"750 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" [id=750, type=Add];
"751 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=751, type=QuantizeLinear, label="751 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"752 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=752, type=DequantizeLinear, label="752 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"753 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=753, type=QuantizeLinear, label="753 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1"];
"754 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=754, type=DequantizeLinear, label="754 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1"];
"755 bert/encoder/layer_1/intermediate/dense/MatMul" [id=755, type=MatMul];
"756 bert/encoder/layer_1/intermediate/dense/BiasAdd" [id=756, type=Add];
"757 bert/encoder/layer_1/intermediate/dense/Pow" [id=757, type=Pow];
"758 bert/encoder/layer_1/intermediate/dense/mul" [id=758, type=Mul];
"759 bert/encoder/layer_1/intermediate/dense/add" [id=759, type=Add];
"760 bert/encoder/layer_1/intermediate/dense/mul_1" [id=760, type=Mul];
"761 bert/encoder/layer_1/intermediate/dense/Tanh" [id=761, type=Tanh];
"762 bert/encoder/layer_1/intermediate/dense/add_1" [id=762, type=Add];
"763 bert/encoder/layer_1/intermediate/dense/mul_2" [id=763, type=Mul];
"764 bert/encoder/layer_1/intermediate/dense/mul_3" [id=764, type=Mul];
"765 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=765, type=QuantizeLinear, label="765 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1"];
"766 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=766, type=DequantizeLinear, label="766 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1"];
"767 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=767, type=QuantizeLinear, label="767 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1"];
"768 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=768, type=DequantizeLinear, label="768 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1"];
"769 bert/encoder/layer_1/output/dense/MatMul" [id=769, type=MatMul];
"770 bert/encoder/layer_1/output/dense/BiasAdd" [id=770, type=Add];
"771 bert/encoder/layer_1/output/add" [id=771, type=Add];
"772 bert/encoder/layer_1/output/LayerNorm/moments/mean" [id=772, type=ReduceMean];
"773 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" [id=773, type=Identity];
"774 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" [id=774, type=Sub];
"775 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" [id=775, type=Mul];
"776 bert/encoder/layer_1/output/LayerNorm/moments/variance" [id=776, type=ReduceMean];
"777 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" [id=777, type=Add];
"778 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" [id=778, type=Sqrt];
"779 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" [id=779, type=Reciprocal];
"780 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" [id=780, type=Mul];
"781 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" [id=781, type=Mul];
"782 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" [id=782, type=Sub];
"783 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" [id=783, type=Mul];
"784 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" [id=784, type=Add];
"785 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=785, type=QuantizeLinear, label="785 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1"];
"786 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=786, type=DequantizeLinear, label="786 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1"];
"787 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=787, type=QuantizeLinear, label="787 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1"];
"788 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=788, type=DequantizeLinear, label="788 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1"];
"789 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=789, type=QuantizeLinear, label="789 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2"];
"790 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=790, type=DequantizeLinear, label="790 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2"];
"791 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=791, type=QuantizeLinear, label="791 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3"];
"792 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=792, type=DequantizeLinear, label="792 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3"];
"793 bert/encoder/layer_2/attention/self/value/MatMul" [id=793, type=MatMul];
"794 bert/encoder/layer_2/attention/self/value/BiasAdd" [id=794, type=Add];
"795 bert/encoder/layer_2/attention/self/Reshape_2" [id=795, type=Reshape];
"796 bert/encoder/layer_2/attention/self/transpose_2" [id=796, type=Transpose];
"797 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=797, type=QuantizeLinear, label="797 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1"];
"798 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=798, type=DequantizeLinear, label="798 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1"];
"799 bert/encoder/layer_2/attention/self/query/MatMul" [id=799, type=MatMul];
"800 bert/encoder/layer_2/attention/self/query/BiasAdd" [id=800, type=Add];
"801 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=801, type=QuantizeLinear, label="801 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1"];
"802 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=802, type=DequantizeLinear, label="802 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1"];
"803 bert/encoder/layer_2/attention/self/Reshape" [id=803, type=Reshape];
"804 bert/encoder/layer_2/attention/self/transpose" [id=804, type=Transpose];
"805 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=805, type=QuantizeLinear, label="805 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1"];
"806 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=806, type=DequantizeLinear, label="806 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1"];
"807 bert/encoder/layer_2/attention/self/key/MatMul" [id=807, type=MatMul];
"808 bert/encoder/layer_2/attention/self/key/BiasAdd" [id=808, type=Add];
"809 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=809, type=QuantizeLinear, label="809 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1"];
"810 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=810, type=DequantizeLinear, label="810 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1"];
"811 bert/encoder/layer_2/attention/self/Reshape_1" [id=811, type=Reshape];
"812 bert/encoder/layer_2/attention/self/transpose_1" [id=812, type=Transpose];
"813 bert/encoder/layer_2/attention/self/MatMul__334" [id=813, type=Transpose];
"814 bert/encoder/layer_2/attention/self/MatMul" [id=814, type=MatMul];
"815 bert/encoder/layer_2/attention/self/Mul" [id=815, type=Mul];
"816 bert/encoder/layer_2/attention/self/add" [id=816, type=Add];
"817 Shape_nncf_739" [id=817, type=Shape];
"818 Flatten_nncf_740" [id=818, type=Flatten];
"819 bert/encoder/layer_2/attention/self/Softmax" [id=819, type=Softmax];
"820 Reshape_nncf_742" [id=820, type=Reshape];
"821 bert/encoder/layer_2/attention/self/MatMul_1" [id=821, type=MatMul];
"822 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=822, type=QuantizeLinear, label="822 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1"];
"823 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=823, type=DequantizeLinear, label="823 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1"];
"824 bert/encoder/layer_2/attention/self/transpose_3" [id=824, type=Transpose];
"825 bert/encoder/layer_2/attention/self/Reshape_3" [id=825, type=Reshape];
"826 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=826, type=QuantizeLinear, label="826 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1"];
"827 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=827, type=DequantizeLinear, label="827 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1"];
"828 bert/encoder/layer_2/attention/output/dense/MatMul" [id=828, type=MatMul];
"829 bert/encoder/layer_2/attention/output/dense/BiasAdd" [id=829, type=Add];
"830 bert/encoder/layer_2/attention/output/add" [id=830, type=Add];
"831 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" [id=831, type=ReduceMean];
"832 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" [id=832, type=Identity];
"833 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" [id=833, type=Sub];
"834 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" [id=834, type=Mul];
"835 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" [id=835, type=ReduceMean];
"836 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" [id=836, type=Add];
"837 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" [id=837, type=Sqrt];
"838 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" [id=838, type=Reciprocal];
"839 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" [id=839, type=Mul];
"840 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" [id=840, type=Mul];
"841 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" [id=841, type=Sub];
"842 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" [id=842, type=Mul];
"843 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" [id=843, type=Add];
"844 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=844, type=QuantizeLinear, label="844 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"845 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=845, type=DequantizeLinear, label="845 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"846 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=846, type=QuantizeLinear, label="846 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1"];
"847 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=847, type=DequantizeLinear, label="847 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1"];
"848 bert/encoder/layer_2/intermediate/dense/MatMul" [id=848, type=MatMul];
"849 bert/encoder/layer_2/intermediate/dense/BiasAdd" [id=849, type=Add];
"850 bert/encoder/layer_2/intermediate/dense/Pow" [id=850, type=Pow];
"851 bert/encoder/layer_2/intermediate/dense/mul" [id=851, type=Mul];
"852 bert/encoder/layer_2/intermediate/dense/add" [id=852, type=Add];
"853 bert/encoder/layer_2/intermediate/dense/mul_1" [id=853, type=Mul];
"854 bert/encoder/layer_2/intermediate/dense/Tanh" [id=854, type=Tanh];
"855 bert/encoder/layer_2/intermediate/dense/add_1" [id=855, type=Add];
"856 bert/encoder/layer_2/intermediate/dense/mul_2" [id=856, type=Mul];
"857 bert/encoder/layer_2/intermediate/dense/mul_3" [id=857, type=Mul];
"858 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=858, type=QuantizeLinear, label="858 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1"];
"859 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=859, type=DequantizeLinear, label="859 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1"];
"860 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=860, type=QuantizeLinear, label="860 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1"];
"861 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=861, type=DequantizeLinear, label="861 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1"];
"862 bert/encoder/layer_2/output/dense/MatMul" [id=862, type=MatMul];
"863 bert/encoder/layer_2/output/dense/BiasAdd" [id=863, type=Add];
"864 bert/encoder/layer_2/output/add" [id=864, type=Add];
"865 bert/encoder/layer_2/output/LayerNorm/moments/mean" [id=865, type=ReduceMean];
"866 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" [id=866, type=Identity];
"867 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" [id=867, type=Sub];
"868 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" [id=868, type=Mul];
"869 bert/encoder/layer_2/output/LayerNorm/moments/variance" [id=869, type=ReduceMean];
"870 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" [id=870, type=Add];
"871 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" [id=871, type=Sqrt];
"872 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" [id=872, type=Reciprocal];
"873 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" [id=873, type=Mul];
"874 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" [id=874, type=Mul];
"875 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" [id=875, type=Sub];
"876 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" [id=876, type=Mul];
"877 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" [id=877, type=Add];
"878 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=878, type=QuantizeLinear, label="878 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1"];
"879 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=879, type=DequantizeLinear, label="879 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1"];
"880 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=880, type=QuantizeLinear, label="880 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1"];
"881 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=881, type=DequantizeLinear, label="881 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1"];
"882 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=882, type=QuantizeLinear, label="882 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2"];
"883 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=883, type=DequantizeLinear, label="883 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2"];
"884 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=884, type=QuantizeLinear, label="884 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3"];
"885 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=885, type=DequantizeLinear, label="885 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3"];
"886 bert/encoder/layer_3/attention/self/value/MatMul" [id=886, type=MatMul];
"887 bert/encoder/layer_3/attention/self/value/BiasAdd" [id=887, type=Add];
"888 bert/encoder/layer_3/attention/self/Reshape_2" [id=888, type=Reshape];
"889 bert/encoder/layer_3/attention/self/transpose_2" [id=889, type=Transpose];
"890 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=890, type=QuantizeLinear, label="890 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1"];
"891 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=891, type=DequantizeLinear, label="891 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1"];
"892 bert/encoder/layer_3/attention/self/query/MatMul" [id=892, type=MatMul];
"893 bert/encoder/layer_3/attention/self/query/BiasAdd" [id=893, type=Add];
"894 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=894, type=QuantizeLinear, label="894 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1"];
"895 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=895, type=DequantizeLinear, label="895 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1"];
"896 bert/encoder/layer_3/attention/self/Reshape" [id=896, type=Reshape];
"897 bert/encoder/layer_3/attention/self/transpose" [id=897, type=Transpose];
"898 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=898, type=QuantizeLinear, label="898 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1"];
"899 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=899, type=DequantizeLinear, label="899 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1"];
"900 bert/encoder/layer_3/attention/self/key/MatMul" [id=900, type=MatMul];
"901 bert/encoder/layer_3/attention/self/key/BiasAdd" [id=901, type=Add];
"902 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=902, type=QuantizeLinear, label="902 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1"];
"903 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=903, type=DequantizeLinear, label="903 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1"];
"904 bert/encoder/layer_3/attention/self/Reshape_1" [id=904, type=Reshape];
"905 bert/encoder/layer_3/attention/self/transpose_1" [id=905, type=Transpose];
"906 bert/encoder/layer_3/attention/self/MatMul__348" [id=906, type=Transpose];
"907 bert/encoder/layer_3/attention/self/MatMul" [id=907, type=MatMul];
"908 bert/encoder/layer_3/attention/self/Mul" [id=908, type=Mul];
"909 bert/encoder/layer_3/attention/self/add" [id=909, type=Add];
"910 Shape_nncf_804" [id=910, type=Shape];
"911 Flatten_nncf_805" [id=911, type=Flatten];
"912 bert/encoder/layer_3/attention/self/Softmax" [id=912, type=Softmax];
"913 Reshape_nncf_807" [id=913, type=Reshape];
"914 bert/encoder/layer_3/attention/self/MatMul_1" [id=914, type=MatMul];
"915 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=915, type=QuantizeLinear, label="915 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1"];
"916 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=916, type=DequantizeLinear, label="916 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1"];
"917 bert/encoder/layer_3/attention/self/transpose_3" [id=917, type=Transpose];
"918 bert/encoder/layer_3/attention/self/Reshape_3" [id=918, type=Reshape];
"919 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=919, type=QuantizeLinear, label="919 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1"];
"920 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=920, type=DequantizeLinear, label="920 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1"];
"921 bert/encoder/layer_3/attention/output/dense/MatMul" [id=921, type=MatMul];
"922 bert/encoder/layer_3/attention/output/dense/BiasAdd" [id=922, type=Add];
"923 bert/encoder/layer_3/attention/output/add" [id=923, type=Add];
"924 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" [id=924, type=ReduceMean];
"925 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" [id=925, type=Identity];
"926 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" [id=926, type=Sub];
"927 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" [id=927, type=Mul];
"928 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" [id=928, type=ReduceMean];
"929 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" [id=929, type=Add];
"930 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" [id=930, type=Sqrt];
"931 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" [id=931, type=Reciprocal];
"932 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" [id=932, type=Mul];
"933 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" [id=933, type=Mul];
"934 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" [id=934, type=Sub];
"935 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" [id=935, type=Mul];
"936 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" [id=936, type=Add];
"937 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=937, type=QuantizeLinear, label="937 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"938 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=938, type=DequantizeLinear, label="938 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"939 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=939, type=QuantizeLinear, label="939 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1"];
"940 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=940, type=DequantizeLinear, label="940 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1"];
"941 bert/encoder/layer_3/intermediate/dense/MatMul" [id=941, type=MatMul];
"942 bert/encoder/layer_3/intermediate/dense/BiasAdd" [id=942, type=Add];
"943 bert/encoder/layer_3/intermediate/dense/Pow" [id=943, type=Pow];
"944 bert/encoder/layer_3/intermediate/dense/mul" [id=944, type=Mul];
"945 bert/encoder/layer_3/intermediate/dense/add" [id=945, type=Add];
"946 bert/encoder/layer_3/intermediate/dense/mul_1" [id=946, type=Mul];
"947 bert/encoder/layer_3/intermediate/dense/Tanh" [id=947, type=Tanh];
"948 bert/encoder/layer_3/intermediate/dense/add_1" [id=948, type=Add];
"949 bert/encoder/layer_3/intermediate/dense/mul_2" [id=949, type=Mul];
"950 bert/encoder/layer_3/intermediate/dense/mul_3" [id=950, type=Mul];
"951 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=951, type=QuantizeLinear, label="951 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1"];
"952 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=952, type=DequantizeLinear, label="952 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1"];
"953 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=953, type=QuantizeLinear, label="953 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1"];
"954 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=954, type=DequantizeLinear, label="954 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1"];
"955 bert/encoder/layer_3/output/dense/MatMul" [id=955, type=MatMul];
"956 bert/encoder/layer_3/output/dense/BiasAdd" [id=956, type=Add];
"957 bert/encoder/layer_3/output/add" [id=957, type=Add];
"958 bert/encoder/layer_3/output/LayerNorm/moments/mean" [id=958, type=ReduceMean];
"959 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" [id=959, type=Identity];
"960 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" [id=960, type=Sub];
"961 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" [id=961, type=Mul];
"962 bert/encoder/layer_3/output/LayerNorm/moments/variance" [id=962, type=ReduceMean];
"963 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" [id=963, type=Add];
"964 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" [id=964, type=Sqrt];
"965 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" [id=965, type=Reciprocal];
"966 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" [id=966, type=Mul];
"967 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" [id=967, type=Mul];
"968 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" [id=968, type=Sub];
"969 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" [id=969, type=Mul];
"970 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" [id=970, type=Add];
"971 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=971, type=QuantizeLinear, label="971 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1"];
"972 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=972, type=DequantizeLinear, label="972 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1"];
"973 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=973, type=QuantizeLinear, label="973 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1"];
"974 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=974, type=DequantizeLinear, label="974 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1"];
"975 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=975, type=QuantizeLinear, label="975 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2"];
"976 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=976, type=DequantizeLinear, label="976 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2"];
"977 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=977, type=QuantizeLinear, label="977 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3"];
"978 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=978, type=DequantizeLinear, label="978 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3"];
"979 bert/encoder/layer_4/attention/self/value/MatMul" [id=979, type=MatMul];
"980 bert/encoder/layer_4/attention/self/value/BiasAdd" [id=980, type=Add];
"981 bert/encoder/layer_4/attention/self/Reshape_2" [id=981, type=Reshape];
"982 bert/encoder/layer_4/attention/self/transpose_2" [id=982, type=Transpose];
"983 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=983, type=QuantizeLinear, label="983 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1"];
"984 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=984, type=DequantizeLinear, label="984 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1"];
"985 bert/encoder/layer_4/attention/self/query/MatMul" [id=985, type=MatMul];
"986 bert/encoder/layer_4/attention/self/query/BiasAdd" [id=986, type=Add];
"987 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=987, type=QuantizeLinear, label="987 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1"];
"988 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=988, type=DequantizeLinear, label="988 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1"];
"989 bert/encoder/layer_4/attention/self/Reshape" [id=989, type=Reshape];
"990 bert/encoder/layer_4/attention/self/transpose" [id=990, type=Transpose];
"991 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=991, type=QuantizeLinear, label="991 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1"];
"992 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=992, type=DequantizeLinear, label="992 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1"];
"993 bert/encoder/layer_4/attention/self/key/MatMul" [id=993, type=MatMul];
"994 bert/encoder/layer_4/attention/self/key/BiasAdd" [id=994, type=Add];
"995 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=995, type=QuantizeLinear, label="995 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1"];
"996 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=996, type=DequantizeLinear, label="996 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1"];
"997 bert/encoder/layer_4/attention/self/Reshape_1" [id=997, type=Reshape];
"998 bert/encoder/layer_4/attention/self/transpose_1" [id=998, type=Transpose];
"999 bert/encoder/layer_4/attention/self/MatMul__362" [id=999, type=Transpose];
"1000 bert/encoder/layer_4/attention/self/MatMul" [id=1000, type=MatMul];
"1001 bert/encoder/layer_4/attention/self/Mul" [id=1001, type=Mul];
"1002 bert/encoder/layer_4/attention/self/add" [id=1002, type=Add];
"1003 Shape_nncf_869" [id=1003, type=Shape];
"1004 Flatten_nncf_870" [id=1004, type=Flatten];
"1005 bert/encoder/layer_4/attention/self/Softmax" [id=1005, type=Softmax];
"1006 Reshape_nncf_872" [id=1006, type=Reshape];
"1007 bert/encoder/layer_4/attention/self/MatMul_1" [id=1007, type=MatMul];
"1008 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=1008, type=QuantizeLinear, label="1008 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1"];
"1009 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=1009, type=DequantizeLinear, label="1009 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1"];
"1010 bert/encoder/layer_4/attention/self/transpose_3" [id=1010, type=Transpose];
"1011 bert/encoder/layer_4/attention/self/Reshape_3" [id=1011, type=Reshape];
"1012 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=1012, type=QuantizeLinear, label="1012 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1"];
"1013 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=1013, type=DequantizeLinear, label="1013 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1"];
"1014 bert/encoder/layer_4/attention/output/dense/MatMul" [id=1014, type=MatMul];
"1015 bert/encoder/layer_4/attention/output/dense/BiasAdd" [id=1015, type=Add];
"1016 bert/encoder/layer_4/attention/output/add" [id=1016, type=Add];
"1017 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" [id=1017, type=ReduceMean];
"1018 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" [id=1018, type=Identity];
"1019 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" [id=1019, type=Sub];
"1020 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" [id=1020, type=Mul];
"1021 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" [id=1021, type=ReduceMean];
"1022 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" [id=1022, type=Add];
"1023 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1023, type=Sqrt];
"1024 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" [id=1024, type=Reciprocal];
"1025 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" [id=1025, type=Mul];
"1026 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" [id=1026, type=Mul];
"1027 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" [id=1027, type=Sub];
"1028 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" [id=1028, type=Mul];
"1029 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" [id=1029, type=Add];
"1030 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1030, type=QuantizeLinear, label="1030 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1031 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1031, type=DequantizeLinear, label="1031 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1032 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=1032, type=QuantizeLinear, label="1032 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1"];
"1033 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=1033, type=DequantizeLinear, label="1033 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1"];
"1034 bert/encoder/layer_4/intermediate/dense/MatMul" [id=1034, type=MatMul];
"1035 bert/encoder/layer_4/intermediate/dense/BiasAdd" [id=1035, type=Add];
"1036 bert/encoder/layer_4/intermediate/dense/Pow" [id=1036, type=Pow];
"1037 bert/encoder/layer_4/intermediate/dense/mul" [id=1037, type=Mul];
"1038 bert/encoder/layer_4/intermediate/dense/add" [id=1038, type=Add];
"1039 bert/encoder/layer_4/intermediate/dense/mul_1" [id=1039, type=Mul];
"1040 bert/encoder/layer_4/intermediate/dense/Tanh" [id=1040, type=Tanh];
"1041 bert/encoder/layer_4/intermediate/dense/add_1" [id=1041, type=Add];
"1042 bert/encoder/layer_4/intermediate/dense/mul_2" [id=1042, type=Mul];
"1043 bert/encoder/layer_4/intermediate/dense/mul_3" [id=1043, type=Mul];
"1044 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=1044, type=QuantizeLinear, label="1044 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1"];
"1045 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=1045, type=DequantizeLinear, label="1045 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1"];
"1046 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=1046, type=QuantizeLinear, label="1046 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1"];
"1047 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=1047, type=DequantizeLinear, label="1047 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1"];
"1048 bert/encoder/layer_4/output/dense/MatMul" [id=1048, type=MatMul];
"1049 bert/encoder/layer_4/output/dense/BiasAdd" [id=1049, type=Add];
"1050 bert/encoder/layer_4/output/add" [id=1050, type=Add];
"1051 bert/encoder/layer_4/output/LayerNorm/moments/mean" [id=1051, type=ReduceMean];
"1052 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" [id=1052, type=Identity];
"1053 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" [id=1053, type=Sub];
"1054 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" [id=1054, type=Mul];
"1055 bert/encoder/layer_4/output/LayerNorm/moments/variance" [id=1055, type=ReduceMean];
"1056 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" [id=1056, type=Add];
"1057 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" [id=1057, type=Sqrt];
"1058 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" [id=1058, type=Reciprocal];
"1059 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" [id=1059, type=Mul];
"1060 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" [id=1060, type=Mul];
"1061 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" [id=1061, type=Sub];
"1062 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" [id=1062, type=Mul];
"1063 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" [id=1063, type=Add];
"1064 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=1064, type=QuantizeLinear, label="1064 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1"];
"1065 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=1065, type=DequantizeLinear, label="1065 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1"];
"1066 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=1066, type=QuantizeLinear, label="1066 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1"];
"1067 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=1067, type=DequantizeLinear, label="1067 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1"];
"1068 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=1068, type=QuantizeLinear, label="1068 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2"];
"1069 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=1069, type=DequantizeLinear, label="1069 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2"];
"1070 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=1070, type=QuantizeLinear, label="1070 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3"];
"1071 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=1071, type=DequantizeLinear, label="1071 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3"];
"1072 bert/encoder/layer_5/attention/self/value/MatMul" [id=1072, type=MatMul];
"1073 bert/encoder/layer_5/attention/self/value/BiasAdd" [id=1073, type=Add];
"1074 bert/encoder/layer_5/attention/self/Reshape_2" [id=1074, type=Reshape];
"1075 bert/encoder/layer_5/attention/self/transpose_2" [id=1075, type=Transpose];
"1076 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=1076, type=QuantizeLinear, label="1076 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1"];
"1077 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=1077, type=DequantizeLinear, label="1077 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1"];
"1078 bert/encoder/layer_5/attention/self/query/MatMul" [id=1078, type=MatMul];
"1079 bert/encoder/layer_5/attention/self/query/BiasAdd" [id=1079, type=Add];
"1080 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=1080, type=QuantizeLinear, label="1080 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1"];
"1081 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=1081, type=DequantizeLinear, label="1081 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1"];
"1082 bert/encoder/layer_5/attention/self/Reshape" [id=1082, type=Reshape];
"1083 bert/encoder/layer_5/attention/self/transpose" [id=1083, type=Transpose];
"1084 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=1084, type=QuantizeLinear, label="1084 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1"];
"1085 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=1085, type=DequantizeLinear, label="1085 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1"];
"1086 bert/encoder/layer_5/attention/self/key/MatMul" [id=1086, type=MatMul];
"1087 bert/encoder/layer_5/attention/self/key/BiasAdd" [id=1087, type=Add];
"1088 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=1088, type=QuantizeLinear, label="1088 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1"];
"1089 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=1089, type=DequantizeLinear, label="1089 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1"];
"1090 bert/encoder/layer_5/attention/self/Reshape_1" [id=1090, type=Reshape];
"1091 bert/encoder/layer_5/attention/self/transpose_1" [id=1091, type=Transpose];
"1092 bert/encoder/layer_5/attention/self/MatMul__376" [id=1092, type=Transpose];
"1093 bert/encoder/layer_5/attention/self/MatMul" [id=1093, type=MatMul];
"1094 bert/encoder/layer_5/attention/self/Mul" [id=1094, type=Mul];
"1095 bert/encoder/layer_5/attention/self/add" [id=1095, type=Add];
"1096 Shape_nncf_934" [id=1096, type=Shape];
"1097 Flatten_nncf_935" [id=1097, type=Flatten];
"1098 bert/encoder/layer_5/attention/self/Softmax" [id=1098, type=Softmax];
"1099 Reshape_nncf_937" [id=1099, type=Reshape];
"1100 bert/encoder/layer_5/attention/self/MatMul_1" [id=1100, type=MatMul];
"1101 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=1101, type=QuantizeLinear, label="1101 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1"];
"1102 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=1102, type=DequantizeLinear, label="1102 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1"];
"1103 bert/encoder/layer_5/attention/self/transpose_3" [id=1103, type=Transpose];
"1104 bert/encoder/layer_5/attention/self/Reshape_3" [id=1104, type=Reshape];
"1105 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=1105, type=QuantizeLinear, label="1105 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1"];
"1106 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=1106, type=DequantizeLinear, label="1106 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1"];
"1107 bert/encoder/layer_5/attention/output/dense/MatMul" [id=1107, type=MatMul];
"1108 bert/encoder/layer_5/attention/output/dense/BiasAdd" [id=1108, type=Add];
"1109 bert/encoder/layer_5/attention/output/add" [id=1109, type=Add];
"1110 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" [id=1110, type=ReduceMean];
"1111 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" [id=1111, type=Identity];
"1112 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" [id=1112, type=Sub];
"1113 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" [id=1113, type=Mul];
"1114 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" [id=1114, type=ReduceMean];
"1115 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" [id=1115, type=Add];
"1116 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1116, type=Sqrt];
"1117 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" [id=1117, type=Reciprocal];
"1118 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" [id=1118, type=Mul];
"1119 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" [id=1119, type=Mul];
"1120 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" [id=1120, type=Sub];
"1121 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" [id=1121, type=Mul];
"1122 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" [id=1122, type=Add];
"1123 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1123, type=QuantizeLinear, label="1123 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1124 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1124, type=DequantizeLinear, label="1124 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1125 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=1125, type=QuantizeLinear, label="1125 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1"];
"1126 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=1126, type=DequantizeLinear, label="1126 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1"];
"1127 bert/encoder/layer_5/intermediate/dense/MatMul" [id=1127, type=MatMul];
"1128 bert/encoder/layer_5/intermediate/dense/BiasAdd" [id=1128, type=Add];
"1129 bert/encoder/layer_5/intermediate/dense/Pow" [id=1129, type=Pow];
"1130 bert/encoder/layer_5/intermediate/dense/mul" [id=1130, type=Mul];
"1131 bert/encoder/layer_5/intermediate/dense/add" [id=1131, type=Add];
"1132 bert/encoder/layer_5/intermediate/dense/mul_1" [id=1132, type=Mul];
"1133 bert/encoder/layer_5/intermediate/dense/Tanh" [id=1133, type=Tanh];
"1134 bert/encoder/layer_5/intermediate/dense/add_1" [id=1134, type=Add];
"1135 bert/encoder/layer_5/intermediate/dense/mul_2" [id=1135, type=Mul];
"1136 bert/encoder/layer_5/intermediate/dense/mul_3" [id=1136, type=Mul];
"1137 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=1137, type=QuantizeLinear, label="1137 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1"];
"1138 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=1138, type=DequantizeLinear, label="1138 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1"];
"1139 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=1139, type=QuantizeLinear, label="1139 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1"];
"1140 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=1140, type=DequantizeLinear, label="1140 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1"];
"1141 bert/encoder/layer_5/output/dense/MatMul" [id=1141, type=MatMul];
"1142 bert/encoder/layer_5/output/dense/BiasAdd" [id=1142, type=Add];
"1143 bert/encoder/layer_5/output/add" [id=1143, type=Add];
"1144 bert/encoder/layer_5/output/LayerNorm/moments/mean" [id=1144, type=ReduceMean];
"1145 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" [id=1145, type=Identity];
"1146 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" [id=1146, type=Sub];
"1147 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" [id=1147, type=Mul];
"1148 bert/encoder/layer_5/output/LayerNorm/moments/variance" [id=1148, type=ReduceMean];
"1149 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" [id=1149, type=Add];
"1150 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" [id=1150, type=Sqrt];
"1151 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" [id=1151, type=Reciprocal];
"1152 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" [id=1152, type=Mul];
"1153 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" [id=1153, type=Mul];
"1154 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" [id=1154, type=Sub];
"1155 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" [id=1155, type=Mul];
"1156 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" [id=1156, type=Add];
"1157 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=1157, type=QuantizeLinear, label="1157 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1"];
"1158 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=1158, type=DequantizeLinear, label="1158 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1"];
"1159 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=1159, type=QuantizeLinear, label="1159 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1"];
"1160 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=1160, type=DequantizeLinear, label="1160 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1"];
"1161 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=1161, type=QuantizeLinear, label="1161 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2"];
"1162 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=1162, type=DequantizeLinear, label="1162 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2"];
"1163 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=1163, type=QuantizeLinear, label="1163 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3"];
"1164 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=1164, type=DequantizeLinear, label="1164 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3"];
"1165 bert/encoder/layer_6/attention/self/value/MatMul" [id=1165, type=MatMul];
"1166 bert/encoder/layer_6/attention/self/value/BiasAdd" [id=1166, type=Add];
"1167 bert/encoder/layer_6/attention/self/Reshape_2" [id=1167, type=Reshape];
"1168 bert/encoder/layer_6/attention/self/transpose_2" [id=1168, type=Transpose];
"1169 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=1169, type=QuantizeLinear, label="1169 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1"];
"1170 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=1170, type=DequantizeLinear, label="1170 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1"];
"1171 bert/encoder/layer_6/attention/self/query/MatMul" [id=1171, type=MatMul];
"1172 bert/encoder/layer_6/attention/self/query/BiasAdd" [id=1172, type=Add];
"1173 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=1173, type=QuantizeLinear, label="1173 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1"];
"1174 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=1174, type=DequantizeLinear, label="1174 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1"];
"1175 bert/encoder/layer_6/attention/self/Reshape" [id=1175, type=Reshape];
"1176 bert/encoder/layer_6/attention/self/transpose" [id=1176, type=Transpose];
"1177 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=1177, type=QuantizeLinear, label="1177 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1"];
"1178 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=1178, type=DequantizeLinear, label="1178 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1"];
"1179 bert/encoder/layer_6/attention/self/key/MatMul" [id=1179, type=MatMul];
"1180 bert/encoder/layer_6/attention/self/key/BiasAdd" [id=1180, type=Add];
"1181 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=1181, type=QuantizeLinear, label="1181 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1"];
"1182 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=1182, type=DequantizeLinear, label="1182 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1"];
"1183 bert/encoder/layer_6/attention/self/Reshape_1" [id=1183, type=Reshape];
"1184 bert/encoder/layer_6/attention/self/transpose_1" [id=1184, type=Transpose];
"1185 bert/encoder/layer_6/attention/self/MatMul__390" [id=1185, type=Transpose];
"1186 bert/encoder/layer_6/attention/self/MatMul" [id=1186, type=MatMul];
"1187 bert/encoder/layer_6/attention/self/Mul" [id=1187, type=Mul];
"1188 bert/encoder/layer_6/attention/self/add" [id=1188, type=Add];
"1189 Shape_nncf_999" [id=1189, type=Shape];
"1190 Flatten_nncf_1000" [id=1190, type=Flatten];
"1191 bert/encoder/layer_6/attention/self/Softmax" [id=1191, type=Softmax];
"1192 Reshape_nncf_1002" [id=1192, type=Reshape];
"1193 bert/encoder/layer_6/attention/self/MatMul_1" [id=1193, type=MatMul];
"1194 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=1194, type=QuantizeLinear, label="1194 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1"];
"1195 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=1195, type=DequantizeLinear, label="1195 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1"];
"1196 bert/encoder/layer_6/attention/self/transpose_3" [id=1196, type=Transpose];
"1197 bert/encoder/layer_6/attention/self/Reshape_3" [id=1197, type=Reshape];
"1198 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=1198, type=QuantizeLinear, label="1198 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1"];
"1199 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=1199, type=DequantizeLinear, label="1199 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1"];
"1200 bert/encoder/layer_6/attention/output/dense/MatMul" [id=1200, type=MatMul];
"1201 bert/encoder/layer_6/attention/output/dense/BiasAdd" [id=1201, type=Add];
"1202 bert/encoder/layer_6/attention/output/add" [id=1202, type=Add];
"1203 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" [id=1203, type=ReduceMean];
"1204 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" [id=1204, type=Identity];
"1205 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" [id=1205, type=Sub];
"1206 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" [id=1206, type=Mul];
"1207 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" [id=1207, type=ReduceMean];
"1208 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" [id=1208, type=Add];
"1209 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1209, type=Sqrt];
"1210 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" [id=1210, type=Reciprocal];
"1211 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" [id=1211, type=Mul];
"1212 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" [id=1212, type=Mul];
"1213 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" [id=1213, type=Sub];
"1214 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" [id=1214, type=Mul];
"1215 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" [id=1215, type=Add];
"1216 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1216, type=QuantizeLinear, label="1216 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1217 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1217, type=DequantizeLinear, label="1217 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1218 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1218, type=QuantizeLinear, label="1218 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1"];
"1219 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1219, type=DequantizeLinear, label="1219 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1"];
"1220 bert/encoder/layer_6/intermediate/dense/MatMul" [id=1220, type=MatMul];
"1221 bert/encoder/layer_6/intermediate/dense/BiasAdd" [id=1221, type=Add];
"1222 bert/encoder/layer_6/intermediate/dense/Pow" [id=1222, type=Pow];
"1223 bert/encoder/layer_6/intermediate/dense/mul" [id=1223, type=Mul];
"1224 bert/encoder/layer_6/intermediate/dense/add" [id=1224, type=Add];
"1225 bert/encoder/layer_6/intermediate/dense/mul_1" [id=1225, type=Mul];
"1226 bert/encoder/layer_6/intermediate/dense/Tanh" [id=1226, type=Tanh];
"1227 bert/encoder/layer_6/intermediate/dense/add_1" [id=1227, type=Add];
"1228 bert/encoder/layer_6/intermediate/dense/mul_2" [id=1228, type=Mul];
"1229 bert/encoder/layer_6/intermediate/dense/mul_3" [id=1229, type=Mul];
"1230 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1230, type=QuantizeLinear, label="1230 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1"];
"1231 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1231, type=DequantizeLinear, label="1231 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1"];
"1232 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1232, type=QuantizeLinear, label="1232 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1"];
"1233 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1233, type=DequantizeLinear, label="1233 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1"];
"1234 bert/encoder/layer_6/output/dense/MatMul" [id=1234, type=MatMul];
"1235 bert/encoder/layer_6/output/dense/BiasAdd" [id=1235, type=Add];
"1236 bert/encoder/layer_6/output/add" [id=1236, type=Add];
"1237 bert/encoder/layer_6/output/LayerNorm/moments/mean" [id=1237, type=ReduceMean];
"1238 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" [id=1238, type=Identity];
"1239 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" [id=1239, type=Sub];
"1240 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" [id=1240, type=Mul];
"1241 bert/encoder/layer_6/output/LayerNorm/moments/variance" [id=1241, type=ReduceMean];
"1242 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" [id=1242, type=Add];
"1243 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" [id=1243, type=Sqrt];
"1244 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" [id=1244, type=Reciprocal];
"1245 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" [id=1245, type=Mul];
"1246 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" [id=1246, type=Mul];
"1247 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" [id=1247, type=Sub];
"1248 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" [id=1248, type=Mul];
"1249 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" [id=1249, type=Add];
"1250 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1250, type=QuantizeLinear, label="1250 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1"];
"1251 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1251, type=DequantizeLinear, label="1251 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1"];
"1252 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1252, type=QuantizeLinear, label="1252 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1"];
"1253 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1253, type=DequantizeLinear, label="1253 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1"];
"1254 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1254, type=QuantizeLinear, label="1254 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2"];
"1255 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1255, type=DequantizeLinear, label="1255 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2"];
"1256 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1256, type=QuantizeLinear, label="1256 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3"];
"1257 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1257, type=DequantizeLinear, label="1257 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3"];
"1258 bert/encoder/layer_7/attention/self/value/MatMul" [id=1258, type=MatMul];
"1259 bert/encoder/layer_7/attention/self/value/BiasAdd" [id=1259, type=Add];
"1260 bert/encoder/layer_7/attention/self/Reshape_2" [id=1260, type=Reshape];
"1261 bert/encoder/layer_7/attention/self/transpose_2" [id=1261, type=Transpose];
"1262 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1262, type=QuantizeLinear, label="1262 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1"];
"1263 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1263, type=DequantizeLinear, label="1263 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1"];
"1264 bert/encoder/layer_7/attention/self/query/MatMul" [id=1264, type=MatMul];
"1265 bert/encoder/layer_7/attention/self/query/BiasAdd" [id=1265, type=Add];
"1266 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1266, type=QuantizeLinear, label="1266 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1"];
"1267 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1267, type=DequantizeLinear, label="1267 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1"];
"1268 bert/encoder/layer_7/attention/self/Reshape" [id=1268, type=Reshape];
"1269 bert/encoder/layer_7/attention/self/transpose" [id=1269, type=Transpose];
"1270 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1270, type=QuantizeLinear, label="1270 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1"];
"1271 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1271, type=DequantizeLinear, label="1271 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1"];
"1272 bert/encoder/layer_7/attention/self/key/MatMul" [id=1272, type=MatMul];
"1273 bert/encoder/layer_7/attention/self/key/BiasAdd" [id=1273, type=Add];
"1274 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1274, type=QuantizeLinear, label="1274 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1"];
"1275 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1275, type=DequantizeLinear, label="1275 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1"];
"1276 bert/encoder/layer_7/attention/self/Reshape_1" [id=1276, type=Reshape];
"1277 bert/encoder/layer_7/attention/self/transpose_1" [id=1277, type=Transpose];
"1278 bert/encoder/layer_7/attention/self/MatMul__404" [id=1278, type=Transpose];
"1279 bert/encoder/layer_7/attention/self/MatMul" [id=1279, type=MatMul];
"1280 bert/encoder/layer_7/attention/self/Mul" [id=1280, type=Mul];
"1281 bert/encoder/layer_7/attention/self/add" [id=1281, type=Add];
"1282 Shape_nncf_1064" [id=1282, type=Shape];
"1283 Flatten_nncf_1065" [id=1283, type=Flatten];
"1284 bert/encoder/layer_7/attention/self/Softmax" [id=1284, type=Softmax];
"1285 Reshape_nncf_1067" [id=1285, type=Reshape];
"1286 bert/encoder/layer_7/attention/self/MatMul_1" [id=1286, type=MatMul];
"1287 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1287, type=QuantizeLinear, label="1287 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1"];
"1288 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1288, type=DequantizeLinear, label="1288 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1"];
"1289 bert/encoder/layer_7/attention/self/transpose_3" [id=1289, type=Transpose];
"1290 bert/encoder/layer_7/attention/self/Reshape_3" [id=1290, type=Reshape];
"1291 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1291, type=QuantizeLinear, label="1291 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1"];
"1292 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1292, type=DequantizeLinear, label="1292 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1"];
"1293 bert/encoder/layer_7/attention/output/dense/MatMul" [id=1293, type=MatMul];
"1294 bert/encoder/layer_7/attention/output/dense/BiasAdd" [id=1294, type=Add];
"1295 bert/encoder/layer_7/attention/output/add" [id=1295, type=Add];
"1296 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" [id=1296, type=ReduceMean];
"1297 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" [id=1297, type=Identity];
"1298 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" [id=1298, type=Sub];
"1299 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" [id=1299, type=Mul];
"1300 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" [id=1300, type=ReduceMean];
"1301 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" [id=1301, type=Add];
"1302 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1302, type=Sqrt];
"1303 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" [id=1303, type=Reciprocal];
"1304 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" [id=1304, type=Mul];
"1305 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" [id=1305, type=Mul];
"1306 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" [id=1306, type=Sub];
"1307 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" [id=1307, type=Mul];
"1308 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" [id=1308, type=Add];
"1309 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1309, type=QuantizeLinear, label="1309 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1310 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1310, type=DequantizeLinear, label="1310 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1311 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1311, type=QuantizeLinear, label="1311 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1"];
"1312 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1312, type=DequantizeLinear, label="1312 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1"];
"1313 bert/encoder/layer_7/intermediate/dense/MatMul" [id=1313, type=MatMul];
"1314 bert/encoder/layer_7/intermediate/dense/BiasAdd" [id=1314, type=Add];
"1315 bert/encoder/layer_7/intermediate/dense/Pow" [id=1315, type=Pow];
"1316 bert/encoder/layer_7/intermediate/dense/mul" [id=1316, type=Mul];
"1317 bert/encoder/layer_7/intermediate/dense/add" [id=1317, type=Add];
"1318 bert/encoder/layer_7/intermediate/dense/mul_1" [id=1318, type=Mul];
"1319 bert/encoder/layer_7/intermediate/dense/Tanh" [id=1319, type=Tanh];
"1320 bert/encoder/layer_7/intermediate/dense/add_1" [id=1320, type=Add];
"1321 bert/encoder/layer_7/intermediate/dense/mul_2" [id=1321, type=Mul];
"1322 bert/encoder/layer_7/intermediate/dense/mul_3" [id=1322, type=Mul];
"1323 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1323, type=QuantizeLinear, label="1323 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1"];
"1324 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1324, type=DequantizeLinear, label="1324 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1"];
"1325 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1325, type=QuantizeLinear, label="1325 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1"];
"1326 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1326, type=DequantizeLinear, label="1326 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1"];
"1327 bert/encoder/layer_7/output/dense/MatMul" [id=1327, type=MatMul];
"1328 bert/encoder/layer_7/output/dense/BiasAdd" [id=1328, type=Add];
"1329 bert/encoder/layer_7/output/add" [id=1329, type=Add];
"1330 bert/encoder/layer_7/output/LayerNorm/moments/mean" [id=1330, type=ReduceMean];
"1331 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" [id=1331, type=Identity];
"1332 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" [id=1332, type=Sub];
"1333 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" [id=1333, type=Mul];
"1334 bert/encoder/layer_7/output/LayerNorm/moments/variance" [id=1334, type=ReduceMean];
"1335 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" [id=1335, type=Add];
"1336 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" [id=1336, type=Sqrt];
"1337 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" [id=1337, type=Reciprocal];
"1338 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" [id=1338, type=Mul];
"1339 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" [id=1339, type=Mul];
"1340 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" [id=1340, type=Sub];
"1341 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" [id=1341, type=Mul];
"1342 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" [id=1342, type=Add];
"1343 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1343, type=QuantizeLinear, label="1343 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1"];
"1344 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1344, type=DequantizeLinear, label="1344 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1"];
"1345 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1345, type=QuantizeLinear, label="1345 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1"];
"1346 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1346, type=DequantizeLinear, label="1346 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1"];
"1347 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1347, type=QuantizeLinear, label="1347 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2"];
"1348 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1348, type=DequantizeLinear, label="1348 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2"];
"1349 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1349, type=QuantizeLinear, label="1349 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3"];
"1350 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1350, type=DequantizeLinear, label="1350 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3"];
"1351 bert/encoder/layer_8/attention/self/value/MatMul" [id=1351, type=MatMul];
"1352 bert/encoder/layer_8/attention/self/value/BiasAdd" [id=1352, type=Add];
"1353 bert/encoder/layer_8/attention/self/Reshape_2" [id=1353, type=Reshape];
"1354 bert/encoder/layer_8/attention/self/transpose_2" [id=1354, type=Transpose];
"1355 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1355, type=QuantizeLinear, label="1355 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1"];
"1356 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1356, type=DequantizeLinear, label="1356 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1"];
"1357 bert/encoder/layer_8/attention/self/query/MatMul" [id=1357, type=MatMul];
"1358 bert/encoder/layer_8/attention/self/query/BiasAdd" [id=1358, type=Add];
"1359 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1359, type=QuantizeLinear, label="1359 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1"];
"1360 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1360, type=DequantizeLinear, label="1360 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1"];
"1361 bert/encoder/layer_8/attention/self/Reshape" [id=1361, type=Reshape];
"1362 bert/encoder/layer_8/attention/self/transpose" [id=1362, type=Transpose];
"1363 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1363, type=QuantizeLinear, label="1363 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1"];
"1364 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1364, type=DequantizeLinear, label="1364 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1"];
"1365 bert/encoder/layer_8/attention/self/key/MatMul" [id=1365, type=MatMul];
"1366 bert/encoder/layer_8/attention/self/key/BiasAdd" [id=1366, type=Add];
"1367 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1367, type=QuantizeLinear, label="1367 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1"];
"1368 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1368, type=DequantizeLinear, label="1368 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1"];
"1369 bert/encoder/layer_8/attention/self/Reshape_1" [id=1369, type=Reshape];
"1370 bert/encoder/layer_8/attention/self/transpose_1" [id=1370, type=Transpose];
"1371 bert/encoder/layer_8/attention/self/MatMul__418" [id=1371, type=Transpose];
"1372 bert/encoder/layer_8/attention/self/MatMul" [id=1372, type=MatMul];
"1373 bert/encoder/layer_8/attention/self/Mul" [id=1373, type=Mul];
"1374 bert/encoder/layer_8/attention/self/add" [id=1374, type=Add];
"1375 Shape_nncf_1129" [id=1375, type=Shape];
"1376 Flatten_nncf_1130" [id=1376, type=Flatten];
"1377 bert/encoder/layer_8/attention/self/Softmax" [id=1377, type=Softmax];
"1378 Reshape_nncf_1132" [id=1378, type=Reshape];
"1379 bert/encoder/layer_8/attention/self/MatMul_1" [id=1379, type=MatMul];
"1380 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1380, type=QuantizeLinear, label="1380 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1"];
"1381 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1381, type=DequantizeLinear, label="1381 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1"];
"1382 bert/encoder/layer_8/attention/self/transpose_3" [id=1382, type=Transpose];
"1383 bert/encoder/layer_8/attention/self/Reshape_3" [id=1383, type=Reshape];
"1384 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1384, type=QuantizeLinear, label="1384 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1"];
"1385 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1385, type=DequantizeLinear, label="1385 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1"];
"1386 bert/encoder/layer_8/attention/output/dense/MatMul" [id=1386, type=MatMul];
"1387 bert/encoder/layer_8/attention/output/dense/BiasAdd" [id=1387, type=Add];
"1388 bert/encoder/layer_8/attention/output/add" [id=1388, type=Add];
"1389 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" [id=1389, type=ReduceMean];
"1390 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" [id=1390, type=Identity];
"1391 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" [id=1391, type=Sub];
"1392 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" [id=1392, type=Mul];
"1393 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" [id=1393, type=ReduceMean];
"1394 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" [id=1394, type=Add];
"1395 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1395, type=Sqrt];
"1396 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" [id=1396, type=Reciprocal];
"1397 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" [id=1397, type=Mul];
"1398 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" [id=1398, type=Mul];
"1399 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" [id=1399, type=Sub];
"1400 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" [id=1400, type=Mul];
"1401 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" [id=1401, type=Add];
"1402 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1402, type=QuantizeLinear, label="1402 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1403 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1403, type=DequantizeLinear, label="1403 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1404 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1404, type=QuantizeLinear, label="1404 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1"];
"1405 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1405, type=DequantizeLinear, label="1405 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1"];
"1406 bert/encoder/layer_8/intermediate/dense/MatMul" [id=1406, type=MatMul];
"1407 bert/encoder/layer_8/intermediate/dense/BiasAdd" [id=1407, type=Add];
"1408 bert/encoder/layer_8/intermediate/dense/Pow" [id=1408, type=Pow];
"1409 bert/encoder/layer_8/intermediate/dense/mul" [id=1409, type=Mul];
"1410 bert/encoder/layer_8/intermediate/dense/add" [id=1410, type=Add];
"1411 bert/encoder/layer_8/intermediate/dense/mul_1" [id=1411, type=Mul];
"1412 bert/encoder/layer_8/intermediate/dense/Tanh" [id=1412, type=Tanh];
"1413 bert/encoder/layer_8/intermediate/dense/add_1" [id=1413, type=Add];
"1414 bert/encoder/layer_8/intermediate/dense/mul_2" [id=1414, type=Mul];
"1415 bert/encoder/layer_8/intermediate/dense/mul_3" [id=1415, type=Mul];
"1416 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1416, type=QuantizeLinear, label="1416 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1"];
"1417 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1417, type=DequantizeLinear, label="1417 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1"];
"1418 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1418, type=QuantizeLinear, label="1418 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1"];
"1419 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1419, type=DequantizeLinear, label="1419 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1"];
"1420 bert/encoder/layer_8/output/dense/MatMul" [id=1420, type=MatMul];
"1421 bert/encoder/layer_8/output/dense/BiasAdd" [id=1421, type=Add];
"1422 bert/encoder/layer_8/output/add" [id=1422, type=Add];
"1423 bert/encoder/layer_8/output/LayerNorm/moments/mean" [id=1423, type=ReduceMean];
"1424 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" [id=1424, type=Identity];
"1425 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" [id=1425, type=Sub];
"1426 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" [id=1426, type=Mul];
"1427 bert/encoder/layer_8/output/LayerNorm/moments/variance" [id=1427, type=ReduceMean];
"1428 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" [id=1428, type=Add];
"1429 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" [id=1429, type=Sqrt];
"1430 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" [id=1430, type=Reciprocal];
"1431 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" [id=1431, type=Mul];
"1432 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" [id=1432, type=Mul];
"1433 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" [id=1433, type=Sub];
"1434 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" [id=1434, type=Mul];
"1435 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" [id=1435, type=Add];
"1436 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1436, type=QuantizeLinear, label="1436 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1"];
"1437 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1437, type=DequantizeLinear, label="1437 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1"];
"1438 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1438, type=QuantizeLinear, label="1438 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1"];
"1439 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1439, type=DequantizeLinear, label="1439 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1"];
"1440 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1440, type=QuantizeLinear, label="1440 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2"];
"1441 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1441, type=DequantizeLinear, label="1441 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2"];
"1442 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1442, type=QuantizeLinear, label="1442 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3"];
"1443 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1443, type=DequantizeLinear, label="1443 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3"];
"1444 bert/encoder/layer_9/attention/self/value/MatMul" [id=1444, type=MatMul];
"1445 bert/encoder/layer_9/attention/self/value/BiasAdd" [id=1445, type=Add];
"1446 bert/encoder/layer_9/attention/self/Reshape_2" [id=1446, type=Reshape];
"1447 bert/encoder/layer_9/attention/self/transpose_2" [id=1447, type=Transpose];
"1448 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1448, type=QuantizeLinear, label="1448 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1"];
"1449 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1449, type=DequantizeLinear, label="1449 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1"];
"1450 bert/encoder/layer_9/attention/self/query/MatMul" [id=1450, type=MatMul];
"1451 bert/encoder/layer_9/attention/self/query/BiasAdd" [id=1451, type=Add];
"1452 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1452, type=QuantizeLinear, label="1452 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1"];
"1453 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1453, type=DequantizeLinear, label="1453 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1"];
"1454 bert/encoder/layer_9/attention/self/Reshape" [id=1454, type=Reshape];
"1455 bert/encoder/layer_9/attention/self/transpose" [id=1455, type=Transpose];
"1456 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1456, type=QuantizeLinear, label="1456 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1"];
"1457 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1457, type=DequantizeLinear, label="1457 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1"];
"1458 bert/encoder/layer_9/attention/self/key/MatMul" [id=1458, type=MatMul];
"1459 bert/encoder/layer_9/attention/self/key/BiasAdd" [id=1459, type=Add];
"1460 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1460, type=QuantizeLinear, label="1460 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1"];
"1461 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1461, type=DequantizeLinear, label="1461 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1"];
"1462 bert/encoder/layer_9/attention/self/Reshape_1" [id=1462, type=Reshape];
"1463 bert/encoder/layer_9/attention/self/transpose_1" [id=1463, type=Transpose];
"1464 bert/encoder/layer_9/attention/self/MatMul__432" [id=1464, type=Transpose];
"1465 bert/encoder/layer_9/attention/self/MatMul" [id=1465, type=MatMul];
"1466 bert/encoder/layer_9/attention/self/Mul" [id=1466, type=Mul];
"1467 bert/encoder/layer_9/attention/self/add" [id=1467, type=Add];
"1468 Shape_nncf_1194" [id=1468, type=Shape];
"1469 Flatten_nncf_1195" [id=1469, type=Flatten];
"1470 bert/encoder/layer_9/attention/self/Softmax" [id=1470, type=Softmax];
"1471 Reshape_nncf_1197" [id=1471, type=Reshape];
"1472 bert/encoder/layer_9/attention/self/MatMul_1" [id=1472, type=MatMul];
"1473 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1473, type=QuantizeLinear, label="1473 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1"];
"1474 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1474, type=DequantizeLinear, label="1474 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1"];
"1475 bert/encoder/layer_9/attention/self/transpose_3" [id=1475, type=Transpose];
"1476 bert/encoder/layer_9/attention/self/Reshape_3" [id=1476, type=Reshape];
"1477 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1477, type=QuantizeLinear, label="1477 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1"];
"1478 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1478, type=DequantizeLinear, label="1478 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1"];
"1479 bert/encoder/layer_9/attention/output/dense/MatMul" [id=1479, type=MatMul];
"1480 bert/encoder/layer_9/attention/output/dense/BiasAdd" [id=1480, type=Add];
"1481 bert/encoder/layer_9/attention/output/add" [id=1481, type=Add];
"1482 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" [id=1482, type=ReduceMean];
"1483 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" [id=1483, type=Identity];
"1484 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" [id=1484, type=Sub];
"1485 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" [id=1485, type=Mul];
"1486 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" [id=1486, type=ReduceMean];
"1487 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" [id=1487, type=Add];
"1488 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1488, type=Sqrt];
"1489 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" [id=1489, type=Reciprocal];
"1490 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" [id=1490, type=Mul];
"1491 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" [id=1491, type=Mul];
"1492 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" [id=1492, type=Sub];
"1493 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" [id=1493, type=Mul];
"1494 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" [id=1494, type=Add];
"1495 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1495, type=QuantizeLinear, label="1495 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1496 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1496, type=DequantizeLinear, label="1496 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1497 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1497, type=QuantizeLinear, label="1497 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1"];
"1498 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1498, type=DequantizeLinear, label="1498 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1"];
"1499 bert/encoder/layer_9/intermediate/dense/MatMul" [id=1499, type=MatMul];
"1500 bert/encoder/layer_9/intermediate/dense/BiasAdd" [id=1500, type=Add];
"1501 bert/encoder/layer_9/intermediate/dense/Pow" [id=1501, type=Pow];
"1502 bert/encoder/layer_9/intermediate/dense/mul" [id=1502, type=Mul];
"1503 bert/encoder/layer_9/intermediate/dense/add" [id=1503, type=Add];
"1504 bert/encoder/layer_9/intermediate/dense/mul_1" [id=1504, type=Mul];
"1505 bert/encoder/layer_9/intermediate/dense/Tanh" [id=1505, type=Tanh];
"1506 bert/encoder/layer_9/intermediate/dense/add_1" [id=1506, type=Add];
"1507 bert/encoder/layer_9/intermediate/dense/mul_2" [id=1507, type=Mul];
"1508 bert/encoder/layer_9/intermediate/dense/mul_3" [id=1508, type=Mul];
"1509 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1509, type=QuantizeLinear, label="1509 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1"];
"1510 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1510, type=DequantizeLinear, label="1510 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1"];
"1511 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1511, type=QuantizeLinear, label="1511 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1"];
"1512 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1512, type=DequantizeLinear, label="1512 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1"];
"1513 bert/encoder/layer_9/output/dense/MatMul" [id=1513, type=MatMul];
"1514 bert/encoder/layer_9/output/dense/BiasAdd" [id=1514, type=Add];
"1515 bert/encoder/layer_9/output/add" [id=1515, type=Add];
"1516 bert/encoder/layer_9/output/LayerNorm/moments/mean" [id=1516, type=ReduceMean];
"1517 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" [id=1517, type=Identity];
"1518 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" [id=1518, type=Sub];
"1519 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" [id=1519, type=Mul];
"1520 bert/encoder/layer_9/output/LayerNorm/moments/variance" [id=1520, type=ReduceMean];
"1521 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" [id=1521, type=Add];
"1522 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" [id=1522, type=Sqrt];
"1523 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" [id=1523, type=Reciprocal];
"1524 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" [id=1524, type=Mul];
"1525 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" [id=1525, type=Mul];
"1526 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" [id=1526, type=Sub];
"1527 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" [id=1527, type=Mul];
"1528 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" [id=1528, type=Add];
"1529 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1529, type=QuantizeLinear, label="1529 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1"];
"1530 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1530, type=DequantizeLinear, label="1530 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1"];
"1531 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1531, type=QuantizeLinear, label="1531 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1"];
"1532 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1532, type=DequantizeLinear, label="1532 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1"];
"1533 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1533, type=QuantizeLinear, label="1533 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2"];
"1534 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1534, type=DequantizeLinear, label="1534 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2"];
"1535 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1535, type=QuantizeLinear, label="1535 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3"];
"1536 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1536, type=DequantizeLinear, label="1536 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3"];
"1537 bert/encoder/layer_10/attention/self/value/MatMul" [id=1537, type=MatMul];
"1538 bert/encoder/layer_10/attention/self/value/BiasAdd" [id=1538, type=Add];
"1539 bert/encoder/layer_10/attention/self/Reshape_2" [id=1539, type=Reshape];
"1540 bert/encoder/layer_10/attention/self/transpose_2" [id=1540, type=Transpose];
"1541 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1541, type=QuantizeLinear, label="1541 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1"];
"1542 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1542, type=DequantizeLinear, label="1542 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1"];
"1543 bert/encoder/layer_10/attention/self/query/MatMul" [id=1543, type=MatMul];
"1544 bert/encoder/layer_10/attention/self/query/BiasAdd" [id=1544, type=Add];
"1545 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1545, type=QuantizeLinear, label="1545 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1"];
"1546 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1546, type=DequantizeLinear, label="1546 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1"];
"1547 bert/encoder/layer_10/attention/self/Reshape" [id=1547, type=Reshape];
"1548 bert/encoder/layer_10/attention/self/transpose" [id=1548, type=Transpose];
"1549 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1549, type=QuantizeLinear, label="1549 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1"];
"1550 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1550, type=DequantizeLinear, label="1550 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1"];
"1551 bert/encoder/layer_10/attention/self/key/MatMul" [id=1551, type=MatMul];
"1552 bert/encoder/layer_10/attention/self/key/BiasAdd" [id=1552, type=Add];
"1553 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1553, type=QuantizeLinear, label="1553 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1"];
"1554 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1554, type=DequantizeLinear, label="1554 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1"];
"1555 bert/encoder/layer_10/attention/self/Reshape_1" [id=1555, type=Reshape];
"1556 bert/encoder/layer_10/attention/self/transpose_1" [id=1556, type=Transpose];
"1557 bert/encoder/layer_10/attention/self/MatMul__446" [id=1557, type=Transpose];
"1558 bert/encoder/layer_10/attention/self/MatMul" [id=1558, type=MatMul];
"1559 bert/encoder/layer_10/attention/self/Mul" [id=1559, type=Mul];
"1560 bert/encoder/layer_10/attention/self/add" [id=1560, type=Add];
"1561 Shape_nncf_1259" [id=1561, type=Shape];
"1562 Flatten_nncf_1260" [id=1562, type=Flatten];
"1563 bert/encoder/layer_10/attention/self/Softmax" [id=1563, type=Softmax];
"1564 Reshape_nncf_1262" [id=1564, type=Reshape];
"1565 bert/encoder/layer_10/attention/self/MatMul_1" [id=1565, type=MatMul];
"1566 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1566, type=QuantizeLinear, label="1566 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1"];
"1567 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1567, type=DequantizeLinear, label="1567 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1"];
"1568 bert/encoder/layer_10/attention/self/transpose_3" [id=1568, type=Transpose];
"1569 bert/encoder/layer_10/attention/self/Reshape_3" [id=1569, type=Reshape];
"1570 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1570, type=QuantizeLinear, label="1570 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1"];
"1571 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1571, type=DequantizeLinear, label="1571 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1"];
"1572 bert/encoder/layer_10/attention/output/dense/MatMul" [id=1572, type=MatMul];
"1573 bert/encoder/layer_10/attention/output/dense/BiasAdd" [id=1573, type=Add];
"1574 bert/encoder/layer_10/attention/output/add" [id=1574, type=Add];
"1575 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" [id=1575, type=ReduceMean];
"1576 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" [id=1576, type=Identity];
"1577 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" [id=1577, type=Sub];
"1578 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" [id=1578, type=Mul];
"1579 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" [id=1579, type=ReduceMean];
"1580 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" [id=1580, type=Add];
"1581 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1581, type=Sqrt];
"1582 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" [id=1582, type=Reciprocal];
"1583 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" [id=1583, type=Mul];
"1584 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" [id=1584, type=Mul];
"1585 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" [id=1585, type=Sub];
"1586 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" [id=1586, type=Mul];
"1587 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" [id=1587, type=Add];
"1588 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1588, type=QuantizeLinear, label="1588 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1589 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1589, type=DequantizeLinear, label="1589 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1590 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1590, type=QuantizeLinear, label="1590 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1"];
"1591 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1591, type=DequantizeLinear, label="1591 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1"];
"1592 bert/encoder/layer_10/intermediate/dense/MatMul" [id=1592, type=MatMul];
"1593 bert/encoder/layer_10/intermediate/dense/BiasAdd" [id=1593, type=Add];
"1594 bert/encoder/layer_10/intermediate/dense/Pow" [id=1594, type=Pow];
"1595 bert/encoder/layer_10/intermediate/dense/mul" [id=1595, type=Mul];
"1596 bert/encoder/layer_10/intermediate/dense/add" [id=1596, type=Add];
"1597 bert/encoder/layer_10/intermediate/dense/mul_1" [id=1597, type=Mul];
"1598 bert/encoder/layer_10/intermediate/dense/Tanh" [id=1598, type=Tanh];
"1599 bert/encoder/layer_10/intermediate/dense/add_1" [id=1599, type=Add];
"1600 bert/encoder/layer_10/intermediate/dense/mul_2" [id=1600, type=Mul];
"1601 bert/encoder/layer_10/intermediate/dense/mul_3" [id=1601, type=Mul];
"1602 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1602, type=QuantizeLinear, label="1602 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1"];
"1603 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1603, type=DequantizeLinear, label="1603 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1"];
"1604 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1604, type=QuantizeLinear, label="1604 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1"];
"1605 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1605, type=DequantizeLinear, label="1605 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1"];
"1606 bert/encoder/layer_10/output/dense/MatMul" [id=1606, type=MatMul];
"1607 bert/encoder/layer_10/output/dense/BiasAdd" [id=1607, type=Add];
"1608 bert/encoder/layer_10/output/add" [id=1608, type=Add];
"1609 bert/encoder/layer_10/output/LayerNorm/moments/mean" [id=1609, type=ReduceMean];
"1610 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" [id=1610, type=Identity];
"1611 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" [id=1611, type=Sub];
"1612 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" [id=1612, type=Mul];
"1613 bert/encoder/layer_10/output/LayerNorm/moments/variance" [id=1613, type=ReduceMean];
"1614 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" [id=1614, type=Add];
"1615 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" [id=1615, type=Sqrt];
"1616 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" [id=1616, type=Reciprocal];
"1617 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" [id=1617, type=Mul];
"1618 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" [id=1618, type=Mul];
"1619 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" [id=1619, type=Sub];
"1620 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" [id=1620, type=Mul];
"1621 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" [id=1621, type=Add];
"1622 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1622, type=QuantizeLinear, label="1622 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1"];
"1623 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1623, type=DequantizeLinear, label="1623 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1"];
"1624 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1624, type=QuantizeLinear, label="1624 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1"];
"1625 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1625, type=DequantizeLinear, label="1625 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1"];
"1626 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1626, type=QuantizeLinear, label="1626 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2"];
"1627 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1627, type=DequantizeLinear, label="1627 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2"];
"1628 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1628, type=QuantizeLinear, label="1628 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3"];
"1629 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1629, type=DequantizeLinear, label="1629 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3"];
"1630 bert/encoder/layer_11/attention/self/value/MatMul" [id=1630, type=MatMul];
"1631 bert/encoder/layer_11/attention/self/value/BiasAdd" [id=1631, type=Add];
"1632 bert/encoder/layer_11/attention/self/Reshape_2" [id=1632, type=Reshape];
"1633 bert/encoder/layer_11/attention/self/transpose_2" [id=1633, type=Transpose];
"1634 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1634, type=QuantizeLinear, label="1634 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1"];
"1635 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1635, type=DequantizeLinear, label="1635 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1"];
"1636 bert/encoder/layer_11/attention/self/query/MatMul" [id=1636, type=MatMul];
"1637 bert/encoder/layer_11/attention/self/query/BiasAdd" [id=1637, type=Add];
"1638 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1638, type=QuantizeLinear, label="1638 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1"];
"1639 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1639, type=DequantizeLinear, label="1639 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1"];
"1640 bert/encoder/layer_11/attention/self/Reshape" [id=1640, type=Reshape];
"1641 bert/encoder/layer_11/attention/self/transpose" [id=1641, type=Transpose];
"1642 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1642, type=QuantizeLinear, label="1642 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1"];
"1643 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1643, type=DequantizeLinear, label="1643 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1"];
"1644 bert/encoder/layer_11/attention/self/key/MatMul" [id=1644, type=MatMul];
"1645 bert/encoder/layer_11/attention/self/key/BiasAdd" [id=1645, type=Add];
"1646 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1646, type=QuantizeLinear, label="1646 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1"];
"1647 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1647, type=DequantizeLinear, label="1647 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1"];
"1648 bert/encoder/layer_11/attention/self/Reshape_1" [id=1648, type=Reshape];
"1649 bert/encoder/layer_11/attention/self/transpose_1" [id=1649, type=Transpose];
"1650 bert/encoder/layer_11/attention/self/MatMul__460" [id=1650, type=Transpose];
"1651 bert/encoder/layer_11/attention/self/MatMul" [id=1651, type=MatMul];
"1652 bert/encoder/layer_11/attention/self/Mul" [id=1652, type=Mul];
"1653 bert/encoder/layer_11/attention/self/add" [id=1653, type=Add];
"1654 Shape_nncf_1324" [id=1654, type=Shape];
"1655 Flatten_nncf_1325" [id=1655, type=Flatten];
"1656 bert/encoder/layer_11/attention/self/Softmax" [id=1656, type=Softmax];
"1657 Reshape_nncf_1327" [id=1657, type=Reshape];
"1658 bert/encoder/layer_11/attention/self/MatMul_1" [id=1658, type=MatMul];
"1659 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1659, type=QuantizeLinear, label="1659 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1"];
"1660 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1660, type=DequantizeLinear, label="1660 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1"];
"1661 bert/encoder/layer_11/attention/self/transpose_3" [id=1661, type=Transpose];
"1662 bert/encoder/layer_11/attention/self/Reshape_3" [id=1662, type=Reshape];
"1663 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1663, type=QuantizeLinear, label="1663 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1"];
"1664 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1664, type=DequantizeLinear, label="1664 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1"];
"1665 bert/encoder/layer_11/attention/output/dense/MatMul" [id=1665, type=MatMul];
"1666 bert/encoder/layer_11/attention/output/dense/BiasAdd" [id=1666, type=Add];
"1667 bert/encoder/layer_11/attention/output/add" [id=1667, type=Add];
"1668 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" [id=1668, type=ReduceMean];
"1669 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" [id=1669, type=Identity];
"1670 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" [id=1670, type=Sub];
"1671 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" [id=1671, type=Mul];
"1672 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" [id=1672, type=ReduceMean];
"1673 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" [id=1673, type=Add];
"1674 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1674, type=Sqrt];
"1675 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" [id=1675, type=Reciprocal];
"1676 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" [id=1676, type=Mul];
"1677 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" [id=1677, type=Mul];
"1678 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" [id=1678, type=Sub];
"1679 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" [id=1679, type=Mul];
"1680 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" [id=1680, type=Add];
"1681 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1681, type=QuantizeLinear, label="1681 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1682 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1682, type=DequantizeLinear, label="1682 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1"];
"1683 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1683, type=QuantizeLinear, label="1683 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1"];
"1684 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1684, type=DequantizeLinear, label="1684 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1"];
"1685 bert/encoder/layer_11/intermediate/dense/MatMul" [id=1685, type=MatMul];
"1686 bert/encoder/layer_11/intermediate/dense/BiasAdd" [id=1686, type=Add];
"1687 bert/encoder/layer_11/intermediate/dense/Pow" [id=1687, type=Pow];
"1688 bert/encoder/layer_11/intermediate/dense/mul" [id=1688, type=Mul];
"1689 bert/encoder/layer_11/intermediate/dense/add" [id=1689, type=Add];
"1690 bert/encoder/layer_11/intermediate/dense/mul_1" [id=1690, type=Mul];
"1691 bert/encoder/layer_11/intermediate/dense/Tanh" [id=1691, type=Tanh];
"1692 bert/encoder/layer_11/intermediate/dense/add_1" [id=1692, type=Add];
"1693 bert/encoder/layer_11/intermediate/dense/mul_2" [id=1693, type=Mul];
"1694 bert/encoder/layer_11/intermediate/dense/mul_3" [id=1694, type=Mul];
"1695 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1695, type=QuantizeLinear, label="1695 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1"];
"1696 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1696, type=DequantizeLinear, label="1696 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1"];
"1697 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1697, type=QuantizeLinear, label="1697 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1"];
"1698 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1698, type=DequantizeLinear, label="1698 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1"];
"1699 bert/encoder/layer_11/output/dense/MatMul" [id=1699, type=MatMul];
"1700 bert/encoder/layer_11/output/dense/BiasAdd" [id=1700, type=Add];
"1701 bert/encoder/layer_11/output/add" [id=1701, type=Add];
"1702 bert/encoder/layer_11/output/LayerNorm/moments/mean" [id=1702, type=ReduceMean];
"1703 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" [id=1703, type=Identity];
"1704 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" [id=1704, type=Sub];
"1705 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" [id=1705, type=Mul];
"1706 bert/encoder/layer_11/output/LayerNorm/moments/variance" [id=1706, type=ReduceMean];
"1707 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" [id=1707, type=Add];
"1708 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" [id=1708, type=Sqrt];
"1709 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" [id=1709, type=Reciprocal];
"1710 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" [id=1710, type=Mul];
"1711 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" [id=1711, type=Mul];
"1712 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" [id=1712, type=Sub];
"1713 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" [id=1713, type=Mul];
"1714 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" [id=1714, type=Add];
"1715 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1715, type=QuantizeLinear, label="1715 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1"];
"1716 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1716, type=DequantizeLinear, label="1716 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1"];
"1717 bert/encoder/Reshape_13" [id=1717, type=Reshape];
"1718 Shape_1" [id=1718, type=Shape];
"1719 Shape_1__472" [id=1719, type=Cast];
"1720 strided_slice_1" [id=1720, type=Slice];
"1721 Constant_nncf_1377" [id=1721, type=Constant];
"1722 strided_slice_1__476" [id=1722, type=Squeeze];
"1723 strided_slice_1__477" [id=1723, type=Cast];
"1724 mul" [id=1724, type=Mul];
"1725 Constant_nncf_1381" [id=1725, type=Constant];
"1726 Reshape/shape_Unsqueeze__482" [id=1726, type=Unsqueeze];
"1727 Reshape/shape_Concat__484" [id=1727, type=Concat];
"1728 Reshape__485" [id=1728, type=Cast];
"1729 Constant_nncf_1385" [id=1729, type=Constant];
"1730 Reshape_1/shape_Unsqueeze__478" [id=1730, type=Unsqueeze];
"1731 Reshape_1/shape_Concat__481" [id=1731, type=Concat];
"1732 Reshape_1__487" [id=1732, type=Cast];
"1733 Reshape" [id=1733, type=Reshape];
"1734 QuantizeLinear_MatMul__486^0_1" [id=1734, type=QuantizeLinear, label="1734 QuantizeLinear_MatMul__486:0_1"];
"1735 DequantizeLinear_MatMul__486^0_1" [id=1735, type=DequantizeLinear, label="1735 DequantizeLinear_MatMul__486:0_1"];
"1736 MatMul" [id=1736, type=MatMul];
"1737 BiasAdd" [id=1737, type=Add];
"1738 Reshape_1" [id=1738, type=Reshape];
"1739 transpose" [id=1739, type=Transpose];
"1740 unstack" [id=1740, type=Split];
"1741 Constant_nncf_1395" [id=1741, type=Constant];
"1742 unstack__490" [id=1742, type=Squeeze];
"1743 unstack_graph_outputs_Identity__4" [id=1743, type=Identity];
"1744 Constant_nncf_1398" [id=1744, type=Constant];
"1745 unstack__488" [id=1745, type=Squeeze];
"1746 unstack_graph_outputs_Identity__7" [id=1746, type=Identity];
"1747 nncf_model_input_0" [id=1747, type="nncf_model_input"];
"1748 nncf_model_input_1" [id=1748, type="nncf_model_input"];
"1749 nncf_model_input_2" [id=1749, type="nncf_model_input"];
"1750 nncf_model_input_3" [id=1750, type="nncf_model_input"];
"1751 nncf_model_output_0" [id=1751, type="nncf_model_output"];
"1752 nncf_model_output_1" [id=1752, type="nncf_model_output"];
"1753 nncf_model_output_2" [id=1753, type="nncf_model_output"];
"0 unique_ids_graph_outputs_Identity__10" -> "1753 nncf_model_output_2" [key=0, style=dashed, label="[-1]"];
"1 Constant_nncf_1" -> "2 bert/encoder/ones/packed_Unsqueeze__20" [key=0, style=dashed, label="[1]"];
"2 bert/encoder/ones/packed_Unsqueeze__20" -> "253 bert/encoder/ones/packed_Concat__21" [key=0, style=dashed, label="[1]"];
"3 Constant_nncf_3" -> "4 bert/encoder/ones/packed_Unsqueeze__19" [key=0, style=dashed, label="[1]"];
"4 bert/encoder/ones/packed_Unsqueeze__19" -> "253 bert/encoder/ones/packed_Concat__21" [key=0, style=dashed, label="[1]"];
"5 Constant_nncf_5" -> "6 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" [key=0, style=dashed, label="[1]"];
"6 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" -> "393 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" [key=0, style=dashed, label="[1]"];
"7 Constant_nncf_7" -> "8 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" [key=0, style=dashed, label="[1]"];
"8 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" -> "397 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [key=0, style=dashed, label="[1]"];
"9 Constant_nncf_9" -> "10 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" [key=0, style=dashed, label="[1]"];
"10 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" -> "397 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [key=0, style=dashed, label="[1]"];
"11 Constant_nncf_11" -> "12 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" [key=0, style=dashed, label="[1]"];
"12 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" -> "397 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [key=0, style=dashed, label="[1]"];
"13 Constant_nncf_13" -> "14 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" [key=0, style=dashed, label="[1]"];
"14 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" -> "401 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [key=0, style=dashed, label="[1]"];
"15 Constant_nncf_15" -> "16 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" [key=0, style=dashed, label="[1]"];
"16 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" -> "401 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [key=0, style=dashed, label="[1]"];
"17 Constant_nncf_17" -> "18 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" [key=0, style=dashed, label="[1]"];
"18 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" -> "401 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [key=0, style=dashed, label="[1]"];
"19 Constant_nncf_19" -> "20 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" [key=0, style=dashed, label="[1]"];
"20 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" -> "405 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [key=0, style=dashed, label="[1]"];
"21 Constant_nncf_21" -> "22 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" [key=0, style=dashed, label="[1]"];
"22 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" -> "405 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [key=0, style=dashed, label="[1]"];
"23 Constant_nncf_23" -> "24 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" [key=0, style=dashed, label="[1]"];
"24 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" -> "405 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [key=0, style=dashed, label="[1]"];
"25 Constant_nncf_25" -> "26 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" [key=0, style=dashed, label="[1]"];
"26 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" -> "410 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" [key=0, style=dashed, label="[1]"];
"27 Constant_nncf_27" -> "28 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" [key=0, style=dashed, label="[1]"];
"28 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" -> "414 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [key=0, style=dashed, label="[1]"];
"29 Constant_nncf_29" -> "30 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" [key=0, style=dashed, label="[1]"];
"30 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" -> "414 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [key=0, style=dashed, label="[1]"];
"31 Constant_nncf_31" -> "32 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" [key=0, style=dashed, label="[1]"];
"32 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" -> "414 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [key=0, style=dashed, label="[1]"];
"33 Constant_nncf_33" -> "34 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" [key=0, style=dashed, label="[1]"];
"34 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" -> "418 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [key=0, style=dashed, label="[1]"];
"35 Constant_nncf_35" -> "36 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" [key=0, style=dashed, label="[1]"];
"36 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" -> "418 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [key=0, style=dashed, label="[1]"];
"37 Constant_nncf_37" -> "38 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" [key=0, style=dashed, label="[1]"];
"38 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" -> "418 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [key=0, style=dashed, label="[1]"];
"39 Constant_nncf_39" -> "40 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" [key=0, style=dashed, label="[1]"];
"40 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" -> "422 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [key=0, style=dashed, label="[1]"];
"41 Constant_nncf_41" -> "42 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" [key=0, style=dashed, label="[1]"];
"42 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" -> "422 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [key=0, style=dashed, label="[1]"];
"43 Constant_nncf_43" -> "44 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" [key=0, style=dashed, label="[1]"];
"44 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" -> "422 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [key=0, style=dashed, label="[1]"];
"45 Constant_nncf_45" -> "46 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" [key=0, style=dashed, label="[1]"];
"46 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" -> "427 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" [key=0, style=dashed, label="[1]"];
"47 Constant_nncf_47" -> "48 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" [key=0, style=dashed, label="[1]"];
"48 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" -> "431 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [key=0, style=dashed, label="[1]"];
"49 Constant_nncf_49" -> "50 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" [key=0, style=dashed, label="[1]"];
"50 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" -> "431 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [key=0, style=dashed, label="[1]"];
"51 Constant_nncf_51" -> "52 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" [key=0, style=dashed, label="[1]"];
"52 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" -> "431 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [key=0, style=dashed, label="[1]"];
"53 Constant_nncf_53" -> "54 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" [key=0, style=dashed, label="[1]"];
"54 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" -> "435 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [key=0, style=dashed, label="[1]"];
"55 Constant_nncf_55" -> "56 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" [key=0, style=dashed, label="[1]"];
"56 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" -> "435 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [key=0, style=dashed, label="[1]"];
"57 Constant_nncf_57" -> "58 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" [key=0, style=dashed, label="[1]"];
"58 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" -> "435 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [key=0, style=dashed, label="[1]"];
"59 Constant_nncf_59" -> "60 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" [key=0, style=dashed, label="[1]"];
"60 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" -> "439 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [key=0, style=dashed, label="[1]"];
"61 Constant_nncf_61" -> "62 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" [key=0, style=dashed, label="[1]"];
"62 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" -> "439 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [key=0, style=dashed, label="[1]"];
"63 Constant_nncf_63" -> "64 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" [key=0, style=dashed, label="[1]"];
"64 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" -> "439 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [key=0, style=dashed, label="[1]"];
"65 Constant_nncf_65" -> "66 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" [key=0, style=dashed, label="[1]"];
"66 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" -> "444 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" [key=0, style=dashed, label="[1]"];
"67 Constant_nncf_67" -> "68 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" [key=0, style=dashed, label="[1]"];
"68 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" -> "448 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [key=0, style=dashed, label="[1]"];
"69 Constant_nncf_69" -> "70 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" [key=0, style=dashed, label="[1]"];
"70 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" -> "448 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [key=0, style=dashed, label="[1]"];
"71 Constant_nncf_71" -> "72 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" [key=0, style=dashed, label="[1]"];
"72 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" -> "448 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [key=0, style=dashed, label="[1]"];
"73 Constant_nncf_73" -> "74 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" [key=0, style=dashed, label="[1]"];
"74 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" -> "452 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [key=0, style=dashed, label="[1]"];
"75 Constant_nncf_75" -> "76 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" [key=0, style=dashed, label="[1]"];
"76 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" -> "452 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [key=0, style=dashed, label="[1]"];
"77 Constant_nncf_77" -> "78 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" [key=0, style=dashed, label="[1]"];
"78 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" -> "452 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [key=0, style=dashed, label="[1]"];
"79 Constant_nncf_79" -> "80 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" [key=0, style=dashed, label="[1]"];
"80 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" -> "456 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [key=0, style=dashed, label="[1]"];
"81 Constant_nncf_81" -> "82 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" [key=0, style=dashed, label="[1]"];
"82 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" -> "456 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [key=0, style=dashed, label="[1]"];
"83 Constant_nncf_83" -> "84 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" [key=0, style=dashed, label="[1]"];
"84 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" -> "456 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [key=0, style=dashed, label="[1]"];
"85 Constant_nncf_85" -> "86 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" [key=0, style=dashed, label="[1]"];
"86 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" -> "461 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" [key=0, style=dashed, label="[1]"];
"87 Constant_nncf_87" -> "88 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" [key=0, style=dashed, label="[1]"];
"88 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" -> "465 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [key=0, style=dashed, label="[1]"];
"89 Constant_nncf_89" -> "90 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" [key=0, style=dashed, label="[1]"];
"90 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" -> "465 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [key=0, style=dashed, label="[1]"];
"91 Constant_nncf_91" -> "92 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" [key=0, style=dashed, label="[1]"];
"92 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" -> "465 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [key=0, style=dashed, label="[1]"];
"93 Constant_nncf_93" -> "94 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" [key=0, style=dashed, label="[1]"];
"94 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" -> "469 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [key=0, style=dashed, label="[1]"];
"95 Constant_nncf_95" -> "96 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" [key=0, style=dashed, label="[1]"];
"96 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" -> "469 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [key=0, style=dashed, label="[1]"];
"97 Constant_nncf_97" -> "98 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" [key=0, style=dashed, label="[1]"];
"98 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" -> "469 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [key=0, style=dashed, label="[1]"];
"99 Constant_nncf_99" -> "100 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" [key=0, style=dashed, label="[1]"];
"100 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" -> "473 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [key=0, style=dashed, label="[1]"];
"101 Constant_nncf_101" -> "102 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" [key=0, style=dashed, label="[1]"];
"102 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" -> "473 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [key=0, style=dashed, label="[1]"];
"103 Constant_nncf_103" -> "104 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" [key=0, style=dashed, label="[1]"];
"104 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" -> "473 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [key=0, style=dashed, label="[1]"];
"105 Constant_nncf_105" -> "106 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" [key=0, style=dashed, label="[1]"];
"106 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" -> "478 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" [key=0, style=dashed, label="[1]"];
"107 Constant_nncf_107" -> "108 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" [key=0, style=dashed, label="[1]"];
"108 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" -> "482 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [key=0, style=dashed, label="[1]"];
"109 Constant_nncf_109" -> "110 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" [key=0, style=dashed, label="[1]"];
"110 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" -> "482 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [key=0, style=dashed, label="[1]"];
"111 Constant_nncf_111" -> "112 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" [key=0, style=dashed, label="[1]"];
"112 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" -> "482 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [key=0, style=dashed, label="[1]"];
"113 Constant_nncf_113" -> "114 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" [key=0, style=dashed, label="[1]"];
"114 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" -> "486 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [key=0, style=dashed, label="[1]"];
"115 Constant_nncf_115" -> "116 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" [key=0, style=dashed, label="[1]"];
"116 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" -> "486 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [key=0, style=dashed, label="[1]"];
"117 Constant_nncf_117" -> "118 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" [key=0, style=dashed, label="[1]"];
"118 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" -> "486 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [key=0, style=dashed, label="[1]"];
"119 Constant_nncf_119" -> "120 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" [key=0, style=dashed, label="[1]"];
"120 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" -> "490 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [key=0, style=dashed, label="[1]"];
"121 Constant_nncf_121" -> "122 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" [key=0, style=dashed, label="[1]"];
"122 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" -> "490 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [key=0, style=dashed, label="[1]"];
"123 Constant_nncf_123" -> "124 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" [key=0, style=dashed, label="[1]"];
"124 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" -> "490 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [key=0, style=dashed, label="[1]"];
"125 Constant_nncf_125" -> "126 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" [key=0, style=dashed, label="[1]"];
"126 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" -> "495 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" [key=0, style=dashed, label="[1]"];
"127 Constant_nncf_127" -> "128 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" [key=0, style=dashed, label="[1]"];
"128 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" -> "499 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [key=0, style=dashed, label="[1]"];
"129 Constant_nncf_129" -> "130 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" [key=0, style=dashed, label="[1]"];
"130 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" -> "499 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [key=0, style=dashed, label="[1]"];
"131 Constant_nncf_131" -> "132 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" [key=0, style=dashed, label="[1]"];
"132 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" -> "499 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [key=0, style=dashed, label="[1]"];
"133 Constant_nncf_133" -> "134 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" [key=0, style=dashed, label="[1]"];
"134 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" -> "503 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [key=0, style=dashed, label="[1]"];
"135 Constant_nncf_135" -> "136 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" [key=0, style=dashed, label="[1]"];
"136 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" -> "503 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [key=0, style=dashed, label="[1]"];
"137 Constant_nncf_137" -> "138 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" [key=0, style=dashed, label="[1]"];
"138 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" -> "503 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [key=0, style=dashed, label="[1]"];
"139 Constant_nncf_139" -> "140 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" [key=0, style=dashed, label="[1]"];
"140 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" -> "507 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [key=0, style=dashed, label="[1]"];
"141 Constant_nncf_141" -> "142 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" [key=0, style=dashed, label="[1]"];
"142 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" -> "507 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [key=0, style=dashed, label="[1]"];
"143 Constant_nncf_143" -> "144 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" [key=0, style=dashed, label="[1]"];
"144 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" -> "507 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [key=0, style=dashed, label="[1]"];
"145 Constant_nncf_145" -> "146 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" [key=0, style=dashed, label="[1]"];
"146 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" -> "512 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" [key=0, style=dashed, label="[1]"];
"147 Constant_nncf_147" -> "148 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" [key=0, style=dashed, label="[1]"];
"148 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" -> "516 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [key=0, style=dashed, label="[1]"];
"149 Constant_nncf_149" -> "150 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" [key=0, style=dashed, label="[1]"];
"150 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" -> "516 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [key=0, style=dashed, label="[1]"];
"151 Constant_nncf_151" -> "152 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" [key=0, style=dashed, label="[1]"];
"152 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" -> "516 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [key=0, style=dashed, label="[1]"];
"153 Constant_nncf_153" -> "154 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" [key=0, style=dashed, label="[1]"];
"154 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" -> "520 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [key=0, style=dashed, label="[1]"];
"155 Constant_nncf_155" -> "156 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" [key=0, style=dashed, label="[1]"];
"156 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" -> "520 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [key=0, style=dashed, label="[1]"];
"157 Constant_nncf_157" -> "158 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" [key=0, style=dashed, label="[1]"];
"158 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" -> "520 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [key=0, style=dashed, label="[1]"];
"159 Constant_nncf_159" -> "160 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" [key=0, style=dashed, label="[1]"];
"160 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" -> "524 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [key=0, style=dashed, label="[1]"];
"161 Constant_nncf_161" -> "162 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" [key=0, style=dashed, label="[1]"];
"162 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" -> "524 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [key=0, style=dashed, label="[1]"];
"163 Constant_nncf_163" -> "164 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" [key=0, style=dashed, label="[1]"];
"164 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" -> "524 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [key=0, style=dashed, label="[1]"];
"165 Constant_nncf_165" -> "166 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" [key=0, style=dashed, label="[1]"];
"166 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" -> "529 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" [key=0, style=dashed, label="[1]"];
"167 Constant_nncf_167" -> "168 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" [key=0, style=dashed, label="[1]"];
"168 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" -> "533 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [key=0, style=dashed, label="[1]"];
"169 Constant_nncf_169" -> "170 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" [key=0, style=dashed, label="[1]"];
"170 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" -> "533 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [key=0, style=dashed, label="[1]"];
"171 Constant_nncf_171" -> "172 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" [key=0, style=dashed, label="[1]"];
"172 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" -> "533 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [key=0, style=dashed, label="[1]"];
"173 Constant_nncf_173" -> "174 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" [key=0, style=dashed, label="[1]"];
"174 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" -> "537 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [key=0, style=dashed, label="[1]"];
"175 Constant_nncf_175" -> "176 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" [key=0, style=dashed, label="[1]"];
"176 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" -> "537 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [key=0, style=dashed, label="[1]"];
"177 Constant_nncf_177" -> "178 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" [key=0, style=dashed, label="[1]"];
"178 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" -> "537 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [key=0, style=dashed, label="[1]"];
"179 Constant_nncf_179" -> "180 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" [key=0, style=dashed, label="[1]"];
"180 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" -> "541 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [key=0, style=dashed, label="[1]"];
"181 Constant_nncf_181" -> "182 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" [key=0, style=dashed, label="[1]"];
"182 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" -> "541 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [key=0, style=dashed, label="[1]"];
"183 Constant_nncf_183" -> "184 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" [key=0, style=dashed, label="[1]"];
"184 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" -> "541 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [key=0, style=dashed, label="[1]"];
"185 Constant_nncf_185" -> "186 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" [key=0, style=dashed, label="[1]"];
"186 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" -> "546 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" [key=0, style=dashed, label="[1]"];
"187 Constant_nncf_187" -> "188 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" [key=0, style=dashed, label="[1]"];
"188 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" -> "550 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [key=0, style=dashed, label="[1]"];
"189 Constant_nncf_189" -> "190 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" [key=0, style=dashed, label="[1]"];
"190 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" -> "550 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [key=0, style=dashed, label="[1]"];
"191 Constant_nncf_191" -> "192 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" [key=0, style=dashed, label="[1]"];
"192 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" -> "550 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [key=0, style=dashed, label="[1]"];
"193 Constant_nncf_193" -> "194 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" [key=0, style=dashed, label="[1]"];
"194 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" -> "554 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [key=0, style=dashed, label="[1]"];
"195 Constant_nncf_195" -> "196 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" [key=0, style=dashed, label="[1]"];
"196 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" -> "554 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [key=0, style=dashed, label="[1]"];
"197 Constant_nncf_197" -> "198 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" [key=0, style=dashed, label="[1]"];
"198 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" -> "554 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [key=0, style=dashed, label="[1]"];
"199 Constant_nncf_199" -> "200 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" [key=0, style=dashed, label="[1]"];
"200 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" -> "558 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [key=0, style=dashed, label="[1]"];
"201 Constant_nncf_201" -> "202 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" [key=0, style=dashed, label="[1]"];
"202 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" -> "558 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [key=0, style=dashed, label="[1]"];
"203 Constant_nncf_203" -> "204 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" [key=0, style=dashed, label="[1]"];
"204 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" -> "558 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [key=0, style=dashed, label="[1]"];
"205 Constant_nncf_205" -> "206 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" [key=0, style=dashed, label="[1]"];
"206 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" -> "563 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" [key=0, style=dashed, label="[1]"];
"207 Constant_nncf_207" -> "208 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" [key=0, style=dashed, label="[1]"];
"208 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" -> "567 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [key=0, style=dashed, label="[1]"];
"209 Constant_nncf_209" -> "210 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" [key=0, style=dashed, label="[1]"];
"210 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" -> "567 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [key=0, style=dashed, label="[1]"];
"211 Constant_nncf_211" -> "212 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" [key=0, style=dashed, label="[1]"];
"212 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" -> "567 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [key=0, style=dashed, label="[1]"];
"213 Constant_nncf_213" -> "214 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" [key=0, style=dashed, label="[1]"];
"214 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" -> "571 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [key=0, style=dashed, label="[1]"];
"215 Constant_nncf_215" -> "216 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" [key=0, style=dashed, label="[1]"];
"216 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" -> "571 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [key=0, style=dashed, label="[1]"];
"217 Constant_nncf_217" -> "218 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" [key=0, style=dashed, label="[1]"];
"218 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" -> "571 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [key=0, style=dashed, label="[1]"];
"219 Constant_nncf_219" -> "220 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" [key=0, style=dashed, label="[1]"];
"220 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" -> "575 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [key=0, style=dashed, label="[1]"];
"221 Constant_nncf_221" -> "222 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" [key=0, style=dashed, label="[1]"];
"222 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" -> "575 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [key=0, style=dashed, label="[1]"];
"223 Constant_nncf_223" -> "224 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" [key=0, style=dashed, label="[1]"];
"224 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" -> "575 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [key=0, style=dashed, label="[1]"];
"225 Constant_nncf_225" -> "226 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" [key=0, style=dashed, label="[1]"];
"226 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" -> "580 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" [key=0, style=dashed, label="[1]"];
"227 Constant_nncf_227" -> "228 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" [key=0, style=dashed, label="[1]"];
"228 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" -> "584 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [key=0, style=dashed, label="[1]"];
"229 Constant_nncf_229" -> "230 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" [key=0, style=dashed, label="[1]"];
"230 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" -> "584 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [key=0, style=dashed, label="[1]"];
"231 Constant_nncf_231" -> "232 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" [key=0, style=dashed, label="[1]"];
"232 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" -> "584 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [key=0, style=dashed, label="[1]"];
"233 Constant_nncf_233" -> "234 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" [key=0, style=dashed, label="[1]"];
"234 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" -> "588 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [key=0, style=dashed, label="[1]"];
"235 Constant_nncf_235" -> "236 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" [key=0, style=dashed, label="[1]"];
"236 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" -> "588 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [key=0, style=dashed, label="[1]"];
"237 Constant_nncf_237" -> "238 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" [key=0, style=dashed, label="[1]"];
"238 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" -> "588 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [key=0, style=dashed, label="[1]"];
"239 Constant_nncf_239" -> "240 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" [key=0, style=dashed, label="[1]"];
"240 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" -> "592 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [key=0, style=dashed, label="[1]"];
"241 Constant_nncf_241" -> "242 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" [key=0, style=dashed, label="[1]"];
"242 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" -> "592 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [key=0, style=dashed, label="[1]"];
"243 Constant_nncf_243" -> "244 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" [key=0, style=dashed, label="[1]"];
"244 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" -> "592 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [key=0, style=dashed, label="[1]"];
"245 bert/encoder/Shape" -> "246 bert/encoder/Shape__12" [key=0, style=dashed, label="[2]"];
"246 bert/encoder/Shape__12" -> "247 bert/encoder/strided_slice" [key=0, style=solid, label="[2]"];
"247 bert/encoder/strided_slice" -> "249 bert/encoder/strided_slice__16" [key=0, style=solid, label="[1]"];
"248 Constant_nncf_248" -> "249 bert/encoder/strided_slice__16" [key=0, style=dashed, label="[1]"];
"249 bert/encoder/strided_slice__16" -> "250 bert/encoder/strided_slice__17" [key=0, style=solid, label="[]"];
"250 bert/encoder/strided_slice__17" -> "252 bert/encoder/ones/packed_Unsqueeze__18" [key=0, style=dashed, label="[]"];
"250 bert/encoder/strided_slice__17" -> "262 bert/encoder/Reshape/shape_Unsqueeze__23" [key=0, style=dashed, label="[]"];
"251 Constant_nncf_251" -> "252 bert/encoder/ones/packed_Unsqueeze__18" [key=0, style=dashed, label="[1]"];
"252 bert/encoder/ones/packed_Unsqueeze__18" -> "253 bert/encoder/ones/packed_Concat__21" [key=0, style=dashed, label="[1]"];
"253 bert/encoder/ones/packed_Concat__21" -> "254 bert/encoder/ones__22" [key=0, style=dashed, label="[3]"];
"254 bert/encoder/ones__22" -> "255 bert/encoder/ones" [key=0, style=dashed, label="[3]"];
"255 bert/encoder/ones" -> "271 bert/encoder/mul" [key=0, style=solid, label="[-1, -1, -1]"];
"256 Constant_nncf_256" -> "257 bert/encoder/Reshape_13/shape_Unsqueeze__300" [key=0, style=dashed, label="[1]"];
"257 bert/encoder/Reshape_13/shape_Unsqueeze__300" -> "596 bert/encoder/Reshape_13/shape_Concat__301" [key=0, style=dashed, label="[1]"];
"258 Constant_nncf_258" -> "259 bert/encoder/Reshape_13/shape_Unsqueeze__299" [key=0, style=dashed, label="[1]"];
"259 bert/encoder/Reshape_13/shape_Unsqueeze__299" -> "596 bert/encoder/Reshape_13/shape_Concat__301" [key=0, style=dashed, label="[1]"];
"260 bert/encoder/Reshape_1__302" -> "598 bert/encoder/Reshape_1" [key=0, style=dashed, label="[2]"];
"261 Constant_nncf_261" -> "262 bert/encoder/Reshape/shape_Unsqueeze__23" [key=0, style=dashed, label="[1]"];
"262 bert/encoder/Reshape/shape_Unsqueeze__23" -> "267 bert/encoder/Reshape/shape_Concat__26" [key=0, style=dashed, label="[1]"];
"263 Constant_nncf_263" -> "264 bert/encoder/Reshape/shape_Unsqueeze__25" [key=0, style=dashed, label="[1]"];
"264 bert/encoder/Reshape/shape_Unsqueeze__25" -> "267 bert/encoder/Reshape/shape_Concat__26" [key=0, style=dashed, label="[1]"];
"265 Constant_nncf_265" -> "266 bert/encoder/Reshape/shape_Unsqueeze__24" [key=0, style=dashed, label="[1]"];
"266 bert/encoder/Reshape/shape_Unsqueeze__24" -> "267 bert/encoder/Reshape/shape_Concat__26" [key=0, style=dashed, label="[1]"];
"267 bert/encoder/Reshape/shape_Concat__26" -> "268 bert/encoder/Reshape__27" [key=0, style=dashed, label="[3]"];
"268 bert/encoder/Reshape__27" -> "269 bert/encoder/Reshape" [key=0, style=dashed, label="[3]"];
"269 bert/encoder/Reshape" -> "270 bert/encoder/Cast" [key=0, style=dashed, label="[]"];
"270 bert/encoder/Cast" -> "271 bert/encoder/mul" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "272 bert/encoder/layer_9/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "275 bert/encoder/layer_8/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "278 bert/encoder/layer_7/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "281 bert/encoder/layer_6/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "284 bert/encoder/layer_5/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "287 bert/encoder/layer_4/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "290 bert/encoder/layer_3/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "293 bert/encoder/layer_2/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "296 bert/encoder/layer_11/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "299 bert/encoder/layer_10/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "302 bert/encoder/layer_1/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"271 bert/encoder/mul" -> "305 bert/encoder/layer_0/attention/self/ExpandDims" [key=0, style=solid, label="[]"];
"272 bert/encoder/layer_9/attention/self/ExpandDims" -> "273 bert/encoder/layer_9/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"273 bert/encoder/layer_9/attention/self/sub" -> "274 bert/encoder/layer_9/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"274 bert/encoder/layer_9/attention/self/mul_1" -> "1467 bert/encoder/layer_9/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"275 bert/encoder/layer_8/attention/self/ExpandDims" -> "276 bert/encoder/layer_8/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"276 bert/encoder/layer_8/attention/self/sub" -> "277 bert/encoder/layer_8/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"277 bert/encoder/layer_8/attention/self/mul_1" -> "1374 bert/encoder/layer_8/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"278 bert/encoder/layer_7/attention/self/ExpandDims" -> "279 bert/encoder/layer_7/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"279 bert/encoder/layer_7/attention/self/sub" -> "280 bert/encoder/layer_7/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"280 bert/encoder/layer_7/attention/self/mul_1" -> "1281 bert/encoder/layer_7/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"281 bert/encoder/layer_6/attention/self/ExpandDims" -> "282 bert/encoder/layer_6/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"282 bert/encoder/layer_6/attention/self/sub" -> "283 bert/encoder/layer_6/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"283 bert/encoder/layer_6/attention/self/mul_1" -> "1188 bert/encoder/layer_6/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"284 bert/encoder/layer_5/attention/self/ExpandDims" -> "285 bert/encoder/layer_5/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"285 bert/encoder/layer_5/attention/self/sub" -> "286 bert/encoder/layer_5/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"286 bert/encoder/layer_5/attention/self/mul_1" -> "1095 bert/encoder/layer_5/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"287 bert/encoder/layer_4/attention/self/ExpandDims" -> "288 bert/encoder/layer_4/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"288 bert/encoder/layer_4/attention/self/sub" -> "289 bert/encoder/layer_4/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"289 bert/encoder/layer_4/attention/self/mul_1" -> "1002 bert/encoder/layer_4/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"290 bert/encoder/layer_3/attention/self/ExpandDims" -> "291 bert/encoder/layer_3/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"291 bert/encoder/layer_3/attention/self/sub" -> "292 bert/encoder/layer_3/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"292 bert/encoder/layer_3/attention/self/mul_1" -> "909 bert/encoder/layer_3/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"293 bert/encoder/layer_2/attention/self/ExpandDims" -> "294 bert/encoder/layer_2/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"294 bert/encoder/layer_2/attention/self/sub" -> "295 bert/encoder/layer_2/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"295 bert/encoder/layer_2/attention/self/mul_1" -> "816 bert/encoder/layer_2/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"296 bert/encoder/layer_11/attention/self/ExpandDims" -> "297 bert/encoder/layer_11/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"297 bert/encoder/layer_11/attention/self/sub" -> "298 bert/encoder/layer_11/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"298 bert/encoder/layer_11/attention/self/mul_1" -> "1653 bert/encoder/layer_11/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"299 bert/encoder/layer_10/attention/self/ExpandDims" -> "300 bert/encoder/layer_10/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"300 bert/encoder/layer_10/attention/self/sub" -> "301 bert/encoder/layer_10/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"301 bert/encoder/layer_10/attention/self/mul_1" -> "1560 bert/encoder/layer_10/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"302 bert/encoder/layer_1/attention/self/ExpandDims" -> "303 bert/encoder/layer_1/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"303 bert/encoder/layer_1/attention/self/sub" -> "304 bert/encoder/layer_1/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"304 bert/encoder/layer_1/attention/self/mul_1" -> "723 bert/encoder/layer_1/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"305 bert/encoder/layer_0/attention/self/ExpandDims" -> "306 bert/encoder/layer_0/attention/self/sub" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"306 bert/encoder/layer_0/attention/self/sub" -> "307 bert/encoder/layer_0/attention/self/mul_1" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"307 bert/encoder/layer_0/attention/self/mul_1" -> "630 bert/encoder/layer_0/attention/self/add" [key=0, style=solid, label="[-1, 1, 256, 256]"];
"308 bert/embeddings/Slice" -> "310 bert/embeddings/Reshape_4" [key=0, style=solid, label="[256, 768]"];
"309 bert/embeddings/Reshape_4__42" -> "310 bert/embeddings/Reshape_4" [key=0, style=dashed, label="[3]"];
"310 bert/embeddings/Reshape_4" -> "370 bert/embeddings/add_1" [key=0, style=solid, label="[]"];
"311 Constant_nncf_311" -> "312 bert/embeddings/Reshape_3/shape_Unsqueeze__69" [key=0, style=dashed, label="[1]"];
"312 bert/embeddings/Reshape_3/shape_Unsqueeze__69" -> "346 bert/embeddings/Reshape_3/shape_Concat__70" [key=0, style=dashed, label="[1]"];
"313 Constant_nncf_313" -> "314 bert/embeddings/Reshape_3/shape_Unsqueeze__68" [key=0, style=dashed, label="[1]"];
"314 bert/embeddings/Reshape_3/shape_Unsqueeze__68" -> "346 bert/embeddings/Reshape_3/shape_Concat__70" [key=0, style=dashed, label="[1]"];
"315 bert/embeddings/Reshape_2__43" -> "316 bert/embeddings/Reshape_2" [key=0, style=dashed, label="[1]"];
"316 bert/embeddings/Reshape_2" -> "362 bert/embeddings/one_hot" [key=0, style=dashed, label="[]"];
"317 Constant_nncf_317" -> "318 bert/embeddings/Reshape_1/shape_Unsqueeze__57" [key=0, style=dashed, label="[1]"];
"318 bert/embeddings/Reshape_1/shape_Unsqueeze__57" -> "331 bert/embeddings/Reshape_1/shape_Concat__58" [key=0, style=dashed, label="[1]"];
"319 Constant_nncf_319" -> "320 bert/embeddings/Reshape_1/shape_Unsqueeze__56" [key=0, style=dashed, label="[1]"];
"320 bert/embeddings/Reshape_1/shape_Unsqueeze__56" -> "331 bert/embeddings/Reshape_1/shape_Concat__58" [key=0, style=dashed, label="[1]"];
"321 bert/embeddings/Reshape__59" -> "333 bert/embeddings/Reshape" [key=0, style=dashed, label="[1]"];
"322 bert/embeddings/ExpandDims" -> "323 bert/embeddings/Shape" [key=0, style=dashed, label="[-1, 256, 1]"];
"322 bert/embeddings/ExpandDims" -> "333 bert/embeddings/Reshape" [key=0, style=dashed, label="[-1, 256, 1]"];
"323 bert/embeddings/Shape" -> "324 bert/embeddings/Shape__49" [key=0, style=dashed, label="[3]"];
"324 bert/embeddings/Shape__49" -> "325 bert/embeddings/strided_slice" [key=0, style=solid, label="[3]"];
"325 bert/embeddings/strided_slice" -> "327 bert/embeddings/strided_slice__53" [key=0, style=solid, label="[1]"];
"326 Constant_nncf_326" -> "327 bert/embeddings/strided_slice__53" [key=0, style=dashed, label="[1]"];
"327 bert/embeddings/strided_slice__53" -> "328 bert/embeddings/strided_slice__54" [key=0, style=solid, label="[]"];
"328 bert/embeddings/strided_slice__54" -> "330 bert/embeddings/Reshape_1/shape_Unsqueeze__55" [key=0, style=dashed, label="[]"];
"329 Constant_nncf_329" -> "330 bert/embeddings/Reshape_1/shape_Unsqueeze__55" [key=0, style=dashed, label="[1]"];
"330 bert/embeddings/Reshape_1/shape_Unsqueeze__55" -> "331 bert/embeddings/Reshape_1/shape_Concat__58" [key=0, style=dashed, label="[1]"];
"331 bert/embeddings/Reshape_1/shape_Concat__58" -> "332 bert/embeddings/Reshape_1__60" [key=0, style=dashed, label="[3]"];
"332 bert/embeddings/Reshape_1__60" -> "337 bert/embeddings/Reshape_1" [key=0, style=dashed, label="[3]"];
"333 bert/embeddings/Reshape" -> "336 bert/embeddings/GatherV2" [key=0, style=dashed, label="[]"];
"334 QuantizeLinear_bert/embeddings/word_embeddings^0_1" -> "335 DequantizeLinear_bert/embeddings/word_embeddings^0_1" [key=0, style=dashed, label="[30522, 768]"];
"335 DequantizeLinear_bert/embeddings/word_embeddings^0_1" -> "336 bert/embeddings/GatherV2" [key=0, style=solid, label="[30522, 768]"];
"336 bert/embeddings/GatherV2" -> "337 bert/embeddings/Reshape_1" [key=0, style=solid, label="[]"];
"337 bert/embeddings/Reshape_1" -> "338 bert/embeddings/Shape_1" [key=0, style=solid, label="[]"];
"337 bert/embeddings/Reshape_1" -> "369 bert/embeddings/add" [key=0, style=solid, label="[]"];
"338 bert/embeddings/Shape_1" -> "339 bert/embeddings/Shape_1__61" [key=0, style=dashed, label="[-1]"];
"339 bert/embeddings/Shape_1__61" -> "340 bert/embeddings/strided_slice_1" [key=0, style=solid, label="[-1]"];
"340 bert/embeddings/strided_slice_1" -> "342 bert/embeddings/strided_slice_1__65" [key=0, style=solid, label="[-1]"];
"341 Constant_nncf_339" -> "342 bert/embeddings/strided_slice_1__65" [key=0, style=dashed, label="[1]"];
"342 bert/embeddings/strided_slice_1__65" -> "343 bert/embeddings/strided_slice_1__66" [key=0, style=solid, label="[]"];
"343 bert/embeddings/strided_slice_1__66" -> "345 bert/embeddings/Reshape_3/shape_Unsqueeze__67" [key=0, style=dashed, label="[]"];
"344 Constant_nncf_342" -> "345 bert/embeddings/Reshape_3/shape_Unsqueeze__67" [key=0, style=dashed, label="[1]"];
"345 bert/embeddings/Reshape_3/shape_Unsqueeze__67" -> "346 bert/embeddings/Reshape_3/shape_Concat__70" [key=0, style=dashed, label="[1]"];
"346 bert/embeddings/Reshape_3/shape_Concat__70" -> "347 bert/embeddings/Reshape_3__71" [key=0, style=dashed, label="[3]"];
"347 bert/embeddings/Reshape_3__71" -> "368 bert/embeddings/Reshape_3" [key=0, style=dashed, label="[3]"];
"348 Constant_nncf_346" -> "349 Unsqueeze__46" [key=0, style=dashed, label="[1]"];
"349 Unsqueeze__46" -> "361 Concat__47" [key=0, style=solid, label="[1]"];
"350 Constant_nncf_348" -> "351 Unsqueeze__45" [key=0, style=dashed, label="[1]"];
"351 Unsqueeze__45" -> "361 Concat__47" [key=0, style=solid, label="[1]"];
"352 Constant_nncf_350" -> "353 Unsqueeze__44" [key=0, style=dashed, label="[1]"];
"353 Unsqueeze__44" -> "362 bert/embeddings/one_hot" [key=0, style=dashed, label="[1]"];
"354 Constant_nncf_352" -> "355 Reshape_1/shape_Unsqueeze__480" [key=0, style=dashed, label="[1]"];
"355 Reshape_1/shape_Unsqueeze__480" -> "1731 Reshape_1/shape_Concat__481" [key=0, style=dashed, label="[1]"];
"356 Constant_nncf_354" -> "357 Reshape_1/shape_Unsqueeze__479" [key=0, style=dashed, label="[1]"];
"357 Reshape_1/shape_Unsqueeze__479" -> "1731 Reshape_1/shape_Concat__481" [key=0, style=dashed, label="[1]"];
"358 Constant_nncf_356" -> "359 Reshape/shape_Unsqueeze__483" [key=0, style=dashed, label="[1]"];
"359 Reshape/shape_Unsqueeze__483" -> "1727 Reshape/shape_Concat__484" [key=0, style=dashed, label="[1]"];
"360 MatMul__486" -> "1734 QuantizeLinear_MatMul__486^0_1" [key=0, style=solid, label="[768, 2]"];
"361 Concat__47" -> "362 bert/embeddings/one_hot" [key=0, style=solid, label="[2]"];
"362 bert/embeddings/one_hot" -> "363 QuantizeLinear_bert/embeddings/one_hot^0_1" [key=0, style=solid, label="[]"];
"363 QuantizeLinear_bert/embeddings/one_hot^0_1" -> "364 DequantizeLinear_bert/embeddings/one_hot^0_1" [key=0, style=dashed, label="[]"];
"364 DequantizeLinear_bert/embeddings/one_hot^0_1" -> "367 bert/embeddings/MatMul" [key=0, style=solid, label="[]"];
"365 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "366 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" [key=0, style=dashed, label="[2, 768]"];
"366 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "367 bert/embeddings/MatMul" [key=0, style=solid, label="[2, 768]"];
"367 bert/embeddings/MatMul" -> "368 bert/embeddings/Reshape_3" [key=0, style=solid, label="[]"];
"368 bert/embeddings/Reshape_3" -> "369 bert/embeddings/add" [key=0, style=solid, label="[]"];
"369 bert/embeddings/add" -> "370 bert/embeddings/add_1" [key=0, style=solid, label="[]"];
"370 bert/embeddings/add_1" -> "371 bert/embeddings/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"370 bert/embeddings/add_1" -> "373 bert/embeddings/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"370 bert/embeddings/add_1" -> "382 bert/embeddings/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"371 bert/embeddings/LayerNorm/moments/mean" -> "372 bert/embeddings/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"371 bert/embeddings/LayerNorm/moments/mean" -> "380 bert/embeddings/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"372 bert/embeddings/LayerNorm/moments/StopGradient" -> "373 bert/embeddings/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"373 bert/embeddings/LayerNorm/moments/SquaredDifference" -> "374 bert/embeddings/LayerNorm/moments/SquaredDifference__72" [key=0, style=solid, label="[]"];
"373 bert/embeddings/LayerNorm/moments/SquaredDifference" -> "374 bert/embeddings/LayerNorm/moments/SquaredDifference__72" [key=1, style=solid, label="[]"];
"374 bert/embeddings/LayerNorm/moments/SquaredDifference__72" -> "375 bert/embeddings/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"375 bert/embeddings/LayerNorm/moments/variance" -> "376 bert/embeddings/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"376 bert/embeddings/LayerNorm/batchnorm/add" -> "377 bert/embeddings/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"377 bert/embeddings/LayerNorm/batchnorm/Rsqrt" -> "378 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" [key=0, style=solid, label="[]"];
"378 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" -> "379 bert/embeddings/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"379 bert/embeddings/LayerNorm/batchnorm/mul" -> "380 bert/embeddings/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"379 bert/embeddings/LayerNorm/batchnorm/mul" -> "382 bert/embeddings/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"380 bert/embeddings/LayerNorm/batchnorm/mul_2" -> "381 bert/embeddings/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"381 bert/embeddings/LayerNorm/batchnorm/sub" -> "383 bert/embeddings/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"382 bert/embeddings/LayerNorm/batchnorm/mul_1" -> "383 bert/embeddings/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"383 bert/embeddings/LayerNorm/batchnorm/add_1" -> "384 bert/encoder/Shape_2" [key=0, style=solid, label="[]"];
"383 bert/embeddings/LayerNorm/batchnorm/add_1" -> "598 bert/encoder/Reshape_1" [key=0, style=solid, label="[]"];
"384 bert/encoder/Shape_2" -> "385 bert/encoder/Shape_2__76" [key=0, style=dashed, label="[-1]"];
"385 bert/encoder/Shape_2__76" -> "386 bert/encoder/strided_slice_2" [key=0, style=solid, label="[-1]"];
"386 bert/encoder/strided_slice_2" -> "388 bert/encoder/strided_slice_2__80" [key=0, style=solid, label="[-1]"];
"387 Constant_nncf_381" -> "388 bert/encoder/strided_slice_2__80" [key=0, style=dashed, label="[1]"];
"388 bert/encoder/strided_slice_2__80" -> "389 bert/encoder/strided_slice_2__81" [key=0, style=solid, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "390 bert/encoder/layer_9/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "396 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "400 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "404 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "407 bert/encoder/layer_8/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "413 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "417 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "421 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "424 bert/encoder/layer_7/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "430 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "434 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "438 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "441 bert/encoder/layer_6/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "447 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "451 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "455 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "458 bert/encoder/layer_5/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "464 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "468 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "472 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "475 bert/encoder/layer_4/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "481 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "485 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "489 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "492 bert/encoder/layer_3/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "498 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "502 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "506 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "509 bert/encoder/layer_2/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "515 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "519 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "523 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "526 bert/encoder/layer_11/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "532 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "536 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "540 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "543 bert/encoder/layer_10/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "549 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "553 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "557 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "560 bert/encoder/layer_1/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "566 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "570 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "574 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "577 bert/encoder/layer_0/attention/self/mul_2" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "583 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "587 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "591 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" [key=0, style=dashed, label="[]"];
"389 bert/encoder/strided_slice_2__81" -> "595 bert/encoder/Reshape_13/shape_Unsqueeze__298" [key=0, style=dashed, label="[]"];
"390 bert/encoder/layer_9/attention/self/mul_2" -> "392 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" [key=0, style=dashed, label="[]"];
"391 Constant_nncf_385" -> "392 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" [key=0, style=dashed, label="[1]"];
"392 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" -> "393 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" [key=0, style=dashed, label="[1]"];
"393 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" -> "394 bert/encoder/layer_9/attention/self/Reshape_3__434" [key=0, style=dashed, label="[2]"];
"394 bert/encoder/layer_9/attention/self/Reshape_3__434" -> "1476 bert/encoder/layer_9/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"395 Constant_nncf_389" -> "396 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" [key=0, style=dashed, label="[1]"];
"396 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" -> "397 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [key=0, style=dashed, label="[1]"];
"397 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" -> "398 bert/encoder/layer_9/attention/self/Reshape_2__429" [key=0, style=dashed, label="[4]"];
"398 bert/encoder/layer_9/attention/self/Reshape_2__429" -> "1446 bert/encoder/layer_9/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"399 Constant_nncf_393" -> "400 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" [key=0, style=dashed, label="[1]"];
"400 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" -> "401 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [key=0, style=dashed, label="[1]"];
"401 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" -> "402 bert/encoder/layer_9/attention/self/Reshape_1__431" [key=0, style=dashed, label="[4]"];
"402 bert/encoder/layer_9/attention/self/Reshape_1__431" -> "1462 bert/encoder/layer_9/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"403 Constant_nncf_397" -> "404 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" [key=0, style=dashed, label="[1]"];
"404 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" -> "405 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [key=0, style=dashed, label="[1]"];
"405 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" -> "406 bert/encoder/layer_9/attention/self/Reshape__430" [key=0, style=dashed, label="[4]"];
"406 bert/encoder/layer_9/attention/self/Reshape__430" -> "1454 bert/encoder/layer_9/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"407 bert/encoder/layer_8/attention/self/mul_2" -> "409 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" [key=0, style=dashed, label="[]"];
"408 Constant_nncf_402" -> "409 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" [key=0, style=dashed, label="[1]"];
"409 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" -> "410 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" [key=0, style=dashed, label="[1]"];
"410 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" -> "411 bert/encoder/layer_8/attention/self/Reshape_3__420" [key=0, style=dashed, label="[2]"];
"411 bert/encoder/layer_8/attention/self/Reshape_3__420" -> "1383 bert/encoder/layer_8/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"412 Constant_nncf_406" -> "413 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" [key=0, style=dashed, label="[1]"];
"413 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" -> "414 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [key=0, style=dashed, label="[1]"];
"414 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" -> "415 bert/encoder/layer_8/attention/self/Reshape_2__415" [key=0, style=dashed, label="[4]"];
"415 bert/encoder/layer_8/attention/self/Reshape_2__415" -> "1353 bert/encoder/layer_8/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"416 Constant_nncf_410" -> "417 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" [key=0, style=dashed, label="[1]"];
"417 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" -> "418 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [key=0, style=dashed, label="[1]"];
"418 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" -> "419 bert/encoder/layer_8/attention/self/Reshape_1__417" [key=0, style=dashed, label="[4]"];
"419 bert/encoder/layer_8/attention/self/Reshape_1__417" -> "1369 bert/encoder/layer_8/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"420 Constant_nncf_414" -> "421 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" [key=0, style=dashed, label="[1]"];
"421 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" -> "422 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [key=0, style=dashed, label="[1]"];
"422 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" -> "423 bert/encoder/layer_8/attention/self/Reshape__416" [key=0, style=dashed, label="[4]"];
"423 bert/encoder/layer_8/attention/self/Reshape__416" -> "1361 bert/encoder/layer_8/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"424 bert/encoder/layer_7/attention/self/mul_2" -> "426 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" [key=0, style=dashed, label="[]"];
"425 Constant_nncf_419" -> "426 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" [key=0, style=dashed, label="[1]"];
"426 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" -> "427 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" [key=0, style=dashed, label="[1]"];
"427 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" -> "428 bert/encoder/layer_7/attention/self/Reshape_3__406" [key=0, style=dashed, label="[2]"];
"428 bert/encoder/layer_7/attention/self/Reshape_3__406" -> "1290 bert/encoder/layer_7/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"429 Constant_nncf_423" -> "430 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" [key=0, style=dashed, label="[1]"];
"430 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" -> "431 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [key=0, style=dashed, label="[1]"];
"431 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" -> "432 bert/encoder/layer_7/attention/self/Reshape_2__401" [key=0, style=dashed, label="[4]"];
"432 bert/encoder/layer_7/attention/self/Reshape_2__401" -> "1260 bert/encoder/layer_7/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"433 Constant_nncf_427" -> "434 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" [key=0, style=dashed, label="[1]"];
"434 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" -> "435 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [key=0, style=dashed, label="[1]"];
"435 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" -> "436 bert/encoder/layer_7/attention/self/Reshape_1__403" [key=0, style=dashed, label="[4]"];
"436 bert/encoder/layer_7/attention/self/Reshape_1__403" -> "1276 bert/encoder/layer_7/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"437 Constant_nncf_431" -> "438 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" [key=0, style=dashed, label="[1]"];
"438 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" -> "439 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [key=0, style=dashed, label="[1]"];
"439 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" -> "440 bert/encoder/layer_7/attention/self/Reshape__402" [key=0, style=dashed, label="[4]"];
"440 bert/encoder/layer_7/attention/self/Reshape__402" -> "1268 bert/encoder/layer_7/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"441 bert/encoder/layer_6/attention/self/mul_2" -> "443 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" [key=0, style=dashed, label="[]"];
"442 Constant_nncf_436" -> "443 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" [key=0, style=dashed, label="[1]"];
"443 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" -> "444 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" [key=0, style=dashed, label="[1]"];
"444 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" -> "445 bert/encoder/layer_6/attention/self/Reshape_3__392" [key=0, style=dashed, label="[2]"];
"445 bert/encoder/layer_6/attention/self/Reshape_3__392" -> "1197 bert/encoder/layer_6/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"446 Constant_nncf_440" -> "447 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" [key=0, style=dashed, label="[1]"];
"447 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" -> "448 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [key=0, style=dashed, label="[1]"];
"448 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" -> "449 bert/encoder/layer_6/attention/self/Reshape_2__387" [key=0, style=dashed, label="[4]"];
"449 bert/encoder/layer_6/attention/self/Reshape_2__387" -> "1167 bert/encoder/layer_6/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"450 Constant_nncf_444" -> "451 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" [key=0, style=dashed, label="[1]"];
"451 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" -> "452 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [key=0, style=dashed, label="[1]"];
"452 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" -> "453 bert/encoder/layer_6/attention/self/Reshape_1__389" [key=0, style=dashed, label="[4]"];
"453 bert/encoder/layer_6/attention/self/Reshape_1__389" -> "1183 bert/encoder/layer_6/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"454 Constant_nncf_448" -> "455 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" [key=0, style=dashed, label="[1]"];
"455 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" -> "456 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [key=0, style=dashed, label="[1]"];
"456 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" -> "457 bert/encoder/layer_6/attention/self/Reshape__388" [key=0, style=dashed, label="[4]"];
"457 bert/encoder/layer_6/attention/self/Reshape__388" -> "1175 bert/encoder/layer_6/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"458 bert/encoder/layer_5/attention/self/mul_2" -> "460 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" [key=0, style=dashed, label="[]"];
"459 Constant_nncf_453" -> "460 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" [key=0, style=dashed, label="[1]"];
"460 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" -> "461 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" [key=0, style=dashed, label="[1]"];
"461 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" -> "462 bert/encoder/layer_5/attention/self/Reshape_3__378" [key=0, style=dashed, label="[2]"];
"462 bert/encoder/layer_5/attention/self/Reshape_3__378" -> "1104 bert/encoder/layer_5/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"463 Constant_nncf_457" -> "464 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" [key=0, style=dashed, label="[1]"];
"464 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" -> "465 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [key=0, style=dashed, label="[1]"];
"465 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" -> "466 bert/encoder/layer_5/attention/self/Reshape_2__373" [key=0, style=dashed, label="[4]"];
"466 bert/encoder/layer_5/attention/self/Reshape_2__373" -> "1074 bert/encoder/layer_5/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"467 Constant_nncf_461" -> "468 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" [key=0, style=dashed, label="[1]"];
"468 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" -> "469 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [key=0, style=dashed, label="[1]"];
"469 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" -> "470 bert/encoder/layer_5/attention/self/Reshape_1__375" [key=0, style=dashed, label="[4]"];
"470 bert/encoder/layer_5/attention/self/Reshape_1__375" -> "1090 bert/encoder/layer_5/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"471 Constant_nncf_465" -> "472 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" [key=0, style=dashed, label="[1]"];
"472 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" -> "473 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [key=0, style=dashed, label="[1]"];
"473 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" -> "474 bert/encoder/layer_5/attention/self/Reshape__374" [key=0, style=dashed, label="[4]"];
"474 bert/encoder/layer_5/attention/self/Reshape__374" -> "1082 bert/encoder/layer_5/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"475 bert/encoder/layer_4/attention/self/mul_2" -> "477 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" [key=0, style=dashed, label="[]"];
"476 Constant_nncf_470" -> "477 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" [key=0, style=dashed, label="[1]"];
"477 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" -> "478 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" [key=0, style=dashed, label="[1]"];
"478 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" -> "479 bert/encoder/layer_4/attention/self/Reshape_3__364" [key=0, style=dashed, label="[2]"];
"479 bert/encoder/layer_4/attention/self/Reshape_3__364" -> "1011 bert/encoder/layer_4/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"480 Constant_nncf_474" -> "481 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" [key=0, style=dashed, label="[1]"];
"481 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" -> "482 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [key=0, style=dashed, label="[1]"];
"482 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" -> "483 bert/encoder/layer_4/attention/self/Reshape_2__359" [key=0, style=dashed, label="[4]"];
"483 bert/encoder/layer_4/attention/self/Reshape_2__359" -> "981 bert/encoder/layer_4/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"484 Constant_nncf_478" -> "485 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" [key=0, style=dashed, label="[1]"];
"485 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" -> "486 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [key=0, style=dashed, label="[1]"];
"486 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" -> "487 bert/encoder/layer_4/attention/self/Reshape_1__361" [key=0, style=dashed, label="[4]"];
"487 bert/encoder/layer_4/attention/self/Reshape_1__361" -> "997 bert/encoder/layer_4/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"488 Constant_nncf_482" -> "489 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" [key=0, style=dashed, label="[1]"];
"489 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" -> "490 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [key=0, style=dashed, label="[1]"];
"490 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" -> "491 bert/encoder/layer_4/attention/self/Reshape__360" [key=0, style=dashed, label="[4]"];
"491 bert/encoder/layer_4/attention/self/Reshape__360" -> "989 bert/encoder/layer_4/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"492 bert/encoder/layer_3/attention/self/mul_2" -> "494 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" [key=0, style=dashed, label="[]"];
"493 Constant_nncf_487" -> "494 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" [key=0, style=dashed, label="[1]"];
"494 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" -> "495 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" [key=0, style=dashed, label="[1]"];
"495 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" -> "496 bert/encoder/layer_3/attention/self/Reshape_3__350" [key=0, style=dashed, label="[2]"];
"496 bert/encoder/layer_3/attention/self/Reshape_3__350" -> "918 bert/encoder/layer_3/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"497 Constant_nncf_491" -> "498 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" [key=0, style=dashed, label="[1]"];
"498 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" -> "499 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [key=0, style=dashed, label="[1]"];
"499 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" -> "500 bert/encoder/layer_3/attention/self/Reshape_2__345" [key=0, style=dashed, label="[4]"];
"500 bert/encoder/layer_3/attention/self/Reshape_2__345" -> "888 bert/encoder/layer_3/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"501 Constant_nncf_495" -> "502 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" [key=0, style=dashed, label="[1]"];
"502 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" -> "503 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [key=0, style=dashed, label="[1]"];
"503 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" -> "504 bert/encoder/layer_3/attention/self/Reshape_1__347" [key=0, style=dashed, label="[4]"];
"504 bert/encoder/layer_3/attention/self/Reshape_1__347" -> "904 bert/encoder/layer_3/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"505 Constant_nncf_499" -> "506 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" [key=0, style=dashed, label="[1]"];
"506 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" -> "507 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [key=0, style=dashed, label="[1]"];
"507 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" -> "508 bert/encoder/layer_3/attention/self/Reshape__346" [key=0, style=dashed, label="[4]"];
"508 bert/encoder/layer_3/attention/self/Reshape__346" -> "896 bert/encoder/layer_3/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"509 bert/encoder/layer_2/attention/self/mul_2" -> "511 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" [key=0, style=dashed, label="[]"];
"510 Constant_nncf_504" -> "511 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" [key=0, style=dashed, label="[1]"];
"511 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" -> "512 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" [key=0, style=dashed, label="[1]"];
"512 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" -> "513 bert/encoder/layer_2/attention/self/Reshape_3__336" [key=0, style=dashed, label="[2]"];
"513 bert/encoder/layer_2/attention/self/Reshape_3__336" -> "825 bert/encoder/layer_2/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"514 Constant_nncf_508" -> "515 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" [key=0, style=dashed, label="[1]"];
"515 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" -> "516 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [key=0, style=dashed, label="[1]"];
"516 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" -> "517 bert/encoder/layer_2/attention/self/Reshape_2__331" [key=0, style=dashed, label="[4]"];
"517 bert/encoder/layer_2/attention/self/Reshape_2__331" -> "795 bert/encoder/layer_2/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"518 Constant_nncf_512" -> "519 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" [key=0, style=dashed, label="[1]"];
"519 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" -> "520 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [key=0, style=dashed, label="[1]"];
"520 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" -> "521 bert/encoder/layer_2/attention/self/Reshape_1__333" [key=0, style=dashed, label="[4]"];
"521 bert/encoder/layer_2/attention/self/Reshape_1__333" -> "811 bert/encoder/layer_2/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"522 Constant_nncf_516" -> "523 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" [key=0, style=dashed, label="[1]"];
"523 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" -> "524 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [key=0, style=dashed, label="[1]"];
"524 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" -> "525 bert/encoder/layer_2/attention/self/Reshape__332" [key=0, style=dashed, label="[4]"];
"525 bert/encoder/layer_2/attention/self/Reshape__332" -> "803 bert/encoder/layer_2/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"526 bert/encoder/layer_11/attention/self/mul_2" -> "528 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" [key=0, style=dashed, label="[]"];
"527 Constant_nncf_521" -> "528 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" [key=0, style=dashed, label="[1]"];
"528 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" -> "529 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" [key=0, style=dashed, label="[1]"];
"529 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" -> "530 bert/encoder/layer_11/attention/self/Reshape_3__462" [key=0, style=dashed, label="[2]"];
"530 bert/encoder/layer_11/attention/self/Reshape_3__462" -> "1662 bert/encoder/layer_11/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"531 Constant_nncf_525" -> "532 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" [key=0, style=dashed, label="[1]"];
"532 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" -> "533 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [key=0, style=dashed, label="[1]"];
"533 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" -> "534 bert/encoder/layer_11/attention/self/Reshape_2__457" [key=0, style=dashed, label="[4]"];
"534 bert/encoder/layer_11/attention/self/Reshape_2__457" -> "1632 bert/encoder/layer_11/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"535 Constant_nncf_529" -> "536 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" [key=0, style=dashed, label="[1]"];
"536 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" -> "537 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [key=0, style=dashed, label="[1]"];
"537 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" -> "538 bert/encoder/layer_11/attention/self/Reshape_1__459" [key=0, style=dashed, label="[4]"];
"538 bert/encoder/layer_11/attention/self/Reshape_1__459" -> "1648 bert/encoder/layer_11/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"539 Constant_nncf_533" -> "540 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" [key=0, style=dashed, label="[1]"];
"540 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" -> "541 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [key=0, style=dashed, label="[1]"];
"541 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" -> "542 bert/encoder/layer_11/attention/self/Reshape__458" [key=0, style=dashed, label="[4]"];
"542 bert/encoder/layer_11/attention/self/Reshape__458" -> "1640 bert/encoder/layer_11/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"543 bert/encoder/layer_10/attention/self/mul_2" -> "545 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" [key=0, style=dashed, label="[]"];
"544 Constant_nncf_538" -> "545 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" [key=0, style=dashed, label="[1]"];
"545 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" -> "546 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" [key=0, style=dashed, label="[1]"];
"546 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" -> "547 bert/encoder/layer_10/attention/self/Reshape_3__448" [key=0, style=dashed, label="[2]"];
"547 bert/encoder/layer_10/attention/self/Reshape_3__448" -> "1569 bert/encoder/layer_10/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"548 Constant_nncf_542" -> "549 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" [key=0, style=dashed, label="[1]"];
"549 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" -> "550 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [key=0, style=dashed, label="[1]"];
"550 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" -> "551 bert/encoder/layer_10/attention/self/Reshape_2__443" [key=0, style=dashed, label="[4]"];
"551 bert/encoder/layer_10/attention/self/Reshape_2__443" -> "1539 bert/encoder/layer_10/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"552 Constant_nncf_546" -> "553 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" [key=0, style=dashed, label="[1]"];
"553 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" -> "554 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [key=0, style=dashed, label="[1]"];
"554 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" -> "555 bert/encoder/layer_10/attention/self/Reshape_1__445" [key=0, style=dashed, label="[4]"];
"555 bert/encoder/layer_10/attention/self/Reshape_1__445" -> "1555 bert/encoder/layer_10/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"556 Constant_nncf_550" -> "557 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" [key=0, style=dashed, label="[1]"];
"557 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" -> "558 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [key=0, style=dashed, label="[1]"];
"558 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" -> "559 bert/encoder/layer_10/attention/self/Reshape__444" [key=0, style=dashed, label="[4]"];
"559 bert/encoder/layer_10/attention/self/Reshape__444" -> "1547 bert/encoder/layer_10/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"560 bert/encoder/layer_1/attention/self/mul_2" -> "562 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" [key=0, style=dashed, label="[]"];
"561 Constant_nncf_555" -> "562 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" [key=0, style=dashed, label="[1]"];
"562 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" -> "563 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" [key=0, style=dashed, label="[1]"];
"563 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" -> "564 bert/encoder/layer_1/attention/self/Reshape_3__322" [key=0, style=dashed, label="[2]"];
"564 bert/encoder/layer_1/attention/self/Reshape_3__322" -> "732 bert/encoder/layer_1/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"565 Constant_nncf_559" -> "566 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" [key=0, style=dashed, label="[1]"];
"566 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" -> "567 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [key=0, style=dashed, label="[1]"];
"567 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" -> "568 bert/encoder/layer_1/attention/self/Reshape_2__317" [key=0, style=dashed, label="[4]"];
"568 bert/encoder/layer_1/attention/self/Reshape_2__317" -> "702 bert/encoder/layer_1/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"569 Constant_nncf_563" -> "570 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" [key=0, style=dashed, label="[1]"];
"570 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" -> "571 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [key=0, style=dashed, label="[1]"];
"571 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" -> "572 bert/encoder/layer_1/attention/self/Reshape_1__319" [key=0, style=dashed, label="[4]"];
"572 bert/encoder/layer_1/attention/self/Reshape_1__319" -> "718 bert/encoder/layer_1/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"573 Constant_nncf_567" -> "574 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" [key=0, style=dashed, label="[1]"];
"574 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" -> "575 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [key=0, style=dashed, label="[1]"];
"575 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" -> "576 bert/encoder/layer_1/attention/self/Reshape__318" [key=0, style=dashed, label="[4]"];
"576 bert/encoder/layer_1/attention/self/Reshape__318" -> "710 bert/encoder/layer_1/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"577 bert/encoder/layer_0/attention/self/mul_2" -> "579 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" [key=0, style=dashed, label="[]"];
"578 Constant_nncf_572" -> "579 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" [key=0, style=dashed, label="[1]"];
"579 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" -> "580 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" [key=0, style=dashed, label="[1]"];
"580 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" -> "581 bert/encoder/layer_0/attention/self/Reshape_3__308" [key=0, style=dashed, label="[2]"];
"581 bert/encoder/layer_0/attention/self/Reshape_3__308" -> "639 bert/encoder/layer_0/attention/self/Reshape_3" [key=0, style=dashed, label="[2]"];
"582 Constant_nncf_576" -> "583 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" [key=0, style=dashed, label="[1]"];
"583 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" -> "584 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [key=0, style=dashed, label="[1]"];
"584 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" -> "585 bert/encoder/layer_0/attention/self/Reshape_2__303" [key=0, style=dashed, label="[4]"];
"585 bert/encoder/layer_0/attention/self/Reshape_2__303" -> "609 bert/encoder/layer_0/attention/self/Reshape_2" [key=0, style=dashed, label="[4]"];
"586 Constant_nncf_580" -> "587 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" [key=0, style=dashed, label="[1]"];
"587 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" -> "588 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [key=0, style=dashed, label="[1]"];
"588 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" -> "589 bert/encoder/layer_0/attention/self/Reshape_1__305" [key=0, style=dashed, label="[4]"];
"589 bert/encoder/layer_0/attention/self/Reshape_1__305" -> "625 bert/encoder/layer_0/attention/self/Reshape_1" [key=0, style=dashed, label="[4]"];
"590 Constant_nncf_584" -> "591 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" [key=0, style=dashed, label="[1]"];
"591 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" -> "592 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [key=0, style=dashed, label="[1]"];
"592 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" -> "593 bert/encoder/layer_0/attention/self/Reshape__304" [key=0, style=dashed, label="[4]"];
"593 bert/encoder/layer_0/attention/self/Reshape__304" -> "617 bert/encoder/layer_0/attention/self/Reshape" [key=0, style=dashed, label="[4]"];
"594 Constant_nncf_588" -> "595 bert/encoder/Reshape_13/shape_Unsqueeze__298" [key=0, style=dashed, label="[1]"];
"595 bert/encoder/Reshape_13/shape_Unsqueeze__298" -> "596 bert/encoder/Reshape_13/shape_Concat__301" [key=0, style=dashed, label="[1]"];
"596 bert/encoder/Reshape_13/shape_Concat__301" -> "597 bert/encoder/Reshape_13__471" [key=0, style=dashed, label="[3]"];
"597 bert/encoder/Reshape_13__471" -> "1717 bert/encoder/Reshape_13" [key=0, style=dashed, label="[3]"];
"598 bert/encoder/Reshape_1" -> "599 QuantizeLinear_bert/encoder/Reshape_1^0_1" [key=0, style=solid, label="[]"];
"598 bert/encoder/Reshape_1" -> "603 QuantizeLinear_bert/encoder/Reshape_1^0_2" [key=0, style=solid, label="[]"];
"598 bert/encoder/Reshape_1" -> "605 QuantizeLinear_bert/encoder/Reshape_1^0_3" [key=0, style=solid, label="[]"];
"598 bert/encoder/Reshape_1" -> "644 bert/encoder/layer_0/attention/output/add" [key=0, style=solid, label="[]"];
"599 QuantizeLinear_bert/encoder/Reshape_1^0_1" -> "600 DequantizeLinear_bert/encoder/Reshape_1^0_1" [key=0, style=dashed, label="[]"];
"600 DequantizeLinear_bert/encoder/Reshape_1^0_1" -> "607 bert/encoder/layer_0/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"601 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "602 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"602 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "607 bert/encoder/layer_0/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"603 QuantizeLinear_bert/encoder/Reshape_1^0_2" -> "604 DequantizeLinear_bert/encoder/Reshape_1^0_2" [key=0, style=dashed, label="[]"];
"604 DequantizeLinear_bert/encoder/Reshape_1^0_2" -> "613 bert/encoder/layer_0/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"605 QuantizeLinear_bert/encoder/Reshape_1^0_3" -> "606 DequantizeLinear_bert/encoder/Reshape_1^0_3" [key=0, style=dashed, label="[]"];
"606 DequantizeLinear_bert/encoder/Reshape_1^0_3" -> "621 bert/encoder/layer_0/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"607 bert/encoder/layer_0/attention/self/value/MatMul" -> "608 bert/encoder/layer_0/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"608 bert/encoder/layer_0/attention/self/value/BiasAdd" -> "609 bert/encoder/layer_0/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"609 bert/encoder/layer_0/attention/self/Reshape_2" -> "610 bert/encoder/layer_0/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"610 bert/encoder/layer_0/attention/self/transpose_2" -> "635 bert/encoder/layer_0/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"611 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "612 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"612 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "613 bert/encoder/layer_0/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"613 bert/encoder/layer_0/attention/self/query/MatMul" -> "614 bert/encoder/layer_0/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"614 bert/encoder/layer_0/attention/self/query/BiasAdd" -> "615 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"615 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "616 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"616 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "617 bert/encoder/layer_0/attention/self/Reshape" [key=0, style=solid, label="[]"];
"617 bert/encoder/layer_0/attention/self/Reshape" -> "618 bert/encoder/layer_0/attention/self/transpose" [key=0, style=solid, label="[]"];
"618 bert/encoder/layer_0/attention/self/transpose" -> "628 bert/encoder/layer_0/attention/self/MatMul" [key=0, style=solid, label="[]"];
"619 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "620 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"620 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "621 bert/encoder/layer_0/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"621 bert/encoder/layer_0/attention/self/key/MatMul" -> "622 bert/encoder/layer_0/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"622 bert/encoder/layer_0/attention/self/key/BiasAdd" -> "623 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"623 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "624 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"624 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "625 bert/encoder/layer_0/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"625 bert/encoder/layer_0/attention/self/Reshape_1" -> "626 bert/encoder/layer_0/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"626 bert/encoder/layer_0/attention/self/transpose_1" -> "627 bert/encoder/layer_0/attention/self/MatMul__306" [key=0, style=solid, label="[]"];
"627 bert/encoder/layer_0/attention/self/MatMul__306" -> "628 bert/encoder/layer_0/attention/self/MatMul" [key=0, style=solid, label="[]"];
"628 bert/encoder/layer_0/attention/self/MatMul" -> "629 bert/encoder/layer_0/attention/self/Mul" [key=0, style=solid, label="[]"];
"629 bert/encoder/layer_0/attention/self/Mul" -> "630 bert/encoder/layer_0/attention/self/add" [key=0, style=solid, label="[]"];
"630 bert/encoder/layer_0/attention/self/add" -> "631 Shape_nncf_609" [key=0, style=solid, label="[]"];
"630 bert/encoder/layer_0/attention/self/add" -> "632 Flatten_nncf_610" [key=0, style=solid, label="[]"];
"631 Shape_nncf_609" -> "634 Reshape_nncf_612" [key=0, style=dashed, label="[-1]"];
"632 Flatten_nncf_610" -> "633 bert/encoder/layer_0/attention/self/Softmax" [key=0, style=solid, label="[]"];
"633 bert/encoder/layer_0/attention/self/Softmax" -> "634 Reshape_nncf_612" [key=0, style=solid, label="[]"];
"634 Reshape_nncf_612" -> "635 bert/encoder/layer_0/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"635 bert/encoder/layer_0/attention/self/MatMul_1" -> "636 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"636 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "637 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"637 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "638 bert/encoder/layer_0/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"638 bert/encoder/layer_0/attention/self/transpose_3" -> "639 bert/encoder/layer_0/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"639 bert/encoder/layer_0/attention/self/Reshape_3" -> "642 bert/encoder/layer_0/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"640 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "641 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"641 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "642 bert/encoder/layer_0/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"642 bert/encoder/layer_0/attention/output/dense/MatMul" -> "643 bert/encoder/layer_0/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"643 bert/encoder/layer_0/attention/output/dense/BiasAdd" -> "644 bert/encoder/layer_0/attention/output/add" [key=0, style=solid, label="[]"];
"644 bert/encoder/layer_0/attention/output/add" -> "645 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"644 bert/encoder/layer_0/attention/output/add" -> "647 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"644 bert/encoder/layer_0/attention/output/add" -> "656 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"645 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "646 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"645 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "654 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"646 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" -> "647 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"647 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" -> "648 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" [key=0, style=solid, label="[]"];
"647 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" -> "648 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" [key=1, style=solid, label="[]"];
"648 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" -> "649 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"649 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" -> "650 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"650 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" -> "651 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"651 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" -> "652 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" [key=0, style=solid, label="[]"];
"652 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" -> "653 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"653 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "654 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"653 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "656 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"654 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" -> "655 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"655 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" -> "657 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"656 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" -> "657 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"657 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "658 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"657 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "678 bert/encoder/layer_0/output/add" [key=0, style=solid, label="[]"];
"658 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "659 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"659 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "662 bert/encoder/layer_0/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"660 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "661 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"661 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "662 bert/encoder/layer_0/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"662 bert/encoder/layer_0/intermediate/dense/MatMul" -> "663 bert/encoder/layer_0/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"663 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "664 bert/encoder/layer_0/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"663 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "666 bert/encoder/layer_0/intermediate/dense/add" [key=0, style=solid, label="[]"];
"663 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "671 bert/encoder/layer_0/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"664 bert/encoder/layer_0/intermediate/dense/Pow" -> "665 bert/encoder/layer_0/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"665 bert/encoder/layer_0/intermediate/dense/mul" -> "666 bert/encoder/layer_0/intermediate/dense/add" [key=0, style=solid, label="[]"];
"666 bert/encoder/layer_0/intermediate/dense/add" -> "667 bert/encoder/layer_0/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"667 bert/encoder/layer_0/intermediate/dense/mul_1" -> "668 bert/encoder/layer_0/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"668 bert/encoder/layer_0/intermediate/dense/Tanh" -> "669 bert/encoder/layer_0/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"669 bert/encoder/layer_0/intermediate/dense/add_1" -> "670 bert/encoder/layer_0/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"670 bert/encoder/layer_0/intermediate/dense/mul_2" -> "671 bert/encoder/layer_0/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"671 bert/encoder/layer_0/intermediate/dense/mul_3" -> "672 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"672 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "673 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"673 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "676 bert/encoder/layer_0/output/dense/MatMul" [key=0, style=solid, label="[]"];
"674 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "675 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"675 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "676 bert/encoder/layer_0/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"676 bert/encoder/layer_0/output/dense/MatMul" -> "677 bert/encoder/layer_0/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"677 bert/encoder/layer_0/output/dense/BiasAdd" -> "678 bert/encoder/layer_0/output/add" [key=0, style=solid, label="[]"];
"678 bert/encoder/layer_0/output/add" -> "679 bert/encoder/layer_0/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"678 bert/encoder/layer_0/output/add" -> "681 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"678 bert/encoder/layer_0/output/add" -> "690 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"679 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "680 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"679 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "688 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"680 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" -> "681 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"681 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" -> "682 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" [key=0, style=solid, label="[]"];
"681 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" -> "682 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" [key=1, style=solid, label="[]"];
"682 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" -> "683 bert/encoder/layer_0/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"683 bert/encoder/layer_0/output/LayerNorm/moments/variance" -> "684 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"684 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" -> "685 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"685 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" -> "686 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" [key=0, style=solid, label="[]"];
"686 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" -> "687 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"687 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "688 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"687 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "690 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"688 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" -> "689 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"689 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" -> "691 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"690 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" -> "691 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"691 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "692 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"691 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "696 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"691 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "698 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"691 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "737 bert/encoder/layer_1/attention/output/add" [key=0, style=solid, label="[]"];
"692 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "693 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"693 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "700 bert/encoder/layer_1/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"694 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "695 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"695 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "700 bert/encoder/layer_1/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"696 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "697 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"697 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "706 bert/encoder/layer_1/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"698 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "699 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"699 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "714 bert/encoder/layer_1/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"700 bert/encoder/layer_1/attention/self/value/MatMul" -> "701 bert/encoder/layer_1/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"701 bert/encoder/layer_1/attention/self/value/BiasAdd" -> "702 bert/encoder/layer_1/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"702 bert/encoder/layer_1/attention/self/Reshape_2" -> "703 bert/encoder/layer_1/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"703 bert/encoder/layer_1/attention/self/transpose_2" -> "728 bert/encoder/layer_1/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"704 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "705 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"705 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "706 bert/encoder/layer_1/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"706 bert/encoder/layer_1/attention/self/query/MatMul" -> "707 bert/encoder/layer_1/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"707 bert/encoder/layer_1/attention/self/query/BiasAdd" -> "708 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"708 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "709 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"709 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "710 bert/encoder/layer_1/attention/self/Reshape" [key=0, style=solid, label="[]"];
"710 bert/encoder/layer_1/attention/self/Reshape" -> "711 bert/encoder/layer_1/attention/self/transpose" [key=0, style=solid, label="[]"];
"711 bert/encoder/layer_1/attention/self/transpose" -> "721 bert/encoder/layer_1/attention/self/MatMul" [key=0, style=solid, label="[]"];
"712 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "713 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"713 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "714 bert/encoder/layer_1/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"714 bert/encoder/layer_1/attention/self/key/MatMul" -> "715 bert/encoder/layer_1/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"715 bert/encoder/layer_1/attention/self/key/BiasAdd" -> "716 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"716 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "717 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"717 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "718 bert/encoder/layer_1/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"718 bert/encoder/layer_1/attention/self/Reshape_1" -> "719 bert/encoder/layer_1/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"719 bert/encoder/layer_1/attention/self/transpose_1" -> "720 bert/encoder/layer_1/attention/self/MatMul__320" [key=0, style=solid, label="[]"];
"720 bert/encoder/layer_1/attention/self/MatMul__320" -> "721 bert/encoder/layer_1/attention/self/MatMul" [key=0, style=solid, label="[]"];
"721 bert/encoder/layer_1/attention/self/MatMul" -> "722 bert/encoder/layer_1/attention/self/Mul" [key=0, style=solid, label="[]"];
"722 bert/encoder/layer_1/attention/self/Mul" -> "723 bert/encoder/layer_1/attention/self/add" [key=0, style=solid, label="[]"];
"723 bert/encoder/layer_1/attention/self/add" -> "724 Shape_nncf_674" [key=0, style=solid, label="[]"];
"723 bert/encoder/layer_1/attention/self/add" -> "725 Flatten_nncf_675" [key=0, style=solid, label="[]"];
"724 Shape_nncf_674" -> "727 Reshape_nncf_677" [key=0, style=dashed, label="[-1]"];
"725 Flatten_nncf_675" -> "726 bert/encoder/layer_1/attention/self/Softmax" [key=0, style=solid, label="[]"];
"726 bert/encoder/layer_1/attention/self/Softmax" -> "727 Reshape_nncf_677" [key=0, style=solid, label="[]"];
"727 Reshape_nncf_677" -> "728 bert/encoder/layer_1/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"728 bert/encoder/layer_1/attention/self/MatMul_1" -> "729 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"729 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "730 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"730 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "731 bert/encoder/layer_1/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"731 bert/encoder/layer_1/attention/self/transpose_3" -> "732 bert/encoder/layer_1/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"732 bert/encoder/layer_1/attention/self/Reshape_3" -> "735 bert/encoder/layer_1/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"733 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "734 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"734 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "735 bert/encoder/layer_1/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"735 bert/encoder/layer_1/attention/output/dense/MatMul" -> "736 bert/encoder/layer_1/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"736 bert/encoder/layer_1/attention/output/dense/BiasAdd" -> "737 bert/encoder/layer_1/attention/output/add" [key=0, style=solid, label="[]"];
"737 bert/encoder/layer_1/attention/output/add" -> "738 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"737 bert/encoder/layer_1/attention/output/add" -> "740 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"737 bert/encoder/layer_1/attention/output/add" -> "749 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"738 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "739 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"738 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "747 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"739 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" -> "740 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"740 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" -> "741 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" [key=0, style=solid, label="[]"];
"740 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" -> "741 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" [key=1, style=solid, label="[]"];
"741 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" -> "742 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"742 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" -> "743 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"743 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" -> "744 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"744 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" -> "745 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" [key=0, style=solid, label="[]"];
"745 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" -> "746 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"746 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "747 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"746 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "749 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"747 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" -> "748 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"748 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" -> "750 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"749 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" -> "750 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"750 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "751 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"750 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "771 bert/encoder/layer_1/output/add" [key=0, style=solid, label="[]"];
"751 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "752 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"752 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "755 bert/encoder/layer_1/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"753 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "754 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"754 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "755 bert/encoder/layer_1/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"755 bert/encoder/layer_1/intermediate/dense/MatMul" -> "756 bert/encoder/layer_1/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"756 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "757 bert/encoder/layer_1/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"756 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "759 bert/encoder/layer_1/intermediate/dense/add" [key=0, style=solid, label="[]"];
"756 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "764 bert/encoder/layer_1/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"757 bert/encoder/layer_1/intermediate/dense/Pow" -> "758 bert/encoder/layer_1/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"758 bert/encoder/layer_1/intermediate/dense/mul" -> "759 bert/encoder/layer_1/intermediate/dense/add" [key=0, style=solid, label="[]"];
"759 bert/encoder/layer_1/intermediate/dense/add" -> "760 bert/encoder/layer_1/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"760 bert/encoder/layer_1/intermediate/dense/mul_1" -> "761 bert/encoder/layer_1/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"761 bert/encoder/layer_1/intermediate/dense/Tanh" -> "762 bert/encoder/layer_1/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"762 bert/encoder/layer_1/intermediate/dense/add_1" -> "763 bert/encoder/layer_1/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"763 bert/encoder/layer_1/intermediate/dense/mul_2" -> "764 bert/encoder/layer_1/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"764 bert/encoder/layer_1/intermediate/dense/mul_3" -> "765 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"765 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "766 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"766 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "769 bert/encoder/layer_1/output/dense/MatMul" [key=0, style=solid, label="[]"];
"767 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "768 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"768 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "769 bert/encoder/layer_1/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"769 bert/encoder/layer_1/output/dense/MatMul" -> "770 bert/encoder/layer_1/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"770 bert/encoder/layer_1/output/dense/BiasAdd" -> "771 bert/encoder/layer_1/output/add" [key=0, style=solid, label="[]"];
"771 bert/encoder/layer_1/output/add" -> "772 bert/encoder/layer_1/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"771 bert/encoder/layer_1/output/add" -> "774 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"771 bert/encoder/layer_1/output/add" -> "783 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"772 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "773 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"772 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "781 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"773 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" -> "774 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"774 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" -> "775 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" [key=0, style=solid, label="[]"];
"774 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" -> "775 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" [key=1, style=solid, label="[]"];
"775 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" -> "776 bert/encoder/layer_1/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"776 bert/encoder/layer_1/output/LayerNorm/moments/variance" -> "777 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"777 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" -> "778 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"778 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" -> "779 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" [key=0, style=solid, label="[]"];
"779 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" -> "780 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"780 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "781 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"780 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "783 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"781 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" -> "782 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"782 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" -> "784 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"783 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" -> "784 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"784 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "785 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"784 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "789 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"784 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "791 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"784 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "830 bert/encoder/layer_2/attention/output/add" [key=0, style=solid, label="[]"];
"785 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "786 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"786 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "793 bert/encoder/layer_2/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"787 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "788 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"788 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "793 bert/encoder/layer_2/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"789 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "790 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"790 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "799 bert/encoder/layer_2/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"791 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "792 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"792 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "807 bert/encoder/layer_2/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"793 bert/encoder/layer_2/attention/self/value/MatMul" -> "794 bert/encoder/layer_2/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"794 bert/encoder/layer_2/attention/self/value/BiasAdd" -> "795 bert/encoder/layer_2/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"795 bert/encoder/layer_2/attention/self/Reshape_2" -> "796 bert/encoder/layer_2/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"796 bert/encoder/layer_2/attention/self/transpose_2" -> "821 bert/encoder/layer_2/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"797 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "798 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"798 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "799 bert/encoder/layer_2/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"799 bert/encoder/layer_2/attention/self/query/MatMul" -> "800 bert/encoder/layer_2/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"800 bert/encoder/layer_2/attention/self/query/BiasAdd" -> "801 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"801 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "802 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"802 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "803 bert/encoder/layer_2/attention/self/Reshape" [key=0, style=solid, label="[]"];
"803 bert/encoder/layer_2/attention/self/Reshape" -> "804 bert/encoder/layer_2/attention/self/transpose" [key=0, style=solid, label="[]"];
"804 bert/encoder/layer_2/attention/self/transpose" -> "814 bert/encoder/layer_2/attention/self/MatMul" [key=0, style=solid, label="[]"];
"805 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "806 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"806 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "807 bert/encoder/layer_2/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"807 bert/encoder/layer_2/attention/self/key/MatMul" -> "808 bert/encoder/layer_2/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"808 bert/encoder/layer_2/attention/self/key/BiasAdd" -> "809 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"809 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "810 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"810 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "811 bert/encoder/layer_2/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"811 bert/encoder/layer_2/attention/self/Reshape_1" -> "812 bert/encoder/layer_2/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"812 bert/encoder/layer_2/attention/self/transpose_1" -> "813 bert/encoder/layer_2/attention/self/MatMul__334" [key=0, style=solid, label="[]"];
"813 bert/encoder/layer_2/attention/self/MatMul__334" -> "814 bert/encoder/layer_2/attention/self/MatMul" [key=0, style=solid, label="[]"];
"814 bert/encoder/layer_2/attention/self/MatMul" -> "815 bert/encoder/layer_2/attention/self/Mul" [key=0, style=solid, label="[]"];
"815 bert/encoder/layer_2/attention/self/Mul" -> "816 bert/encoder/layer_2/attention/self/add" [key=0, style=solid, label="[]"];
"816 bert/encoder/layer_2/attention/self/add" -> "817 Shape_nncf_739" [key=0, style=solid, label="[]"];
"816 bert/encoder/layer_2/attention/self/add" -> "818 Flatten_nncf_740" [key=0, style=solid, label="[]"];
"817 Shape_nncf_739" -> "820 Reshape_nncf_742" [key=0, style=dashed, label="[-1]"];
"818 Flatten_nncf_740" -> "819 bert/encoder/layer_2/attention/self/Softmax" [key=0, style=solid, label="[]"];
"819 bert/encoder/layer_2/attention/self/Softmax" -> "820 Reshape_nncf_742" [key=0, style=solid, label="[]"];
"820 Reshape_nncf_742" -> "821 bert/encoder/layer_2/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"821 bert/encoder/layer_2/attention/self/MatMul_1" -> "822 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"822 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "823 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"823 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "824 bert/encoder/layer_2/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"824 bert/encoder/layer_2/attention/self/transpose_3" -> "825 bert/encoder/layer_2/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"825 bert/encoder/layer_2/attention/self/Reshape_3" -> "828 bert/encoder/layer_2/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"826 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "827 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"827 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "828 bert/encoder/layer_2/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"828 bert/encoder/layer_2/attention/output/dense/MatMul" -> "829 bert/encoder/layer_2/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"829 bert/encoder/layer_2/attention/output/dense/BiasAdd" -> "830 bert/encoder/layer_2/attention/output/add" [key=0, style=solid, label="[]"];
"830 bert/encoder/layer_2/attention/output/add" -> "831 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"830 bert/encoder/layer_2/attention/output/add" -> "833 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"830 bert/encoder/layer_2/attention/output/add" -> "842 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"831 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "832 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"831 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "840 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"832 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" -> "833 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"833 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" -> "834 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" [key=0, style=solid, label="[]"];
"833 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" -> "834 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" [key=1, style=solid, label="[]"];
"834 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" -> "835 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"835 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" -> "836 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"836 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" -> "837 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"837 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" -> "838 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" [key=0, style=solid, label="[]"];
"838 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" -> "839 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"839 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "840 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"839 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "842 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"840 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" -> "841 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"841 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" -> "843 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"842 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" -> "843 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"843 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "844 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"843 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "864 bert/encoder/layer_2/output/add" [key=0, style=solid, label="[]"];
"844 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "845 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"845 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "848 bert/encoder/layer_2/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"846 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "847 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"847 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "848 bert/encoder/layer_2/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"848 bert/encoder/layer_2/intermediate/dense/MatMul" -> "849 bert/encoder/layer_2/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"849 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "850 bert/encoder/layer_2/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"849 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "852 bert/encoder/layer_2/intermediate/dense/add" [key=0, style=solid, label="[]"];
"849 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "857 bert/encoder/layer_2/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"850 bert/encoder/layer_2/intermediate/dense/Pow" -> "851 bert/encoder/layer_2/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"851 bert/encoder/layer_2/intermediate/dense/mul" -> "852 bert/encoder/layer_2/intermediate/dense/add" [key=0, style=solid, label="[]"];
"852 bert/encoder/layer_2/intermediate/dense/add" -> "853 bert/encoder/layer_2/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"853 bert/encoder/layer_2/intermediate/dense/mul_1" -> "854 bert/encoder/layer_2/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"854 bert/encoder/layer_2/intermediate/dense/Tanh" -> "855 bert/encoder/layer_2/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"855 bert/encoder/layer_2/intermediate/dense/add_1" -> "856 bert/encoder/layer_2/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"856 bert/encoder/layer_2/intermediate/dense/mul_2" -> "857 bert/encoder/layer_2/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"857 bert/encoder/layer_2/intermediate/dense/mul_3" -> "858 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"858 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "859 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"859 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "862 bert/encoder/layer_2/output/dense/MatMul" [key=0, style=solid, label="[]"];
"860 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "861 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"861 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "862 bert/encoder/layer_2/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"862 bert/encoder/layer_2/output/dense/MatMul" -> "863 bert/encoder/layer_2/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"863 bert/encoder/layer_2/output/dense/BiasAdd" -> "864 bert/encoder/layer_2/output/add" [key=0, style=solid, label="[]"];
"864 bert/encoder/layer_2/output/add" -> "865 bert/encoder/layer_2/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"864 bert/encoder/layer_2/output/add" -> "867 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"864 bert/encoder/layer_2/output/add" -> "876 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"865 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "866 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"865 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "874 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"866 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" -> "867 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"867 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" -> "868 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" [key=0, style=solid, label="[]"];
"867 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" -> "868 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" [key=1, style=solid, label="[]"];
"868 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" -> "869 bert/encoder/layer_2/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"869 bert/encoder/layer_2/output/LayerNorm/moments/variance" -> "870 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"870 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" -> "871 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"871 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" -> "872 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" [key=0, style=solid, label="[]"];
"872 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" -> "873 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"873 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "874 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"873 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "876 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"874 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" -> "875 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"875 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" -> "877 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"876 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" -> "877 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"877 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "878 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"877 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "882 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"877 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "884 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"877 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "923 bert/encoder/layer_3/attention/output/add" [key=0, style=solid, label="[]"];
"878 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "879 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"879 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "886 bert/encoder/layer_3/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"880 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "881 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"881 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "886 bert/encoder/layer_3/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"882 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "883 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"883 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "892 bert/encoder/layer_3/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"884 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "885 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"885 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "900 bert/encoder/layer_3/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"886 bert/encoder/layer_3/attention/self/value/MatMul" -> "887 bert/encoder/layer_3/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"887 bert/encoder/layer_3/attention/self/value/BiasAdd" -> "888 bert/encoder/layer_3/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"888 bert/encoder/layer_3/attention/self/Reshape_2" -> "889 bert/encoder/layer_3/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"889 bert/encoder/layer_3/attention/self/transpose_2" -> "914 bert/encoder/layer_3/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"890 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "891 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"891 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "892 bert/encoder/layer_3/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"892 bert/encoder/layer_3/attention/self/query/MatMul" -> "893 bert/encoder/layer_3/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"893 bert/encoder/layer_3/attention/self/query/BiasAdd" -> "894 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"894 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "895 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"895 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "896 bert/encoder/layer_3/attention/self/Reshape" [key=0, style=solid, label="[]"];
"896 bert/encoder/layer_3/attention/self/Reshape" -> "897 bert/encoder/layer_3/attention/self/transpose" [key=0, style=solid, label="[]"];
"897 bert/encoder/layer_3/attention/self/transpose" -> "907 bert/encoder/layer_3/attention/self/MatMul" [key=0, style=solid, label="[]"];
"898 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "899 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"899 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "900 bert/encoder/layer_3/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"900 bert/encoder/layer_3/attention/self/key/MatMul" -> "901 bert/encoder/layer_3/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"901 bert/encoder/layer_3/attention/self/key/BiasAdd" -> "902 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"902 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "903 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"903 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "904 bert/encoder/layer_3/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"904 bert/encoder/layer_3/attention/self/Reshape_1" -> "905 bert/encoder/layer_3/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"905 bert/encoder/layer_3/attention/self/transpose_1" -> "906 bert/encoder/layer_3/attention/self/MatMul__348" [key=0, style=solid, label="[]"];
"906 bert/encoder/layer_3/attention/self/MatMul__348" -> "907 bert/encoder/layer_3/attention/self/MatMul" [key=0, style=solid, label="[]"];
"907 bert/encoder/layer_3/attention/self/MatMul" -> "908 bert/encoder/layer_3/attention/self/Mul" [key=0, style=solid, label="[]"];
"908 bert/encoder/layer_3/attention/self/Mul" -> "909 bert/encoder/layer_3/attention/self/add" [key=0, style=solid, label="[]"];
"909 bert/encoder/layer_3/attention/self/add" -> "910 Shape_nncf_804" [key=0, style=solid, label="[]"];
"909 bert/encoder/layer_3/attention/self/add" -> "911 Flatten_nncf_805" [key=0, style=solid, label="[]"];
"910 Shape_nncf_804" -> "913 Reshape_nncf_807" [key=0, style=dashed, label="[-1]"];
"911 Flatten_nncf_805" -> "912 bert/encoder/layer_3/attention/self/Softmax" [key=0, style=solid, label="[]"];
"912 bert/encoder/layer_3/attention/self/Softmax" -> "913 Reshape_nncf_807" [key=0, style=solid, label="[]"];
"913 Reshape_nncf_807" -> "914 bert/encoder/layer_3/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"914 bert/encoder/layer_3/attention/self/MatMul_1" -> "915 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"915 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "916 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"916 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "917 bert/encoder/layer_3/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"917 bert/encoder/layer_3/attention/self/transpose_3" -> "918 bert/encoder/layer_3/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"918 bert/encoder/layer_3/attention/self/Reshape_3" -> "921 bert/encoder/layer_3/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"919 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "920 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"920 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "921 bert/encoder/layer_3/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"921 bert/encoder/layer_3/attention/output/dense/MatMul" -> "922 bert/encoder/layer_3/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"922 bert/encoder/layer_3/attention/output/dense/BiasAdd" -> "923 bert/encoder/layer_3/attention/output/add" [key=0, style=solid, label="[]"];
"923 bert/encoder/layer_3/attention/output/add" -> "924 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"923 bert/encoder/layer_3/attention/output/add" -> "926 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"923 bert/encoder/layer_3/attention/output/add" -> "935 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"924 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "925 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"924 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "933 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"925 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" -> "926 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"926 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" -> "927 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" [key=0, style=solid, label="[]"];
"926 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" -> "927 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" [key=1, style=solid, label="[]"];
"927 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" -> "928 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"928 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" -> "929 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"929 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" -> "930 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"930 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" -> "931 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" [key=0, style=solid, label="[]"];
"931 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" -> "932 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"932 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "933 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"932 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "935 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"933 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" -> "934 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"934 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" -> "936 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"935 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" -> "936 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"936 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "937 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"936 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "957 bert/encoder/layer_3/output/add" [key=0, style=solid, label="[]"];
"937 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "938 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"938 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "941 bert/encoder/layer_3/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"939 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "940 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"940 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "941 bert/encoder/layer_3/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"941 bert/encoder/layer_3/intermediate/dense/MatMul" -> "942 bert/encoder/layer_3/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"942 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "943 bert/encoder/layer_3/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"942 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "945 bert/encoder/layer_3/intermediate/dense/add" [key=0, style=solid, label="[]"];
"942 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "950 bert/encoder/layer_3/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"943 bert/encoder/layer_3/intermediate/dense/Pow" -> "944 bert/encoder/layer_3/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"944 bert/encoder/layer_3/intermediate/dense/mul" -> "945 bert/encoder/layer_3/intermediate/dense/add" [key=0, style=solid, label="[]"];
"945 bert/encoder/layer_3/intermediate/dense/add" -> "946 bert/encoder/layer_3/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"946 bert/encoder/layer_3/intermediate/dense/mul_1" -> "947 bert/encoder/layer_3/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"947 bert/encoder/layer_3/intermediate/dense/Tanh" -> "948 bert/encoder/layer_3/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"948 bert/encoder/layer_3/intermediate/dense/add_1" -> "949 bert/encoder/layer_3/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"949 bert/encoder/layer_3/intermediate/dense/mul_2" -> "950 bert/encoder/layer_3/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"950 bert/encoder/layer_3/intermediate/dense/mul_3" -> "951 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"951 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "952 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"952 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "955 bert/encoder/layer_3/output/dense/MatMul" [key=0, style=solid, label="[]"];
"953 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "954 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"954 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "955 bert/encoder/layer_3/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"955 bert/encoder/layer_3/output/dense/MatMul" -> "956 bert/encoder/layer_3/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"956 bert/encoder/layer_3/output/dense/BiasAdd" -> "957 bert/encoder/layer_3/output/add" [key=0, style=solid, label="[]"];
"957 bert/encoder/layer_3/output/add" -> "958 bert/encoder/layer_3/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"957 bert/encoder/layer_3/output/add" -> "960 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"957 bert/encoder/layer_3/output/add" -> "969 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"958 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "959 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"958 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "967 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"959 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" -> "960 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"960 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" -> "961 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" [key=0, style=solid, label="[]"];
"960 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" -> "961 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" [key=1, style=solid, label="[]"];
"961 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" -> "962 bert/encoder/layer_3/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"962 bert/encoder/layer_3/output/LayerNorm/moments/variance" -> "963 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"963 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" -> "964 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"964 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" -> "965 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" [key=0, style=solid, label="[]"];
"965 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" -> "966 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"966 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "967 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"966 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "969 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"967 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" -> "968 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"968 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" -> "970 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"969 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" -> "970 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"970 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "971 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"970 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "975 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"970 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "977 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"970 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "1016 bert/encoder/layer_4/attention/output/add" [key=0, style=solid, label="[]"];
"971 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "972 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"972 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "979 bert/encoder/layer_4/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"973 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "974 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"974 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "979 bert/encoder/layer_4/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"975 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "976 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"976 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "985 bert/encoder/layer_4/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"977 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "978 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"978 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "993 bert/encoder/layer_4/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"979 bert/encoder/layer_4/attention/self/value/MatMul" -> "980 bert/encoder/layer_4/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"980 bert/encoder/layer_4/attention/self/value/BiasAdd" -> "981 bert/encoder/layer_4/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"981 bert/encoder/layer_4/attention/self/Reshape_2" -> "982 bert/encoder/layer_4/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"982 bert/encoder/layer_4/attention/self/transpose_2" -> "1007 bert/encoder/layer_4/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"983 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "984 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"984 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "985 bert/encoder/layer_4/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"985 bert/encoder/layer_4/attention/self/query/MatMul" -> "986 bert/encoder/layer_4/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"986 bert/encoder/layer_4/attention/self/query/BiasAdd" -> "987 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"987 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "988 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"988 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "989 bert/encoder/layer_4/attention/self/Reshape" [key=0, style=solid, label="[]"];
"989 bert/encoder/layer_4/attention/self/Reshape" -> "990 bert/encoder/layer_4/attention/self/transpose" [key=0, style=solid, label="[]"];
"990 bert/encoder/layer_4/attention/self/transpose" -> "1000 bert/encoder/layer_4/attention/self/MatMul" [key=0, style=solid, label="[]"];
"991 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "992 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"992 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "993 bert/encoder/layer_4/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"993 bert/encoder/layer_4/attention/self/key/MatMul" -> "994 bert/encoder/layer_4/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"994 bert/encoder/layer_4/attention/self/key/BiasAdd" -> "995 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"995 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "996 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"996 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "997 bert/encoder/layer_4/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"997 bert/encoder/layer_4/attention/self/Reshape_1" -> "998 bert/encoder/layer_4/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"998 bert/encoder/layer_4/attention/self/transpose_1" -> "999 bert/encoder/layer_4/attention/self/MatMul__362" [key=0, style=solid, label="[]"];
"999 bert/encoder/layer_4/attention/self/MatMul__362" -> "1000 bert/encoder/layer_4/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1000 bert/encoder/layer_4/attention/self/MatMul" -> "1001 bert/encoder/layer_4/attention/self/Mul" [key=0, style=solid, label="[]"];
"1001 bert/encoder/layer_4/attention/self/Mul" -> "1002 bert/encoder/layer_4/attention/self/add" [key=0, style=solid, label="[]"];
"1002 bert/encoder/layer_4/attention/self/add" -> "1003 Shape_nncf_869" [key=0, style=solid, label="[]"];
"1002 bert/encoder/layer_4/attention/self/add" -> "1004 Flatten_nncf_870" [key=0, style=solid, label="[]"];
"1003 Shape_nncf_869" -> "1006 Reshape_nncf_872" [key=0, style=dashed, label="[-1]"];
"1004 Flatten_nncf_870" -> "1005 bert/encoder/layer_4/attention/self/Softmax" [key=0, style=solid, label="[]"];
"1005 bert/encoder/layer_4/attention/self/Softmax" -> "1006 Reshape_nncf_872" [key=0, style=solid, label="[]"];
"1006 Reshape_nncf_872" -> "1007 bert/encoder/layer_4/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1007 bert/encoder/layer_4/attention/self/MatMul_1" -> "1008 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"1008 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "1009 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"1009 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "1010 bert/encoder/layer_4/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"1010 bert/encoder/layer_4/attention/self/transpose_3" -> "1011 bert/encoder/layer_4/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"1011 bert/encoder/layer_4/attention/self/Reshape_3" -> "1014 bert/encoder/layer_4/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1012 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "1013 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1013 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "1014 bert/encoder/layer_4/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"1014 bert/encoder/layer_4/attention/output/dense/MatMul" -> "1015 bert/encoder/layer_4/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1015 bert/encoder/layer_4/attention/output/dense/BiasAdd" -> "1016 bert/encoder/layer_4/attention/output/add" [key=0, style=solid, label="[]"];
"1016 bert/encoder/layer_4/attention/output/add" -> "1017 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1016 bert/encoder/layer_4/attention/output/add" -> "1019 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1016 bert/encoder/layer_4/attention/output/add" -> "1028 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1017 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "1018 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1017 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "1026 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1018 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" -> "1019 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1019 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" -> "1020 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" [key=0, style=solid, label="[]"];
"1019 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" -> "1020 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" [key=1, style=solid, label="[]"];
"1020 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" -> "1021 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1021 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" -> "1022 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1022 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" -> "1023 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1023 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1024 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" [key=0, style=solid, label="[]"];
"1024 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" -> "1025 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1025 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "1026 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1025 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "1028 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1026 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" -> "1027 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1027 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" -> "1029 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1028 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" -> "1029 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1029 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "1030 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1029 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "1050 bert/encoder/layer_4/output/add" [key=0, style=solid, label="[]"];
"1030 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1031 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1031 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1034 bert/encoder/layer_4/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"1032 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "1033 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"1033 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "1034 bert/encoder/layer_4/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"1034 bert/encoder/layer_4/intermediate/dense/MatMul" -> "1035 bert/encoder/layer_4/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1035 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "1036 bert/encoder/layer_4/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"1035 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "1038 bert/encoder/layer_4/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1035 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "1043 bert/encoder/layer_4/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1036 bert/encoder/layer_4/intermediate/dense/Pow" -> "1037 bert/encoder/layer_4/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"1037 bert/encoder/layer_4/intermediate/dense/mul" -> "1038 bert/encoder/layer_4/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1038 bert/encoder/layer_4/intermediate/dense/add" -> "1039 bert/encoder/layer_4/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"1039 bert/encoder/layer_4/intermediate/dense/mul_1" -> "1040 bert/encoder/layer_4/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"1040 bert/encoder/layer_4/intermediate/dense/Tanh" -> "1041 bert/encoder/layer_4/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"1041 bert/encoder/layer_4/intermediate/dense/add_1" -> "1042 bert/encoder/layer_4/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"1042 bert/encoder/layer_4/intermediate/dense/mul_2" -> "1043 bert/encoder/layer_4/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1043 bert/encoder/layer_4/intermediate/dense/mul_3" -> "1044 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"1044 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "1045 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"1045 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "1048 bert/encoder/layer_4/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1046 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "1047 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"1047 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "1048 bert/encoder/layer_4/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"1048 bert/encoder/layer_4/output/dense/MatMul" -> "1049 bert/encoder/layer_4/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1049 bert/encoder/layer_4/output/dense/BiasAdd" -> "1050 bert/encoder/layer_4/output/add" [key=0, style=solid, label="[]"];
"1050 bert/encoder/layer_4/output/add" -> "1051 bert/encoder/layer_4/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1050 bert/encoder/layer_4/output/add" -> "1053 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1050 bert/encoder/layer_4/output/add" -> "1062 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1051 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "1052 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1051 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "1060 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1052 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" -> "1053 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1053 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" -> "1054 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" [key=0, style=solid, label="[]"];
"1053 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" -> "1054 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" [key=1, style=solid, label="[]"];
"1054 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" -> "1055 bert/encoder/layer_4/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1055 bert/encoder/layer_4/output/LayerNorm/moments/variance" -> "1056 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1056 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" -> "1057 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1057 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" -> "1058 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" [key=0, style=solid, label="[]"];
"1058 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" -> "1059 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1059 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "1060 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1059 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "1062 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1060 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" -> "1061 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1061 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" -> "1063 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1062 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" -> "1063 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1063 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "1064 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1063 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "1068 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"1063 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "1070 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"1063 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "1109 bert/encoder/layer_5/attention/output/add" [key=0, style=solid, label="[]"];
"1064 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "1065 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1065 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "1072 bert/encoder/layer_5/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"1066 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "1067 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1067 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "1072 bert/encoder/layer_5/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"1068 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "1069 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"1069 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "1078 bert/encoder/layer_5/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"1070 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "1071 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"1071 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "1086 bert/encoder/layer_5/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"1072 bert/encoder/layer_5/attention/self/value/MatMul" -> "1073 bert/encoder/layer_5/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"1073 bert/encoder/layer_5/attention/self/value/BiasAdd" -> "1074 bert/encoder/layer_5/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"1074 bert/encoder/layer_5/attention/self/Reshape_2" -> "1075 bert/encoder/layer_5/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"1075 bert/encoder/layer_5/attention/self/transpose_2" -> "1100 bert/encoder/layer_5/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1076 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "1077 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1077 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "1078 bert/encoder/layer_5/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"1078 bert/encoder/layer_5/attention/self/query/MatMul" -> "1079 bert/encoder/layer_5/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"1079 bert/encoder/layer_5/attention/self/query/BiasAdd" -> "1080 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1080 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "1081 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1081 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "1082 bert/encoder/layer_5/attention/self/Reshape" [key=0, style=solid, label="[]"];
"1082 bert/encoder/layer_5/attention/self/Reshape" -> "1083 bert/encoder/layer_5/attention/self/transpose" [key=0, style=solid, label="[]"];
"1083 bert/encoder/layer_5/attention/self/transpose" -> "1093 bert/encoder/layer_5/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1084 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "1085 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1085 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "1086 bert/encoder/layer_5/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"1086 bert/encoder/layer_5/attention/self/key/MatMul" -> "1087 bert/encoder/layer_5/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"1087 bert/encoder/layer_5/attention/self/key/BiasAdd" -> "1088 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1088 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "1089 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1089 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "1090 bert/encoder/layer_5/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"1090 bert/encoder/layer_5/attention/self/Reshape_1" -> "1091 bert/encoder/layer_5/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"1091 bert/encoder/layer_5/attention/self/transpose_1" -> "1092 bert/encoder/layer_5/attention/self/MatMul__376" [key=0, style=solid, label="[]"];
"1092 bert/encoder/layer_5/attention/self/MatMul__376" -> "1093 bert/encoder/layer_5/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1093 bert/encoder/layer_5/attention/self/MatMul" -> "1094 bert/encoder/layer_5/attention/self/Mul" [key=0, style=solid, label="[]"];
"1094 bert/encoder/layer_5/attention/self/Mul" -> "1095 bert/encoder/layer_5/attention/self/add" [key=0, style=solid, label="[]"];
"1095 bert/encoder/layer_5/attention/self/add" -> "1096 Shape_nncf_934" [key=0, style=solid, label="[]"];
"1095 bert/encoder/layer_5/attention/self/add" -> "1097 Flatten_nncf_935" [key=0, style=solid, label="[]"];
"1096 Shape_nncf_934" -> "1099 Reshape_nncf_937" [key=0, style=dashed, label="[-1]"];
"1097 Flatten_nncf_935" -> "1098 bert/encoder/layer_5/attention/self/Softmax" [key=0, style=solid, label="[]"];
"1098 bert/encoder/layer_5/attention/self/Softmax" -> "1099 Reshape_nncf_937" [key=0, style=solid, label="[]"];
"1099 Reshape_nncf_937" -> "1100 bert/encoder/layer_5/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1100 bert/encoder/layer_5/attention/self/MatMul_1" -> "1101 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"1101 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "1102 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"1102 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "1103 bert/encoder/layer_5/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"1103 bert/encoder/layer_5/attention/self/transpose_3" -> "1104 bert/encoder/layer_5/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"1104 bert/encoder/layer_5/attention/self/Reshape_3" -> "1107 bert/encoder/layer_5/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1105 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "1106 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1106 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "1107 bert/encoder/layer_5/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"1107 bert/encoder/layer_5/attention/output/dense/MatMul" -> "1108 bert/encoder/layer_5/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1108 bert/encoder/layer_5/attention/output/dense/BiasAdd" -> "1109 bert/encoder/layer_5/attention/output/add" [key=0, style=solid, label="[]"];
"1109 bert/encoder/layer_5/attention/output/add" -> "1110 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1109 bert/encoder/layer_5/attention/output/add" -> "1112 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1109 bert/encoder/layer_5/attention/output/add" -> "1121 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1110 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "1111 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1110 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "1119 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1111 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" -> "1112 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1112 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" -> "1113 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" [key=0, style=solid, label="[]"];
"1112 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" -> "1113 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" [key=1, style=solid, label="[]"];
"1113 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" -> "1114 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1114 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" -> "1115 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1115 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" -> "1116 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1116 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1117 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" [key=0, style=solid, label="[]"];
"1117 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" -> "1118 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1118 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "1119 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1118 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "1121 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1119 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" -> "1120 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1120 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" -> "1122 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1121 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" -> "1122 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1122 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "1123 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1122 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "1143 bert/encoder/layer_5/output/add" [key=0, style=solid, label="[]"];
"1123 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1124 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1124 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1127 bert/encoder/layer_5/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"1125 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "1126 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"1126 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "1127 bert/encoder/layer_5/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"1127 bert/encoder/layer_5/intermediate/dense/MatMul" -> "1128 bert/encoder/layer_5/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1128 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "1129 bert/encoder/layer_5/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"1128 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "1131 bert/encoder/layer_5/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1128 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "1136 bert/encoder/layer_5/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1129 bert/encoder/layer_5/intermediate/dense/Pow" -> "1130 bert/encoder/layer_5/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"1130 bert/encoder/layer_5/intermediate/dense/mul" -> "1131 bert/encoder/layer_5/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1131 bert/encoder/layer_5/intermediate/dense/add" -> "1132 bert/encoder/layer_5/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"1132 bert/encoder/layer_5/intermediate/dense/mul_1" -> "1133 bert/encoder/layer_5/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"1133 bert/encoder/layer_5/intermediate/dense/Tanh" -> "1134 bert/encoder/layer_5/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"1134 bert/encoder/layer_5/intermediate/dense/add_1" -> "1135 bert/encoder/layer_5/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"1135 bert/encoder/layer_5/intermediate/dense/mul_2" -> "1136 bert/encoder/layer_5/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1136 bert/encoder/layer_5/intermediate/dense/mul_3" -> "1137 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"1137 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "1138 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"1138 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "1141 bert/encoder/layer_5/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1139 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "1140 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"1140 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "1141 bert/encoder/layer_5/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"1141 bert/encoder/layer_5/output/dense/MatMul" -> "1142 bert/encoder/layer_5/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1142 bert/encoder/layer_5/output/dense/BiasAdd" -> "1143 bert/encoder/layer_5/output/add" [key=0, style=solid, label="[]"];
"1143 bert/encoder/layer_5/output/add" -> "1144 bert/encoder/layer_5/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1143 bert/encoder/layer_5/output/add" -> "1146 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1143 bert/encoder/layer_5/output/add" -> "1155 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1144 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "1145 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1144 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "1153 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1145 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" -> "1146 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1146 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" -> "1147 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" [key=0, style=solid, label="[]"];
"1146 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" -> "1147 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" [key=1, style=solid, label="[]"];
"1147 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" -> "1148 bert/encoder/layer_5/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1148 bert/encoder/layer_5/output/LayerNorm/moments/variance" -> "1149 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1149 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" -> "1150 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1150 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" -> "1151 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" [key=0, style=solid, label="[]"];
"1151 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" -> "1152 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1152 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "1153 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1152 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "1155 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1153 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" -> "1154 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1154 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" -> "1156 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1155 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" -> "1156 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1156 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "1157 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1156 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "1161 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"1156 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "1163 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"1156 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "1202 bert/encoder/layer_6/attention/output/add" [key=0, style=solid, label="[]"];
"1157 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "1158 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1158 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "1165 bert/encoder/layer_6/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"1159 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "1160 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1160 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "1165 bert/encoder/layer_6/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"1161 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "1162 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"1162 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "1171 bert/encoder/layer_6/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"1163 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "1164 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"1164 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "1179 bert/encoder/layer_6/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"1165 bert/encoder/layer_6/attention/self/value/MatMul" -> "1166 bert/encoder/layer_6/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"1166 bert/encoder/layer_6/attention/self/value/BiasAdd" -> "1167 bert/encoder/layer_6/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"1167 bert/encoder/layer_6/attention/self/Reshape_2" -> "1168 bert/encoder/layer_6/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"1168 bert/encoder/layer_6/attention/self/transpose_2" -> "1193 bert/encoder/layer_6/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1169 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "1170 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1170 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "1171 bert/encoder/layer_6/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"1171 bert/encoder/layer_6/attention/self/query/MatMul" -> "1172 bert/encoder/layer_6/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"1172 bert/encoder/layer_6/attention/self/query/BiasAdd" -> "1173 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1173 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "1174 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1174 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "1175 bert/encoder/layer_6/attention/self/Reshape" [key=0, style=solid, label="[]"];
"1175 bert/encoder/layer_6/attention/self/Reshape" -> "1176 bert/encoder/layer_6/attention/self/transpose" [key=0, style=solid, label="[]"];
"1176 bert/encoder/layer_6/attention/self/transpose" -> "1186 bert/encoder/layer_6/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1177 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "1178 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1178 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "1179 bert/encoder/layer_6/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"1179 bert/encoder/layer_6/attention/self/key/MatMul" -> "1180 bert/encoder/layer_6/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"1180 bert/encoder/layer_6/attention/self/key/BiasAdd" -> "1181 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1181 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "1182 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1182 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "1183 bert/encoder/layer_6/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"1183 bert/encoder/layer_6/attention/self/Reshape_1" -> "1184 bert/encoder/layer_6/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"1184 bert/encoder/layer_6/attention/self/transpose_1" -> "1185 bert/encoder/layer_6/attention/self/MatMul__390" [key=0, style=solid, label="[]"];
"1185 bert/encoder/layer_6/attention/self/MatMul__390" -> "1186 bert/encoder/layer_6/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1186 bert/encoder/layer_6/attention/self/MatMul" -> "1187 bert/encoder/layer_6/attention/self/Mul" [key=0, style=solid, label="[]"];
"1187 bert/encoder/layer_6/attention/self/Mul" -> "1188 bert/encoder/layer_6/attention/self/add" [key=0, style=solid, label="[]"];
"1188 bert/encoder/layer_6/attention/self/add" -> "1189 Shape_nncf_999" [key=0, style=solid, label="[]"];
"1188 bert/encoder/layer_6/attention/self/add" -> "1190 Flatten_nncf_1000" [key=0, style=solid, label="[]"];
"1189 Shape_nncf_999" -> "1192 Reshape_nncf_1002" [key=0, style=dashed, label="[-1]"];
"1190 Flatten_nncf_1000" -> "1191 bert/encoder/layer_6/attention/self/Softmax" [key=0, style=solid, label="[]"];
"1191 bert/encoder/layer_6/attention/self/Softmax" -> "1192 Reshape_nncf_1002" [key=0, style=solid, label="[]"];
"1192 Reshape_nncf_1002" -> "1193 bert/encoder/layer_6/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1193 bert/encoder/layer_6/attention/self/MatMul_1" -> "1194 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"1194 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "1195 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"1195 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "1196 bert/encoder/layer_6/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"1196 bert/encoder/layer_6/attention/self/transpose_3" -> "1197 bert/encoder/layer_6/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"1197 bert/encoder/layer_6/attention/self/Reshape_3" -> "1200 bert/encoder/layer_6/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1198 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "1199 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1199 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "1200 bert/encoder/layer_6/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"1200 bert/encoder/layer_6/attention/output/dense/MatMul" -> "1201 bert/encoder/layer_6/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1201 bert/encoder/layer_6/attention/output/dense/BiasAdd" -> "1202 bert/encoder/layer_6/attention/output/add" [key=0, style=solid, label="[]"];
"1202 bert/encoder/layer_6/attention/output/add" -> "1203 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1202 bert/encoder/layer_6/attention/output/add" -> "1205 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1202 bert/encoder/layer_6/attention/output/add" -> "1214 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1203 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "1204 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1203 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "1212 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1204 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" -> "1205 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1205 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" -> "1206 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" [key=0, style=solid, label="[]"];
"1205 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" -> "1206 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" [key=1, style=solid, label="[]"];
"1206 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" -> "1207 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1207 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" -> "1208 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1208 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" -> "1209 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1209 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1210 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" [key=0, style=solid, label="[]"];
"1210 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" -> "1211 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1211 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "1212 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1211 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "1214 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1212 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" -> "1213 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1213 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" -> "1215 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1214 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" -> "1215 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1215 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1216 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1215 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1236 bert/encoder/layer_6/output/add" [key=0, style=solid, label="[]"];
"1216 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1217 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1217 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1220 bert/encoder/layer_6/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"1218 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1219 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"1219 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1220 bert/encoder/layer_6/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"1220 bert/encoder/layer_6/intermediate/dense/MatMul" -> "1221 bert/encoder/layer_6/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1221 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1222 bert/encoder/layer_6/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"1221 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1224 bert/encoder/layer_6/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1221 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1229 bert/encoder/layer_6/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1222 bert/encoder/layer_6/intermediate/dense/Pow" -> "1223 bert/encoder/layer_6/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"1223 bert/encoder/layer_6/intermediate/dense/mul" -> "1224 bert/encoder/layer_6/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1224 bert/encoder/layer_6/intermediate/dense/add" -> "1225 bert/encoder/layer_6/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"1225 bert/encoder/layer_6/intermediate/dense/mul_1" -> "1226 bert/encoder/layer_6/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"1226 bert/encoder/layer_6/intermediate/dense/Tanh" -> "1227 bert/encoder/layer_6/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"1227 bert/encoder/layer_6/intermediate/dense/add_1" -> "1228 bert/encoder/layer_6/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"1228 bert/encoder/layer_6/intermediate/dense/mul_2" -> "1229 bert/encoder/layer_6/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1229 bert/encoder/layer_6/intermediate/dense/mul_3" -> "1230 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"1230 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1231 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"1231 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1234 bert/encoder/layer_6/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1232 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1233 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"1233 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1234 bert/encoder/layer_6/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"1234 bert/encoder/layer_6/output/dense/MatMul" -> "1235 bert/encoder/layer_6/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1235 bert/encoder/layer_6/output/dense/BiasAdd" -> "1236 bert/encoder/layer_6/output/add" [key=0, style=solid, label="[]"];
"1236 bert/encoder/layer_6/output/add" -> "1237 bert/encoder/layer_6/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1236 bert/encoder/layer_6/output/add" -> "1239 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1236 bert/encoder/layer_6/output/add" -> "1248 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1237 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1238 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1237 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1246 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1238 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" -> "1239 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1239 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" -> "1240 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" [key=0, style=solid, label="[]"];
"1239 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" -> "1240 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" [key=1, style=solid, label="[]"];
"1240 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" -> "1241 bert/encoder/layer_6/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1241 bert/encoder/layer_6/output/LayerNorm/moments/variance" -> "1242 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1242 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" -> "1243 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1243 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" -> "1244 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" [key=0, style=solid, label="[]"];
"1244 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" -> "1245 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1245 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1246 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1245 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1248 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1246 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" -> "1247 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1247 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" -> "1249 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1248 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" -> "1249 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1249 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1250 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1249 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1254 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"1249 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1256 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"1249 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1295 bert/encoder/layer_7/attention/output/add" [key=0, style=solid, label="[]"];
"1250 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1251 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1251 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1258 bert/encoder/layer_7/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"1252 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1253 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1253 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1258 bert/encoder/layer_7/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"1254 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1255 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"1255 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1264 bert/encoder/layer_7/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"1256 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1257 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"1257 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1272 bert/encoder/layer_7/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"1258 bert/encoder/layer_7/attention/self/value/MatMul" -> "1259 bert/encoder/layer_7/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"1259 bert/encoder/layer_7/attention/self/value/BiasAdd" -> "1260 bert/encoder/layer_7/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"1260 bert/encoder/layer_7/attention/self/Reshape_2" -> "1261 bert/encoder/layer_7/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"1261 bert/encoder/layer_7/attention/self/transpose_2" -> "1286 bert/encoder/layer_7/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1262 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1263 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1263 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1264 bert/encoder/layer_7/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"1264 bert/encoder/layer_7/attention/self/query/MatMul" -> "1265 bert/encoder/layer_7/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"1265 bert/encoder/layer_7/attention/self/query/BiasAdd" -> "1266 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1266 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1267 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1267 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1268 bert/encoder/layer_7/attention/self/Reshape" [key=0, style=solid, label="[]"];
"1268 bert/encoder/layer_7/attention/self/Reshape" -> "1269 bert/encoder/layer_7/attention/self/transpose" [key=0, style=solid, label="[]"];
"1269 bert/encoder/layer_7/attention/self/transpose" -> "1279 bert/encoder/layer_7/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1270 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1271 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1271 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1272 bert/encoder/layer_7/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"1272 bert/encoder/layer_7/attention/self/key/MatMul" -> "1273 bert/encoder/layer_7/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"1273 bert/encoder/layer_7/attention/self/key/BiasAdd" -> "1274 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1274 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1275 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1275 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1276 bert/encoder/layer_7/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"1276 bert/encoder/layer_7/attention/self/Reshape_1" -> "1277 bert/encoder/layer_7/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"1277 bert/encoder/layer_7/attention/self/transpose_1" -> "1278 bert/encoder/layer_7/attention/self/MatMul__404" [key=0, style=solid, label="[]"];
"1278 bert/encoder/layer_7/attention/self/MatMul__404" -> "1279 bert/encoder/layer_7/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1279 bert/encoder/layer_7/attention/self/MatMul" -> "1280 bert/encoder/layer_7/attention/self/Mul" [key=0, style=solid, label="[]"];
"1280 bert/encoder/layer_7/attention/self/Mul" -> "1281 bert/encoder/layer_7/attention/self/add" [key=0, style=solid, label="[]"];
"1281 bert/encoder/layer_7/attention/self/add" -> "1282 Shape_nncf_1064" [key=0, style=solid, label="[]"];
"1281 bert/encoder/layer_7/attention/self/add" -> "1283 Flatten_nncf_1065" [key=0, style=solid, label="[]"];
"1282 Shape_nncf_1064" -> "1285 Reshape_nncf_1067" [key=0, style=dashed, label="[-1]"];
"1283 Flatten_nncf_1065" -> "1284 bert/encoder/layer_7/attention/self/Softmax" [key=0, style=solid, label="[]"];
"1284 bert/encoder/layer_7/attention/self/Softmax" -> "1285 Reshape_nncf_1067" [key=0, style=solid, label="[]"];
"1285 Reshape_nncf_1067" -> "1286 bert/encoder/layer_7/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1286 bert/encoder/layer_7/attention/self/MatMul_1" -> "1287 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"1287 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1288 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"1288 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1289 bert/encoder/layer_7/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"1289 bert/encoder/layer_7/attention/self/transpose_3" -> "1290 bert/encoder/layer_7/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"1290 bert/encoder/layer_7/attention/self/Reshape_3" -> "1293 bert/encoder/layer_7/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1291 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1292 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1292 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1293 bert/encoder/layer_7/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"1293 bert/encoder/layer_7/attention/output/dense/MatMul" -> "1294 bert/encoder/layer_7/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1294 bert/encoder/layer_7/attention/output/dense/BiasAdd" -> "1295 bert/encoder/layer_7/attention/output/add" [key=0, style=solid, label="[]"];
"1295 bert/encoder/layer_7/attention/output/add" -> "1296 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1295 bert/encoder/layer_7/attention/output/add" -> "1298 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1295 bert/encoder/layer_7/attention/output/add" -> "1307 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1296 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1297 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1296 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1305 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1297 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" -> "1298 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1298 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" -> "1299 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" [key=0, style=solid, label="[]"];
"1298 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" -> "1299 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" [key=1, style=solid, label="[]"];
"1299 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" -> "1300 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1300 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" -> "1301 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1301 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" -> "1302 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1302 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1303 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" [key=0, style=solid, label="[]"];
"1303 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" -> "1304 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1304 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1305 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1304 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1307 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1305 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" -> "1306 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1306 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" -> "1308 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1307 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" -> "1308 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1308 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1309 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1308 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1329 bert/encoder/layer_7/output/add" [key=0, style=solid, label="[]"];
"1309 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1310 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1310 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1313 bert/encoder/layer_7/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"1311 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1312 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"1312 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1313 bert/encoder/layer_7/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"1313 bert/encoder/layer_7/intermediate/dense/MatMul" -> "1314 bert/encoder/layer_7/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1314 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1315 bert/encoder/layer_7/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"1314 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1317 bert/encoder/layer_7/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1314 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1322 bert/encoder/layer_7/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1315 bert/encoder/layer_7/intermediate/dense/Pow" -> "1316 bert/encoder/layer_7/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"1316 bert/encoder/layer_7/intermediate/dense/mul" -> "1317 bert/encoder/layer_7/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1317 bert/encoder/layer_7/intermediate/dense/add" -> "1318 bert/encoder/layer_7/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"1318 bert/encoder/layer_7/intermediate/dense/mul_1" -> "1319 bert/encoder/layer_7/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"1319 bert/encoder/layer_7/intermediate/dense/Tanh" -> "1320 bert/encoder/layer_7/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"1320 bert/encoder/layer_7/intermediate/dense/add_1" -> "1321 bert/encoder/layer_7/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"1321 bert/encoder/layer_7/intermediate/dense/mul_2" -> "1322 bert/encoder/layer_7/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1322 bert/encoder/layer_7/intermediate/dense/mul_3" -> "1323 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"1323 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1324 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"1324 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1327 bert/encoder/layer_7/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1325 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1326 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"1326 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1327 bert/encoder/layer_7/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"1327 bert/encoder/layer_7/output/dense/MatMul" -> "1328 bert/encoder/layer_7/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1328 bert/encoder/layer_7/output/dense/BiasAdd" -> "1329 bert/encoder/layer_7/output/add" [key=0, style=solid, label="[]"];
"1329 bert/encoder/layer_7/output/add" -> "1330 bert/encoder/layer_7/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1329 bert/encoder/layer_7/output/add" -> "1332 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1329 bert/encoder/layer_7/output/add" -> "1341 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1330 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1331 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1330 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1339 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1331 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" -> "1332 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1332 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" -> "1333 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" [key=0, style=solid, label="[]"];
"1332 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" -> "1333 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" [key=1, style=solid, label="[]"];
"1333 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" -> "1334 bert/encoder/layer_7/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1334 bert/encoder/layer_7/output/LayerNorm/moments/variance" -> "1335 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1335 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" -> "1336 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1336 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" -> "1337 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" [key=0, style=solid, label="[]"];
"1337 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" -> "1338 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1338 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1339 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1338 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1341 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1339 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" -> "1340 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1340 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" -> "1342 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1341 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" -> "1342 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1342 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1343 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1342 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1347 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"1342 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1349 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"1342 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1388 bert/encoder/layer_8/attention/output/add" [key=0, style=solid, label="[]"];
"1343 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1344 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1344 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1351 bert/encoder/layer_8/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"1345 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1346 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1346 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1351 bert/encoder/layer_8/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"1347 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1348 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"1348 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1357 bert/encoder/layer_8/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"1349 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1350 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"1350 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1365 bert/encoder/layer_8/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"1351 bert/encoder/layer_8/attention/self/value/MatMul" -> "1352 bert/encoder/layer_8/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"1352 bert/encoder/layer_8/attention/self/value/BiasAdd" -> "1353 bert/encoder/layer_8/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"1353 bert/encoder/layer_8/attention/self/Reshape_2" -> "1354 bert/encoder/layer_8/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"1354 bert/encoder/layer_8/attention/self/transpose_2" -> "1379 bert/encoder/layer_8/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1355 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1356 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1356 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1357 bert/encoder/layer_8/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"1357 bert/encoder/layer_8/attention/self/query/MatMul" -> "1358 bert/encoder/layer_8/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"1358 bert/encoder/layer_8/attention/self/query/BiasAdd" -> "1359 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1359 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1360 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1360 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1361 bert/encoder/layer_8/attention/self/Reshape" [key=0, style=solid, label="[]"];
"1361 bert/encoder/layer_8/attention/self/Reshape" -> "1362 bert/encoder/layer_8/attention/self/transpose" [key=0, style=solid, label="[]"];
"1362 bert/encoder/layer_8/attention/self/transpose" -> "1372 bert/encoder/layer_8/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1363 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1364 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1364 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1365 bert/encoder/layer_8/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"1365 bert/encoder/layer_8/attention/self/key/MatMul" -> "1366 bert/encoder/layer_8/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"1366 bert/encoder/layer_8/attention/self/key/BiasAdd" -> "1367 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1367 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1368 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1368 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1369 bert/encoder/layer_8/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"1369 bert/encoder/layer_8/attention/self/Reshape_1" -> "1370 bert/encoder/layer_8/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"1370 bert/encoder/layer_8/attention/self/transpose_1" -> "1371 bert/encoder/layer_8/attention/self/MatMul__418" [key=0, style=solid, label="[]"];
"1371 bert/encoder/layer_8/attention/self/MatMul__418" -> "1372 bert/encoder/layer_8/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1372 bert/encoder/layer_8/attention/self/MatMul" -> "1373 bert/encoder/layer_8/attention/self/Mul" [key=0, style=solid, label="[]"];
"1373 bert/encoder/layer_8/attention/self/Mul" -> "1374 bert/encoder/layer_8/attention/self/add" [key=0, style=solid, label="[]"];
"1374 bert/encoder/layer_8/attention/self/add" -> "1375 Shape_nncf_1129" [key=0, style=solid, label="[]"];
"1374 bert/encoder/layer_8/attention/self/add" -> "1376 Flatten_nncf_1130" [key=0, style=solid, label="[]"];
"1375 Shape_nncf_1129" -> "1378 Reshape_nncf_1132" [key=0, style=dashed, label="[-1]"];
"1376 Flatten_nncf_1130" -> "1377 bert/encoder/layer_8/attention/self/Softmax" [key=0, style=solid, label="[]"];
"1377 bert/encoder/layer_8/attention/self/Softmax" -> "1378 Reshape_nncf_1132" [key=0, style=solid, label="[]"];
"1378 Reshape_nncf_1132" -> "1379 bert/encoder/layer_8/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1379 bert/encoder/layer_8/attention/self/MatMul_1" -> "1380 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"1380 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1381 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"1381 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1382 bert/encoder/layer_8/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"1382 bert/encoder/layer_8/attention/self/transpose_3" -> "1383 bert/encoder/layer_8/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"1383 bert/encoder/layer_8/attention/self/Reshape_3" -> "1386 bert/encoder/layer_8/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1384 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1385 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1385 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1386 bert/encoder/layer_8/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"1386 bert/encoder/layer_8/attention/output/dense/MatMul" -> "1387 bert/encoder/layer_8/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1387 bert/encoder/layer_8/attention/output/dense/BiasAdd" -> "1388 bert/encoder/layer_8/attention/output/add" [key=0, style=solid, label="[]"];
"1388 bert/encoder/layer_8/attention/output/add" -> "1389 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1388 bert/encoder/layer_8/attention/output/add" -> "1391 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1388 bert/encoder/layer_8/attention/output/add" -> "1400 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1389 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1390 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1389 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1398 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1390 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" -> "1391 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1391 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" -> "1392 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" [key=0, style=solid, label="[]"];
"1391 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" -> "1392 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" [key=1, style=solid, label="[]"];
"1392 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" -> "1393 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1393 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" -> "1394 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1394 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" -> "1395 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1395 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1396 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" [key=0, style=solid, label="[]"];
"1396 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" -> "1397 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1397 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1398 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1397 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1400 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1398 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" -> "1399 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1399 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" -> "1401 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1400 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" -> "1401 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1401 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1402 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1401 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1422 bert/encoder/layer_8/output/add" [key=0, style=solid, label="[]"];
"1402 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1403 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1403 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1406 bert/encoder/layer_8/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"1404 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1405 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"1405 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1406 bert/encoder/layer_8/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"1406 bert/encoder/layer_8/intermediate/dense/MatMul" -> "1407 bert/encoder/layer_8/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1407 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1408 bert/encoder/layer_8/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"1407 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1410 bert/encoder/layer_8/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1407 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1415 bert/encoder/layer_8/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1408 bert/encoder/layer_8/intermediate/dense/Pow" -> "1409 bert/encoder/layer_8/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"1409 bert/encoder/layer_8/intermediate/dense/mul" -> "1410 bert/encoder/layer_8/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1410 bert/encoder/layer_8/intermediate/dense/add" -> "1411 bert/encoder/layer_8/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"1411 bert/encoder/layer_8/intermediate/dense/mul_1" -> "1412 bert/encoder/layer_8/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"1412 bert/encoder/layer_8/intermediate/dense/Tanh" -> "1413 bert/encoder/layer_8/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"1413 bert/encoder/layer_8/intermediate/dense/add_1" -> "1414 bert/encoder/layer_8/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"1414 bert/encoder/layer_8/intermediate/dense/mul_2" -> "1415 bert/encoder/layer_8/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1415 bert/encoder/layer_8/intermediate/dense/mul_3" -> "1416 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"1416 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1417 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"1417 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1420 bert/encoder/layer_8/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1418 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1419 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"1419 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1420 bert/encoder/layer_8/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"1420 bert/encoder/layer_8/output/dense/MatMul" -> "1421 bert/encoder/layer_8/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1421 bert/encoder/layer_8/output/dense/BiasAdd" -> "1422 bert/encoder/layer_8/output/add" [key=0, style=solid, label="[]"];
"1422 bert/encoder/layer_8/output/add" -> "1423 bert/encoder/layer_8/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1422 bert/encoder/layer_8/output/add" -> "1425 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1422 bert/encoder/layer_8/output/add" -> "1434 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1423 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1424 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1423 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1432 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1424 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" -> "1425 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1425 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" -> "1426 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" [key=0, style=solid, label="[]"];
"1425 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" -> "1426 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" [key=1, style=solid, label="[]"];
"1426 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" -> "1427 bert/encoder/layer_8/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1427 bert/encoder/layer_8/output/LayerNorm/moments/variance" -> "1428 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1428 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" -> "1429 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1429 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" -> "1430 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" [key=0, style=solid, label="[]"];
"1430 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" -> "1431 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1431 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1432 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1431 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1434 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1432 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" -> "1433 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1433 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" -> "1435 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1434 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" -> "1435 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1435 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1436 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1435 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1440 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"1435 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1442 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"1435 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1481 bert/encoder/layer_9/attention/output/add" [key=0, style=solid, label="[]"];
"1436 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1437 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1437 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1444 bert/encoder/layer_9/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"1438 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1439 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1439 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1444 bert/encoder/layer_9/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"1440 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1441 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"1441 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1450 bert/encoder/layer_9/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"1442 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1443 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"1443 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1458 bert/encoder/layer_9/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"1444 bert/encoder/layer_9/attention/self/value/MatMul" -> "1445 bert/encoder/layer_9/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"1445 bert/encoder/layer_9/attention/self/value/BiasAdd" -> "1446 bert/encoder/layer_9/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"1446 bert/encoder/layer_9/attention/self/Reshape_2" -> "1447 bert/encoder/layer_9/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"1447 bert/encoder/layer_9/attention/self/transpose_2" -> "1472 bert/encoder/layer_9/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1448 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1449 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1449 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1450 bert/encoder/layer_9/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"1450 bert/encoder/layer_9/attention/self/query/MatMul" -> "1451 bert/encoder/layer_9/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"1451 bert/encoder/layer_9/attention/self/query/BiasAdd" -> "1452 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1452 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1453 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1453 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1454 bert/encoder/layer_9/attention/self/Reshape" [key=0, style=solid, label="[]"];
"1454 bert/encoder/layer_9/attention/self/Reshape" -> "1455 bert/encoder/layer_9/attention/self/transpose" [key=0, style=solid, label="[]"];
"1455 bert/encoder/layer_9/attention/self/transpose" -> "1465 bert/encoder/layer_9/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1456 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1457 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1457 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1458 bert/encoder/layer_9/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"1458 bert/encoder/layer_9/attention/self/key/MatMul" -> "1459 bert/encoder/layer_9/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"1459 bert/encoder/layer_9/attention/self/key/BiasAdd" -> "1460 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1460 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1461 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1461 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1462 bert/encoder/layer_9/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"1462 bert/encoder/layer_9/attention/self/Reshape_1" -> "1463 bert/encoder/layer_9/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"1463 bert/encoder/layer_9/attention/self/transpose_1" -> "1464 bert/encoder/layer_9/attention/self/MatMul__432" [key=0, style=solid, label="[]"];
"1464 bert/encoder/layer_9/attention/self/MatMul__432" -> "1465 bert/encoder/layer_9/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1465 bert/encoder/layer_9/attention/self/MatMul" -> "1466 bert/encoder/layer_9/attention/self/Mul" [key=0, style=solid, label="[]"];
"1466 bert/encoder/layer_9/attention/self/Mul" -> "1467 bert/encoder/layer_9/attention/self/add" [key=0, style=solid, label="[]"];
"1467 bert/encoder/layer_9/attention/self/add" -> "1468 Shape_nncf_1194" [key=0, style=solid, label="[]"];
"1467 bert/encoder/layer_9/attention/self/add" -> "1469 Flatten_nncf_1195" [key=0, style=solid, label="[]"];
"1468 Shape_nncf_1194" -> "1471 Reshape_nncf_1197" [key=0, style=dashed, label="[-1]"];
"1469 Flatten_nncf_1195" -> "1470 bert/encoder/layer_9/attention/self/Softmax" [key=0, style=solid, label="[]"];
"1470 bert/encoder/layer_9/attention/self/Softmax" -> "1471 Reshape_nncf_1197" [key=0, style=solid, label="[]"];
"1471 Reshape_nncf_1197" -> "1472 bert/encoder/layer_9/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1472 bert/encoder/layer_9/attention/self/MatMul_1" -> "1473 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"1473 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1474 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"1474 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1475 bert/encoder/layer_9/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"1475 bert/encoder/layer_9/attention/self/transpose_3" -> "1476 bert/encoder/layer_9/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"1476 bert/encoder/layer_9/attention/self/Reshape_3" -> "1479 bert/encoder/layer_9/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1477 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1478 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1478 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1479 bert/encoder/layer_9/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"1479 bert/encoder/layer_9/attention/output/dense/MatMul" -> "1480 bert/encoder/layer_9/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1480 bert/encoder/layer_9/attention/output/dense/BiasAdd" -> "1481 bert/encoder/layer_9/attention/output/add" [key=0, style=solid, label="[]"];
"1481 bert/encoder/layer_9/attention/output/add" -> "1482 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1481 bert/encoder/layer_9/attention/output/add" -> "1484 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1481 bert/encoder/layer_9/attention/output/add" -> "1493 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1482 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1483 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1482 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1491 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1483 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" -> "1484 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1484 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" -> "1485 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" [key=0, style=solid, label="[]"];
"1484 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" -> "1485 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" [key=1, style=solid, label="[]"];
"1485 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" -> "1486 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1486 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" -> "1487 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1487 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" -> "1488 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1488 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1489 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" [key=0, style=solid, label="[]"];
"1489 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" -> "1490 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1490 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1491 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1490 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1493 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1491 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" -> "1492 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1492 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" -> "1494 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1493 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" -> "1494 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1494 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1495 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1494 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1515 bert/encoder/layer_9/output/add" [key=0, style=solid, label="[]"];
"1495 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1496 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1496 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1499 bert/encoder/layer_9/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"1497 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1498 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"1498 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1499 bert/encoder/layer_9/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"1499 bert/encoder/layer_9/intermediate/dense/MatMul" -> "1500 bert/encoder/layer_9/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1500 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1501 bert/encoder/layer_9/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"1500 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1503 bert/encoder/layer_9/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1500 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1508 bert/encoder/layer_9/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1501 bert/encoder/layer_9/intermediate/dense/Pow" -> "1502 bert/encoder/layer_9/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"1502 bert/encoder/layer_9/intermediate/dense/mul" -> "1503 bert/encoder/layer_9/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1503 bert/encoder/layer_9/intermediate/dense/add" -> "1504 bert/encoder/layer_9/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"1504 bert/encoder/layer_9/intermediate/dense/mul_1" -> "1505 bert/encoder/layer_9/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"1505 bert/encoder/layer_9/intermediate/dense/Tanh" -> "1506 bert/encoder/layer_9/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"1506 bert/encoder/layer_9/intermediate/dense/add_1" -> "1507 bert/encoder/layer_9/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"1507 bert/encoder/layer_9/intermediate/dense/mul_2" -> "1508 bert/encoder/layer_9/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1508 bert/encoder/layer_9/intermediate/dense/mul_3" -> "1509 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"1509 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1510 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"1510 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1513 bert/encoder/layer_9/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1511 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1512 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"1512 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1513 bert/encoder/layer_9/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"1513 bert/encoder/layer_9/output/dense/MatMul" -> "1514 bert/encoder/layer_9/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1514 bert/encoder/layer_9/output/dense/BiasAdd" -> "1515 bert/encoder/layer_9/output/add" [key=0, style=solid, label="[]"];
"1515 bert/encoder/layer_9/output/add" -> "1516 bert/encoder/layer_9/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1515 bert/encoder/layer_9/output/add" -> "1518 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1515 bert/encoder/layer_9/output/add" -> "1527 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1516 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1517 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1516 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1525 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1517 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" -> "1518 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1518 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" -> "1519 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" [key=0, style=solid, label="[]"];
"1518 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" -> "1519 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" [key=1, style=solid, label="[]"];
"1519 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" -> "1520 bert/encoder/layer_9/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1520 bert/encoder/layer_9/output/LayerNorm/moments/variance" -> "1521 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1521 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" -> "1522 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1522 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" -> "1523 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" [key=0, style=solid, label="[]"];
"1523 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" -> "1524 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1524 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1525 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1524 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1527 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1525 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" -> "1526 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1526 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" -> "1528 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1527 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" -> "1528 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1528 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1529 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1528 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1533 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"1528 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1535 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"1528 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1574 bert/encoder/layer_10/attention/output/add" [key=0, style=solid, label="[]"];
"1529 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1530 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1530 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1537 bert/encoder/layer_10/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"1531 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1532 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1532 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1537 bert/encoder/layer_10/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"1533 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1534 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"1534 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1543 bert/encoder/layer_10/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"1535 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1536 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"1536 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1551 bert/encoder/layer_10/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"1537 bert/encoder/layer_10/attention/self/value/MatMul" -> "1538 bert/encoder/layer_10/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"1538 bert/encoder/layer_10/attention/self/value/BiasAdd" -> "1539 bert/encoder/layer_10/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"1539 bert/encoder/layer_10/attention/self/Reshape_2" -> "1540 bert/encoder/layer_10/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"1540 bert/encoder/layer_10/attention/self/transpose_2" -> "1565 bert/encoder/layer_10/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1541 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1542 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1542 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1543 bert/encoder/layer_10/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"1543 bert/encoder/layer_10/attention/self/query/MatMul" -> "1544 bert/encoder/layer_10/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"1544 bert/encoder/layer_10/attention/self/query/BiasAdd" -> "1545 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1545 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1546 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1546 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1547 bert/encoder/layer_10/attention/self/Reshape" [key=0, style=solid, label="[]"];
"1547 bert/encoder/layer_10/attention/self/Reshape" -> "1548 bert/encoder/layer_10/attention/self/transpose" [key=0, style=solid, label="[]"];
"1548 bert/encoder/layer_10/attention/self/transpose" -> "1558 bert/encoder/layer_10/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1549 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1550 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1550 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1551 bert/encoder/layer_10/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"1551 bert/encoder/layer_10/attention/self/key/MatMul" -> "1552 bert/encoder/layer_10/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"1552 bert/encoder/layer_10/attention/self/key/BiasAdd" -> "1553 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1553 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1554 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1554 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1555 bert/encoder/layer_10/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"1555 bert/encoder/layer_10/attention/self/Reshape_1" -> "1556 bert/encoder/layer_10/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"1556 bert/encoder/layer_10/attention/self/transpose_1" -> "1557 bert/encoder/layer_10/attention/self/MatMul__446" [key=0, style=solid, label="[]"];
"1557 bert/encoder/layer_10/attention/self/MatMul__446" -> "1558 bert/encoder/layer_10/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1558 bert/encoder/layer_10/attention/self/MatMul" -> "1559 bert/encoder/layer_10/attention/self/Mul" [key=0, style=solid, label="[]"];
"1559 bert/encoder/layer_10/attention/self/Mul" -> "1560 bert/encoder/layer_10/attention/self/add" [key=0, style=solid, label="[]"];
"1560 bert/encoder/layer_10/attention/self/add" -> "1561 Shape_nncf_1259" [key=0, style=solid, label="[]"];
"1560 bert/encoder/layer_10/attention/self/add" -> "1562 Flatten_nncf_1260" [key=0, style=solid, label="[]"];
"1561 Shape_nncf_1259" -> "1564 Reshape_nncf_1262" [key=0, style=dashed, label="[-1]"];
"1562 Flatten_nncf_1260" -> "1563 bert/encoder/layer_10/attention/self/Softmax" [key=0, style=solid, label="[]"];
"1563 bert/encoder/layer_10/attention/self/Softmax" -> "1564 Reshape_nncf_1262" [key=0, style=solid, label="[]"];
"1564 Reshape_nncf_1262" -> "1565 bert/encoder/layer_10/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1565 bert/encoder/layer_10/attention/self/MatMul_1" -> "1566 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"1566 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1567 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"1567 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1568 bert/encoder/layer_10/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"1568 bert/encoder/layer_10/attention/self/transpose_3" -> "1569 bert/encoder/layer_10/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"1569 bert/encoder/layer_10/attention/self/Reshape_3" -> "1572 bert/encoder/layer_10/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1570 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1571 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1571 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1572 bert/encoder/layer_10/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"1572 bert/encoder/layer_10/attention/output/dense/MatMul" -> "1573 bert/encoder/layer_10/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1573 bert/encoder/layer_10/attention/output/dense/BiasAdd" -> "1574 bert/encoder/layer_10/attention/output/add" [key=0, style=solid, label="[]"];
"1574 bert/encoder/layer_10/attention/output/add" -> "1575 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1574 bert/encoder/layer_10/attention/output/add" -> "1577 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1574 bert/encoder/layer_10/attention/output/add" -> "1586 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1575 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1576 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1575 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1584 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1576 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" -> "1577 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1577 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" -> "1578 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" [key=0, style=solid, label="[]"];
"1577 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" -> "1578 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" [key=1, style=solid, label="[]"];
"1578 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" -> "1579 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1579 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" -> "1580 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1580 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" -> "1581 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1581 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1582 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" [key=0, style=solid, label="[]"];
"1582 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" -> "1583 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1583 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1584 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1583 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1586 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1584 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" -> "1585 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1585 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" -> "1587 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1586 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" -> "1587 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1587 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1588 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1587 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1608 bert/encoder/layer_10/output/add" [key=0, style=solid, label="[]"];
"1588 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1589 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1589 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1592 bert/encoder/layer_10/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"1590 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1591 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"1591 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1592 bert/encoder/layer_10/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"1592 bert/encoder/layer_10/intermediate/dense/MatMul" -> "1593 bert/encoder/layer_10/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1593 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1594 bert/encoder/layer_10/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"1593 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1596 bert/encoder/layer_10/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1593 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1601 bert/encoder/layer_10/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1594 bert/encoder/layer_10/intermediate/dense/Pow" -> "1595 bert/encoder/layer_10/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"1595 bert/encoder/layer_10/intermediate/dense/mul" -> "1596 bert/encoder/layer_10/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1596 bert/encoder/layer_10/intermediate/dense/add" -> "1597 bert/encoder/layer_10/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"1597 bert/encoder/layer_10/intermediate/dense/mul_1" -> "1598 bert/encoder/layer_10/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"1598 bert/encoder/layer_10/intermediate/dense/Tanh" -> "1599 bert/encoder/layer_10/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"1599 bert/encoder/layer_10/intermediate/dense/add_1" -> "1600 bert/encoder/layer_10/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"1600 bert/encoder/layer_10/intermediate/dense/mul_2" -> "1601 bert/encoder/layer_10/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1601 bert/encoder/layer_10/intermediate/dense/mul_3" -> "1602 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"1602 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1603 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"1603 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1606 bert/encoder/layer_10/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1604 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1605 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"1605 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1606 bert/encoder/layer_10/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"1606 bert/encoder/layer_10/output/dense/MatMul" -> "1607 bert/encoder/layer_10/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1607 bert/encoder/layer_10/output/dense/BiasAdd" -> "1608 bert/encoder/layer_10/output/add" [key=0, style=solid, label="[]"];
"1608 bert/encoder/layer_10/output/add" -> "1609 bert/encoder/layer_10/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1608 bert/encoder/layer_10/output/add" -> "1611 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1608 bert/encoder/layer_10/output/add" -> "1620 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1609 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1610 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1609 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1618 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1610 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" -> "1611 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1611 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" -> "1612 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" [key=0, style=solid, label="[]"];
"1611 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" -> "1612 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" [key=1, style=solid, label="[]"];
"1612 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" -> "1613 bert/encoder/layer_10/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1613 bert/encoder/layer_10/output/LayerNorm/moments/variance" -> "1614 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1614 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" -> "1615 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1615 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" -> "1616 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" [key=0, style=solid, label="[]"];
"1616 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" -> "1617 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1617 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1618 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1617 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1620 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1618 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" -> "1619 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1619 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" -> "1621 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1620 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" -> "1621 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1621 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1622 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1621 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1626 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=solid, label="[]"];
"1621 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1628 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=solid, label="[]"];
"1621 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1667 bert/encoder/layer_11/attention/output/add" [key=0, style=solid, label="[]"];
"1622 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1623 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1623 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1630 bert/encoder/layer_11/attention/self/value/MatMul" [key=0, style=solid, label="[]"];
"1624 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1625 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1625 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1630 bert/encoder/layer_11/attention/self/value/MatMul" [key=0, style=solid, label="[768, 768]"];
"1626 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1627 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [key=0, style=dashed, label="[]"];
"1627 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1636 bert/encoder/layer_11/attention/self/query/MatMul" [key=0, style=solid, label="[]"];
"1628 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1629 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [key=0, style=dashed, label="[]"];
"1629 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1644 bert/encoder/layer_11/attention/self/key/MatMul" [key=0, style=solid, label="[]"];
"1630 bert/encoder/layer_11/attention/self/value/MatMul" -> "1631 bert/encoder/layer_11/attention/self/value/BiasAdd" [key=0, style=solid, label="[]"];
"1631 bert/encoder/layer_11/attention/self/value/BiasAdd" -> "1632 bert/encoder/layer_11/attention/self/Reshape_2" [key=0, style=solid, label="[]"];
"1632 bert/encoder/layer_11/attention/self/Reshape_2" -> "1633 bert/encoder/layer_11/attention/self/transpose_2" [key=0, style=solid, label="[]"];
"1633 bert/encoder/layer_11/attention/self/transpose_2" -> "1658 bert/encoder/layer_11/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1634 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1635 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1635 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1636 bert/encoder/layer_11/attention/self/query/MatMul" [key=0, style=solid, label="[768, 768]"];
"1636 bert/encoder/layer_11/attention/self/query/MatMul" -> "1637 bert/encoder/layer_11/attention/self/query/BiasAdd" [key=0, style=solid, label="[]"];
"1637 bert/encoder/layer_11/attention/self/query/BiasAdd" -> "1638 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1638 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1639 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1639 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1640 bert/encoder/layer_11/attention/self/Reshape" [key=0, style=solid, label="[]"];
"1640 bert/encoder/layer_11/attention/self/Reshape" -> "1641 bert/encoder/layer_11/attention/self/transpose" [key=0, style=solid, label="[]"];
"1641 bert/encoder/layer_11/attention/self/transpose" -> "1651 bert/encoder/layer_11/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1642 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1643 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1643 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1644 bert/encoder/layer_11/attention/self/key/MatMul" [key=0, style=solid, label="[768, 768]"];
"1644 bert/encoder/layer_11/attention/self/key/MatMul" -> "1645 bert/encoder/layer_11/attention/self/key/BiasAdd" [key=0, style=solid, label="[]"];
"1645 bert/encoder/layer_11/attention/self/key/BiasAdd" -> "1646 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [key=0, style=solid, label="[]"];
"1646 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1647 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [key=0, style=dashed, label="[]"];
"1647 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1648 bert/encoder/layer_11/attention/self/Reshape_1" [key=0, style=solid, label="[]"];
"1648 bert/encoder/layer_11/attention/self/Reshape_1" -> "1649 bert/encoder/layer_11/attention/self/transpose_1" [key=0, style=solid, label="[]"];
"1649 bert/encoder/layer_11/attention/self/transpose_1" -> "1650 bert/encoder/layer_11/attention/self/MatMul__460" [key=0, style=solid, label="[]"];
"1650 bert/encoder/layer_11/attention/self/MatMul__460" -> "1651 bert/encoder/layer_11/attention/self/MatMul" [key=0, style=solid, label="[]"];
"1651 bert/encoder/layer_11/attention/self/MatMul" -> "1652 bert/encoder/layer_11/attention/self/Mul" [key=0, style=solid, label="[]"];
"1652 bert/encoder/layer_11/attention/self/Mul" -> "1653 bert/encoder/layer_11/attention/self/add" [key=0, style=solid, label="[]"];
"1653 bert/encoder/layer_11/attention/self/add" -> "1654 Shape_nncf_1324" [key=0, style=solid, label="[]"];
"1653 bert/encoder/layer_11/attention/self/add" -> "1655 Flatten_nncf_1325" [key=0, style=solid, label="[]"];
"1654 Shape_nncf_1324" -> "1657 Reshape_nncf_1327" [key=0, style=dashed, label="[-1]"];
"1655 Flatten_nncf_1325" -> "1656 bert/encoder/layer_11/attention/self/Softmax" [key=0, style=solid, label="[]"];
"1656 bert/encoder/layer_11/attention/self/Softmax" -> "1657 Reshape_nncf_1327" [key=0, style=solid, label="[]"];
"1657 Reshape_nncf_1327" -> "1658 bert/encoder/layer_11/attention/self/MatMul_1" [key=0, style=solid, label="[]"];
"1658 bert/encoder/layer_11/attention/self/MatMul_1" -> "1659 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [key=0, style=solid, label="[]"];
"1659 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1660 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [key=0, style=dashed, label="[]"];
"1660 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1661 bert/encoder/layer_11/attention/self/transpose_3" [key=0, style=solid, label="[]"];
"1661 bert/encoder/layer_11/attention/self/transpose_3" -> "1662 bert/encoder/layer_11/attention/self/Reshape_3" [key=0, style=solid, label="[]"];
"1662 bert/encoder/layer_11/attention/self/Reshape_3" -> "1665 bert/encoder/layer_11/attention/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1663 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1664 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [key=0, style=dashed, label="[768, 768]"];
"1664 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1665 bert/encoder/layer_11/attention/output/dense/MatMul" [key=0, style=solid, label="[768, 768]"];
"1665 bert/encoder/layer_11/attention/output/dense/MatMul" -> "1666 bert/encoder/layer_11/attention/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1666 bert/encoder/layer_11/attention/output/dense/BiasAdd" -> "1667 bert/encoder/layer_11/attention/output/add" [key=0, style=solid, label="[]"];
"1667 bert/encoder/layer_11/attention/output/add" -> "1668 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1667 bert/encoder/layer_11/attention/output/add" -> "1670 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1667 bert/encoder/layer_11/attention/output/add" -> "1679 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1668 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1669 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1668 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1677 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1669 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" -> "1670 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1670 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" -> "1671 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" [key=0, style=solid, label="[]"];
"1670 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" -> "1671 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" [key=1, style=solid, label="[]"];
"1671 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" -> "1672 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1672 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" -> "1673 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1673 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" -> "1674 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1674 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1675 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" [key=0, style=solid, label="[]"];
"1675 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" -> "1676 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1676 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1677 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1676 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1679 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1677 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" -> "1678 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1678 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" -> "1680 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1679 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" -> "1680 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1680 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1681 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1680 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1701 bert/encoder/layer_11/output/add" [key=0, style=solid, label="[]"];
"1681 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1682 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1682 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1685 bert/encoder/layer_11/intermediate/dense/MatMul" [key=0, style=solid, label="[]"];
"1683 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1684 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [key=0, style=dashed, label="[768, 3072]"];
"1684 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1685 bert/encoder/layer_11/intermediate/dense/MatMul" [key=0, style=solid, label="[768, 3072]"];
"1685 bert/encoder/layer_11/intermediate/dense/MatMul" -> "1686 bert/encoder/layer_11/intermediate/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1686 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1687 bert/encoder/layer_11/intermediate/dense/Pow" [key=0, style=solid, label="[]"];
"1686 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1689 bert/encoder/layer_11/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1686 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1694 bert/encoder/layer_11/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1687 bert/encoder/layer_11/intermediate/dense/Pow" -> "1688 bert/encoder/layer_11/intermediate/dense/mul" [key=0, style=solid, label="[]"];
"1688 bert/encoder/layer_11/intermediate/dense/mul" -> "1689 bert/encoder/layer_11/intermediate/dense/add" [key=0, style=solid, label="[]"];
"1689 bert/encoder/layer_11/intermediate/dense/add" -> "1690 bert/encoder/layer_11/intermediate/dense/mul_1" [key=0, style=solid, label="[]"];
"1690 bert/encoder/layer_11/intermediate/dense/mul_1" -> "1691 bert/encoder/layer_11/intermediate/dense/Tanh" [key=0, style=solid, label="[]"];
"1691 bert/encoder/layer_11/intermediate/dense/Tanh" -> "1692 bert/encoder/layer_11/intermediate/dense/add_1" [key=0, style=solid, label="[]"];
"1692 bert/encoder/layer_11/intermediate/dense/add_1" -> "1693 bert/encoder/layer_11/intermediate/dense/mul_2" [key=0, style=solid, label="[]"];
"1693 bert/encoder/layer_11/intermediate/dense/mul_2" -> "1694 bert/encoder/layer_11/intermediate/dense/mul_3" [key=0, style=solid, label="[]"];
"1694 bert/encoder/layer_11/intermediate/dense/mul_3" -> "1695 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [key=0, style=solid, label="[]"];
"1695 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1696 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [key=0, style=dashed, label="[]"];
"1696 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1699 bert/encoder/layer_11/output/dense/MatMul" [key=0, style=solid, label="[]"];
"1697 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1698 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [key=0, style=dashed, label="[3072, 768]"];
"1698 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1699 bert/encoder/layer_11/output/dense/MatMul" [key=0, style=solid, label="[3072, 768]"];
"1699 bert/encoder/layer_11/output/dense/MatMul" -> "1700 bert/encoder/layer_11/output/dense/BiasAdd" [key=0, style=solid, label="[]"];
"1700 bert/encoder/layer_11/output/dense/BiasAdd" -> "1701 bert/encoder/layer_11/output/add" [key=0, style=solid, label="[]"];
"1701 bert/encoder/layer_11/output/add" -> "1702 bert/encoder/layer_11/output/LayerNorm/moments/mean" [key=0, style=solid, label="[]"];
"1701 bert/encoder/layer_11/output/add" -> "1704 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1701 bert/encoder/layer_11/output/add" -> "1713 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1702 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1703 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" [key=0, style=solid, label="[]"];
"1702 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1711 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1703 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" -> "1704 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" [key=0, style=solid, label="[]"];
"1704 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" -> "1705 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" [key=0, style=solid, label="[]"];
"1704 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" -> "1705 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" [key=1, style=solid, label="[]"];
"1705 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" -> "1706 bert/encoder/layer_11/output/LayerNorm/moments/variance" [key=0, style=solid, label="[]"];
"1706 bert/encoder/layer_11/output/LayerNorm/moments/variance" -> "1707 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" [key=0, style=solid, label="[]"];
"1707 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" -> "1708 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" [key=0, style=solid, label="[]"];
"1708 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" -> "1709 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" [key=0, style=solid, label="[]"];
"1709 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" -> "1710 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" [key=0, style=solid, label="[]"];
"1710 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1711 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" [key=0, style=solid, label="[]"];
"1710 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1713 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" [key=0, style=solid, label="[]"];
"1711 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" -> "1712 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" [key=0, style=solid, label="[]"];
"1712 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" -> "1714 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1713 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" -> "1714 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" [key=0, style=solid, label="[]"];
"1714 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" -> "1715 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=solid, label="[]"];
"1715 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1716 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [key=0, style=dashed, label="[]"];
"1716 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1717 bert/encoder/Reshape_13" [key=0, style=solid, label="[]"];
"1717 bert/encoder/Reshape_13" -> "1718 Shape_1" [key=0, style=solid, label="[]"];
"1717 bert/encoder/Reshape_13" -> "1733 Reshape" [key=0, style=solid, label="[]"];
"1718 Shape_1" -> "1719 Shape_1__472" [key=0, style=dashed, label="[-1]"];
"1719 Shape_1__472" -> "1720 strided_slice_1" [key=0, style=solid, label="[-1]"];
"1720 strided_slice_1" -> "1722 strided_slice_1__476" [key=0, style=solid, label="[-1]"];
"1721 Constant_nncf_1377" -> "1722 strided_slice_1__476" [key=0, style=dashed, label="[1]"];
"1722 strided_slice_1__476" -> "1723 strided_slice_1__477" [key=0, style=solid, label="[]"];
"1723 strided_slice_1__477" -> "1724 mul" [key=0, style=dashed, label="[]"];
"1723 strided_slice_1__477" -> "1730 Reshape_1/shape_Unsqueeze__478" [key=0, style=dashed, label="[]"];
"1724 mul" -> "1726 Reshape/shape_Unsqueeze__482" [key=0, style=dashed, label="[]"];
"1725 Constant_nncf_1381" -> "1726 Reshape/shape_Unsqueeze__482" [key=0, style=dashed, label="[1]"];
"1726 Reshape/shape_Unsqueeze__482" -> "1727 Reshape/shape_Concat__484" [key=0, style=dashed, label="[1]"];
"1727 Reshape/shape_Concat__484" -> "1728 Reshape__485" [key=0, style=dashed, label="[2]"];
"1728 Reshape__485" -> "1733 Reshape" [key=0, style=dashed, label="[2]"];
"1729 Constant_nncf_1385" -> "1730 Reshape_1/shape_Unsqueeze__478" [key=0, style=dashed, label="[1]"];
"1730 Reshape_1/shape_Unsqueeze__478" -> "1731 Reshape_1/shape_Concat__481" [key=0, style=dashed, label="[1]"];
"1731 Reshape_1/shape_Concat__481" -> "1732 Reshape_1__487" [key=0, style=dashed, label="[3]"];
"1732 Reshape_1__487" -> "1738 Reshape_1" [key=0, style=dashed, label="[3]"];
"1733 Reshape" -> "1736 MatMul" [key=0, style=solid, label="[]"];
"1734 QuantizeLinear_MatMul__486^0_1" -> "1735 DequantizeLinear_MatMul__486^0_1" [key=0, style=dashed, label="[768, 2]"];
"1735 DequantizeLinear_MatMul__486^0_1" -> "1736 MatMul" [key=0, style=solid, label="[768, 2]"];
"1736 MatMul" -> "1737 BiasAdd" [key=0, style=solid, label="[]"];
"1737 BiasAdd" -> "1738 Reshape_1" [key=0, style=solid, label="[]"];
"1738 Reshape_1" -> "1739 transpose" [key=0, style=solid, label="[]"];
"1739 transpose" -> "1740 unstack" [key=0, style=solid, label="[]"];
"1740 unstack" -> "1742 unstack__490" [key=0, style=solid, label="[]"];
"1740 unstack" -> "1745 unstack__488" [key=0, style=solid, label="[]"];
"1741 Constant_nncf_1395" -> "1742 unstack__490" [key=0, style=dashed, label="[1]"];
"1742 unstack__490" -> "1743 unstack_graph_outputs_Identity__4" [key=0, style=solid, label="[]"];
"1743 unstack_graph_outputs_Identity__4" -> "1751 nncf_model_output_0" [key=0, style=solid, label="[-1, 256]"];
"1744 Constant_nncf_1398" -> "1745 unstack__488" [key=0, style=dashed, label="[1]"];
"1745 unstack__488" -> "1746 unstack_graph_outputs_Identity__7" [key=0, style=solid, label="[]"];
"1746 unstack_graph_outputs_Identity__7" -> "1752 nncf_model_output_1" [key=0, style=solid, label="[-1, 256]"];
"1747 nncf_model_input_0" -> "0 unique_ids_graph_outputs_Identity__10" [key=0, style=dashed, label="[-1]"];
"1748 nncf_model_input_1" -> "316 bert/embeddings/Reshape_2" [key=0, style=dashed, label="[-1, 256]"];
"1749 nncf_model_input_2" -> "269 bert/encoder/Reshape" [key=0, style=dashed, label="[-1, 256]"];
"1750 nncf_model_input_3" -> "245 bert/encoder/Shape" [key=0, style=dashed, label="[-1, 256]"];
"1750 nncf_model_input_3" -> "322 bert/embeddings/ExpandDims" [key=0, style=dashed, label="[-1, 256]"];
}
