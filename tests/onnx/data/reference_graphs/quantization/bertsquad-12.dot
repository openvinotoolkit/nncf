strict digraph  {
"0 unique_ids_graph_outputs_Identity__10" [id=0, type=Identity];
"1 bert/encoder/ones/packed_Unsqueeze__20" [id=1, type=Unsqueeze];
"2 bert/encoder/ones/packed_Unsqueeze__19" [id=2, type=Unsqueeze];
"3 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" [id=3, type=Unsqueeze];
"4 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" [id=4, type=Unsqueeze];
"5 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" [id=5, type=Unsqueeze];
"6 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" [id=6, type=Unsqueeze];
"7 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" [id=7, type=Unsqueeze];
"8 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" [id=8, type=Unsqueeze];
"9 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" [id=9, type=Unsqueeze];
"10 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" [id=10, type=Unsqueeze];
"11 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" [id=11, type=Unsqueeze];
"12 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" [id=12, type=Unsqueeze];
"13 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" [id=13, type=Unsqueeze];
"14 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" [id=14, type=Unsqueeze];
"15 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" [id=15, type=Unsqueeze];
"16 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" [id=16, type=Unsqueeze];
"17 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" [id=17, type=Unsqueeze];
"18 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" [id=18, type=Unsqueeze];
"19 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" [id=19, type=Unsqueeze];
"20 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" [id=20, type=Unsqueeze];
"21 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" [id=21, type=Unsqueeze];
"22 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" [id=22, type=Unsqueeze];
"23 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" [id=23, type=Unsqueeze];
"24 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" [id=24, type=Unsqueeze];
"25 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" [id=25, type=Unsqueeze];
"26 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" [id=26, type=Unsqueeze];
"27 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" [id=27, type=Unsqueeze];
"28 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" [id=28, type=Unsqueeze];
"29 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" [id=29, type=Unsqueeze];
"30 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" [id=30, type=Unsqueeze];
"31 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" [id=31, type=Unsqueeze];
"32 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" [id=32, type=Unsqueeze];
"33 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" [id=33, type=Unsqueeze];
"34 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" [id=34, type=Unsqueeze];
"35 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" [id=35, type=Unsqueeze];
"36 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" [id=36, type=Unsqueeze];
"37 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" [id=37, type=Unsqueeze];
"38 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" [id=38, type=Unsqueeze];
"39 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" [id=39, type=Unsqueeze];
"40 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" [id=40, type=Unsqueeze];
"41 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" [id=41, type=Unsqueeze];
"42 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" [id=42, type=Unsqueeze];
"43 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" [id=43, type=Unsqueeze];
"44 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" [id=44, type=Unsqueeze];
"45 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" [id=45, type=Unsqueeze];
"46 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" [id=46, type=Unsqueeze];
"47 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" [id=47, type=Unsqueeze];
"48 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" [id=48, type=Unsqueeze];
"49 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" [id=49, type=Unsqueeze];
"50 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" [id=50, type=Unsqueeze];
"51 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" [id=51, type=Unsqueeze];
"52 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" [id=52, type=Unsqueeze];
"53 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" [id=53, type=Unsqueeze];
"54 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" [id=54, type=Unsqueeze];
"55 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" [id=55, type=Unsqueeze];
"56 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" [id=56, type=Unsqueeze];
"57 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" [id=57, type=Unsqueeze];
"58 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" [id=58, type=Unsqueeze];
"59 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" [id=59, type=Unsqueeze];
"60 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" [id=60, type=Unsqueeze];
"61 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" [id=61, type=Unsqueeze];
"62 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" [id=62, type=Unsqueeze];
"63 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" [id=63, type=Unsqueeze];
"64 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" [id=64, type=Unsqueeze];
"65 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" [id=65, type=Unsqueeze];
"66 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" [id=66, type=Unsqueeze];
"67 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" [id=67, type=Unsqueeze];
"68 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" [id=68, type=Unsqueeze];
"69 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" [id=69, type=Unsqueeze];
"70 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" [id=70, type=Unsqueeze];
"71 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" [id=71, type=Unsqueeze];
"72 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" [id=72, type=Unsqueeze];
"73 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" [id=73, type=Unsqueeze];
"74 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" [id=74, type=Unsqueeze];
"75 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" [id=75, type=Unsqueeze];
"76 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" [id=76, type=Unsqueeze];
"77 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" [id=77, type=Unsqueeze];
"78 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" [id=78, type=Unsqueeze];
"79 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" [id=79, type=Unsqueeze];
"80 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" [id=80, type=Unsqueeze];
"81 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" [id=81, type=Unsqueeze];
"82 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" [id=82, type=Unsqueeze];
"83 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" [id=83, type=Unsqueeze];
"84 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" [id=84, type=Unsqueeze];
"85 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" [id=85, type=Unsqueeze];
"86 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" [id=86, type=Unsqueeze];
"87 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" [id=87, type=Unsqueeze];
"88 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" [id=88, type=Unsqueeze];
"89 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" [id=89, type=Unsqueeze];
"90 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" [id=90, type=Unsqueeze];
"91 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" [id=91, type=Unsqueeze];
"92 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" [id=92, type=Unsqueeze];
"93 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" [id=93, type=Unsqueeze];
"94 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" [id=94, type=Unsqueeze];
"95 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" [id=95, type=Unsqueeze];
"96 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" [id=96, type=Unsqueeze];
"97 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" [id=97, type=Unsqueeze];
"98 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" [id=98, type=Unsqueeze];
"99 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" [id=99, type=Unsqueeze];
"100 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" [id=100, type=Unsqueeze];
"101 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" [id=101, type=Unsqueeze];
"102 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" [id=102, type=Unsqueeze];
"103 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" [id=103, type=Unsqueeze];
"104 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" [id=104, type=Unsqueeze];
"105 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" [id=105, type=Unsqueeze];
"106 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" [id=106, type=Unsqueeze];
"107 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" [id=107, type=Unsqueeze];
"108 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" [id=108, type=Unsqueeze];
"109 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" [id=109, type=Unsqueeze];
"110 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" [id=110, type=Unsqueeze];
"111 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" [id=111, type=Unsqueeze];
"112 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" [id=112, type=Unsqueeze];
"113 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" [id=113, type=Unsqueeze];
"114 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" [id=114, type=Unsqueeze];
"115 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" [id=115, type=Unsqueeze];
"116 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" [id=116, type=Unsqueeze];
"117 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" [id=117, type=Unsqueeze];
"118 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" [id=118, type=Unsqueeze];
"119 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" [id=119, type=Unsqueeze];
"120 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" [id=120, type=Unsqueeze];
"121 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" [id=121, type=Unsqueeze];
"122 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" [id=122, type=Unsqueeze];
"123 bert/encoder/Shape" [id=123, type=Shape];
"124 bert/encoder/Shape__12" [id=124, type=Cast];
"125 bert/encoder/strided_slice" [id=125, type=Slice];
"126 bert/encoder/strided_slice__16" [id=126, type=Squeeze];
"127 bert/encoder/strided_slice__17" [id=127, type=Cast];
"128 bert/encoder/ones/packed_Unsqueeze__18" [id=128, type=Unsqueeze];
"129 bert/encoder/ones/packed_Concat__21" [id=129, type=Concat];
"130 bert/encoder/ones__22" [id=130, type=Cast];
"131 bert/encoder/ones" [id=131, type=ConstantOfShape];
"132 bert/encoder/Reshape_13/shape_Unsqueeze__300" [id=132, type=Unsqueeze];
"133 bert/encoder/Reshape_13/shape_Unsqueeze__299" [id=133, type=Unsqueeze];
"134 bert/encoder/Reshape_1__302" [id=134, type=Cast];
"135 bert/encoder/Reshape/shape_Unsqueeze__23" [id=135, type=Unsqueeze];
"136 bert/encoder/Reshape/shape_Unsqueeze__25" [id=136, type=Unsqueeze];
"137 bert/encoder/Reshape/shape_Unsqueeze__24" [id=137, type=Unsqueeze];
"138 bert/encoder/Reshape/shape_Concat__26" [id=138, type=Concat];
"139 bert/encoder/Reshape__27" [id=139, type=Cast];
"140 bert/encoder/Reshape" [id=140, type=Reshape];
"141 bert/encoder/Cast" [id=141, type=Cast];
"142 bert/encoder/mul" [id=142, type=Mul];
"143 bert/encoder/layer_9/attention/self/ExpandDims" [id=143, type=Reshape];
"144 bert/encoder/layer_9/attention/self/sub" [id=144, type=Sub];
"145 bert/encoder/layer_9/attention/self/mul_1" [id=145, type=Mul];
"146 bert/encoder/layer_8/attention/self/ExpandDims" [id=146, type=Reshape];
"147 bert/encoder/layer_8/attention/self/sub" [id=147, type=Sub];
"148 bert/encoder/layer_8/attention/self/mul_1" [id=148, type=Mul];
"149 bert/encoder/layer_7/attention/self/ExpandDims" [id=149, type=Reshape];
"150 bert/encoder/layer_7/attention/self/sub" [id=150, type=Sub];
"151 bert/encoder/layer_7/attention/self/mul_1" [id=151, type=Mul];
"152 bert/encoder/layer_6/attention/self/ExpandDims" [id=152, type=Reshape];
"153 bert/encoder/layer_6/attention/self/sub" [id=153, type=Sub];
"154 bert/encoder/layer_6/attention/self/mul_1" [id=154, type=Mul];
"155 bert/encoder/layer_5/attention/self/ExpandDims" [id=155, type=Reshape];
"156 bert/encoder/layer_5/attention/self/sub" [id=156, type=Sub];
"157 bert/encoder/layer_5/attention/self/mul_1" [id=157, type=Mul];
"158 bert/encoder/layer_4/attention/self/ExpandDims" [id=158, type=Reshape];
"159 bert/encoder/layer_4/attention/self/sub" [id=159, type=Sub];
"160 bert/encoder/layer_4/attention/self/mul_1" [id=160, type=Mul];
"161 bert/encoder/layer_3/attention/self/ExpandDims" [id=161, type=Reshape];
"162 bert/encoder/layer_3/attention/self/sub" [id=162, type=Sub];
"163 bert/encoder/layer_3/attention/self/mul_1" [id=163, type=Mul];
"164 bert/encoder/layer_2/attention/self/ExpandDims" [id=164, type=Reshape];
"165 bert/encoder/layer_2/attention/self/sub" [id=165, type=Sub];
"166 bert/encoder/layer_2/attention/self/mul_1" [id=166, type=Mul];
"167 bert/encoder/layer_11/attention/self/ExpandDims" [id=167, type=Reshape];
"168 bert/encoder/layer_11/attention/self/sub" [id=168, type=Sub];
"169 bert/encoder/layer_11/attention/self/mul_1" [id=169, type=Mul];
"170 bert/encoder/layer_10/attention/self/ExpandDims" [id=170, type=Reshape];
"171 bert/encoder/layer_10/attention/self/sub" [id=171, type=Sub];
"172 bert/encoder/layer_10/attention/self/mul_1" [id=172, type=Mul];
"173 bert/encoder/layer_1/attention/self/ExpandDims" [id=173, type=Reshape];
"174 bert/encoder/layer_1/attention/self/sub" [id=174, type=Sub];
"175 bert/encoder/layer_1/attention/self/mul_1" [id=175, type=Mul];
"176 bert/encoder/layer_0/attention/self/ExpandDims" [id=176, type=Reshape];
"177 bert/encoder/layer_0/attention/self/sub" [id=177, type=Sub];
"178 bert/encoder/layer_0/attention/self/mul_1" [id=178, type=Mul];
"179 bert/embeddings/Slice" [id=179, type=Slice];
"180 bert/embeddings/Reshape_4__42" [id=180, type=Cast];
"181 bert/embeddings/Reshape_4" [id=181, type=Reshape];
"182 bert/embeddings/Reshape_3/shape_Unsqueeze__69" [id=182, type=Unsqueeze];
"183 bert/embeddings/Reshape_3/shape_Unsqueeze__68" [id=183, type=Unsqueeze];
"184 bert/embeddings/Reshape_2__43" [id=184, type=Cast];
"185 bert/embeddings/Reshape_2" [id=185, type=Reshape];
"186 bert/embeddings/Reshape_1/shape_Unsqueeze__57" [id=186, type=Unsqueeze];
"187 bert/embeddings/Reshape_1/shape_Unsqueeze__56" [id=187, type=Unsqueeze];
"188 bert/embeddings/Reshape__59" [id=188, type=Cast];
"189 bert/embeddings/ExpandDims" [id=189, type=Reshape];
"190 bert/embeddings/Shape" [id=190, type=Shape];
"191 bert/embeddings/Shape__49" [id=191, type=Cast];
"192 bert/embeddings/strided_slice" [id=192, type=Slice];
"193 bert/embeddings/strided_slice__53" [id=193, type=Squeeze];
"194 bert/embeddings/strided_slice__54" [id=194, type=Cast];
"195 bert/embeddings/Reshape_1/shape_Unsqueeze__55" [id=195, type=Unsqueeze];
"196 bert/embeddings/Reshape_1/shape_Concat__58" [id=196, type=Concat];
"197 bert/embeddings/Reshape_1__60" [id=197, type=Cast];
"198 bert/embeddings/Reshape" [id=198, type=Reshape];
"199 QuantizeLinear_bert/embeddings/word_embeddings^0_1" [id=199, label="199 QuantizeLinear_bert/embeddings/word_embeddings:0_1", type=QuantizeLinear];
"200 DequantizeLinear_bert/embeddings/word_embeddings^0_1" [id=200, label="200 DequantizeLinear_bert/embeddings/word_embeddings:0_1", type=DequantizeLinear];
"201 bert/embeddings/GatherV2" [id=201, type=Gather];
"202 bert/embeddings/Reshape_1" [id=202, type=Reshape];
"203 bert/embeddings/Shape_1" [id=203, type=Shape];
"204 bert/embeddings/Shape_1__61" [id=204, type=Cast];
"205 bert/embeddings/strided_slice_1" [id=205, type=Slice];
"206 bert/embeddings/strided_slice_1__65" [id=206, type=Squeeze];
"207 bert/embeddings/strided_slice_1__66" [id=207, type=Cast];
"208 bert/embeddings/Reshape_3/shape_Unsqueeze__67" [id=208, type=Unsqueeze];
"209 bert/embeddings/Reshape_3/shape_Concat__70" [id=209, type=Concat];
"210 bert/embeddings/Reshape_3__71" [id=210, type=Cast];
"211 Unsqueeze__46" [id=211, type=Unsqueeze];
"212 Unsqueeze__45" [id=212, type=Unsqueeze];
"213 Unsqueeze__44" [id=213, type=Unsqueeze];
"214 Reshape_1/shape_Unsqueeze__480" [id=214, type=Unsqueeze];
"215 Reshape_1/shape_Unsqueeze__479" [id=215, type=Unsqueeze];
"216 Reshape/shape_Unsqueeze__483" [id=216, type=Unsqueeze];
"217 MatMul__486" [id=217, type=Transpose];
"218 Concat__47" [id=218, type=Concat];
"219 bert/embeddings/one_hot" [id=219, type=OneHot];
"220 QuantizeLinear_bert/embeddings/one_hot^0_1" [id=220, label="220 QuantizeLinear_bert/embeddings/one_hot:0_1", type=QuantizeLinear];
"221 DequantizeLinear_bert/embeddings/one_hot^0_1" [id=221, label="221 DequantizeLinear_bert/embeddings/one_hot:0_1", type=DequantizeLinear];
"222 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=222, label="222 QuantizeLinear_bert/embeddings/token_type_embeddings:0_1", type=QuantizeLinear];
"223 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=223, label="223 DequantizeLinear_bert/embeddings/token_type_embeddings:0_1", type=DequantizeLinear];
"224 bert/embeddings/MatMul" [id=224, type=MatMul];
"225 bert/embeddings/Reshape_3" [id=225, type=Reshape];
"226 bert/embeddings/add" [id=226, type=Add];
"227 bert/embeddings/add_1" [id=227, type=Add];
"228 bert/embeddings/LayerNorm/moments/mean" [id=228, type=ReduceMean];
"229 bert/embeddings/LayerNorm/moments/StopGradient" [id=229, type=Identity];
"230 bert/embeddings/LayerNorm/moments/SquaredDifference" [id=230, type=Sub];
"231 bert/embeddings/LayerNorm/moments/SquaredDifference__72" [id=231, type=Mul];
"232 bert/embeddings/LayerNorm/moments/variance" [id=232, type=ReduceMean];
"233 bert/embeddings/LayerNorm/batchnorm/add" [id=233, type=Add];
"234 bert/embeddings/LayerNorm/batchnorm/Rsqrt" [id=234, type=Sqrt];
"235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" [id=235, type=Reciprocal];
"236 bert/embeddings/LayerNorm/batchnorm/mul" [id=236, type=Mul];
"237 bert/embeddings/LayerNorm/batchnorm/mul_2" [id=237, type=Mul];
"238 bert/embeddings/LayerNorm/batchnorm/sub" [id=238, type=Sub];
"239 bert/embeddings/LayerNorm/batchnorm/mul_1" [id=239, type=Mul];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" [id=240, type=Add];
"241 bert/encoder/Shape_2" [id=241, type=Shape];
"242 bert/encoder/Shape_2__76" [id=242, type=Cast];
"243 bert/encoder/strided_slice_2" [id=243, type=Slice];
"244 bert/encoder/strided_slice_2__80" [id=244, type=Squeeze];
"245 bert/encoder/strided_slice_2__81" [id=245, type=Cast];
"246 bert/encoder/layer_9/attention/self/mul_2" [id=246, type=Mul];
"247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" [id=247, type=Unsqueeze];
"248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" [id=248, type=Concat];
"249 bert/encoder/layer_9/attention/self/Reshape_3__434" [id=249, type=Cast];
"250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" [id=250, type=Unsqueeze];
"251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [id=251, type=Concat];
"252 bert/encoder/layer_9/attention/self/Reshape_2__429" [id=252, type=Cast];
"253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" [id=253, type=Unsqueeze];
"254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [id=254, type=Concat];
"255 bert/encoder/layer_9/attention/self/Reshape_1__431" [id=255, type=Cast];
"256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" [id=256, type=Unsqueeze];
"257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [id=257, type=Concat];
"258 bert/encoder/layer_9/attention/self/Reshape__430" [id=258, type=Cast];
"259 bert/encoder/layer_8/attention/self/mul_2" [id=259, type=Mul];
"260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" [id=260, type=Unsqueeze];
"261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" [id=261, type=Concat];
"262 bert/encoder/layer_8/attention/self/Reshape_3__420" [id=262, type=Cast];
"263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" [id=263, type=Unsqueeze];
"264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [id=264, type=Concat];
"265 bert/encoder/layer_8/attention/self/Reshape_2__415" [id=265, type=Cast];
"266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" [id=266, type=Unsqueeze];
"267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [id=267, type=Concat];
"268 bert/encoder/layer_8/attention/self/Reshape_1__417" [id=268, type=Cast];
"269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" [id=269, type=Unsqueeze];
"270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [id=270, type=Concat];
"271 bert/encoder/layer_8/attention/self/Reshape__416" [id=271, type=Cast];
"272 bert/encoder/layer_7/attention/self/mul_2" [id=272, type=Mul];
"273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" [id=273, type=Unsqueeze];
"274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" [id=274, type=Concat];
"275 bert/encoder/layer_7/attention/self/Reshape_3__406" [id=275, type=Cast];
"276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" [id=276, type=Unsqueeze];
"277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [id=277, type=Concat];
"278 bert/encoder/layer_7/attention/self/Reshape_2__401" [id=278, type=Cast];
"279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" [id=279, type=Unsqueeze];
"280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [id=280, type=Concat];
"281 bert/encoder/layer_7/attention/self/Reshape_1__403" [id=281, type=Cast];
"282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" [id=282, type=Unsqueeze];
"283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [id=283, type=Concat];
"284 bert/encoder/layer_7/attention/self/Reshape__402" [id=284, type=Cast];
"285 bert/encoder/layer_6/attention/self/mul_2" [id=285, type=Mul];
"286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" [id=286, type=Unsqueeze];
"287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" [id=287, type=Concat];
"288 bert/encoder/layer_6/attention/self/Reshape_3__392" [id=288, type=Cast];
"289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" [id=289, type=Unsqueeze];
"290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [id=290, type=Concat];
"291 bert/encoder/layer_6/attention/self/Reshape_2__387" [id=291, type=Cast];
"292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" [id=292, type=Unsqueeze];
"293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [id=293, type=Concat];
"294 bert/encoder/layer_6/attention/self/Reshape_1__389" [id=294, type=Cast];
"295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" [id=295, type=Unsqueeze];
"296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [id=296, type=Concat];
"297 bert/encoder/layer_6/attention/self/Reshape__388" [id=297, type=Cast];
"298 bert/encoder/layer_5/attention/self/mul_2" [id=298, type=Mul];
"299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" [id=299, type=Unsqueeze];
"300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" [id=300, type=Concat];
"301 bert/encoder/layer_5/attention/self/Reshape_3__378" [id=301, type=Cast];
"302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" [id=302, type=Unsqueeze];
"303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [id=303, type=Concat];
"304 bert/encoder/layer_5/attention/self/Reshape_2__373" [id=304, type=Cast];
"305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" [id=305, type=Unsqueeze];
"306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [id=306, type=Concat];
"307 bert/encoder/layer_5/attention/self/Reshape_1__375" [id=307, type=Cast];
"308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" [id=308, type=Unsqueeze];
"309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [id=309, type=Concat];
"310 bert/encoder/layer_5/attention/self/Reshape__374" [id=310, type=Cast];
"311 bert/encoder/layer_4/attention/self/mul_2" [id=311, type=Mul];
"312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" [id=312, type=Unsqueeze];
"313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" [id=313, type=Concat];
"314 bert/encoder/layer_4/attention/self/Reshape_3__364" [id=314, type=Cast];
"315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" [id=315, type=Unsqueeze];
"316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [id=316, type=Concat];
"317 bert/encoder/layer_4/attention/self/Reshape_2__359" [id=317, type=Cast];
"318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" [id=318, type=Unsqueeze];
"319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [id=319, type=Concat];
"320 bert/encoder/layer_4/attention/self/Reshape_1__361" [id=320, type=Cast];
"321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" [id=321, type=Unsqueeze];
"322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [id=322, type=Concat];
"323 bert/encoder/layer_4/attention/self/Reshape__360" [id=323, type=Cast];
"324 bert/encoder/layer_3/attention/self/mul_2" [id=324, type=Mul];
"325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" [id=325, type=Unsqueeze];
"326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" [id=326, type=Concat];
"327 bert/encoder/layer_3/attention/self/Reshape_3__350" [id=327, type=Cast];
"328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" [id=328, type=Unsqueeze];
"329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [id=329, type=Concat];
"330 bert/encoder/layer_3/attention/self/Reshape_2__345" [id=330, type=Cast];
"331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" [id=331, type=Unsqueeze];
"332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [id=332, type=Concat];
"333 bert/encoder/layer_3/attention/self/Reshape_1__347" [id=333, type=Cast];
"334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" [id=334, type=Unsqueeze];
"335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [id=335, type=Concat];
"336 bert/encoder/layer_3/attention/self/Reshape__346" [id=336, type=Cast];
"337 bert/encoder/layer_2/attention/self/mul_2" [id=337, type=Mul];
"338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" [id=338, type=Unsqueeze];
"339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" [id=339, type=Concat];
"340 bert/encoder/layer_2/attention/self/Reshape_3__336" [id=340, type=Cast];
"341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" [id=341, type=Unsqueeze];
"342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [id=342, type=Concat];
"343 bert/encoder/layer_2/attention/self/Reshape_2__331" [id=343, type=Cast];
"344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" [id=344, type=Unsqueeze];
"345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [id=345, type=Concat];
"346 bert/encoder/layer_2/attention/self/Reshape_1__333" [id=346, type=Cast];
"347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" [id=347, type=Unsqueeze];
"348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [id=348, type=Concat];
"349 bert/encoder/layer_2/attention/self/Reshape__332" [id=349, type=Cast];
"350 bert/encoder/layer_11/attention/self/mul_2" [id=350, type=Mul];
"351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" [id=351, type=Unsqueeze];
"352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" [id=352, type=Concat];
"353 bert/encoder/layer_11/attention/self/Reshape_3__462" [id=353, type=Cast];
"354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" [id=354, type=Unsqueeze];
"355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [id=355, type=Concat];
"356 bert/encoder/layer_11/attention/self/Reshape_2__457" [id=356, type=Cast];
"357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" [id=357, type=Unsqueeze];
"358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [id=358, type=Concat];
"359 bert/encoder/layer_11/attention/self/Reshape_1__459" [id=359, type=Cast];
"360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" [id=360, type=Unsqueeze];
"361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [id=361, type=Concat];
"362 bert/encoder/layer_11/attention/self/Reshape__458" [id=362, type=Cast];
"363 bert/encoder/layer_10/attention/self/mul_2" [id=363, type=Mul];
"364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" [id=364, type=Unsqueeze];
"365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" [id=365, type=Concat];
"366 bert/encoder/layer_10/attention/self/Reshape_3__448" [id=366, type=Cast];
"367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" [id=367, type=Unsqueeze];
"368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [id=368, type=Concat];
"369 bert/encoder/layer_10/attention/self/Reshape_2__443" [id=369, type=Cast];
"370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" [id=370, type=Unsqueeze];
"371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [id=371, type=Concat];
"372 bert/encoder/layer_10/attention/self/Reshape_1__445" [id=372, type=Cast];
"373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" [id=373, type=Unsqueeze];
"374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [id=374, type=Concat];
"375 bert/encoder/layer_10/attention/self/Reshape__444" [id=375, type=Cast];
"376 bert/encoder/layer_1/attention/self/mul_2" [id=376, type=Mul];
"377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" [id=377, type=Unsqueeze];
"378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" [id=378, type=Concat];
"379 bert/encoder/layer_1/attention/self/Reshape_3__322" [id=379, type=Cast];
"380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" [id=380, type=Unsqueeze];
"381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [id=381, type=Concat];
"382 bert/encoder/layer_1/attention/self/Reshape_2__317" [id=382, type=Cast];
"383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" [id=383, type=Unsqueeze];
"384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [id=384, type=Concat];
"385 bert/encoder/layer_1/attention/self/Reshape_1__319" [id=385, type=Cast];
"386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" [id=386, type=Unsqueeze];
"387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [id=387, type=Concat];
"388 bert/encoder/layer_1/attention/self/Reshape__318" [id=388, type=Cast];
"389 bert/encoder/layer_0/attention/self/mul_2" [id=389, type=Mul];
"390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" [id=390, type=Unsqueeze];
"391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" [id=391, type=Concat];
"392 bert/encoder/layer_0/attention/self/Reshape_3__308" [id=392, type=Cast];
"393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" [id=393, type=Unsqueeze];
"394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [id=394, type=Concat];
"395 bert/encoder/layer_0/attention/self/Reshape_2__303" [id=395, type=Cast];
"396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" [id=396, type=Unsqueeze];
"397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [id=397, type=Concat];
"398 bert/encoder/layer_0/attention/self/Reshape_1__305" [id=398, type=Cast];
"399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" [id=399, type=Unsqueeze];
"400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [id=400, type=Concat];
"401 bert/encoder/layer_0/attention/self/Reshape__304" [id=401, type=Cast];
"402 bert/encoder/Reshape_13/shape_Unsqueeze__298" [id=402, type=Unsqueeze];
"403 bert/encoder/Reshape_13/shape_Concat__301" [id=403, type=Concat];
"404 bert/encoder/Reshape_13__471" [id=404, type=Cast];
"405 bert/encoder/Reshape_1" [id=405, type=Reshape];
"406 QuantizeLinear_bert/encoder/Reshape_1^0_1" [id=406, label="406 QuantizeLinear_bert/encoder/Reshape_1:0_1", type=QuantizeLinear];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_1" [id=407, label="407 DequantizeLinear_bert/encoder/Reshape_1:0_1", type=DequantizeLinear];
"408 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=408, label="408 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1", type=QuantizeLinear];
"409 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=409, label="409 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1", type=DequantizeLinear];
"410 QuantizeLinear_bert/encoder/Reshape_1^0_2" [id=410, label="410 QuantizeLinear_bert/encoder/Reshape_1:0_2", type=QuantizeLinear];
"411 DequantizeLinear_bert/encoder/Reshape_1^0_2" [id=411, label="411 DequantizeLinear_bert/encoder/Reshape_1:0_2", type=DequantizeLinear];
"412 QuantizeLinear_bert/encoder/Reshape_1^0_3" [id=412, label="412 QuantizeLinear_bert/encoder/Reshape_1:0_3", type=QuantizeLinear];
"413 DequantizeLinear_bert/encoder/Reshape_1^0_3" [id=413, label="413 DequantizeLinear_bert/encoder/Reshape_1:0_3", type=DequantizeLinear];
"414 bert/encoder/layer_0/attention/self/value/MatMul" [id=414, type=MatMul];
"415 bert/encoder/layer_0/attention/self/value/BiasAdd" [id=415, type=Add];
"416 bert/encoder/layer_0/attention/self/Reshape_2" [id=416, type=Reshape];
"417 bert/encoder/layer_0/attention/self/transpose_2" [id=417, type=Transpose];
"418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=418, label="418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1", type=QuantizeLinear];
"419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=419, label="419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1", type=DequantizeLinear];
"420 bert/encoder/layer_0/attention/self/query/MatMul" [id=420, type=MatMul];
"421 bert/encoder/layer_0/attention/self/query/BiasAdd" [id=421, type=Add];
"422 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=422, label="422 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"423 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=423, label="423 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"424 bert/encoder/layer_0/attention/self/Reshape" [id=424, type=Reshape];
"425 bert/encoder/layer_0/attention/self/transpose" [id=425, type=Transpose];
"426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=426, label="426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1", type=QuantizeLinear];
"427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=427, label="427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1", type=DequantizeLinear];
"428 bert/encoder/layer_0/attention/self/key/MatMul" [id=428, type=MatMul];
"429 bert/encoder/layer_0/attention/self/key/BiasAdd" [id=429, type=Add];
"430 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=430, label="430 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"431 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=431, label="431 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"432 bert/encoder/layer_0/attention/self/Reshape_1" [id=432, type=Reshape];
"433 bert/encoder/layer_0/attention/self/transpose_1" [id=433, type=Transpose];
"434 bert/encoder/layer_0/attention/self/MatMul__306" [id=434, type=Transpose];
"435 bert/encoder/layer_0/attention/self/MatMul" [id=435, type=MatMul];
"436 bert/encoder/layer_0/attention/self/Mul" [id=436, type=Mul];
"437 bert/encoder/layer_0/attention/self/add" [id=437, type=Add];
"438 bert/encoder/layer_0/attention/self/Softmax" [id=438, type=Softmax];
"439 bert/encoder/layer_0/attention/self/MatMul_1" [id=439, type=MatMul];
"440 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=440, label="440 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"441 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=441, label="441 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"442 bert/encoder/layer_0/attention/self/transpose_3" [id=442, type=Transpose];
"443 bert/encoder/layer_0/attention/self/Reshape_3" [id=443, type=Reshape];
"444 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=444, label="444 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"445 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=445, label="445 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"446 bert/encoder/layer_0/attention/output/dense/MatMul" [id=446, type=MatMul];
"447 bert/encoder/layer_0/attention/output/dense/BiasAdd" [id=447, type=Add];
"448 bert/encoder/layer_0/attention/output/add" [id=448, type=Add];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" [id=449, type=ReduceMean];
"450 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" [id=450, type=Identity];
"451 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" [id=451, type=Sub];
"452 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" [id=452, type=Mul];
"453 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" [id=453, type=ReduceMean];
"454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" [id=454, type=Add];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" [id=455, type=Sqrt];
"456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" [id=456, type=Reciprocal];
"457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" [id=457, type=Mul];
"458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" [id=458, type=Mul];
"459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" [id=459, type=Sub];
"460 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" [id=460, type=Mul];
"461 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" [id=461, type=Add];
"462 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=462, label="462 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"463 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=463, label="463 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"464 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=464, label="464 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"465 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=465, label="465 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"466 bert/encoder/layer_0/intermediate/dense/MatMul" [id=466, type=MatMul];
"467 bert/encoder/layer_0/intermediate/dense/BiasAdd" [id=467, type=Add];
"468 bert/encoder/layer_0/intermediate/dense/Pow" [id=468, type=Pow];
"469 bert/encoder/layer_0/intermediate/dense/mul" [id=469, type=Mul];
"470 bert/encoder/layer_0/intermediate/dense/add" [id=470, type=Add];
"471 bert/encoder/layer_0/intermediate/dense/mul_1" [id=471, type=Mul];
"472 bert/encoder/layer_0/intermediate/dense/Tanh" [id=472, type=Tanh];
"473 bert/encoder/layer_0/intermediate/dense/add_1" [id=473, type=Add];
"474 bert/encoder/layer_0/intermediate/dense/mul_2" [id=474, type=Mul];
"475 bert/encoder/layer_0/intermediate/dense/mul_3" [id=475, type=Mul];
"476 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=476, label="476 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"477 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=477, label="477 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"478 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=478, label="478 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1", type=QuantizeLinear];
"479 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=479, label="479 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1", type=DequantizeLinear];
"480 bert/encoder/layer_0/output/dense/MatMul" [id=480, type=MatMul];
"481 bert/encoder/layer_0/output/dense/BiasAdd" [id=481, type=Add];
"482 bert/encoder/layer_0/output/add" [id=482, type=Add];
"483 bert/encoder/layer_0/output/LayerNorm/moments/mean" [id=483, type=ReduceMean];
"484 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" [id=484, type=Identity];
"485 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" [id=485, type=Sub];
"486 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" [id=486, type=Mul];
"487 bert/encoder/layer_0/output/LayerNorm/moments/variance" [id=487, type=ReduceMean];
"488 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" [id=488, type=Add];
"489 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" [id=489, type=Sqrt];
"490 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" [id=490, type=Reciprocal];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" [id=491, type=Mul];
"492 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" [id=492, type=Mul];
"493 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" [id=493, type=Sub];
"494 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" [id=494, type=Mul];
"495 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" [id=495, type=Add];
"496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=496, label="496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=497, label="497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"498 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=498, label="498 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1", type=QuantizeLinear];
"499 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=499, label="499 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1", type=DequantizeLinear];
"500 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=500, label="500 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"501 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=501, label="501 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"502 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=502, label="502 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"503 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=503, label="503 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"504 bert/encoder/layer_1/attention/self/value/MatMul" [id=504, type=MatMul];
"505 bert/encoder/layer_1/attention/self/value/BiasAdd" [id=505, type=Add];
"506 bert/encoder/layer_1/attention/self/Reshape_2" [id=506, type=Reshape];
"507 bert/encoder/layer_1/attention/self/transpose_2" [id=507, type=Transpose];
"508 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=508, label="508 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1", type=QuantizeLinear];
"509 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=509, label="509 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1", type=DequantizeLinear];
"510 bert/encoder/layer_1/attention/self/query/MatMul" [id=510, type=MatMul];
"511 bert/encoder/layer_1/attention/self/query/BiasAdd" [id=511, type=Add];
"512 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=512, label="512 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"513 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=513, label="513 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"514 bert/encoder/layer_1/attention/self/Reshape" [id=514, type=Reshape];
"515 bert/encoder/layer_1/attention/self/transpose" [id=515, type=Transpose];
"516 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=516, label="516 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1", type=QuantizeLinear];
"517 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=517, label="517 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1", type=DequantizeLinear];
"518 bert/encoder/layer_1/attention/self/key/MatMul" [id=518, type=MatMul];
"519 bert/encoder/layer_1/attention/self/key/BiasAdd" [id=519, type=Add];
"520 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=520, label="520 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"521 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=521, label="521 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"522 bert/encoder/layer_1/attention/self/Reshape_1" [id=522, type=Reshape];
"523 bert/encoder/layer_1/attention/self/transpose_1" [id=523, type=Transpose];
"524 bert/encoder/layer_1/attention/self/MatMul__320" [id=524, type=Transpose];
"525 bert/encoder/layer_1/attention/self/MatMul" [id=525, type=MatMul];
"526 bert/encoder/layer_1/attention/self/Mul" [id=526, type=Mul];
"527 bert/encoder/layer_1/attention/self/add" [id=527, type=Add];
"528 bert/encoder/layer_1/attention/self/Softmax" [id=528, type=Softmax];
"529 bert/encoder/layer_1/attention/self/MatMul_1" [id=529, type=MatMul];
"530 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=530, label="530 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"531 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=531, label="531 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"532 bert/encoder/layer_1/attention/self/transpose_3" [id=532, type=Transpose];
"533 bert/encoder/layer_1/attention/self/Reshape_3" [id=533, type=Reshape];
"534 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=534, label="534 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"535 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=535, label="535 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"536 bert/encoder/layer_1/attention/output/dense/MatMul" [id=536, type=MatMul];
"537 bert/encoder/layer_1/attention/output/dense/BiasAdd" [id=537, type=Add];
"538 bert/encoder/layer_1/attention/output/add" [id=538, type=Add];
"539 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" [id=539, type=ReduceMean];
"540 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" [id=540, type=Identity];
"541 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" [id=541, type=Sub];
"542 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" [id=542, type=Mul];
"543 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" [id=543, type=ReduceMean];
"544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" [id=544, type=Add];
"545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" [id=545, type=Sqrt];
"546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" [id=546, type=Reciprocal];
"547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" [id=547, type=Mul];
"548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" [id=548, type=Mul];
"549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" [id=549, type=Sub];
"550 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" [id=550, type=Mul];
"551 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" [id=551, type=Add];
"552 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=552, label="552 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"553 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=553, label="553 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"554 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=554, label="554 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"555 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=555, label="555 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"556 bert/encoder/layer_1/intermediate/dense/MatMul" [id=556, type=MatMul];
"557 bert/encoder/layer_1/intermediate/dense/BiasAdd" [id=557, type=Add];
"558 bert/encoder/layer_1/intermediate/dense/Pow" [id=558, type=Pow];
"559 bert/encoder/layer_1/intermediate/dense/mul" [id=559, type=Mul];
"560 bert/encoder/layer_1/intermediate/dense/add" [id=560, type=Add];
"561 bert/encoder/layer_1/intermediate/dense/mul_1" [id=561, type=Mul];
"562 bert/encoder/layer_1/intermediate/dense/Tanh" [id=562, type=Tanh];
"563 bert/encoder/layer_1/intermediate/dense/add_1" [id=563, type=Add];
"564 bert/encoder/layer_1/intermediate/dense/mul_2" [id=564, type=Mul];
"565 bert/encoder/layer_1/intermediate/dense/mul_3" [id=565, type=Mul];
"566 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=566, label="566 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"567 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=567, label="567 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"568 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=568, label="568 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1", type=QuantizeLinear];
"569 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=569, label="569 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1", type=DequantizeLinear];
"570 bert/encoder/layer_1/output/dense/MatMul" [id=570, type=MatMul];
"571 bert/encoder/layer_1/output/dense/BiasAdd" [id=571, type=Add];
"572 bert/encoder/layer_1/output/add" [id=572, type=Add];
"573 bert/encoder/layer_1/output/LayerNorm/moments/mean" [id=573, type=ReduceMean];
"574 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" [id=574, type=Identity];
"575 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" [id=575, type=Sub];
"576 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" [id=576, type=Mul];
"577 bert/encoder/layer_1/output/LayerNorm/moments/variance" [id=577, type=ReduceMean];
"578 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" [id=578, type=Add];
"579 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" [id=579, type=Sqrt];
"580 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" [id=580, type=Reciprocal];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" [id=581, type=Mul];
"582 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" [id=582, type=Mul];
"583 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" [id=583, type=Sub];
"584 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" [id=584, type=Mul];
"585 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" [id=585, type=Add];
"586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=586, label="586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=587, label="587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"588 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=588, label="588 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1", type=QuantizeLinear];
"589 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=589, label="589 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1", type=DequantizeLinear];
"590 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=590, label="590 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"591 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=591, label="591 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"592 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=592, label="592 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"593 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=593, label="593 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"594 bert/encoder/layer_2/attention/self/value/MatMul" [id=594, type=MatMul];
"595 bert/encoder/layer_2/attention/self/value/BiasAdd" [id=595, type=Add];
"596 bert/encoder/layer_2/attention/self/Reshape_2" [id=596, type=Reshape];
"597 bert/encoder/layer_2/attention/self/transpose_2" [id=597, type=Transpose];
"598 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=598, label="598 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1", type=QuantizeLinear];
"599 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=599, label="599 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1", type=DequantizeLinear];
"600 bert/encoder/layer_2/attention/self/query/MatMul" [id=600, type=MatMul];
"601 bert/encoder/layer_2/attention/self/query/BiasAdd" [id=601, type=Add];
"602 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=602, label="602 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"603 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=603, label="603 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"604 bert/encoder/layer_2/attention/self/Reshape" [id=604, type=Reshape];
"605 bert/encoder/layer_2/attention/self/transpose" [id=605, type=Transpose];
"606 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=606, label="606 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1", type=QuantizeLinear];
"607 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=607, label="607 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1", type=DequantizeLinear];
"608 bert/encoder/layer_2/attention/self/key/MatMul" [id=608, type=MatMul];
"609 bert/encoder/layer_2/attention/self/key/BiasAdd" [id=609, type=Add];
"610 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=610, label="610 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"611 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=611, label="611 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"612 bert/encoder/layer_2/attention/self/Reshape_1" [id=612, type=Reshape];
"613 bert/encoder/layer_2/attention/self/transpose_1" [id=613, type=Transpose];
"614 bert/encoder/layer_2/attention/self/MatMul__334" [id=614, type=Transpose];
"615 bert/encoder/layer_2/attention/self/MatMul" [id=615, type=MatMul];
"616 bert/encoder/layer_2/attention/self/Mul" [id=616, type=Mul];
"617 bert/encoder/layer_2/attention/self/add" [id=617, type=Add];
"618 bert/encoder/layer_2/attention/self/Softmax" [id=618, type=Softmax];
"619 bert/encoder/layer_2/attention/self/MatMul_1" [id=619, type=MatMul];
"620 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=620, label="620 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"621 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=621, label="621 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"622 bert/encoder/layer_2/attention/self/transpose_3" [id=622, type=Transpose];
"623 bert/encoder/layer_2/attention/self/Reshape_3" [id=623, type=Reshape];
"624 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=624, label="624 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"625 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=625, label="625 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"626 bert/encoder/layer_2/attention/output/dense/MatMul" [id=626, type=MatMul];
"627 bert/encoder/layer_2/attention/output/dense/BiasAdd" [id=627, type=Add];
"628 bert/encoder/layer_2/attention/output/add" [id=628, type=Add];
"629 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" [id=629, type=ReduceMean];
"630 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" [id=630, type=Identity];
"631 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" [id=631, type=Sub];
"632 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" [id=632, type=Mul];
"633 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" [id=633, type=ReduceMean];
"634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" [id=634, type=Add];
"635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" [id=635, type=Sqrt];
"636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" [id=636, type=Reciprocal];
"637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" [id=637, type=Mul];
"638 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" [id=638, type=Mul];
"639 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" [id=639, type=Sub];
"640 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" [id=640, type=Mul];
"641 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" [id=641, type=Add];
"642 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=642, label="642 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"643 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=643, label="643 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"644 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=644, label="644 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"645 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=645, label="645 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"646 bert/encoder/layer_2/intermediate/dense/MatMul" [id=646, type=MatMul];
"647 bert/encoder/layer_2/intermediate/dense/BiasAdd" [id=647, type=Add];
"648 bert/encoder/layer_2/intermediate/dense/Pow" [id=648, type=Pow];
"649 bert/encoder/layer_2/intermediate/dense/mul" [id=649, type=Mul];
"650 bert/encoder/layer_2/intermediate/dense/add" [id=650, type=Add];
"651 bert/encoder/layer_2/intermediate/dense/mul_1" [id=651, type=Mul];
"652 bert/encoder/layer_2/intermediate/dense/Tanh" [id=652, type=Tanh];
"653 bert/encoder/layer_2/intermediate/dense/add_1" [id=653, type=Add];
"654 bert/encoder/layer_2/intermediate/dense/mul_2" [id=654, type=Mul];
"655 bert/encoder/layer_2/intermediate/dense/mul_3" [id=655, type=Mul];
"656 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=656, label="656 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"657 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=657, label="657 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"658 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=658, label="658 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1", type=QuantizeLinear];
"659 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=659, label="659 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1", type=DequantizeLinear];
"660 bert/encoder/layer_2/output/dense/MatMul" [id=660, type=MatMul];
"661 bert/encoder/layer_2/output/dense/BiasAdd" [id=661, type=Add];
"662 bert/encoder/layer_2/output/add" [id=662, type=Add];
"663 bert/encoder/layer_2/output/LayerNorm/moments/mean" [id=663, type=ReduceMean];
"664 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" [id=664, type=Identity];
"665 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" [id=665, type=Sub];
"666 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" [id=666, type=Mul];
"667 bert/encoder/layer_2/output/LayerNorm/moments/variance" [id=667, type=ReduceMean];
"668 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" [id=668, type=Add];
"669 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" [id=669, type=Sqrt];
"670 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" [id=670, type=Reciprocal];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" [id=671, type=Mul];
"672 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" [id=672, type=Mul];
"673 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" [id=673, type=Sub];
"674 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" [id=674, type=Mul];
"675 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" [id=675, type=Add];
"676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=676, label="676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=677, label="677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"678 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=678, label="678 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1", type=QuantizeLinear];
"679 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=679, label="679 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1", type=DequantizeLinear];
"680 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=680, label="680 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"681 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=681, label="681 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"682 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=682, label="682 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"683 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=683, label="683 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"684 bert/encoder/layer_3/attention/self/value/MatMul" [id=684, type=MatMul];
"685 bert/encoder/layer_3/attention/self/value/BiasAdd" [id=685, type=Add];
"686 bert/encoder/layer_3/attention/self/Reshape_2" [id=686, type=Reshape];
"687 bert/encoder/layer_3/attention/self/transpose_2" [id=687, type=Transpose];
"688 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=688, label="688 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1", type=QuantizeLinear];
"689 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=689, label="689 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1", type=DequantizeLinear];
"690 bert/encoder/layer_3/attention/self/query/MatMul" [id=690, type=MatMul];
"691 bert/encoder/layer_3/attention/self/query/BiasAdd" [id=691, type=Add];
"692 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=692, label="692 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"693 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=693, label="693 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"694 bert/encoder/layer_3/attention/self/Reshape" [id=694, type=Reshape];
"695 bert/encoder/layer_3/attention/self/transpose" [id=695, type=Transpose];
"696 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=696, label="696 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1", type=QuantizeLinear];
"697 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=697, label="697 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1", type=DequantizeLinear];
"698 bert/encoder/layer_3/attention/self/key/MatMul" [id=698, type=MatMul];
"699 bert/encoder/layer_3/attention/self/key/BiasAdd" [id=699, type=Add];
"700 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=700, label="700 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"701 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=701, label="701 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"702 bert/encoder/layer_3/attention/self/Reshape_1" [id=702, type=Reshape];
"703 bert/encoder/layer_3/attention/self/transpose_1" [id=703, type=Transpose];
"704 bert/encoder/layer_3/attention/self/MatMul__348" [id=704, type=Transpose];
"705 bert/encoder/layer_3/attention/self/MatMul" [id=705, type=MatMul];
"706 bert/encoder/layer_3/attention/self/Mul" [id=706, type=Mul];
"707 bert/encoder/layer_3/attention/self/add" [id=707, type=Add];
"708 bert/encoder/layer_3/attention/self/Softmax" [id=708, type=Softmax];
"709 bert/encoder/layer_3/attention/self/MatMul_1" [id=709, type=MatMul];
"710 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=710, label="710 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"711 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=711, label="711 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"712 bert/encoder/layer_3/attention/self/transpose_3" [id=712, type=Transpose];
"713 bert/encoder/layer_3/attention/self/Reshape_3" [id=713, type=Reshape];
"714 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=714, label="714 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"715 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=715, label="715 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"716 bert/encoder/layer_3/attention/output/dense/MatMul" [id=716, type=MatMul];
"717 bert/encoder/layer_3/attention/output/dense/BiasAdd" [id=717, type=Add];
"718 bert/encoder/layer_3/attention/output/add" [id=718, type=Add];
"719 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" [id=719, type=ReduceMean];
"720 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" [id=720, type=Identity];
"721 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" [id=721, type=Sub];
"722 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" [id=722, type=Mul];
"723 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" [id=723, type=ReduceMean];
"724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" [id=724, type=Add];
"725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" [id=725, type=Sqrt];
"726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" [id=726, type=Reciprocal];
"727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" [id=727, type=Mul];
"728 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" [id=728, type=Mul];
"729 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" [id=729, type=Sub];
"730 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" [id=730, type=Mul];
"731 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" [id=731, type=Add];
"732 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=732, label="732 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"733 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=733, label="733 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"734 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=734, label="734 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"735 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=735, label="735 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"736 bert/encoder/layer_3/intermediate/dense/MatMul" [id=736, type=MatMul];
"737 bert/encoder/layer_3/intermediate/dense/BiasAdd" [id=737, type=Add];
"738 bert/encoder/layer_3/intermediate/dense/Pow" [id=738, type=Pow];
"739 bert/encoder/layer_3/intermediate/dense/mul" [id=739, type=Mul];
"740 bert/encoder/layer_3/intermediate/dense/add" [id=740, type=Add];
"741 bert/encoder/layer_3/intermediate/dense/mul_1" [id=741, type=Mul];
"742 bert/encoder/layer_3/intermediate/dense/Tanh" [id=742, type=Tanh];
"743 bert/encoder/layer_3/intermediate/dense/add_1" [id=743, type=Add];
"744 bert/encoder/layer_3/intermediate/dense/mul_2" [id=744, type=Mul];
"745 bert/encoder/layer_3/intermediate/dense/mul_3" [id=745, type=Mul];
"746 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=746, label="746 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"747 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=747, label="747 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"748 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=748, label="748 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1", type=QuantizeLinear];
"749 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=749, label="749 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1", type=DequantizeLinear];
"750 bert/encoder/layer_3/output/dense/MatMul" [id=750, type=MatMul];
"751 bert/encoder/layer_3/output/dense/BiasAdd" [id=751, type=Add];
"752 bert/encoder/layer_3/output/add" [id=752, type=Add];
"753 bert/encoder/layer_3/output/LayerNorm/moments/mean" [id=753, type=ReduceMean];
"754 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" [id=754, type=Identity];
"755 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" [id=755, type=Sub];
"756 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" [id=756, type=Mul];
"757 bert/encoder/layer_3/output/LayerNorm/moments/variance" [id=757, type=ReduceMean];
"758 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" [id=758, type=Add];
"759 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" [id=759, type=Sqrt];
"760 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" [id=760, type=Reciprocal];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" [id=761, type=Mul];
"762 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" [id=762, type=Mul];
"763 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" [id=763, type=Sub];
"764 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" [id=764, type=Mul];
"765 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" [id=765, type=Add];
"766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=766, label="766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=767, label="767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"768 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=768, label="768 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1", type=QuantizeLinear];
"769 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=769, label="769 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1", type=DequantizeLinear];
"770 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=770, label="770 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"771 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=771, label="771 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"772 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=772, label="772 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"773 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=773, label="773 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"774 bert/encoder/layer_4/attention/self/value/MatMul" [id=774, type=MatMul];
"775 bert/encoder/layer_4/attention/self/value/BiasAdd" [id=775, type=Add];
"776 bert/encoder/layer_4/attention/self/Reshape_2" [id=776, type=Reshape];
"777 bert/encoder/layer_4/attention/self/transpose_2" [id=777, type=Transpose];
"778 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=778, label="778 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1", type=QuantizeLinear];
"779 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=779, label="779 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1", type=DequantizeLinear];
"780 bert/encoder/layer_4/attention/self/query/MatMul" [id=780, type=MatMul];
"781 bert/encoder/layer_4/attention/self/query/BiasAdd" [id=781, type=Add];
"782 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=782, label="782 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"783 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=783, label="783 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"784 bert/encoder/layer_4/attention/self/Reshape" [id=784, type=Reshape];
"785 bert/encoder/layer_4/attention/self/transpose" [id=785, type=Transpose];
"786 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=786, label="786 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1", type=QuantizeLinear];
"787 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=787, label="787 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1", type=DequantizeLinear];
"788 bert/encoder/layer_4/attention/self/key/MatMul" [id=788, type=MatMul];
"789 bert/encoder/layer_4/attention/self/key/BiasAdd" [id=789, type=Add];
"790 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=790, label="790 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"791 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=791, label="791 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"792 bert/encoder/layer_4/attention/self/Reshape_1" [id=792, type=Reshape];
"793 bert/encoder/layer_4/attention/self/transpose_1" [id=793, type=Transpose];
"794 bert/encoder/layer_4/attention/self/MatMul__362" [id=794, type=Transpose];
"795 bert/encoder/layer_4/attention/self/MatMul" [id=795, type=MatMul];
"796 bert/encoder/layer_4/attention/self/Mul" [id=796, type=Mul];
"797 bert/encoder/layer_4/attention/self/add" [id=797, type=Add];
"798 bert/encoder/layer_4/attention/self/Softmax" [id=798, type=Softmax];
"799 bert/encoder/layer_4/attention/self/MatMul_1" [id=799, type=MatMul];
"800 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=800, label="800 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"801 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=801, label="801 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"802 bert/encoder/layer_4/attention/self/transpose_3" [id=802, type=Transpose];
"803 bert/encoder/layer_4/attention/self/Reshape_3" [id=803, type=Reshape];
"804 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=804, label="804 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"805 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=805, label="805 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"806 bert/encoder/layer_4/attention/output/dense/MatMul" [id=806, type=MatMul];
"807 bert/encoder/layer_4/attention/output/dense/BiasAdd" [id=807, type=Add];
"808 bert/encoder/layer_4/attention/output/add" [id=808, type=Add];
"809 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" [id=809, type=ReduceMean];
"810 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" [id=810, type=Identity];
"811 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" [id=811, type=Sub];
"812 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" [id=812, type=Mul];
"813 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" [id=813, type=ReduceMean];
"814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" [id=814, type=Add];
"815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" [id=815, type=Sqrt];
"816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" [id=816, type=Reciprocal];
"817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" [id=817, type=Mul];
"818 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" [id=818, type=Mul];
"819 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" [id=819, type=Sub];
"820 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" [id=820, type=Mul];
"821 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" [id=821, type=Add];
"822 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=822, label="822 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"823 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=823, label="823 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"824 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=824, label="824 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"825 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=825, label="825 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"826 bert/encoder/layer_4/intermediate/dense/MatMul" [id=826, type=MatMul];
"827 bert/encoder/layer_4/intermediate/dense/BiasAdd" [id=827, type=Add];
"828 bert/encoder/layer_4/intermediate/dense/Pow" [id=828, type=Pow];
"829 bert/encoder/layer_4/intermediate/dense/mul" [id=829, type=Mul];
"830 bert/encoder/layer_4/intermediate/dense/add" [id=830, type=Add];
"831 bert/encoder/layer_4/intermediate/dense/mul_1" [id=831, type=Mul];
"832 bert/encoder/layer_4/intermediate/dense/Tanh" [id=832, type=Tanh];
"833 bert/encoder/layer_4/intermediate/dense/add_1" [id=833, type=Add];
"834 bert/encoder/layer_4/intermediate/dense/mul_2" [id=834, type=Mul];
"835 bert/encoder/layer_4/intermediate/dense/mul_3" [id=835, type=Mul];
"836 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=836, label="836 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"837 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=837, label="837 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"838 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=838, label="838 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1", type=QuantizeLinear];
"839 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=839, label="839 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1", type=DequantizeLinear];
"840 bert/encoder/layer_4/output/dense/MatMul" [id=840, type=MatMul];
"841 bert/encoder/layer_4/output/dense/BiasAdd" [id=841, type=Add];
"842 bert/encoder/layer_4/output/add" [id=842, type=Add];
"843 bert/encoder/layer_4/output/LayerNorm/moments/mean" [id=843, type=ReduceMean];
"844 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" [id=844, type=Identity];
"845 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" [id=845, type=Sub];
"846 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" [id=846, type=Mul];
"847 bert/encoder/layer_4/output/LayerNorm/moments/variance" [id=847, type=ReduceMean];
"848 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" [id=848, type=Add];
"849 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" [id=849, type=Sqrt];
"850 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" [id=850, type=Reciprocal];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" [id=851, type=Mul];
"852 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" [id=852, type=Mul];
"853 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" [id=853, type=Sub];
"854 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" [id=854, type=Mul];
"855 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" [id=855, type=Add];
"856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=856, label="856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=857, label="857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"858 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=858, label="858 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1", type=QuantizeLinear];
"859 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=859, label="859 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1", type=DequantizeLinear];
"860 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=860, label="860 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"861 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=861, label="861 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"862 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=862, label="862 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"863 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=863, label="863 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"864 bert/encoder/layer_5/attention/self/value/MatMul" [id=864, type=MatMul];
"865 bert/encoder/layer_5/attention/self/value/BiasAdd" [id=865, type=Add];
"866 bert/encoder/layer_5/attention/self/Reshape_2" [id=866, type=Reshape];
"867 bert/encoder/layer_5/attention/self/transpose_2" [id=867, type=Transpose];
"868 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=868, label="868 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1", type=QuantizeLinear];
"869 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=869, label="869 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1", type=DequantizeLinear];
"870 bert/encoder/layer_5/attention/self/query/MatMul" [id=870, type=MatMul];
"871 bert/encoder/layer_5/attention/self/query/BiasAdd" [id=871, type=Add];
"872 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=872, label="872 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"873 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=873, label="873 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"874 bert/encoder/layer_5/attention/self/Reshape" [id=874, type=Reshape];
"875 bert/encoder/layer_5/attention/self/transpose" [id=875, type=Transpose];
"876 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=876, label="876 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1", type=QuantizeLinear];
"877 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=877, label="877 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1", type=DequantizeLinear];
"878 bert/encoder/layer_5/attention/self/key/MatMul" [id=878, type=MatMul];
"879 bert/encoder/layer_5/attention/self/key/BiasAdd" [id=879, type=Add];
"880 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=880, label="880 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"881 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=881, label="881 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"882 bert/encoder/layer_5/attention/self/Reshape_1" [id=882, type=Reshape];
"883 bert/encoder/layer_5/attention/self/transpose_1" [id=883, type=Transpose];
"884 bert/encoder/layer_5/attention/self/MatMul__376" [id=884, type=Transpose];
"885 bert/encoder/layer_5/attention/self/MatMul" [id=885, type=MatMul];
"886 bert/encoder/layer_5/attention/self/Mul" [id=886, type=Mul];
"887 bert/encoder/layer_5/attention/self/add" [id=887, type=Add];
"888 bert/encoder/layer_5/attention/self/Softmax" [id=888, type=Softmax];
"889 bert/encoder/layer_5/attention/self/MatMul_1" [id=889, type=MatMul];
"890 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=890, label="890 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"891 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=891, label="891 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"892 bert/encoder/layer_5/attention/self/transpose_3" [id=892, type=Transpose];
"893 bert/encoder/layer_5/attention/self/Reshape_3" [id=893, type=Reshape];
"894 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=894, label="894 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"895 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=895, label="895 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"896 bert/encoder/layer_5/attention/output/dense/MatMul" [id=896, type=MatMul];
"897 bert/encoder/layer_5/attention/output/dense/BiasAdd" [id=897, type=Add];
"898 bert/encoder/layer_5/attention/output/add" [id=898, type=Add];
"899 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" [id=899, type=ReduceMean];
"900 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" [id=900, type=Identity];
"901 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" [id=901, type=Sub];
"902 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" [id=902, type=Mul];
"903 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" [id=903, type=ReduceMean];
"904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" [id=904, type=Add];
"905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" [id=905, type=Sqrt];
"906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" [id=906, type=Reciprocal];
"907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" [id=907, type=Mul];
"908 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" [id=908, type=Mul];
"909 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" [id=909, type=Sub];
"910 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" [id=910, type=Mul];
"911 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" [id=911, type=Add];
"912 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=912, label="912 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"913 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=913, label="913 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"914 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=914, label="914 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"915 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=915, label="915 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"916 bert/encoder/layer_5/intermediate/dense/MatMul" [id=916, type=MatMul];
"917 bert/encoder/layer_5/intermediate/dense/BiasAdd" [id=917, type=Add];
"918 bert/encoder/layer_5/intermediate/dense/Pow" [id=918, type=Pow];
"919 bert/encoder/layer_5/intermediate/dense/mul" [id=919, type=Mul];
"920 bert/encoder/layer_5/intermediate/dense/add" [id=920, type=Add];
"921 bert/encoder/layer_5/intermediate/dense/mul_1" [id=921, type=Mul];
"922 bert/encoder/layer_5/intermediate/dense/Tanh" [id=922, type=Tanh];
"923 bert/encoder/layer_5/intermediate/dense/add_1" [id=923, type=Add];
"924 bert/encoder/layer_5/intermediate/dense/mul_2" [id=924, type=Mul];
"925 bert/encoder/layer_5/intermediate/dense/mul_3" [id=925, type=Mul];
"926 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=926, label="926 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"927 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=927, label="927 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"928 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=928, label="928 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1", type=QuantizeLinear];
"929 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=929, label="929 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1", type=DequantizeLinear];
"930 bert/encoder/layer_5/output/dense/MatMul" [id=930, type=MatMul];
"931 bert/encoder/layer_5/output/dense/BiasAdd" [id=931, type=Add];
"932 bert/encoder/layer_5/output/add" [id=932, type=Add];
"933 bert/encoder/layer_5/output/LayerNorm/moments/mean" [id=933, type=ReduceMean];
"934 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" [id=934, type=Identity];
"935 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" [id=935, type=Sub];
"936 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" [id=936, type=Mul];
"937 bert/encoder/layer_5/output/LayerNorm/moments/variance" [id=937, type=ReduceMean];
"938 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" [id=938, type=Add];
"939 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" [id=939, type=Sqrt];
"940 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" [id=940, type=Reciprocal];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" [id=941, type=Mul];
"942 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" [id=942, type=Mul];
"943 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" [id=943, type=Sub];
"944 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" [id=944, type=Mul];
"945 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" [id=945, type=Add];
"946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=946, label="946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=947, label="947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"948 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=948, label="948 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1", type=QuantizeLinear];
"949 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=949, label="949 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1", type=DequantizeLinear];
"950 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=950, label="950 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"951 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=951, label="951 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"952 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=952, label="952 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"953 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=953, label="953 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"954 bert/encoder/layer_6/attention/self/value/MatMul" [id=954, type=MatMul];
"955 bert/encoder/layer_6/attention/self/value/BiasAdd" [id=955, type=Add];
"956 bert/encoder/layer_6/attention/self/Reshape_2" [id=956, type=Reshape];
"957 bert/encoder/layer_6/attention/self/transpose_2" [id=957, type=Transpose];
"958 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=958, label="958 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1", type=QuantizeLinear];
"959 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=959, label="959 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1", type=DequantizeLinear];
"960 bert/encoder/layer_6/attention/self/query/MatMul" [id=960, type=MatMul];
"961 bert/encoder/layer_6/attention/self/query/BiasAdd" [id=961, type=Add];
"962 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=962, label="962 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"963 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=963, label="963 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"964 bert/encoder/layer_6/attention/self/Reshape" [id=964, type=Reshape];
"965 bert/encoder/layer_6/attention/self/transpose" [id=965, type=Transpose];
"966 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=966, label="966 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1", type=QuantizeLinear];
"967 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=967, label="967 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1", type=DequantizeLinear];
"968 bert/encoder/layer_6/attention/self/key/MatMul" [id=968, type=MatMul];
"969 bert/encoder/layer_6/attention/self/key/BiasAdd" [id=969, type=Add];
"970 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=970, label="970 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"971 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=971, label="971 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"972 bert/encoder/layer_6/attention/self/Reshape_1" [id=972, type=Reshape];
"973 bert/encoder/layer_6/attention/self/transpose_1" [id=973, type=Transpose];
"974 bert/encoder/layer_6/attention/self/MatMul__390" [id=974, type=Transpose];
"975 bert/encoder/layer_6/attention/self/MatMul" [id=975, type=MatMul];
"976 bert/encoder/layer_6/attention/self/Mul" [id=976, type=Mul];
"977 bert/encoder/layer_6/attention/self/add" [id=977, type=Add];
"978 bert/encoder/layer_6/attention/self/Softmax" [id=978, type=Softmax];
"979 bert/encoder/layer_6/attention/self/MatMul_1" [id=979, type=MatMul];
"980 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=980, label="980 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"981 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=981, label="981 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"982 bert/encoder/layer_6/attention/self/transpose_3" [id=982, type=Transpose];
"983 bert/encoder/layer_6/attention/self/Reshape_3" [id=983, type=Reshape];
"984 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=984, label="984 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"985 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=985, label="985 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"986 bert/encoder/layer_6/attention/output/dense/MatMul" [id=986, type=MatMul];
"987 bert/encoder/layer_6/attention/output/dense/BiasAdd" [id=987, type=Add];
"988 bert/encoder/layer_6/attention/output/add" [id=988, type=Add];
"989 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" [id=989, type=ReduceMean];
"990 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" [id=990, type=Identity];
"991 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" [id=991, type=Sub];
"992 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" [id=992, type=Mul];
"993 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" [id=993, type=ReduceMean];
"994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" [id=994, type=Add];
"995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" [id=995, type=Sqrt];
"996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" [id=996, type=Reciprocal];
"997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" [id=997, type=Mul];
"998 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" [id=998, type=Mul];
"999 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" [id=999, type=Sub];
"1000 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" [id=1000, type=Mul];
"1001 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" [id=1001, type=Add];
"1002 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1002, label="1002 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1003 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1003, label="1003 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1004 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1004, label="1004 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1005 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1005, label="1005 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1006 bert/encoder/layer_6/intermediate/dense/MatMul" [id=1006, type=MatMul];
"1007 bert/encoder/layer_6/intermediate/dense/BiasAdd" [id=1007, type=Add];
"1008 bert/encoder/layer_6/intermediate/dense/Pow" [id=1008, type=Pow];
"1009 bert/encoder/layer_6/intermediate/dense/mul" [id=1009, type=Mul];
"1010 bert/encoder/layer_6/intermediate/dense/add" [id=1010, type=Add];
"1011 bert/encoder/layer_6/intermediate/dense/mul_1" [id=1011, type=Mul];
"1012 bert/encoder/layer_6/intermediate/dense/Tanh" [id=1012, type=Tanh];
"1013 bert/encoder/layer_6/intermediate/dense/add_1" [id=1013, type=Add];
"1014 bert/encoder/layer_6/intermediate/dense/mul_2" [id=1014, type=Mul];
"1015 bert/encoder/layer_6/intermediate/dense/mul_3" [id=1015, type=Mul];
"1016 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1016, label="1016 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1017 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1017, label="1017 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1018 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1018, label="1018 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1", type=QuantizeLinear];
"1019 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1019, label="1019 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1", type=DequantizeLinear];
"1020 bert/encoder/layer_6/output/dense/MatMul" [id=1020, type=MatMul];
"1021 bert/encoder/layer_6/output/dense/BiasAdd" [id=1021, type=Add];
"1022 bert/encoder/layer_6/output/add" [id=1022, type=Add];
"1023 bert/encoder/layer_6/output/LayerNorm/moments/mean" [id=1023, type=ReduceMean];
"1024 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" [id=1024, type=Identity];
"1025 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" [id=1025, type=Sub];
"1026 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" [id=1026, type=Mul];
"1027 bert/encoder/layer_6/output/LayerNorm/moments/variance" [id=1027, type=ReduceMean];
"1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" [id=1028, type=Add];
"1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" [id=1029, type=Sqrt];
"1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" [id=1030, type=Reciprocal];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" [id=1031, type=Mul];
"1032 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" [id=1032, type=Mul];
"1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" [id=1033, type=Sub];
"1034 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" [id=1034, type=Mul];
"1035 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" [id=1035, type=Add];
"1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1036, label="1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1037, label="1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1038 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1038, label="1038 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1039 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1039, label="1039 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1040 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1040, label="1040 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1041 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1041, label="1041 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1042 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1042, label="1042 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1043 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1043, label="1043 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1044 bert/encoder/layer_7/attention/self/value/MatMul" [id=1044, type=MatMul];
"1045 bert/encoder/layer_7/attention/self/value/BiasAdd" [id=1045, type=Add];
"1046 bert/encoder/layer_7/attention/self/Reshape_2" [id=1046, type=Reshape];
"1047 bert/encoder/layer_7/attention/self/transpose_2" [id=1047, type=Transpose];
"1048 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1048, label="1048 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1049 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1049, label="1049 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1050 bert/encoder/layer_7/attention/self/query/MatMul" [id=1050, type=MatMul];
"1051 bert/encoder/layer_7/attention/self/query/BiasAdd" [id=1051, type=Add];
"1052 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1052, label="1052 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1053 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1053, label="1053 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1054 bert/encoder/layer_7/attention/self/Reshape" [id=1054, type=Reshape];
"1055 bert/encoder/layer_7/attention/self/transpose" [id=1055, type=Transpose];
"1056 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1056, label="1056 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1057 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1057, label="1057 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1058 bert/encoder/layer_7/attention/self/key/MatMul" [id=1058, type=MatMul];
"1059 bert/encoder/layer_7/attention/self/key/BiasAdd" [id=1059, type=Add];
"1060 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1060, label="1060 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1061 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1061, label="1061 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1062 bert/encoder/layer_7/attention/self/Reshape_1" [id=1062, type=Reshape];
"1063 bert/encoder/layer_7/attention/self/transpose_1" [id=1063, type=Transpose];
"1064 bert/encoder/layer_7/attention/self/MatMul__404" [id=1064, type=Transpose];
"1065 bert/encoder/layer_7/attention/self/MatMul" [id=1065, type=MatMul];
"1066 bert/encoder/layer_7/attention/self/Mul" [id=1066, type=Mul];
"1067 bert/encoder/layer_7/attention/self/add" [id=1067, type=Add];
"1068 bert/encoder/layer_7/attention/self/Softmax" [id=1068, type=Softmax];
"1069 bert/encoder/layer_7/attention/self/MatMul_1" [id=1069, type=MatMul];
"1070 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1070, label="1070 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1071 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1071, label="1071 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1072 bert/encoder/layer_7/attention/self/transpose_3" [id=1072, type=Transpose];
"1073 bert/encoder/layer_7/attention/self/Reshape_3" [id=1073, type=Reshape];
"1074 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1074, label="1074 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1075 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1075, label="1075 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1076 bert/encoder/layer_7/attention/output/dense/MatMul" [id=1076, type=MatMul];
"1077 bert/encoder/layer_7/attention/output/dense/BiasAdd" [id=1077, type=Add];
"1078 bert/encoder/layer_7/attention/output/add" [id=1078, type=Add];
"1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" [id=1079, type=ReduceMean];
"1080 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" [id=1080, type=Identity];
"1081 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" [id=1081, type=Sub];
"1082 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" [id=1082, type=Mul];
"1083 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" [id=1083, type=ReduceMean];
"1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" [id=1084, type=Add];
"1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1085, type=Sqrt];
"1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" [id=1086, type=Reciprocal];
"1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" [id=1087, type=Mul];
"1088 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" [id=1088, type=Mul];
"1089 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" [id=1089, type=Sub];
"1090 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" [id=1090, type=Mul];
"1091 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" [id=1091, type=Add];
"1092 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1092, label="1092 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1093 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1093, label="1093 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1094 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1094, label="1094 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1095 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1095, label="1095 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1096 bert/encoder/layer_7/intermediate/dense/MatMul" [id=1096, type=MatMul];
"1097 bert/encoder/layer_7/intermediate/dense/BiasAdd" [id=1097, type=Add];
"1098 bert/encoder/layer_7/intermediate/dense/Pow" [id=1098, type=Pow];
"1099 bert/encoder/layer_7/intermediate/dense/mul" [id=1099, type=Mul];
"1100 bert/encoder/layer_7/intermediate/dense/add" [id=1100, type=Add];
"1101 bert/encoder/layer_7/intermediate/dense/mul_1" [id=1101, type=Mul];
"1102 bert/encoder/layer_7/intermediate/dense/Tanh" [id=1102, type=Tanh];
"1103 bert/encoder/layer_7/intermediate/dense/add_1" [id=1103, type=Add];
"1104 bert/encoder/layer_7/intermediate/dense/mul_2" [id=1104, type=Mul];
"1105 bert/encoder/layer_7/intermediate/dense/mul_3" [id=1105, type=Mul];
"1106 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1106, label="1106 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1107 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1107, label="1107 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1108 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1108, label="1108 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1", type=QuantizeLinear];
"1109 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1109, label="1109 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1", type=DequantizeLinear];
"1110 bert/encoder/layer_7/output/dense/MatMul" [id=1110, type=MatMul];
"1111 bert/encoder/layer_7/output/dense/BiasAdd" [id=1111, type=Add];
"1112 bert/encoder/layer_7/output/add" [id=1112, type=Add];
"1113 bert/encoder/layer_7/output/LayerNorm/moments/mean" [id=1113, type=ReduceMean];
"1114 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" [id=1114, type=Identity];
"1115 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" [id=1115, type=Sub];
"1116 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" [id=1116, type=Mul];
"1117 bert/encoder/layer_7/output/LayerNorm/moments/variance" [id=1117, type=ReduceMean];
"1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" [id=1118, type=Add];
"1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" [id=1119, type=Sqrt];
"1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" [id=1120, type=Reciprocal];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" [id=1121, type=Mul];
"1122 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" [id=1122, type=Mul];
"1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" [id=1123, type=Sub];
"1124 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" [id=1124, type=Mul];
"1125 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" [id=1125, type=Add];
"1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1126, label="1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1127, label="1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1128 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1128, label="1128 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1129 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1129, label="1129 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1130 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1130, label="1130 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1131 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1131, label="1131 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1132 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1132, label="1132 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1133 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1133, label="1133 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1134 bert/encoder/layer_8/attention/self/value/MatMul" [id=1134, type=MatMul];
"1135 bert/encoder/layer_8/attention/self/value/BiasAdd" [id=1135, type=Add];
"1136 bert/encoder/layer_8/attention/self/Reshape_2" [id=1136, type=Reshape];
"1137 bert/encoder/layer_8/attention/self/transpose_2" [id=1137, type=Transpose];
"1138 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1138, label="1138 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1139 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1139, label="1139 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1140 bert/encoder/layer_8/attention/self/query/MatMul" [id=1140, type=MatMul];
"1141 bert/encoder/layer_8/attention/self/query/BiasAdd" [id=1141, type=Add];
"1142 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1142, label="1142 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1143 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1143, label="1143 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1144 bert/encoder/layer_8/attention/self/Reshape" [id=1144, type=Reshape];
"1145 bert/encoder/layer_8/attention/self/transpose" [id=1145, type=Transpose];
"1146 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1146, label="1146 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1147 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1147, label="1147 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1148 bert/encoder/layer_8/attention/self/key/MatMul" [id=1148, type=MatMul];
"1149 bert/encoder/layer_8/attention/self/key/BiasAdd" [id=1149, type=Add];
"1150 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1150, label="1150 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1151 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1151, label="1151 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1152 bert/encoder/layer_8/attention/self/Reshape_1" [id=1152, type=Reshape];
"1153 bert/encoder/layer_8/attention/self/transpose_1" [id=1153, type=Transpose];
"1154 bert/encoder/layer_8/attention/self/MatMul__418" [id=1154, type=Transpose];
"1155 bert/encoder/layer_8/attention/self/MatMul" [id=1155, type=MatMul];
"1156 bert/encoder/layer_8/attention/self/Mul" [id=1156, type=Mul];
"1157 bert/encoder/layer_8/attention/self/add" [id=1157, type=Add];
"1158 bert/encoder/layer_8/attention/self/Softmax" [id=1158, type=Softmax];
"1159 bert/encoder/layer_8/attention/self/MatMul_1" [id=1159, type=MatMul];
"1160 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1160, label="1160 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1161 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1161, label="1161 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1162 bert/encoder/layer_8/attention/self/transpose_3" [id=1162, type=Transpose];
"1163 bert/encoder/layer_8/attention/self/Reshape_3" [id=1163, type=Reshape];
"1164 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1164, label="1164 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1165 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1165, label="1165 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1166 bert/encoder/layer_8/attention/output/dense/MatMul" [id=1166, type=MatMul];
"1167 bert/encoder/layer_8/attention/output/dense/BiasAdd" [id=1167, type=Add];
"1168 bert/encoder/layer_8/attention/output/add" [id=1168, type=Add];
"1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" [id=1169, type=ReduceMean];
"1170 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" [id=1170, type=Identity];
"1171 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" [id=1171, type=Sub];
"1172 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" [id=1172, type=Mul];
"1173 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" [id=1173, type=ReduceMean];
"1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" [id=1174, type=Add];
"1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1175, type=Sqrt];
"1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" [id=1176, type=Reciprocal];
"1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" [id=1177, type=Mul];
"1178 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" [id=1178, type=Mul];
"1179 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" [id=1179, type=Sub];
"1180 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" [id=1180, type=Mul];
"1181 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" [id=1181, type=Add];
"1182 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1182, label="1182 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1183 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1183, label="1183 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1184 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1184, label="1184 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1185 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1185, label="1185 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1186 bert/encoder/layer_8/intermediate/dense/MatMul" [id=1186, type=MatMul];
"1187 bert/encoder/layer_8/intermediate/dense/BiasAdd" [id=1187, type=Add];
"1188 bert/encoder/layer_8/intermediate/dense/Pow" [id=1188, type=Pow];
"1189 bert/encoder/layer_8/intermediate/dense/mul" [id=1189, type=Mul];
"1190 bert/encoder/layer_8/intermediate/dense/add" [id=1190, type=Add];
"1191 bert/encoder/layer_8/intermediate/dense/mul_1" [id=1191, type=Mul];
"1192 bert/encoder/layer_8/intermediate/dense/Tanh" [id=1192, type=Tanh];
"1193 bert/encoder/layer_8/intermediate/dense/add_1" [id=1193, type=Add];
"1194 bert/encoder/layer_8/intermediate/dense/mul_2" [id=1194, type=Mul];
"1195 bert/encoder/layer_8/intermediate/dense/mul_3" [id=1195, type=Mul];
"1196 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1196, label="1196 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1197 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1197, label="1197 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1198 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1198, label="1198 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1", type=QuantizeLinear];
"1199 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1199, label="1199 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1", type=DequantizeLinear];
"1200 bert/encoder/layer_8/output/dense/MatMul" [id=1200, type=MatMul];
"1201 bert/encoder/layer_8/output/dense/BiasAdd" [id=1201, type=Add];
"1202 bert/encoder/layer_8/output/add" [id=1202, type=Add];
"1203 bert/encoder/layer_8/output/LayerNorm/moments/mean" [id=1203, type=ReduceMean];
"1204 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" [id=1204, type=Identity];
"1205 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" [id=1205, type=Sub];
"1206 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" [id=1206, type=Mul];
"1207 bert/encoder/layer_8/output/LayerNorm/moments/variance" [id=1207, type=ReduceMean];
"1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" [id=1208, type=Add];
"1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" [id=1209, type=Sqrt];
"1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" [id=1210, type=Reciprocal];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" [id=1211, type=Mul];
"1212 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" [id=1212, type=Mul];
"1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" [id=1213, type=Sub];
"1214 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" [id=1214, type=Mul];
"1215 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" [id=1215, type=Add];
"1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1216, label="1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1217, label="1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1218 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1218, label="1218 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1219 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1219, label="1219 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1220 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1220, label="1220 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1221 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1221, label="1221 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1222 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1222, label="1222 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1223 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1223, label="1223 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1224 bert/encoder/layer_9/attention/self/value/MatMul" [id=1224, type=MatMul];
"1225 bert/encoder/layer_9/attention/self/value/BiasAdd" [id=1225, type=Add];
"1226 bert/encoder/layer_9/attention/self/Reshape_2" [id=1226, type=Reshape];
"1227 bert/encoder/layer_9/attention/self/transpose_2" [id=1227, type=Transpose];
"1228 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1228, label="1228 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1229 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1229, label="1229 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1230 bert/encoder/layer_9/attention/self/query/MatMul" [id=1230, type=MatMul];
"1231 bert/encoder/layer_9/attention/self/query/BiasAdd" [id=1231, type=Add];
"1232 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1232, label="1232 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1233 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1233, label="1233 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1234 bert/encoder/layer_9/attention/self/Reshape" [id=1234, type=Reshape];
"1235 bert/encoder/layer_9/attention/self/transpose" [id=1235, type=Transpose];
"1236 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1236, label="1236 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1237 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1237, label="1237 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1238 bert/encoder/layer_9/attention/self/key/MatMul" [id=1238, type=MatMul];
"1239 bert/encoder/layer_9/attention/self/key/BiasAdd" [id=1239, type=Add];
"1240 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1240, label="1240 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1241 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1241, label="1241 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1242 bert/encoder/layer_9/attention/self/Reshape_1" [id=1242, type=Reshape];
"1243 bert/encoder/layer_9/attention/self/transpose_1" [id=1243, type=Transpose];
"1244 bert/encoder/layer_9/attention/self/MatMul__432" [id=1244, type=Transpose];
"1245 bert/encoder/layer_9/attention/self/MatMul" [id=1245, type=MatMul];
"1246 bert/encoder/layer_9/attention/self/Mul" [id=1246, type=Mul];
"1247 bert/encoder/layer_9/attention/self/add" [id=1247, type=Add];
"1248 bert/encoder/layer_9/attention/self/Softmax" [id=1248, type=Softmax];
"1249 bert/encoder/layer_9/attention/self/MatMul_1" [id=1249, type=MatMul];
"1250 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1250, label="1250 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1251 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1251, label="1251 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1252 bert/encoder/layer_9/attention/self/transpose_3" [id=1252, type=Transpose];
"1253 bert/encoder/layer_9/attention/self/Reshape_3" [id=1253, type=Reshape];
"1254 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1254, label="1254 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1255 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1255, label="1255 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1256 bert/encoder/layer_9/attention/output/dense/MatMul" [id=1256, type=MatMul];
"1257 bert/encoder/layer_9/attention/output/dense/BiasAdd" [id=1257, type=Add];
"1258 bert/encoder/layer_9/attention/output/add" [id=1258, type=Add];
"1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" [id=1259, type=ReduceMean];
"1260 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" [id=1260, type=Identity];
"1261 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" [id=1261, type=Sub];
"1262 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" [id=1262, type=Mul];
"1263 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" [id=1263, type=ReduceMean];
"1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" [id=1264, type=Add];
"1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1265, type=Sqrt];
"1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" [id=1266, type=Reciprocal];
"1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" [id=1267, type=Mul];
"1268 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" [id=1268, type=Mul];
"1269 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" [id=1269, type=Sub];
"1270 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" [id=1270, type=Mul];
"1271 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" [id=1271, type=Add];
"1272 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1272, label="1272 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1273 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1273, label="1273 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1274 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1274, label="1274 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1275 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1275, label="1275 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1276 bert/encoder/layer_9/intermediate/dense/MatMul" [id=1276, type=MatMul];
"1277 bert/encoder/layer_9/intermediate/dense/BiasAdd" [id=1277, type=Add];
"1278 bert/encoder/layer_9/intermediate/dense/Pow" [id=1278, type=Pow];
"1279 bert/encoder/layer_9/intermediate/dense/mul" [id=1279, type=Mul];
"1280 bert/encoder/layer_9/intermediate/dense/add" [id=1280, type=Add];
"1281 bert/encoder/layer_9/intermediate/dense/mul_1" [id=1281, type=Mul];
"1282 bert/encoder/layer_9/intermediate/dense/Tanh" [id=1282, type=Tanh];
"1283 bert/encoder/layer_9/intermediate/dense/add_1" [id=1283, type=Add];
"1284 bert/encoder/layer_9/intermediate/dense/mul_2" [id=1284, type=Mul];
"1285 bert/encoder/layer_9/intermediate/dense/mul_3" [id=1285, type=Mul];
"1286 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1286, label="1286 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1287 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1287, label="1287 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1288 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1288, label="1288 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1", type=QuantizeLinear];
"1289 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1289, label="1289 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1", type=DequantizeLinear];
"1290 bert/encoder/layer_9/output/dense/MatMul" [id=1290, type=MatMul];
"1291 bert/encoder/layer_9/output/dense/BiasAdd" [id=1291, type=Add];
"1292 bert/encoder/layer_9/output/add" [id=1292, type=Add];
"1293 bert/encoder/layer_9/output/LayerNorm/moments/mean" [id=1293, type=ReduceMean];
"1294 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" [id=1294, type=Identity];
"1295 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" [id=1295, type=Sub];
"1296 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" [id=1296, type=Mul];
"1297 bert/encoder/layer_9/output/LayerNorm/moments/variance" [id=1297, type=ReduceMean];
"1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" [id=1298, type=Add];
"1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" [id=1299, type=Sqrt];
"1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" [id=1300, type=Reciprocal];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" [id=1301, type=Mul];
"1302 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" [id=1302, type=Mul];
"1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" [id=1303, type=Sub];
"1304 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" [id=1304, type=Mul];
"1305 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" [id=1305, type=Add];
"1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1306, label="1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1307, label="1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1308 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1308, label="1308 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1309 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1309, label="1309 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1310 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1310, label="1310 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1311 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1311, label="1311 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1312 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1312, label="1312 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1313 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1313, label="1313 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1314 bert/encoder/layer_10/attention/self/value/MatMul" [id=1314, type=MatMul];
"1315 bert/encoder/layer_10/attention/self/value/BiasAdd" [id=1315, type=Add];
"1316 bert/encoder/layer_10/attention/self/Reshape_2" [id=1316, type=Reshape];
"1317 bert/encoder/layer_10/attention/self/transpose_2" [id=1317, type=Transpose];
"1318 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1318, label="1318 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1319 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1319, label="1319 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1320 bert/encoder/layer_10/attention/self/query/MatMul" [id=1320, type=MatMul];
"1321 bert/encoder/layer_10/attention/self/query/BiasAdd" [id=1321, type=Add];
"1322 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1322, label="1322 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1323 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1323, label="1323 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1324 bert/encoder/layer_10/attention/self/Reshape" [id=1324, type=Reshape];
"1325 bert/encoder/layer_10/attention/self/transpose" [id=1325, type=Transpose];
"1326 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1326, label="1326 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1327 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1327, label="1327 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1328 bert/encoder/layer_10/attention/self/key/MatMul" [id=1328, type=MatMul];
"1329 bert/encoder/layer_10/attention/self/key/BiasAdd" [id=1329, type=Add];
"1330 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1330, label="1330 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1331 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1331, label="1331 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1332 bert/encoder/layer_10/attention/self/Reshape_1" [id=1332, type=Reshape];
"1333 bert/encoder/layer_10/attention/self/transpose_1" [id=1333, type=Transpose];
"1334 bert/encoder/layer_10/attention/self/MatMul__446" [id=1334, type=Transpose];
"1335 bert/encoder/layer_10/attention/self/MatMul" [id=1335, type=MatMul];
"1336 bert/encoder/layer_10/attention/self/Mul" [id=1336, type=Mul];
"1337 bert/encoder/layer_10/attention/self/add" [id=1337, type=Add];
"1338 bert/encoder/layer_10/attention/self/Softmax" [id=1338, type=Softmax];
"1339 bert/encoder/layer_10/attention/self/MatMul_1" [id=1339, type=MatMul];
"1340 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1340, label="1340 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1341 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1341, label="1341 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1342 bert/encoder/layer_10/attention/self/transpose_3" [id=1342, type=Transpose];
"1343 bert/encoder/layer_10/attention/self/Reshape_3" [id=1343, type=Reshape];
"1344 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1344, label="1344 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1345 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1345, label="1345 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1346 bert/encoder/layer_10/attention/output/dense/MatMul" [id=1346, type=MatMul];
"1347 bert/encoder/layer_10/attention/output/dense/BiasAdd" [id=1347, type=Add];
"1348 bert/encoder/layer_10/attention/output/add" [id=1348, type=Add];
"1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" [id=1349, type=ReduceMean];
"1350 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" [id=1350, type=Identity];
"1351 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" [id=1351, type=Sub];
"1352 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" [id=1352, type=Mul];
"1353 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" [id=1353, type=ReduceMean];
"1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" [id=1354, type=Add];
"1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1355, type=Sqrt];
"1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" [id=1356, type=Reciprocal];
"1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" [id=1357, type=Mul];
"1358 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" [id=1358, type=Mul];
"1359 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" [id=1359, type=Sub];
"1360 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" [id=1360, type=Mul];
"1361 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" [id=1361, type=Add];
"1362 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1362, label="1362 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1363 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1363, label="1363 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1364 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1364, label="1364 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1365 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1365, label="1365 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1366 bert/encoder/layer_10/intermediate/dense/MatMul" [id=1366, type=MatMul];
"1367 bert/encoder/layer_10/intermediate/dense/BiasAdd" [id=1367, type=Add];
"1368 bert/encoder/layer_10/intermediate/dense/Pow" [id=1368, type=Pow];
"1369 bert/encoder/layer_10/intermediate/dense/mul" [id=1369, type=Mul];
"1370 bert/encoder/layer_10/intermediate/dense/add" [id=1370, type=Add];
"1371 bert/encoder/layer_10/intermediate/dense/mul_1" [id=1371, type=Mul];
"1372 bert/encoder/layer_10/intermediate/dense/Tanh" [id=1372, type=Tanh];
"1373 bert/encoder/layer_10/intermediate/dense/add_1" [id=1373, type=Add];
"1374 bert/encoder/layer_10/intermediate/dense/mul_2" [id=1374, type=Mul];
"1375 bert/encoder/layer_10/intermediate/dense/mul_3" [id=1375, type=Mul];
"1376 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1376, label="1376 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1377 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1377, label="1377 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1378 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1378, label="1378 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1", type=QuantizeLinear];
"1379 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1379, label="1379 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1", type=DequantizeLinear];
"1380 bert/encoder/layer_10/output/dense/MatMul" [id=1380, type=MatMul];
"1381 bert/encoder/layer_10/output/dense/BiasAdd" [id=1381, type=Add];
"1382 bert/encoder/layer_10/output/add" [id=1382, type=Add];
"1383 bert/encoder/layer_10/output/LayerNorm/moments/mean" [id=1383, type=ReduceMean];
"1384 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" [id=1384, type=Identity];
"1385 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" [id=1385, type=Sub];
"1386 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" [id=1386, type=Mul];
"1387 bert/encoder/layer_10/output/LayerNorm/moments/variance" [id=1387, type=ReduceMean];
"1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" [id=1388, type=Add];
"1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" [id=1389, type=Sqrt];
"1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" [id=1390, type=Reciprocal];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" [id=1391, type=Mul];
"1392 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" [id=1392, type=Mul];
"1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" [id=1393, type=Sub];
"1394 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" [id=1394, type=Mul];
"1395 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" [id=1395, type=Add];
"1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1396, label="1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1397, label="1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1398 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1398, label="1398 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1399 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1399, label="1399 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1400 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1400, label="1400 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1401 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1401, label="1401 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1402 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1402, label="1402 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1403 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1403, label="1403 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1404 bert/encoder/layer_11/attention/self/value/MatMul" [id=1404, type=MatMul];
"1405 bert/encoder/layer_11/attention/self/value/BiasAdd" [id=1405, type=Add];
"1406 bert/encoder/layer_11/attention/self/Reshape_2" [id=1406, type=Reshape];
"1407 bert/encoder/layer_11/attention/self/transpose_2" [id=1407, type=Transpose];
"1408 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1408, label="1408 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1409 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1409, label="1409 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1410 bert/encoder/layer_11/attention/self/query/MatMul" [id=1410, type=MatMul];
"1411 bert/encoder/layer_11/attention/self/query/BiasAdd" [id=1411, type=Add];
"1412 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1412, label="1412 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1413 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1413, label="1413 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1414 bert/encoder/layer_11/attention/self/Reshape" [id=1414, type=Reshape];
"1415 bert/encoder/layer_11/attention/self/transpose" [id=1415, type=Transpose];
"1416 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1416, label="1416 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1417 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1417, label="1417 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1418 bert/encoder/layer_11/attention/self/key/MatMul" [id=1418, type=MatMul];
"1419 bert/encoder/layer_11/attention/self/key/BiasAdd" [id=1419, type=Add];
"1420 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1420, label="1420 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1421 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1421, label="1421 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1422 bert/encoder/layer_11/attention/self/Reshape_1" [id=1422, type=Reshape];
"1423 bert/encoder/layer_11/attention/self/transpose_1" [id=1423, type=Transpose];
"1424 bert/encoder/layer_11/attention/self/MatMul__460" [id=1424, type=Transpose];
"1425 bert/encoder/layer_11/attention/self/MatMul" [id=1425, type=MatMul];
"1426 bert/encoder/layer_11/attention/self/Mul" [id=1426, type=Mul];
"1427 bert/encoder/layer_11/attention/self/add" [id=1427, type=Add];
"1428 bert/encoder/layer_11/attention/self/Softmax" [id=1428, type=Softmax];
"1429 bert/encoder/layer_11/attention/self/MatMul_1" [id=1429, type=MatMul];
"1430 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1430, label="1430 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1431 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1431, label="1431 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1432 bert/encoder/layer_11/attention/self/transpose_3" [id=1432, type=Transpose];
"1433 bert/encoder/layer_11/attention/self/Reshape_3" [id=1433, type=Reshape];
"1434 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1434, label="1434 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1435 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1435, label="1435 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1436 bert/encoder/layer_11/attention/output/dense/MatMul" [id=1436, type=MatMul];
"1437 bert/encoder/layer_11/attention/output/dense/BiasAdd" [id=1437, type=Add];
"1438 bert/encoder/layer_11/attention/output/add" [id=1438, type=Add];
"1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" [id=1439, type=ReduceMean];
"1440 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" [id=1440, type=Identity];
"1441 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" [id=1441, type=Sub];
"1442 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" [id=1442, type=Mul];
"1443 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" [id=1443, type=ReduceMean];
"1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" [id=1444, type=Add];
"1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1445, type=Sqrt];
"1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" [id=1446, type=Reciprocal];
"1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" [id=1447, type=Mul];
"1448 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" [id=1448, type=Mul];
"1449 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" [id=1449, type=Sub];
"1450 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" [id=1450, type=Mul];
"1451 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" [id=1451, type=Add];
"1452 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1452, label="1452 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1453 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1453, label="1453 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1454 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1454, label="1454 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1455 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1455, label="1455 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1456 bert/encoder/layer_11/intermediate/dense/MatMul" [id=1456, type=MatMul];
"1457 bert/encoder/layer_11/intermediate/dense/BiasAdd" [id=1457, type=Add];
"1458 bert/encoder/layer_11/intermediate/dense/Pow" [id=1458, type=Pow];
"1459 bert/encoder/layer_11/intermediate/dense/mul" [id=1459, type=Mul];
"1460 bert/encoder/layer_11/intermediate/dense/add" [id=1460, type=Add];
"1461 bert/encoder/layer_11/intermediate/dense/mul_1" [id=1461, type=Mul];
"1462 bert/encoder/layer_11/intermediate/dense/Tanh" [id=1462, type=Tanh];
"1463 bert/encoder/layer_11/intermediate/dense/add_1" [id=1463, type=Add];
"1464 bert/encoder/layer_11/intermediate/dense/mul_2" [id=1464, type=Mul];
"1465 bert/encoder/layer_11/intermediate/dense/mul_3" [id=1465, type=Mul];
"1466 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1466, label="1466 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1467 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1467, label="1467 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1468 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1468, label="1468 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1", type=QuantizeLinear];
"1469 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1469, label="1469 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1", type=DequantizeLinear];
"1470 bert/encoder/layer_11/output/dense/MatMul" [id=1470, type=MatMul];
"1471 bert/encoder/layer_11/output/dense/BiasAdd" [id=1471, type=Add];
"1472 bert/encoder/layer_11/output/add" [id=1472, type=Add];
"1473 bert/encoder/layer_11/output/LayerNorm/moments/mean" [id=1473, type=ReduceMean];
"1474 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" [id=1474, type=Identity];
"1475 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" [id=1475, type=Sub];
"1476 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" [id=1476, type=Mul];
"1477 bert/encoder/layer_11/output/LayerNorm/moments/variance" [id=1477, type=ReduceMean];
"1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" [id=1478, type=Add];
"1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" [id=1479, type=Sqrt];
"1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" [id=1480, type=Reciprocal];
"1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" [id=1481, type=Mul];
"1482 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" [id=1482, type=Mul];
"1483 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" [id=1483, type=Sub];
"1484 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" [id=1484, type=Mul];
"1485 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" [id=1485, type=Add];
"1486 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1486, label="1486 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1487 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1487, label="1487 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1488 bert/encoder/Reshape_13" [id=1488, type=Reshape];
"1489 Shape_1" [id=1489, type=Shape];
"1490 Shape_1__472" [id=1490, type=Cast];
"1491 strided_slice_1" [id=1491, type=Slice];
"1492 strided_slice_1__476" [id=1492, type=Squeeze];
"1493 strided_slice_1__477" [id=1493, type=Cast];
"1494 mul" [id=1494, type=Mul];
"1495 Reshape/shape_Unsqueeze__482" [id=1495, type=Unsqueeze];
"1496 Reshape/shape_Concat__484" [id=1496, type=Concat];
"1497 Reshape__485" [id=1497, type=Cast];
"1498 Reshape_1/shape_Unsqueeze__478" [id=1498, type=Unsqueeze];
"1499 Reshape_1/shape_Concat__481" [id=1499, type=Concat];
"1500 Reshape_1__487" [id=1500, type=Cast];
"1501 Reshape" [id=1501, type=Reshape];
"1502 QuantizeLinear_MatMul__486^0_1" [id=1502, label="1502 QuantizeLinear_MatMul__486:0_1", type=QuantizeLinear];
"1503 DequantizeLinear_MatMul__486^0_1" [id=1503, label="1503 DequantizeLinear_MatMul__486:0_1", type=DequantizeLinear];
"1504 MatMul" [id=1504, type=MatMul];
"1505 BiasAdd" [id=1505, type=Add];
"1506 Reshape_1" [id=1506, type=Reshape];
"1507 transpose" [id=1507, type=Transpose];
"1508 unstack" [id=1508, type=Split];
"1509 unstack__490" [id=1509, type=Squeeze];
"1510 unstack_graph_outputs_Identity__4" [id=1510, type=Identity];
"1511 unstack__488" [id=1511, type=Squeeze];
"1512 unstack_graph_outputs_Identity__7" [id=1512, type=Identity];
"1513 nncf_model_input_0" [id=1513, type=nncf_model_input];
"1514 nncf_model_input_1" [id=1514, type=nncf_model_input];
"1515 nncf_model_input_2" [id=1515, type=nncf_model_input];
"1516 nncf_model_input_3" [id=1516, type=nncf_model_input];
"1517 nncf_model_output_0" [id=1517, type=nncf_model_output];
"1518 nncf_model_output_1" [id=1518, type=nncf_model_output];
"1519 nncf_model_output_2" [id=1519, type=nncf_model_output];
"0 unique_ids_graph_outputs_Identity__10" -> "1519 nncf_model_output_2"  [label="[-1]", style=dashed];
"1 bert/encoder/ones/packed_Unsqueeze__20" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"2 bert/encoder/ones/packed_Unsqueeze__19" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"3 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" -> "248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84"  [label="[1]", style=dashed];
"4 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"5 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"6 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"7 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"8 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"9 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"10 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"11 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"12 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"13 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" -> "261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102"  [label="[1]", style=dashed];
"14 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"15 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"16 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"17 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"18 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"19 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"20 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"21 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"22 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"23 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" -> "274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120"  [label="[1]", style=dashed];
"24 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"25 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"26 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"27 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"28 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"29 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"30 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"31 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"32 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"33 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" -> "287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138"  [label="[1]", style=dashed];
"34 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"35 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"36 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"37 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"38 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"39 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"40 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"41 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"42 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"43 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" -> "300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156"  [label="[1]", style=dashed];
"44 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"45 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"46 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"47 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"48 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"49 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"50 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"51 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"52 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"53 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" -> "313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174"  [label="[1]", style=dashed];
"54 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"55 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"56 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"57 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"58 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"59 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"60 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"61 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"62 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"63 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" -> "326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192"  [label="[1]", style=dashed];
"64 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"65 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"66 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"67 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"68 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"69 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"70 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"71 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"72 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"73 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" -> "339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210"  [label="[1]", style=dashed];
"74 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"75 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"76 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"77 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"78 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"79 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"80 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"81 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"82 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"83 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" -> "352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228"  [label="[1]", style=dashed];
"84 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"85 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"86 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"87 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"88 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"89 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"90 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"91 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"92 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"93 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" -> "365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246"  [label="[1]", style=dashed];
"94 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"95 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"96 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"97 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"98 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"99 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"100 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"101 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"102 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"103 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" -> "378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264"  [label="[1]", style=dashed];
"104 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"105 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"106 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"107 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"108 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"109 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"110 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"111 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"112 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"113 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" -> "391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282"  [label="[1]", style=dashed];
"114 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"115 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"116 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"117 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"118 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"119 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"120 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"121 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"122 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"123 bert/encoder/Shape" -> "124 bert/encoder/Shape__12"  [label="[2]", style=dashed];
"124 bert/encoder/Shape__12" -> "125 bert/encoder/strided_slice"  [label="[2]", style=solid];
"125 bert/encoder/strided_slice" -> "126 bert/encoder/strided_slice__16"  [label="[1]", style=solid];
"126 bert/encoder/strided_slice__16" -> "127 bert/encoder/strided_slice__17"  [label="[]", style=solid];
"127 bert/encoder/strided_slice__17" -> "128 bert/encoder/ones/packed_Unsqueeze__18"  [label="[]", style=dashed];
"127 bert/encoder/strided_slice__17" -> "135 bert/encoder/Reshape/shape_Unsqueeze__23"  [label="[]", style=dashed];
"128 bert/encoder/ones/packed_Unsqueeze__18" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"129 bert/encoder/ones/packed_Concat__21" -> "130 bert/encoder/ones__22"  [label="[3]", style=dashed];
"130 bert/encoder/ones__22" -> "131 bert/encoder/ones"  [label="[3]", style=dashed];
"131 bert/encoder/ones" -> "142 bert/encoder/mul"  [label="[-1, -1, -1]", style=solid];
"132 bert/encoder/Reshape_13/shape_Unsqueeze__300" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"133 bert/encoder/Reshape_13/shape_Unsqueeze__299" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"134 bert/encoder/Reshape_1__302" -> "405 bert/encoder/Reshape_1"  [label="[2]", style=dashed];
"135 bert/encoder/Reshape/shape_Unsqueeze__23" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"136 bert/encoder/Reshape/shape_Unsqueeze__25" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"137 bert/encoder/Reshape/shape_Unsqueeze__24" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"138 bert/encoder/Reshape/shape_Concat__26" -> "139 bert/encoder/Reshape__27"  [label="[3]", style=dashed];
"139 bert/encoder/Reshape__27" -> "140 bert/encoder/Reshape"  [label="[3]", style=dashed];
"140 bert/encoder/Reshape" -> "141 bert/encoder/Cast"  [label="[]", style=dashed];
"141 bert/encoder/Cast" -> "142 bert/encoder/mul"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "143 bert/encoder/layer_9/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "146 bert/encoder/layer_8/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "149 bert/encoder/layer_7/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "152 bert/encoder/layer_6/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "155 bert/encoder/layer_5/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "158 bert/encoder/layer_4/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "161 bert/encoder/layer_3/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "164 bert/encoder/layer_2/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "167 bert/encoder/layer_11/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "170 bert/encoder/layer_10/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "173 bert/encoder/layer_1/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "176 bert/encoder/layer_0/attention/self/ExpandDims"  [label="[]", style=solid];
"143 bert/encoder/layer_9/attention/self/ExpandDims" -> "144 bert/encoder/layer_9/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"144 bert/encoder/layer_9/attention/self/sub" -> "145 bert/encoder/layer_9/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"145 bert/encoder/layer_9/attention/self/mul_1" -> "1247 bert/encoder/layer_9/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"146 bert/encoder/layer_8/attention/self/ExpandDims" -> "147 bert/encoder/layer_8/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"147 bert/encoder/layer_8/attention/self/sub" -> "148 bert/encoder/layer_8/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"148 bert/encoder/layer_8/attention/self/mul_1" -> "1157 bert/encoder/layer_8/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"149 bert/encoder/layer_7/attention/self/ExpandDims" -> "150 bert/encoder/layer_7/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"150 bert/encoder/layer_7/attention/self/sub" -> "151 bert/encoder/layer_7/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"151 bert/encoder/layer_7/attention/self/mul_1" -> "1067 bert/encoder/layer_7/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"152 bert/encoder/layer_6/attention/self/ExpandDims" -> "153 bert/encoder/layer_6/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"153 bert/encoder/layer_6/attention/self/sub" -> "154 bert/encoder/layer_6/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"154 bert/encoder/layer_6/attention/self/mul_1" -> "977 bert/encoder/layer_6/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"155 bert/encoder/layer_5/attention/self/ExpandDims" -> "156 bert/encoder/layer_5/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"156 bert/encoder/layer_5/attention/self/sub" -> "157 bert/encoder/layer_5/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"157 bert/encoder/layer_5/attention/self/mul_1" -> "887 bert/encoder/layer_5/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"158 bert/encoder/layer_4/attention/self/ExpandDims" -> "159 bert/encoder/layer_4/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"159 bert/encoder/layer_4/attention/self/sub" -> "160 bert/encoder/layer_4/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"160 bert/encoder/layer_4/attention/self/mul_1" -> "797 bert/encoder/layer_4/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"161 bert/encoder/layer_3/attention/self/ExpandDims" -> "162 bert/encoder/layer_3/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"162 bert/encoder/layer_3/attention/self/sub" -> "163 bert/encoder/layer_3/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"163 bert/encoder/layer_3/attention/self/mul_1" -> "707 bert/encoder/layer_3/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"164 bert/encoder/layer_2/attention/self/ExpandDims" -> "165 bert/encoder/layer_2/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"165 bert/encoder/layer_2/attention/self/sub" -> "166 bert/encoder/layer_2/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"166 bert/encoder/layer_2/attention/self/mul_1" -> "617 bert/encoder/layer_2/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"167 bert/encoder/layer_11/attention/self/ExpandDims" -> "168 bert/encoder/layer_11/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"168 bert/encoder/layer_11/attention/self/sub" -> "169 bert/encoder/layer_11/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"169 bert/encoder/layer_11/attention/self/mul_1" -> "1427 bert/encoder/layer_11/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"170 bert/encoder/layer_10/attention/self/ExpandDims" -> "171 bert/encoder/layer_10/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"171 bert/encoder/layer_10/attention/self/sub" -> "172 bert/encoder/layer_10/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"172 bert/encoder/layer_10/attention/self/mul_1" -> "1337 bert/encoder/layer_10/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"173 bert/encoder/layer_1/attention/self/ExpandDims" -> "174 bert/encoder/layer_1/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"174 bert/encoder/layer_1/attention/self/sub" -> "175 bert/encoder/layer_1/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"175 bert/encoder/layer_1/attention/self/mul_1" -> "527 bert/encoder/layer_1/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"176 bert/encoder/layer_0/attention/self/ExpandDims" -> "177 bert/encoder/layer_0/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"177 bert/encoder/layer_0/attention/self/sub" -> "178 bert/encoder/layer_0/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"178 bert/encoder/layer_0/attention/self/mul_1" -> "437 bert/encoder/layer_0/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"179 bert/embeddings/Slice" -> "181 bert/embeddings/Reshape_4"  [label="[256, 768]", style=solid];
"180 bert/embeddings/Reshape_4__42" -> "181 bert/embeddings/Reshape_4"  [label="[3]", style=dashed];
"181 bert/embeddings/Reshape_4" -> "227 bert/embeddings/add_1"  [label="[]", style=solid];
"182 bert/embeddings/Reshape_3/shape_Unsqueeze__69" -> "209 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"183 bert/embeddings/Reshape_3/shape_Unsqueeze__68" -> "209 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"184 bert/embeddings/Reshape_2__43" -> "185 bert/embeddings/Reshape_2"  [label="[1]", style=dashed];
"185 bert/embeddings/Reshape_2" -> "219 bert/embeddings/one_hot"  [label="[]", style=dashed];
"186 bert/embeddings/Reshape_1/shape_Unsqueeze__57" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"187 bert/embeddings/Reshape_1/shape_Unsqueeze__56" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"188 bert/embeddings/Reshape__59" -> "198 bert/embeddings/Reshape"  [label="[1]", style=dashed];
"189 bert/embeddings/ExpandDims" -> "190 bert/embeddings/Shape"  [label="[-1, 256, 1]", style=dashed];
"189 bert/embeddings/ExpandDims" -> "198 bert/embeddings/Reshape"  [label="[-1, 256, 1]", style=dashed];
"190 bert/embeddings/Shape" -> "191 bert/embeddings/Shape__49"  [label="[3]", style=dashed];
"191 bert/embeddings/Shape__49" -> "192 bert/embeddings/strided_slice"  [label="[3]", style=solid];
"192 bert/embeddings/strided_slice" -> "193 bert/embeddings/strided_slice__53"  [label="[1]", style=solid];
"193 bert/embeddings/strided_slice__53" -> "194 bert/embeddings/strided_slice__54"  [label="[]", style=solid];
"194 bert/embeddings/strided_slice__54" -> "195 bert/embeddings/Reshape_1/shape_Unsqueeze__55"  [label="[]", style=dashed];
"195 bert/embeddings/Reshape_1/shape_Unsqueeze__55" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"196 bert/embeddings/Reshape_1/shape_Concat__58" -> "197 bert/embeddings/Reshape_1__60"  [label="[3]", style=dashed];
"197 bert/embeddings/Reshape_1__60" -> "202 bert/embeddings/Reshape_1"  [label="[3]", style=dashed];
"198 bert/embeddings/Reshape" -> "201 bert/embeddings/GatherV2"  [label="[]", style=dashed];
"199 QuantizeLinear_bert/embeddings/word_embeddings^0_1" -> "200 DequantizeLinear_bert/embeddings/word_embeddings^0_1"  [label="[30522, 768]", style=dashed];
"200 DequantizeLinear_bert/embeddings/word_embeddings^0_1" -> "201 bert/embeddings/GatherV2"  [label="[30522, 768]", style=solid];
"201 bert/embeddings/GatherV2" -> "202 bert/embeddings/Reshape_1"  [label="[]", style=solid];
"202 bert/embeddings/Reshape_1" -> "203 bert/embeddings/Shape_1"  [label="[]", style=solid];
"202 bert/embeddings/Reshape_1" -> "226 bert/embeddings/add"  [label="[]", style=solid];
"203 bert/embeddings/Shape_1" -> "204 bert/embeddings/Shape_1__61"  [label="[-1]", style=dashed];
"204 bert/embeddings/Shape_1__61" -> "205 bert/embeddings/strided_slice_1"  [label="[-1]", style=solid];
"205 bert/embeddings/strided_slice_1" -> "206 bert/embeddings/strided_slice_1__65"  [label="[-1]", style=solid];
"206 bert/embeddings/strided_slice_1__65" -> "207 bert/embeddings/strided_slice_1__66"  [label="[]", style=solid];
"207 bert/embeddings/strided_slice_1__66" -> "208 bert/embeddings/Reshape_3/shape_Unsqueeze__67"  [label="[]", style=dashed];
"208 bert/embeddings/Reshape_3/shape_Unsqueeze__67" -> "209 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"209 bert/embeddings/Reshape_3/shape_Concat__70" -> "210 bert/embeddings/Reshape_3__71"  [label="[3]", style=dashed];
"210 bert/embeddings/Reshape_3__71" -> "225 bert/embeddings/Reshape_3"  [label="[3]", style=dashed];
"211 Unsqueeze__46" -> "218 Concat__47"  [label="[1]", style=solid];
"212 Unsqueeze__45" -> "218 Concat__47"  [label="[1]", style=solid];
"213 Unsqueeze__44" -> "219 bert/embeddings/one_hot"  [label="[1]", style=dashed];
"214 Reshape_1/shape_Unsqueeze__480" -> "1499 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"215 Reshape_1/shape_Unsqueeze__479" -> "1499 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"216 Reshape/shape_Unsqueeze__483" -> "1496 Reshape/shape_Concat__484"  [label="[1]", style=dashed];
"217 MatMul__486" -> "1502 QuantizeLinear_MatMul__486^0_1"  [label="[768, 2]", style=solid];
"218 Concat__47" -> "219 bert/embeddings/one_hot"  [label="[2]", style=solid];
"219 bert/embeddings/one_hot" -> "220 QuantizeLinear_bert/embeddings/one_hot^0_1"  [label="[]", style=solid];
"220 QuantizeLinear_bert/embeddings/one_hot^0_1" -> "221 DequantizeLinear_bert/embeddings/one_hot^0_1"  [label="[]", style=dashed];
"221 DequantizeLinear_bert/embeddings/one_hot^0_1" -> "224 bert/embeddings/MatMul"  [label="[]", style=solid];
"222 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "223 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1"  [label="[2, 768]", style=dashed];
"223 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "224 bert/embeddings/MatMul"  [label="[2, 768]", style=solid];
"224 bert/embeddings/MatMul" -> "225 bert/embeddings/Reshape_3"  [label="[]", style=solid];
"225 bert/embeddings/Reshape_3" -> "226 bert/embeddings/add"  [label="[]", style=solid];
"226 bert/embeddings/add" -> "227 bert/embeddings/add_1"  [label="[]", style=solid];
"227 bert/embeddings/add_1" -> "228 bert/embeddings/LayerNorm/moments/mean"  [label="[]", style=solid];
"227 bert/embeddings/add_1" -> "230 bert/embeddings/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"227 bert/embeddings/add_1" -> "239 bert/embeddings/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"228 bert/embeddings/LayerNorm/moments/mean" -> "229 bert/embeddings/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"228 bert/embeddings/LayerNorm/moments/mean" -> "237 bert/embeddings/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"229 bert/embeddings/LayerNorm/moments/StopGradient" -> "230 bert/embeddings/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"230 bert/embeddings/LayerNorm/moments/SquaredDifference" -> "231 bert/embeddings/LayerNorm/moments/SquaredDifference__72"  [label="[]", style=solid];
"231 bert/embeddings/LayerNorm/moments/SquaredDifference__72" -> "232 bert/embeddings/LayerNorm/moments/variance"  [label="[]", style=solid];
"232 bert/embeddings/LayerNorm/moments/variance" -> "233 bert/embeddings/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"233 bert/embeddings/LayerNorm/batchnorm/add" -> "234 bert/embeddings/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"234 bert/embeddings/LayerNorm/batchnorm/Rsqrt" -> "235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74"  [label="[]", style=solid];
"235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" -> "236 bert/embeddings/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"236 bert/embeddings/LayerNorm/batchnorm/mul" -> "237 bert/embeddings/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"236 bert/embeddings/LayerNorm/batchnorm/mul" -> "239 bert/embeddings/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"237 bert/embeddings/LayerNorm/batchnorm/mul_2" -> "238 bert/embeddings/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"238 bert/embeddings/LayerNorm/batchnorm/sub" -> "240 bert/embeddings/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"239 bert/embeddings/LayerNorm/batchnorm/mul_1" -> "240 bert/embeddings/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" -> "241 bert/encoder/Shape_2"  [label="[]", style=solid];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" -> "405 bert/encoder/Reshape_1"  [label="[]", style=solid];
"241 bert/encoder/Shape_2" -> "242 bert/encoder/Shape_2__76"  [label="[-1]", style=dashed];
"242 bert/encoder/Shape_2__76" -> "243 bert/encoder/strided_slice_2"  [label="[-1]", style=solid];
"243 bert/encoder/strided_slice_2" -> "244 bert/encoder/strided_slice_2__80"  [label="[-1]", style=solid];
"244 bert/encoder/strided_slice_2__80" -> "245 bert/encoder/strided_slice_2__81"  [label="[]", style=solid];
"245 bert/encoder/strided_slice_2__81" -> "246 bert/encoder/layer_9/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "259 bert/encoder/layer_8/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "272 bert/encoder/layer_7/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "285 bert/encoder/layer_6/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "298 bert/encoder/layer_5/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "311 bert/encoder/layer_4/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "324 bert/encoder/layer_3/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "337 bert/encoder/layer_2/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "350 bert/encoder/layer_11/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "363 bert/encoder/layer_10/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "376 bert/encoder/layer_1/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "389 bert/encoder/layer_0/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "402 bert/encoder/Reshape_13/shape_Unsqueeze__298"  [label="[]", style=dashed];
"246 bert/encoder/layer_9/attention/self/mul_2" -> "247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82"  [label="[]", style=dashed];
"247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" -> "248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84"  [label="[1]", style=dashed];
"248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" -> "249 bert/encoder/layer_9/attention/self/Reshape_3__434"  [label="[2]", style=dashed];
"249 bert/encoder/layer_9/attention/self/Reshape_3__434" -> "1253 bert/encoder/layer_9/attention/self/Reshape_3"  [label="[2]", style=dashed];
"250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" -> "252 bert/encoder/layer_9/attention/self/Reshape_2__429"  [label="[4]", style=dashed];
"252 bert/encoder/layer_9/attention/self/Reshape_2__429" -> "1226 bert/encoder/layer_9/attention/self/Reshape_2"  [label="[4]", style=dashed];
"253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" -> "255 bert/encoder/layer_9/attention/self/Reshape_1__431"  [label="[4]", style=dashed];
"255 bert/encoder/layer_9/attention/self/Reshape_1__431" -> "1242 bert/encoder/layer_9/attention/self/Reshape_1"  [label="[4]", style=dashed];
"256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" -> "258 bert/encoder/layer_9/attention/self/Reshape__430"  [label="[4]", style=dashed];
"258 bert/encoder/layer_9/attention/self/Reshape__430" -> "1234 bert/encoder/layer_9/attention/self/Reshape"  [label="[4]", style=dashed];
"259 bert/encoder/layer_8/attention/self/mul_2" -> "260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100"  [label="[]", style=dashed];
"260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" -> "261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102"  [label="[1]", style=dashed];
"261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" -> "262 bert/encoder/layer_8/attention/self/Reshape_3__420"  [label="[2]", style=dashed];
"262 bert/encoder/layer_8/attention/self/Reshape_3__420" -> "1163 bert/encoder/layer_8/attention/self/Reshape_3"  [label="[2]", style=dashed];
"263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" -> "265 bert/encoder/layer_8/attention/self/Reshape_2__415"  [label="[4]", style=dashed];
"265 bert/encoder/layer_8/attention/self/Reshape_2__415" -> "1136 bert/encoder/layer_8/attention/self/Reshape_2"  [label="[4]", style=dashed];
"266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" -> "268 bert/encoder/layer_8/attention/self/Reshape_1__417"  [label="[4]", style=dashed];
"268 bert/encoder/layer_8/attention/self/Reshape_1__417" -> "1152 bert/encoder/layer_8/attention/self/Reshape_1"  [label="[4]", style=dashed];
"269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" -> "271 bert/encoder/layer_8/attention/self/Reshape__416"  [label="[4]", style=dashed];
"271 bert/encoder/layer_8/attention/self/Reshape__416" -> "1144 bert/encoder/layer_8/attention/self/Reshape"  [label="[4]", style=dashed];
"272 bert/encoder/layer_7/attention/self/mul_2" -> "273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118"  [label="[]", style=dashed];
"273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" -> "274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120"  [label="[1]", style=dashed];
"274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" -> "275 bert/encoder/layer_7/attention/self/Reshape_3__406"  [label="[2]", style=dashed];
"275 bert/encoder/layer_7/attention/self/Reshape_3__406" -> "1073 bert/encoder/layer_7/attention/self/Reshape_3"  [label="[2]", style=dashed];
"276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" -> "278 bert/encoder/layer_7/attention/self/Reshape_2__401"  [label="[4]", style=dashed];
"278 bert/encoder/layer_7/attention/self/Reshape_2__401" -> "1046 bert/encoder/layer_7/attention/self/Reshape_2"  [label="[4]", style=dashed];
"279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" -> "281 bert/encoder/layer_7/attention/self/Reshape_1__403"  [label="[4]", style=dashed];
"281 bert/encoder/layer_7/attention/self/Reshape_1__403" -> "1062 bert/encoder/layer_7/attention/self/Reshape_1"  [label="[4]", style=dashed];
"282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" -> "284 bert/encoder/layer_7/attention/self/Reshape__402"  [label="[4]", style=dashed];
"284 bert/encoder/layer_7/attention/self/Reshape__402" -> "1054 bert/encoder/layer_7/attention/self/Reshape"  [label="[4]", style=dashed];
"285 bert/encoder/layer_6/attention/self/mul_2" -> "286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136"  [label="[]", style=dashed];
"286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" -> "287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138"  [label="[1]", style=dashed];
"287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" -> "288 bert/encoder/layer_6/attention/self/Reshape_3__392"  [label="[2]", style=dashed];
"288 bert/encoder/layer_6/attention/self/Reshape_3__392" -> "983 bert/encoder/layer_6/attention/self/Reshape_3"  [label="[2]", style=dashed];
"289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" -> "291 bert/encoder/layer_6/attention/self/Reshape_2__387"  [label="[4]", style=dashed];
"291 bert/encoder/layer_6/attention/self/Reshape_2__387" -> "956 bert/encoder/layer_6/attention/self/Reshape_2"  [label="[4]", style=dashed];
"292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" -> "294 bert/encoder/layer_6/attention/self/Reshape_1__389"  [label="[4]", style=dashed];
"294 bert/encoder/layer_6/attention/self/Reshape_1__389" -> "972 bert/encoder/layer_6/attention/self/Reshape_1"  [label="[4]", style=dashed];
"295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" -> "297 bert/encoder/layer_6/attention/self/Reshape__388"  [label="[4]", style=dashed];
"297 bert/encoder/layer_6/attention/self/Reshape__388" -> "964 bert/encoder/layer_6/attention/self/Reshape"  [label="[4]", style=dashed];
"298 bert/encoder/layer_5/attention/self/mul_2" -> "299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154"  [label="[]", style=dashed];
"299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" -> "300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156"  [label="[1]", style=dashed];
"300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" -> "301 bert/encoder/layer_5/attention/self/Reshape_3__378"  [label="[2]", style=dashed];
"301 bert/encoder/layer_5/attention/self/Reshape_3__378" -> "893 bert/encoder/layer_5/attention/self/Reshape_3"  [label="[2]", style=dashed];
"302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" -> "304 bert/encoder/layer_5/attention/self/Reshape_2__373"  [label="[4]", style=dashed];
"304 bert/encoder/layer_5/attention/self/Reshape_2__373" -> "866 bert/encoder/layer_5/attention/self/Reshape_2"  [label="[4]", style=dashed];
"305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" -> "307 bert/encoder/layer_5/attention/self/Reshape_1__375"  [label="[4]", style=dashed];
"307 bert/encoder/layer_5/attention/self/Reshape_1__375" -> "882 bert/encoder/layer_5/attention/self/Reshape_1"  [label="[4]", style=dashed];
"308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" -> "310 bert/encoder/layer_5/attention/self/Reshape__374"  [label="[4]", style=dashed];
"310 bert/encoder/layer_5/attention/self/Reshape__374" -> "874 bert/encoder/layer_5/attention/self/Reshape"  [label="[4]", style=dashed];
"311 bert/encoder/layer_4/attention/self/mul_2" -> "312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172"  [label="[]", style=dashed];
"312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" -> "313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174"  [label="[1]", style=dashed];
"313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" -> "314 bert/encoder/layer_4/attention/self/Reshape_3__364"  [label="[2]", style=dashed];
"314 bert/encoder/layer_4/attention/self/Reshape_3__364" -> "803 bert/encoder/layer_4/attention/self/Reshape_3"  [label="[2]", style=dashed];
"315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" -> "317 bert/encoder/layer_4/attention/self/Reshape_2__359"  [label="[4]", style=dashed];
"317 bert/encoder/layer_4/attention/self/Reshape_2__359" -> "776 bert/encoder/layer_4/attention/self/Reshape_2"  [label="[4]", style=dashed];
"318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" -> "320 bert/encoder/layer_4/attention/self/Reshape_1__361"  [label="[4]", style=dashed];
"320 bert/encoder/layer_4/attention/self/Reshape_1__361" -> "792 bert/encoder/layer_4/attention/self/Reshape_1"  [label="[4]", style=dashed];
"321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" -> "323 bert/encoder/layer_4/attention/self/Reshape__360"  [label="[4]", style=dashed];
"323 bert/encoder/layer_4/attention/self/Reshape__360" -> "784 bert/encoder/layer_4/attention/self/Reshape"  [label="[4]", style=dashed];
"324 bert/encoder/layer_3/attention/self/mul_2" -> "325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190"  [label="[]", style=dashed];
"325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" -> "326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192"  [label="[1]", style=dashed];
"326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" -> "327 bert/encoder/layer_3/attention/self/Reshape_3__350"  [label="[2]", style=dashed];
"327 bert/encoder/layer_3/attention/self/Reshape_3__350" -> "713 bert/encoder/layer_3/attention/self/Reshape_3"  [label="[2]", style=dashed];
"328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" -> "330 bert/encoder/layer_3/attention/self/Reshape_2__345"  [label="[4]", style=dashed];
"330 bert/encoder/layer_3/attention/self/Reshape_2__345" -> "686 bert/encoder/layer_3/attention/self/Reshape_2"  [label="[4]", style=dashed];
"331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" -> "333 bert/encoder/layer_3/attention/self/Reshape_1__347"  [label="[4]", style=dashed];
"333 bert/encoder/layer_3/attention/self/Reshape_1__347" -> "702 bert/encoder/layer_3/attention/self/Reshape_1"  [label="[4]", style=dashed];
"334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" -> "336 bert/encoder/layer_3/attention/self/Reshape__346"  [label="[4]", style=dashed];
"336 bert/encoder/layer_3/attention/self/Reshape__346" -> "694 bert/encoder/layer_3/attention/self/Reshape"  [label="[4]", style=dashed];
"337 bert/encoder/layer_2/attention/self/mul_2" -> "338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208"  [label="[]", style=dashed];
"338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" -> "339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210"  [label="[1]", style=dashed];
"339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" -> "340 bert/encoder/layer_2/attention/self/Reshape_3__336"  [label="[2]", style=dashed];
"340 bert/encoder/layer_2/attention/self/Reshape_3__336" -> "623 bert/encoder/layer_2/attention/self/Reshape_3"  [label="[2]", style=dashed];
"341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" -> "343 bert/encoder/layer_2/attention/self/Reshape_2__331"  [label="[4]", style=dashed];
"343 bert/encoder/layer_2/attention/self/Reshape_2__331" -> "596 bert/encoder/layer_2/attention/self/Reshape_2"  [label="[4]", style=dashed];
"344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" -> "346 bert/encoder/layer_2/attention/self/Reshape_1__333"  [label="[4]", style=dashed];
"346 bert/encoder/layer_2/attention/self/Reshape_1__333" -> "612 bert/encoder/layer_2/attention/self/Reshape_1"  [label="[4]", style=dashed];
"347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" -> "349 bert/encoder/layer_2/attention/self/Reshape__332"  [label="[4]", style=dashed];
"349 bert/encoder/layer_2/attention/self/Reshape__332" -> "604 bert/encoder/layer_2/attention/self/Reshape"  [label="[4]", style=dashed];
"350 bert/encoder/layer_11/attention/self/mul_2" -> "351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226"  [label="[]", style=dashed];
"351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" -> "352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228"  [label="[1]", style=dashed];
"352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" -> "353 bert/encoder/layer_11/attention/self/Reshape_3__462"  [label="[2]", style=dashed];
"353 bert/encoder/layer_11/attention/self/Reshape_3__462" -> "1433 bert/encoder/layer_11/attention/self/Reshape_3"  [label="[2]", style=dashed];
"354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" -> "356 bert/encoder/layer_11/attention/self/Reshape_2__457"  [label="[4]", style=dashed];
"356 bert/encoder/layer_11/attention/self/Reshape_2__457" -> "1406 bert/encoder/layer_11/attention/self/Reshape_2"  [label="[4]", style=dashed];
"357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" -> "359 bert/encoder/layer_11/attention/self/Reshape_1__459"  [label="[4]", style=dashed];
"359 bert/encoder/layer_11/attention/self/Reshape_1__459" -> "1422 bert/encoder/layer_11/attention/self/Reshape_1"  [label="[4]", style=dashed];
"360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" -> "362 bert/encoder/layer_11/attention/self/Reshape__458"  [label="[4]", style=dashed];
"362 bert/encoder/layer_11/attention/self/Reshape__458" -> "1414 bert/encoder/layer_11/attention/self/Reshape"  [label="[4]", style=dashed];
"363 bert/encoder/layer_10/attention/self/mul_2" -> "364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244"  [label="[]", style=dashed];
"364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" -> "365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246"  [label="[1]", style=dashed];
"365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" -> "366 bert/encoder/layer_10/attention/self/Reshape_3__448"  [label="[2]", style=dashed];
"366 bert/encoder/layer_10/attention/self/Reshape_3__448" -> "1343 bert/encoder/layer_10/attention/self/Reshape_3"  [label="[2]", style=dashed];
"367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" -> "369 bert/encoder/layer_10/attention/self/Reshape_2__443"  [label="[4]", style=dashed];
"369 bert/encoder/layer_10/attention/self/Reshape_2__443" -> "1316 bert/encoder/layer_10/attention/self/Reshape_2"  [label="[4]", style=dashed];
"370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" -> "372 bert/encoder/layer_10/attention/self/Reshape_1__445"  [label="[4]", style=dashed];
"372 bert/encoder/layer_10/attention/self/Reshape_1__445" -> "1332 bert/encoder/layer_10/attention/self/Reshape_1"  [label="[4]", style=dashed];
"373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" -> "375 bert/encoder/layer_10/attention/self/Reshape__444"  [label="[4]", style=dashed];
"375 bert/encoder/layer_10/attention/self/Reshape__444" -> "1324 bert/encoder/layer_10/attention/self/Reshape"  [label="[4]", style=dashed];
"376 bert/encoder/layer_1/attention/self/mul_2" -> "377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262"  [label="[]", style=dashed];
"377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" -> "378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264"  [label="[1]", style=dashed];
"378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" -> "379 bert/encoder/layer_1/attention/self/Reshape_3__322"  [label="[2]", style=dashed];
"379 bert/encoder/layer_1/attention/self/Reshape_3__322" -> "533 bert/encoder/layer_1/attention/self/Reshape_3"  [label="[2]", style=dashed];
"380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" -> "382 bert/encoder/layer_1/attention/self/Reshape_2__317"  [label="[4]", style=dashed];
"382 bert/encoder/layer_1/attention/self/Reshape_2__317" -> "506 bert/encoder/layer_1/attention/self/Reshape_2"  [label="[4]", style=dashed];
"383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" -> "385 bert/encoder/layer_1/attention/self/Reshape_1__319"  [label="[4]", style=dashed];
"385 bert/encoder/layer_1/attention/self/Reshape_1__319" -> "522 bert/encoder/layer_1/attention/self/Reshape_1"  [label="[4]", style=dashed];
"386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" -> "388 bert/encoder/layer_1/attention/self/Reshape__318"  [label="[4]", style=dashed];
"388 bert/encoder/layer_1/attention/self/Reshape__318" -> "514 bert/encoder/layer_1/attention/self/Reshape"  [label="[4]", style=dashed];
"389 bert/encoder/layer_0/attention/self/mul_2" -> "390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280"  [label="[]", style=dashed];
"390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" -> "391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282"  [label="[1]", style=dashed];
"391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" -> "392 bert/encoder/layer_0/attention/self/Reshape_3__308"  [label="[2]", style=dashed];
"392 bert/encoder/layer_0/attention/self/Reshape_3__308" -> "443 bert/encoder/layer_0/attention/self/Reshape_3"  [label="[2]", style=dashed];
"393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" -> "395 bert/encoder/layer_0/attention/self/Reshape_2__303"  [label="[4]", style=dashed];
"395 bert/encoder/layer_0/attention/self/Reshape_2__303" -> "416 bert/encoder/layer_0/attention/self/Reshape_2"  [label="[4]", style=dashed];
"396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" -> "398 bert/encoder/layer_0/attention/self/Reshape_1__305"  [label="[4]", style=dashed];
"398 bert/encoder/layer_0/attention/self/Reshape_1__305" -> "432 bert/encoder/layer_0/attention/self/Reshape_1"  [label="[4]", style=dashed];
"399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" -> "401 bert/encoder/layer_0/attention/self/Reshape__304"  [label="[4]", style=dashed];
"401 bert/encoder/layer_0/attention/self/Reshape__304" -> "424 bert/encoder/layer_0/attention/self/Reshape"  [label="[4]", style=dashed];
"402 bert/encoder/Reshape_13/shape_Unsqueeze__298" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"403 bert/encoder/Reshape_13/shape_Concat__301" -> "404 bert/encoder/Reshape_13__471"  [label="[3]", style=dashed];
"404 bert/encoder/Reshape_13__471" -> "1488 bert/encoder/Reshape_13"  [label="[3]", style=dashed];
"405 bert/encoder/Reshape_1" -> "406 QuantizeLinear_bert/encoder/Reshape_1^0_1"  [label="[]", style=solid];
"405 bert/encoder/Reshape_1" -> "410 QuantizeLinear_bert/encoder/Reshape_1^0_2"  [label="[]", style=solid];
"405 bert/encoder/Reshape_1" -> "412 QuantizeLinear_bert/encoder/Reshape_1^0_3"  [label="[]", style=solid];
"405 bert/encoder/Reshape_1" -> "448 bert/encoder/layer_0/attention/output/add"  [label="[]", style=solid];
"406 QuantizeLinear_bert/encoder/Reshape_1^0_1" -> "407 DequantizeLinear_bert/encoder/Reshape_1^0_1"  [label="[]", style=dashed];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_1" -> "414 bert/encoder/layer_0/attention/self/value/MatMul"  [label="[]", style=solid];
"408 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "409 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"409 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "414 bert/encoder/layer_0/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"410 QuantizeLinear_bert/encoder/Reshape_1^0_2" -> "411 DequantizeLinear_bert/encoder/Reshape_1^0_2"  [label="[]", style=dashed];
"411 DequantizeLinear_bert/encoder/Reshape_1^0_2" -> "420 bert/encoder/layer_0/attention/self/query/MatMul"  [label="[]", style=solid];
"412 QuantizeLinear_bert/encoder/Reshape_1^0_3" -> "413 DequantizeLinear_bert/encoder/Reshape_1^0_3"  [label="[]", style=dashed];
"413 DequantizeLinear_bert/encoder/Reshape_1^0_3" -> "428 bert/encoder/layer_0/attention/self/key/MatMul"  [label="[]", style=solid];
"414 bert/encoder/layer_0/attention/self/value/MatMul" -> "415 bert/encoder/layer_0/attention/self/value/BiasAdd"  [label="[]", style=solid];
"415 bert/encoder/layer_0/attention/self/value/BiasAdd" -> "416 bert/encoder/layer_0/attention/self/Reshape_2"  [label="[]", style=solid];
"416 bert/encoder/layer_0/attention/self/Reshape_2" -> "417 bert/encoder/layer_0/attention/self/transpose_2"  [label="[]", style=solid];
"417 bert/encoder/layer_0/attention/self/transpose_2" -> "439 bert/encoder/layer_0/attention/self/MatMul_1"  [label="[]", style=solid];
"418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "420 bert/encoder/layer_0/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"420 bert/encoder/layer_0/attention/self/query/MatMul" -> "421 bert/encoder/layer_0/attention/self/query/BiasAdd"  [label="[]", style=solid];
"421 bert/encoder/layer_0/attention/self/query/BiasAdd" -> "422 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"422 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "423 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"423 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "424 bert/encoder/layer_0/attention/self/Reshape"  [label="[]", style=solid];
"424 bert/encoder/layer_0/attention/self/Reshape" -> "425 bert/encoder/layer_0/attention/self/transpose"  [label="[]", style=solid];
"425 bert/encoder/layer_0/attention/self/transpose" -> "435 bert/encoder/layer_0/attention/self/MatMul"  [label="[]", style=solid];
"426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "428 bert/encoder/layer_0/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"428 bert/encoder/layer_0/attention/self/key/MatMul" -> "429 bert/encoder/layer_0/attention/self/key/BiasAdd"  [label="[]", style=solid];
"429 bert/encoder/layer_0/attention/self/key/BiasAdd" -> "430 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"430 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "431 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"431 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "432 bert/encoder/layer_0/attention/self/Reshape_1"  [label="[]", style=solid];
"432 bert/encoder/layer_0/attention/self/Reshape_1" -> "433 bert/encoder/layer_0/attention/self/transpose_1"  [label="[]", style=solid];
"433 bert/encoder/layer_0/attention/self/transpose_1" -> "434 bert/encoder/layer_0/attention/self/MatMul__306"  [label="[]", style=solid];
"434 bert/encoder/layer_0/attention/self/MatMul__306" -> "435 bert/encoder/layer_0/attention/self/MatMul"  [label="[]", style=solid];
"435 bert/encoder/layer_0/attention/self/MatMul" -> "436 bert/encoder/layer_0/attention/self/Mul"  [label="[]", style=solid];
"436 bert/encoder/layer_0/attention/self/Mul" -> "437 bert/encoder/layer_0/attention/self/add"  [label="[]", style=solid];
"437 bert/encoder/layer_0/attention/self/add" -> "438 bert/encoder/layer_0/attention/self/Softmax"  [label="[]", style=solid];
"438 bert/encoder/layer_0/attention/self/Softmax" -> "439 bert/encoder/layer_0/attention/self/MatMul_1"  [label="[]", style=solid];
"439 bert/encoder/layer_0/attention/self/MatMul_1" -> "440 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"440 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "441 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"441 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "442 bert/encoder/layer_0/attention/self/transpose_3"  [label="[]", style=solid];
"442 bert/encoder/layer_0/attention/self/transpose_3" -> "443 bert/encoder/layer_0/attention/self/Reshape_3"  [label="[]", style=solid];
"443 bert/encoder/layer_0/attention/self/Reshape_3" -> "446 bert/encoder/layer_0/attention/output/dense/MatMul"  [label="[]", style=solid];
"444 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "445 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"445 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "446 bert/encoder/layer_0/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"446 bert/encoder/layer_0/attention/output/dense/MatMul" -> "447 bert/encoder/layer_0/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"447 bert/encoder/layer_0/attention/output/dense/BiasAdd" -> "448 bert/encoder/layer_0/attention/output/add"  [label="[]", style=solid];
"448 bert/encoder/layer_0/attention/output/add" -> "449 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"448 bert/encoder/layer_0/attention/output/add" -> "451 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"448 bert/encoder/layer_0/attention/output/add" -> "460 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "450 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"450 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" -> "451 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"451 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" -> "452 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309"  [label="[]", style=solid];
"452 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" -> "453 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"453 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" -> "454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" -> "455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" -> "456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311"  [label="[]", style=solid];
"456 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" -> "457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"457 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "460 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" -> "459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" -> "461 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"460 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" -> "461 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"461 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "462 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"461 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "482 bert/encoder/layer_0/output/add"  [label="[]", style=solid];
"462 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "463 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"463 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "466 bert/encoder/layer_0/intermediate/dense/MatMul"  [label="[]", style=solid];
"464 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "465 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"465 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "466 bert/encoder/layer_0/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"466 bert/encoder/layer_0/intermediate/dense/MatMul" -> "467 bert/encoder/layer_0/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"467 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "468 bert/encoder/layer_0/intermediate/dense/Pow"  [label="[]", style=solid];
"467 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "470 bert/encoder/layer_0/intermediate/dense/add"  [label="[]", style=solid];
"467 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "475 bert/encoder/layer_0/intermediate/dense/mul_3"  [label="[]", style=solid];
"468 bert/encoder/layer_0/intermediate/dense/Pow" -> "469 bert/encoder/layer_0/intermediate/dense/mul"  [label="[]", style=solid];
"469 bert/encoder/layer_0/intermediate/dense/mul" -> "470 bert/encoder/layer_0/intermediate/dense/add"  [label="[]", style=solid];
"470 bert/encoder/layer_0/intermediate/dense/add" -> "471 bert/encoder/layer_0/intermediate/dense/mul_1"  [label="[]", style=solid];
"471 bert/encoder/layer_0/intermediate/dense/mul_1" -> "472 bert/encoder/layer_0/intermediate/dense/Tanh"  [label="[]", style=solid];
"472 bert/encoder/layer_0/intermediate/dense/Tanh" -> "473 bert/encoder/layer_0/intermediate/dense/add_1"  [label="[]", style=solid];
"473 bert/encoder/layer_0/intermediate/dense/add_1" -> "474 bert/encoder/layer_0/intermediate/dense/mul_2"  [label="[]", style=solid];
"474 bert/encoder/layer_0/intermediate/dense/mul_2" -> "475 bert/encoder/layer_0/intermediate/dense/mul_3"  [label="[]", style=solid];
"475 bert/encoder/layer_0/intermediate/dense/mul_3" -> "476 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"476 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "477 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"477 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "480 bert/encoder/layer_0/output/dense/MatMul"  [label="[]", style=solid];
"478 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "479 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"479 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "480 bert/encoder/layer_0/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"480 bert/encoder/layer_0/output/dense/MatMul" -> "481 bert/encoder/layer_0/output/dense/BiasAdd"  [label="[]", style=solid];
"481 bert/encoder/layer_0/output/dense/BiasAdd" -> "482 bert/encoder/layer_0/output/add"  [label="[]", style=solid];
"482 bert/encoder/layer_0/output/add" -> "483 bert/encoder/layer_0/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"482 bert/encoder/layer_0/output/add" -> "485 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"482 bert/encoder/layer_0/output/add" -> "494 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"483 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "484 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"483 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "492 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"484 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" -> "485 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"485 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" -> "486 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313"  [label="[]", style=solid];
"486 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" -> "487 bert/encoder/layer_0/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"487 bert/encoder/layer_0/output/LayerNorm/moments/variance" -> "488 bert/encoder/layer_0/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"488 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" -> "489 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"489 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" -> "490 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315"  [label="[]", style=solid];
"490 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" -> "491 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "492 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "494 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"492 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" -> "493 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"493 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" -> "495 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"494 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" -> "495 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"495 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"495 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "500 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"495 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "502 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"495 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "538 bert/encoder/layer_1/attention/output/add"  [label="[]", style=solid];
"496 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"497 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "504 bert/encoder/layer_1/attention/self/value/MatMul"  [label="[]", style=solid];
"498 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "499 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"499 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "504 bert/encoder/layer_1/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"500 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "501 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"501 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "510 bert/encoder/layer_1/attention/self/query/MatMul"  [label="[]", style=solid];
"502 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "503 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"503 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "518 bert/encoder/layer_1/attention/self/key/MatMul"  [label="[]", style=solid];
"504 bert/encoder/layer_1/attention/self/value/MatMul" -> "505 bert/encoder/layer_1/attention/self/value/BiasAdd"  [label="[]", style=solid];
"505 bert/encoder/layer_1/attention/self/value/BiasAdd" -> "506 bert/encoder/layer_1/attention/self/Reshape_2"  [label="[]", style=solid];
"506 bert/encoder/layer_1/attention/self/Reshape_2" -> "507 bert/encoder/layer_1/attention/self/transpose_2"  [label="[]", style=solid];
"507 bert/encoder/layer_1/attention/self/transpose_2" -> "529 bert/encoder/layer_1/attention/self/MatMul_1"  [label="[]", style=solid];
"508 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "509 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"509 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "510 bert/encoder/layer_1/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"510 bert/encoder/layer_1/attention/self/query/MatMul" -> "511 bert/encoder/layer_1/attention/self/query/BiasAdd"  [label="[]", style=solid];
"511 bert/encoder/layer_1/attention/self/query/BiasAdd" -> "512 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"512 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "513 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"513 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "514 bert/encoder/layer_1/attention/self/Reshape"  [label="[]", style=solid];
"514 bert/encoder/layer_1/attention/self/Reshape" -> "515 bert/encoder/layer_1/attention/self/transpose"  [label="[]", style=solid];
"515 bert/encoder/layer_1/attention/self/transpose" -> "525 bert/encoder/layer_1/attention/self/MatMul"  [label="[]", style=solid];
"516 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "517 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"517 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "518 bert/encoder/layer_1/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"518 bert/encoder/layer_1/attention/self/key/MatMul" -> "519 bert/encoder/layer_1/attention/self/key/BiasAdd"  [label="[]", style=solid];
"519 bert/encoder/layer_1/attention/self/key/BiasAdd" -> "520 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"520 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "521 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"521 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "522 bert/encoder/layer_1/attention/self/Reshape_1"  [label="[]", style=solid];
"522 bert/encoder/layer_1/attention/self/Reshape_1" -> "523 bert/encoder/layer_1/attention/self/transpose_1"  [label="[]", style=solid];
"523 bert/encoder/layer_1/attention/self/transpose_1" -> "524 bert/encoder/layer_1/attention/self/MatMul__320"  [label="[]", style=solid];
"524 bert/encoder/layer_1/attention/self/MatMul__320" -> "525 bert/encoder/layer_1/attention/self/MatMul"  [label="[]", style=solid];
"525 bert/encoder/layer_1/attention/self/MatMul" -> "526 bert/encoder/layer_1/attention/self/Mul"  [label="[]", style=solid];
"526 bert/encoder/layer_1/attention/self/Mul" -> "527 bert/encoder/layer_1/attention/self/add"  [label="[]", style=solid];
"527 bert/encoder/layer_1/attention/self/add" -> "528 bert/encoder/layer_1/attention/self/Softmax"  [label="[]", style=solid];
"528 bert/encoder/layer_1/attention/self/Softmax" -> "529 bert/encoder/layer_1/attention/self/MatMul_1"  [label="[]", style=solid];
"529 bert/encoder/layer_1/attention/self/MatMul_1" -> "530 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"530 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "531 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"531 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "532 bert/encoder/layer_1/attention/self/transpose_3"  [label="[]", style=solid];
"532 bert/encoder/layer_1/attention/self/transpose_3" -> "533 bert/encoder/layer_1/attention/self/Reshape_3"  [label="[]", style=solid];
"533 bert/encoder/layer_1/attention/self/Reshape_3" -> "536 bert/encoder/layer_1/attention/output/dense/MatMul"  [label="[]", style=solid];
"534 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "535 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"535 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "536 bert/encoder/layer_1/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"536 bert/encoder/layer_1/attention/output/dense/MatMul" -> "537 bert/encoder/layer_1/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"537 bert/encoder/layer_1/attention/output/dense/BiasAdd" -> "538 bert/encoder/layer_1/attention/output/add"  [label="[]", style=solid];
"538 bert/encoder/layer_1/attention/output/add" -> "539 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"538 bert/encoder/layer_1/attention/output/add" -> "541 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"538 bert/encoder/layer_1/attention/output/add" -> "550 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"539 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "540 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"539 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"540 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" -> "541 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"541 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" -> "542 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323"  [label="[]", style=solid];
"542 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" -> "543 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"543 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" -> "544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"544 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" -> "545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"545 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" -> "546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325"  [label="[]", style=solid];
"546 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" -> "547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"547 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "550 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" -> "549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" -> "551 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"550 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" -> "551 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"551 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "552 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"551 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "572 bert/encoder/layer_1/output/add"  [label="[]", style=solid];
"552 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "553 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"553 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "556 bert/encoder/layer_1/intermediate/dense/MatMul"  [label="[]", style=solid];
"554 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "555 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"555 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "556 bert/encoder/layer_1/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"556 bert/encoder/layer_1/intermediate/dense/MatMul" -> "557 bert/encoder/layer_1/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"557 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "558 bert/encoder/layer_1/intermediate/dense/Pow"  [label="[]", style=solid];
"557 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "560 bert/encoder/layer_1/intermediate/dense/add"  [label="[]", style=solid];
"557 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "565 bert/encoder/layer_1/intermediate/dense/mul_3"  [label="[]", style=solid];
"558 bert/encoder/layer_1/intermediate/dense/Pow" -> "559 bert/encoder/layer_1/intermediate/dense/mul"  [label="[]", style=solid];
"559 bert/encoder/layer_1/intermediate/dense/mul" -> "560 bert/encoder/layer_1/intermediate/dense/add"  [label="[]", style=solid];
"560 bert/encoder/layer_1/intermediate/dense/add" -> "561 bert/encoder/layer_1/intermediate/dense/mul_1"  [label="[]", style=solid];
"561 bert/encoder/layer_1/intermediate/dense/mul_1" -> "562 bert/encoder/layer_1/intermediate/dense/Tanh"  [label="[]", style=solid];
"562 bert/encoder/layer_1/intermediate/dense/Tanh" -> "563 bert/encoder/layer_1/intermediate/dense/add_1"  [label="[]", style=solid];
"563 bert/encoder/layer_1/intermediate/dense/add_1" -> "564 bert/encoder/layer_1/intermediate/dense/mul_2"  [label="[]", style=solid];
"564 bert/encoder/layer_1/intermediate/dense/mul_2" -> "565 bert/encoder/layer_1/intermediate/dense/mul_3"  [label="[]", style=solid];
"565 bert/encoder/layer_1/intermediate/dense/mul_3" -> "566 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"566 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "567 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"567 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "570 bert/encoder/layer_1/output/dense/MatMul"  [label="[]", style=solid];
"568 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "569 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"569 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "570 bert/encoder/layer_1/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"570 bert/encoder/layer_1/output/dense/MatMul" -> "571 bert/encoder/layer_1/output/dense/BiasAdd"  [label="[]", style=solid];
"571 bert/encoder/layer_1/output/dense/BiasAdd" -> "572 bert/encoder/layer_1/output/add"  [label="[]", style=solid];
"572 bert/encoder/layer_1/output/add" -> "573 bert/encoder/layer_1/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"572 bert/encoder/layer_1/output/add" -> "575 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"572 bert/encoder/layer_1/output/add" -> "584 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"573 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "574 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"573 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "582 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"574 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" -> "575 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"575 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" -> "576 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327"  [label="[]", style=solid];
"576 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" -> "577 bert/encoder/layer_1/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"577 bert/encoder/layer_1/output/LayerNorm/moments/variance" -> "578 bert/encoder/layer_1/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"578 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" -> "579 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"579 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" -> "580 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329"  [label="[]", style=solid];
"580 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" -> "581 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "582 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"581 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "584 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"582 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" -> "583 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"583 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" -> "585 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"584 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" -> "585 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"585 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"585 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "590 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"585 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "592 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"585 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "628 bert/encoder/layer_2/attention/output/add"  [label="[]", style=solid];
"586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "594 bert/encoder/layer_2/attention/self/value/MatMul"  [label="[]", style=solid];
"588 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "589 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"589 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "594 bert/encoder/layer_2/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"590 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "591 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"591 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "600 bert/encoder/layer_2/attention/self/query/MatMul"  [label="[]", style=solid];
"592 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "593 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"593 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "608 bert/encoder/layer_2/attention/self/key/MatMul"  [label="[]", style=solid];
"594 bert/encoder/layer_2/attention/self/value/MatMul" -> "595 bert/encoder/layer_2/attention/self/value/BiasAdd"  [label="[]", style=solid];
"595 bert/encoder/layer_2/attention/self/value/BiasAdd" -> "596 bert/encoder/layer_2/attention/self/Reshape_2"  [label="[]", style=solid];
"596 bert/encoder/layer_2/attention/self/Reshape_2" -> "597 bert/encoder/layer_2/attention/self/transpose_2"  [label="[]", style=solid];
"597 bert/encoder/layer_2/attention/self/transpose_2" -> "619 bert/encoder/layer_2/attention/self/MatMul_1"  [label="[]", style=solid];
"598 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "599 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"599 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "600 bert/encoder/layer_2/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"600 bert/encoder/layer_2/attention/self/query/MatMul" -> "601 bert/encoder/layer_2/attention/self/query/BiasAdd"  [label="[]", style=solid];
"601 bert/encoder/layer_2/attention/self/query/BiasAdd" -> "602 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"602 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "603 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"603 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "604 bert/encoder/layer_2/attention/self/Reshape"  [label="[]", style=solid];
"604 bert/encoder/layer_2/attention/self/Reshape" -> "605 bert/encoder/layer_2/attention/self/transpose"  [label="[]", style=solid];
"605 bert/encoder/layer_2/attention/self/transpose" -> "615 bert/encoder/layer_2/attention/self/MatMul"  [label="[]", style=solid];
"606 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "607 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"607 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "608 bert/encoder/layer_2/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"608 bert/encoder/layer_2/attention/self/key/MatMul" -> "609 bert/encoder/layer_2/attention/self/key/BiasAdd"  [label="[]", style=solid];
"609 bert/encoder/layer_2/attention/self/key/BiasAdd" -> "610 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"610 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "611 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"611 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "612 bert/encoder/layer_2/attention/self/Reshape_1"  [label="[]", style=solid];
"612 bert/encoder/layer_2/attention/self/Reshape_1" -> "613 bert/encoder/layer_2/attention/self/transpose_1"  [label="[]", style=solid];
"613 bert/encoder/layer_2/attention/self/transpose_1" -> "614 bert/encoder/layer_2/attention/self/MatMul__334"  [label="[]", style=solid];
"614 bert/encoder/layer_2/attention/self/MatMul__334" -> "615 bert/encoder/layer_2/attention/self/MatMul"  [label="[]", style=solid];
"615 bert/encoder/layer_2/attention/self/MatMul" -> "616 bert/encoder/layer_2/attention/self/Mul"  [label="[]", style=solid];
"616 bert/encoder/layer_2/attention/self/Mul" -> "617 bert/encoder/layer_2/attention/self/add"  [label="[]", style=solid];
"617 bert/encoder/layer_2/attention/self/add" -> "618 bert/encoder/layer_2/attention/self/Softmax"  [label="[]", style=solid];
"618 bert/encoder/layer_2/attention/self/Softmax" -> "619 bert/encoder/layer_2/attention/self/MatMul_1"  [label="[]", style=solid];
"619 bert/encoder/layer_2/attention/self/MatMul_1" -> "620 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"620 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "621 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"621 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "622 bert/encoder/layer_2/attention/self/transpose_3"  [label="[]", style=solid];
"622 bert/encoder/layer_2/attention/self/transpose_3" -> "623 bert/encoder/layer_2/attention/self/Reshape_3"  [label="[]", style=solid];
"623 bert/encoder/layer_2/attention/self/Reshape_3" -> "626 bert/encoder/layer_2/attention/output/dense/MatMul"  [label="[]", style=solid];
"624 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "625 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"625 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "626 bert/encoder/layer_2/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"626 bert/encoder/layer_2/attention/output/dense/MatMul" -> "627 bert/encoder/layer_2/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"627 bert/encoder/layer_2/attention/output/dense/BiasAdd" -> "628 bert/encoder/layer_2/attention/output/add"  [label="[]", style=solid];
"628 bert/encoder/layer_2/attention/output/add" -> "629 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"628 bert/encoder/layer_2/attention/output/add" -> "631 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"628 bert/encoder/layer_2/attention/output/add" -> "640 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"629 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "630 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"629 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "638 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"630 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" -> "631 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"631 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" -> "632 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337"  [label="[]", style=solid];
"632 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" -> "633 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"633 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" -> "634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"634 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" -> "635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"635 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" -> "636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339"  [label="[]", style=solid];
"636 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" -> "637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "638 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"637 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "640 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"638 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" -> "639 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"639 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" -> "641 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"640 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" -> "641 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"641 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "642 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"641 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "662 bert/encoder/layer_2/output/add"  [label="[]", style=solid];
"642 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "643 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"643 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "646 bert/encoder/layer_2/intermediate/dense/MatMul"  [label="[]", style=solid];
"644 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "645 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"645 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "646 bert/encoder/layer_2/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"646 bert/encoder/layer_2/intermediate/dense/MatMul" -> "647 bert/encoder/layer_2/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"647 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "648 bert/encoder/layer_2/intermediate/dense/Pow"  [label="[]", style=solid];
"647 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "650 bert/encoder/layer_2/intermediate/dense/add"  [label="[]", style=solid];
"647 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "655 bert/encoder/layer_2/intermediate/dense/mul_3"  [label="[]", style=solid];
"648 bert/encoder/layer_2/intermediate/dense/Pow" -> "649 bert/encoder/layer_2/intermediate/dense/mul"  [label="[]", style=solid];
"649 bert/encoder/layer_2/intermediate/dense/mul" -> "650 bert/encoder/layer_2/intermediate/dense/add"  [label="[]", style=solid];
"650 bert/encoder/layer_2/intermediate/dense/add" -> "651 bert/encoder/layer_2/intermediate/dense/mul_1"  [label="[]", style=solid];
"651 bert/encoder/layer_2/intermediate/dense/mul_1" -> "652 bert/encoder/layer_2/intermediate/dense/Tanh"  [label="[]", style=solid];
"652 bert/encoder/layer_2/intermediate/dense/Tanh" -> "653 bert/encoder/layer_2/intermediate/dense/add_1"  [label="[]", style=solid];
"653 bert/encoder/layer_2/intermediate/dense/add_1" -> "654 bert/encoder/layer_2/intermediate/dense/mul_2"  [label="[]", style=solid];
"654 bert/encoder/layer_2/intermediate/dense/mul_2" -> "655 bert/encoder/layer_2/intermediate/dense/mul_3"  [label="[]", style=solid];
"655 bert/encoder/layer_2/intermediate/dense/mul_3" -> "656 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"656 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "657 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"657 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "660 bert/encoder/layer_2/output/dense/MatMul"  [label="[]", style=solid];
"658 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "659 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"659 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "660 bert/encoder/layer_2/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"660 bert/encoder/layer_2/output/dense/MatMul" -> "661 bert/encoder/layer_2/output/dense/BiasAdd"  [label="[]", style=solid];
"661 bert/encoder/layer_2/output/dense/BiasAdd" -> "662 bert/encoder/layer_2/output/add"  [label="[]", style=solid];
"662 bert/encoder/layer_2/output/add" -> "663 bert/encoder/layer_2/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"662 bert/encoder/layer_2/output/add" -> "665 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"662 bert/encoder/layer_2/output/add" -> "674 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"663 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "664 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"663 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "672 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"664 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" -> "665 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"665 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" -> "666 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341"  [label="[]", style=solid];
"666 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" -> "667 bert/encoder/layer_2/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"667 bert/encoder/layer_2/output/LayerNorm/moments/variance" -> "668 bert/encoder/layer_2/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"668 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" -> "669 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"669 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" -> "670 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343"  [label="[]", style=solid];
"670 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" -> "671 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "672 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"671 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "674 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"672 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" -> "673 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"673 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" -> "675 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"674 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" -> "675 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"675 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"675 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "680 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"675 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "682 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"675 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "718 bert/encoder/layer_3/attention/output/add"  [label="[]", style=solid];
"676 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"677 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "684 bert/encoder/layer_3/attention/self/value/MatMul"  [label="[]", style=solid];
"678 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "679 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"679 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "684 bert/encoder/layer_3/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"680 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "681 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"681 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "690 bert/encoder/layer_3/attention/self/query/MatMul"  [label="[]", style=solid];
"682 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "683 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"683 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "698 bert/encoder/layer_3/attention/self/key/MatMul"  [label="[]", style=solid];
"684 bert/encoder/layer_3/attention/self/value/MatMul" -> "685 bert/encoder/layer_3/attention/self/value/BiasAdd"  [label="[]", style=solid];
"685 bert/encoder/layer_3/attention/self/value/BiasAdd" -> "686 bert/encoder/layer_3/attention/self/Reshape_2"  [label="[]", style=solid];
"686 bert/encoder/layer_3/attention/self/Reshape_2" -> "687 bert/encoder/layer_3/attention/self/transpose_2"  [label="[]", style=solid];
"687 bert/encoder/layer_3/attention/self/transpose_2" -> "709 bert/encoder/layer_3/attention/self/MatMul_1"  [label="[]", style=solid];
"688 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "689 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"689 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "690 bert/encoder/layer_3/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"690 bert/encoder/layer_3/attention/self/query/MatMul" -> "691 bert/encoder/layer_3/attention/self/query/BiasAdd"  [label="[]", style=solid];
"691 bert/encoder/layer_3/attention/self/query/BiasAdd" -> "692 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"692 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "693 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"693 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "694 bert/encoder/layer_3/attention/self/Reshape"  [label="[]", style=solid];
"694 bert/encoder/layer_3/attention/self/Reshape" -> "695 bert/encoder/layer_3/attention/self/transpose"  [label="[]", style=solid];
"695 bert/encoder/layer_3/attention/self/transpose" -> "705 bert/encoder/layer_3/attention/self/MatMul"  [label="[]", style=solid];
"696 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "697 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"697 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "698 bert/encoder/layer_3/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"698 bert/encoder/layer_3/attention/self/key/MatMul" -> "699 bert/encoder/layer_3/attention/self/key/BiasAdd"  [label="[]", style=solid];
"699 bert/encoder/layer_3/attention/self/key/BiasAdd" -> "700 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"700 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "701 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"701 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "702 bert/encoder/layer_3/attention/self/Reshape_1"  [label="[]", style=solid];
"702 bert/encoder/layer_3/attention/self/Reshape_1" -> "703 bert/encoder/layer_3/attention/self/transpose_1"  [label="[]", style=solid];
"703 bert/encoder/layer_3/attention/self/transpose_1" -> "704 bert/encoder/layer_3/attention/self/MatMul__348"  [label="[]", style=solid];
"704 bert/encoder/layer_3/attention/self/MatMul__348" -> "705 bert/encoder/layer_3/attention/self/MatMul"  [label="[]", style=solid];
"705 bert/encoder/layer_3/attention/self/MatMul" -> "706 bert/encoder/layer_3/attention/self/Mul"  [label="[]", style=solid];
"706 bert/encoder/layer_3/attention/self/Mul" -> "707 bert/encoder/layer_3/attention/self/add"  [label="[]", style=solid];
"707 bert/encoder/layer_3/attention/self/add" -> "708 bert/encoder/layer_3/attention/self/Softmax"  [label="[]", style=solid];
"708 bert/encoder/layer_3/attention/self/Softmax" -> "709 bert/encoder/layer_3/attention/self/MatMul_1"  [label="[]", style=solid];
"709 bert/encoder/layer_3/attention/self/MatMul_1" -> "710 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"710 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "711 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"711 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "712 bert/encoder/layer_3/attention/self/transpose_3"  [label="[]", style=solid];
"712 bert/encoder/layer_3/attention/self/transpose_3" -> "713 bert/encoder/layer_3/attention/self/Reshape_3"  [label="[]", style=solid];
"713 bert/encoder/layer_3/attention/self/Reshape_3" -> "716 bert/encoder/layer_3/attention/output/dense/MatMul"  [label="[]", style=solid];
"714 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "715 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"715 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "716 bert/encoder/layer_3/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"716 bert/encoder/layer_3/attention/output/dense/MatMul" -> "717 bert/encoder/layer_3/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"717 bert/encoder/layer_3/attention/output/dense/BiasAdd" -> "718 bert/encoder/layer_3/attention/output/add"  [label="[]", style=solid];
"718 bert/encoder/layer_3/attention/output/add" -> "719 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"718 bert/encoder/layer_3/attention/output/add" -> "721 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"718 bert/encoder/layer_3/attention/output/add" -> "730 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"719 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "720 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"719 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "728 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"720 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" -> "721 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"721 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" -> "722 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351"  [label="[]", style=solid];
"722 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" -> "723 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"723 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" -> "724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"724 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" -> "725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"725 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" -> "726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353"  [label="[]", style=solid];
"726 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" -> "727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "728 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"727 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "730 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"728 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" -> "729 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"729 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" -> "731 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"730 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" -> "731 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"731 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "732 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"731 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "752 bert/encoder/layer_3/output/add"  [label="[]", style=solid];
"732 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "733 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"733 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "736 bert/encoder/layer_3/intermediate/dense/MatMul"  [label="[]", style=solid];
"734 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "735 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"735 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "736 bert/encoder/layer_3/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"736 bert/encoder/layer_3/intermediate/dense/MatMul" -> "737 bert/encoder/layer_3/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"737 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "738 bert/encoder/layer_3/intermediate/dense/Pow"  [label="[]", style=solid];
"737 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "740 bert/encoder/layer_3/intermediate/dense/add"  [label="[]", style=solid];
"737 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "745 bert/encoder/layer_3/intermediate/dense/mul_3"  [label="[]", style=solid];
"738 bert/encoder/layer_3/intermediate/dense/Pow" -> "739 bert/encoder/layer_3/intermediate/dense/mul"  [label="[]", style=solid];
"739 bert/encoder/layer_3/intermediate/dense/mul" -> "740 bert/encoder/layer_3/intermediate/dense/add"  [label="[]", style=solid];
"740 bert/encoder/layer_3/intermediate/dense/add" -> "741 bert/encoder/layer_3/intermediate/dense/mul_1"  [label="[]", style=solid];
"741 bert/encoder/layer_3/intermediate/dense/mul_1" -> "742 bert/encoder/layer_3/intermediate/dense/Tanh"  [label="[]", style=solid];
"742 bert/encoder/layer_3/intermediate/dense/Tanh" -> "743 bert/encoder/layer_3/intermediate/dense/add_1"  [label="[]", style=solid];
"743 bert/encoder/layer_3/intermediate/dense/add_1" -> "744 bert/encoder/layer_3/intermediate/dense/mul_2"  [label="[]", style=solid];
"744 bert/encoder/layer_3/intermediate/dense/mul_2" -> "745 bert/encoder/layer_3/intermediate/dense/mul_3"  [label="[]", style=solid];
"745 bert/encoder/layer_3/intermediate/dense/mul_3" -> "746 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"746 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "747 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"747 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "750 bert/encoder/layer_3/output/dense/MatMul"  [label="[]", style=solid];
"748 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "749 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"749 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "750 bert/encoder/layer_3/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"750 bert/encoder/layer_3/output/dense/MatMul" -> "751 bert/encoder/layer_3/output/dense/BiasAdd"  [label="[]", style=solid];
"751 bert/encoder/layer_3/output/dense/BiasAdd" -> "752 bert/encoder/layer_3/output/add"  [label="[]", style=solid];
"752 bert/encoder/layer_3/output/add" -> "753 bert/encoder/layer_3/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"752 bert/encoder/layer_3/output/add" -> "755 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"752 bert/encoder/layer_3/output/add" -> "764 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"753 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "754 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"753 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "762 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"754 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" -> "755 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"755 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" -> "756 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355"  [label="[]", style=solid];
"756 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" -> "757 bert/encoder/layer_3/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"757 bert/encoder/layer_3/output/LayerNorm/moments/variance" -> "758 bert/encoder/layer_3/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"758 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" -> "759 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"759 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" -> "760 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357"  [label="[]", style=solid];
"760 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" -> "761 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "762 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"761 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "764 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"762 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" -> "763 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"763 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" -> "765 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"764 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" -> "765 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"765 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"765 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "770 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"765 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "772 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"765 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "808 bert/encoder/layer_4/attention/output/add"  [label="[]", style=solid];
"766 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"767 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "774 bert/encoder/layer_4/attention/self/value/MatMul"  [label="[]", style=solid];
"768 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "769 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"769 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "774 bert/encoder/layer_4/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"770 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "771 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"771 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "780 bert/encoder/layer_4/attention/self/query/MatMul"  [label="[]", style=solid];
"772 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "773 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"773 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "788 bert/encoder/layer_4/attention/self/key/MatMul"  [label="[]", style=solid];
"774 bert/encoder/layer_4/attention/self/value/MatMul" -> "775 bert/encoder/layer_4/attention/self/value/BiasAdd"  [label="[]", style=solid];
"775 bert/encoder/layer_4/attention/self/value/BiasAdd" -> "776 bert/encoder/layer_4/attention/self/Reshape_2"  [label="[]", style=solid];
"776 bert/encoder/layer_4/attention/self/Reshape_2" -> "777 bert/encoder/layer_4/attention/self/transpose_2"  [label="[]", style=solid];
"777 bert/encoder/layer_4/attention/self/transpose_2" -> "799 bert/encoder/layer_4/attention/self/MatMul_1"  [label="[]", style=solid];
"778 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "779 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"779 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "780 bert/encoder/layer_4/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"780 bert/encoder/layer_4/attention/self/query/MatMul" -> "781 bert/encoder/layer_4/attention/self/query/BiasAdd"  [label="[]", style=solid];
"781 bert/encoder/layer_4/attention/self/query/BiasAdd" -> "782 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"782 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "783 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"783 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "784 bert/encoder/layer_4/attention/self/Reshape"  [label="[]", style=solid];
"784 bert/encoder/layer_4/attention/self/Reshape" -> "785 bert/encoder/layer_4/attention/self/transpose"  [label="[]", style=solid];
"785 bert/encoder/layer_4/attention/self/transpose" -> "795 bert/encoder/layer_4/attention/self/MatMul"  [label="[]", style=solid];
"786 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "787 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"787 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "788 bert/encoder/layer_4/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"788 bert/encoder/layer_4/attention/self/key/MatMul" -> "789 bert/encoder/layer_4/attention/self/key/BiasAdd"  [label="[]", style=solid];
"789 bert/encoder/layer_4/attention/self/key/BiasAdd" -> "790 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"790 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "791 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"791 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "792 bert/encoder/layer_4/attention/self/Reshape_1"  [label="[]", style=solid];
"792 bert/encoder/layer_4/attention/self/Reshape_1" -> "793 bert/encoder/layer_4/attention/self/transpose_1"  [label="[]", style=solid];
"793 bert/encoder/layer_4/attention/self/transpose_1" -> "794 bert/encoder/layer_4/attention/self/MatMul__362"  [label="[]", style=solid];
"794 bert/encoder/layer_4/attention/self/MatMul__362" -> "795 bert/encoder/layer_4/attention/self/MatMul"  [label="[]", style=solid];
"795 bert/encoder/layer_4/attention/self/MatMul" -> "796 bert/encoder/layer_4/attention/self/Mul"  [label="[]", style=solid];
"796 bert/encoder/layer_4/attention/self/Mul" -> "797 bert/encoder/layer_4/attention/self/add"  [label="[]", style=solid];
"797 bert/encoder/layer_4/attention/self/add" -> "798 bert/encoder/layer_4/attention/self/Softmax"  [label="[]", style=solid];
"798 bert/encoder/layer_4/attention/self/Softmax" -> "799 bert/encoder/layer_4/attention/self/MatMul_1"  [label="[]", style=solid];
"799 bert/encoder/layer_4/attention/self/MatMul_1" -> "800 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"800 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "801 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"801 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "802 bert/encoder/layer_4/attention/self/transpose_3"  [label="[]", style=solid];
"802 bert/encoder/layer_4/attention/self/transpose_3" -> "803 bert/encoder/layer_4/attention/self/Reshape_3"  [label="[]", style=solid];
"803 bert/encoder/layer_4/attention/self/Reshape_3" -> "806 bert/encoder/layer_4/attention/output/dense/MatMul"  [label="[]", style=solid];
"804 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "805 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"805 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "806 bert/encoder/layer_4/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"806 bert/encoder/layer_4/attention/output/dense/MatMul" -> "807 bert/encoder/layer_4/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"807 bert/encoder/layer_4/attention/output/dense/BiasAdd" -> "808 bert/encoder/layer_4/attention/output/add"  [label="[]", style=solid];
"808 bert/encoder/layer_4/attention/output/add" -> "809 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"808 bert/encoder/layer_4/attention/output/add" -> "811 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"808 bert/encoder/layer_4/attention/output/add" -> "820 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"809 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "810 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"809 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "818 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"810 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" -> "811 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"811 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" -> "812 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365"  [label="[]", style=solid];
"812 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" -> "813 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"813 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" -> "814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"814 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" -> "815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"815 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" -> "816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367"  [label="[]", style=solid];
"816 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" -> "817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "818 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"817 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "820 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"818 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" -> "819 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"819 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" -> "821 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"820 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" -> "821 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"821 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "822 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"821 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "842 bert/encoder/layer_4/output/add"  [label="[]", style=solid];
"822 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "823 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"823 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "826 bert/encoder/layer_4/intermediate/dense/MatMul"  [label="[]", style=solid];
"824 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "825 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"825 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "826 bert/encoder/layer_4/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"826 bert/encoder/layer_4/intermediate/dense/MatMul" -> "827 bert/encoder/layer_4/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"827 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "828 bert/encoder/layer_4/intermediate/dense/Pow"  [label="[]", style=solid];
"827 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "830 bert/encoder/layer_4/intermediate/dense/add"  [label="[]", style=solid];
"827 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "835 bert/encoder/layer_4/intermediate/dense/mul_3"  [label="[]", style=solid];
"828 bert/encoder/layer_4/intermediate/dense/Pow" -> "829 bert/encoder/layer_4/intermediate/dense/mul"  [label="[]", style=solid];
"829 bert/encoder/layer_4/intermediate/dense/mul" -> "830 bert/encoder/layer_4/intermediate/dense/add"  [label="[]", style=solid];
"830 bert/encoder/layer_4/intermediate/dense/add" -> "831 bert/encoder/layer_4/intermediate/dense/mul_1"  [label="[]", style=solid];
"831 bert/encoder/layer_4/intermediate/dense/mul_1" -> "832 bert/encoder/layer_4/intermediate/dense/Tanh"  [label="[]", style=solid];
"832 bert/encoder/layer_4/intermediate/dense/Tanh" -> "833 bert/encoder/layer_4/intermediate/dense/add_1"  [label="[]", style=solid];
"833 bert/encoder/layer_4/intermediate/dense/add_1" -> "834 bert/encoder/layer_4/intermediate/dense/mul_2"  [label="[]", style=solid];
"834 bert/encoder/layer_4/intermediate/dense/mul_2" -> "835 bert/encoder/layer_4/intermediate/dense/mul_3"  [label="[]", style=solid];
"835 bert/encoder/layer_4/intermediate/dense/mul_3" -> "836 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"836 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "837 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"837 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "840 bert/encoder/layer_4/output/dense/MatMul"  [label="[]", style=solid];
"838 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "839 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"839 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "840 bert/encoder/layer_4/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"840 bert/encoder/layer_4/output/dense/MatMul" -> "841 bert/encoder/layer_4/output/dense/BiasAdd"  [label="[]", style=solid];
"841 bert/encoder/layer_4/output/dense/BiasAdd" -> "842 bert/encoder/layer_4/output/add"  [label="[]", style=solid];
"842 bert/encoder/layer_4/output/add" -> "843 bert/encoder/layer_4/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"842 bert/encoder/layer_4/output/add" -> "845 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"842 bert/encoder/layer_4/output/add" -> "854 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"843 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "844 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"843 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "852 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"844 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" -> "845 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"845 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" -> "846 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369"  [label="[]", style=solid];
"846 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" -> "847 bert/encoder/layer_4/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"847 bert/encoder/layer_4/output/LayerNorm/moments/variance" -> "848 bert/encoder/layer_4/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"848 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" -> "849 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"849 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" -> "850 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371"  [label="[]", style=solid];
"850 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" -> "851 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "852 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"851 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "854 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"852 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" -> "853 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"853 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" -> "855 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"854 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" -> "855 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"855 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"855 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "860 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"855 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "862 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"855 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "898 bert/encoder/layer_5/attention/output/add"  [label="[]", style=solid];
"856 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"857 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "864 bert/encoder/layer_5/attention/self/value/MatMul"  [label="[]", style=solid];
"858 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "859 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"859 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "864 bert/encoder/layer_5/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"860 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "861 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"861 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "870 bert/encoder/layer_5/attention/self/query/MatMul"  [label="[]", style=solid];
"862 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "863 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"863 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "878 bert/encoder/layer_5/attention/self/key/MatMul"  [label="[]", style=solid];
"864 bert/encoder/layer_5/attention/self/value/MatMul" -> "865 bert/encoder/layer_5/attention/self/value/BiasAdd"  [label="[]", style=solid];
"865 bert/encoder/layer_5/attention/self/value/BiasAdd" -> "866 bert/encoder/layer_5/attention/self/Reshape_2"  [label="[]", style=solid];
"866 bert/encoder/layer_5/attention/self/Reshape_2" -> "867 bert/encoder/layer_5/attention/self/transpose_2"  [label="[]", style=solid];
"867 bert/encoder/layer_5/attention/self/transpose_2" -> "889 bert/encoder/layer_5/attention/self/MatMul_1"  [label="[]", style=solid];
"868 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "869 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"869 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "870 bert/encoder/layer_5/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"870 bert/encoder/layer_5/attention/self/query/MatMul" -> "871 bert/encoder/layer_5/attention/self/query/BiasAdd"  [label="[]", style=solid];
"871 bert/encoder/layer_5/attention/self/query/BiasAdd" -> "872 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"872 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "873 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"873 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "874 bert/encoder/layer_5/attention/self/Reshape"  [label="[]", style=solid];
"874 bert/encoder/layer_5/attention/self/Reshape" -> "875 bert/encoder/layer_5/attention/self/transpose"  [label="[]", style=solid];
"875 bert/encoder/layer_5/attention/self/transpose" -> "885 bert/encoder/layer_5/attention/self/MatMul"  [label="[]", style=solid];
"876 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "877 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"877 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "878 bert/encoder/layer_5/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"878 bert/encoder/layer_5/attention/self/key/MatMul" -> "879 bert/encoder/layer_5/attention/self/key/BiasAdd"  [label="[]", style=solid];
"879 bert/encoder/layer_5/attention/self/key/BiasAdd" -> "880 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"880 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "881 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"881 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "882 bert/encoder/layer_5/attention/self/Reshape_1"  [label="[]", style=solid];
"882 bert/encoder/layer_5/attention/self/Reshape_1" -> "883 bert/encoder/layer_5/attention/self/transpose_1"  [label="[]", style=solid];
"883 bert/encoder/layer_5/attention/self/transpose_1" -> "884 bert/encoder/layer_5/attention/self/MatMul__376"  [label="[]", style=solid];
"884 bert/encoder/layer_5/attention/self/MatMul__376" -> "885 bert/encoder/layer_5/attention/self/MatMul"  [label="[]", style=solid];
"885 bert/encoder/layer_5/attention/self/MatMul" -> "886 bert/encoder/layer_5/attention/self/Mul"  [label="[]", style=solid];
"886 bert/encoder/layer_5/attention/self/Mul" -> "887 bert/encoder/layer_5/attention/self/add"  [label="[]", style=solid];
"887 bert/encoder/layer_5/attention/self/add" -> "888 bert/encoder/layer_5/attention/self/Softmax"  [label="[]", style=solid];
"888 bert/encoder/layer_5/attention/self/Softmax" -> "889 bert/encoder/layer_5/attention/self/MatMul_1"  [label="[]", style=solid];
"889 bert/encoder/layer_5/attention/self/MatMul_1" -> "890 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"890 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "891 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"891 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "892 bert/encoder/layer_5/attention/self/transpose_3"  [label="[]", style=solid];
"892 bert/encoder/layer_5/attention/self/transpose_3" -> "893 bert/encoder/layer_5/attention/self/Reshape_3"  [label="[]", style=solid];
"893 bert/encoder/layer_5/attention/self/Reshape_3" -> "896 bert/encoder/layer_5/attention/output/dense/MatMul"  [label="[]", style=solid];
"894 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "895 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"895 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "896 bert/encoder/layer_5/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"896 bert/encoder/layer_5/attention/output/dense/MatMul" -> "897 bert/encoder/layer_5/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"897 bert/encoder/layer_5/attention/output/dense/BiasAdd" -> "898 bert/encoder/layer_5/attention/output/add"  [label="[]", style=solid];
"898 bert/encoder/layer_5/attention/output/add" -> "899 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"898 bert/encoder/layer_5/attention/output/add" -> "901 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"898 bert/encoder/layer_5/attention/output/add" -> "910 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"899 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "900 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"899 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "908 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"900 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" -> "901 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"901 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" -> "902 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379"  [label="[]", style=solid];
"902 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" -> "903 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"903 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" -> "904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"904 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" -> "905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"905 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" -> "906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381"  [label="[]", style=solid];
"906 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" -> "907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "908 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"907 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "910 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"908 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" -> "909 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"909 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" -> "911 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"910 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" -> "911 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"911 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "912 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"911 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "932 bert/encoder/layer_5/output/add"  [label="[]", style=solid];
"912 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "913 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"913 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "916 bert/encoder/layer_5/intermediate/dense/MatMul"  [label="[]", style=solid];
"914 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "915 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"915 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "916 bert/encoder/layer_5/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"916 bert/encoder/layer_5/intermediate/dense/MatMul" -> "917 bert/encoder/layer_5/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"917 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "918 bert/encoder/layer_5/intermediate/dense/Pow"  [label="[]", style=solid];
"917 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "920 bert/encoder/layer_5/intermediate/dense/add"  [label="[]", style=solid];
"917 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "925 bert/encoder/layer_5/intermediate/dense/mul_3"  [label="[]", style=solid];
"918 bert/encoder/layer_5/intermediate/dense/Pow" -> "919 bert/encoder/layer_5/intermediate/dense/mul"  [label="[]", style=solid];
"919 bert/encoder/layer_5/intermediate/dense/mul" -> "920 bert/encoder/layer_5/intermediate/dense/add"  [label="[]", style=solid];
"920 bert/encoder/layer_5/intermediate/dense/add" -> "921 bert/encoder/layer_5/intermediate/dense/mul_1"  [label="[]", style=solid];
"921 bert/encoder/layer_5/intermediate/dense/mul_1" -> "922 bert/encoder/layer_5/intermediate/dense/Tanh"  [label="[]", style=solid];
"922 bert/encoder/layer_5/intermediate/dense/Tanh" -> "923 bert/encoder/layer_5/intermediate/dense/add_1"  [label="[]", style=solid];
"923 bert/encoder/layer_5/intermediate/dense/add_1" -> "924 bert/encoder/layer_5/intermediate/dense/mul_2"  [label="[]", style=solid];
"924 bert/encoder/layer_5/intermediate/dense/mul_2" -> "925 bert/encoder/layer_5/intermediate/dense/mul_3"  [label="[]", style=solid];
"925 bert/encoder/layer_5/intermediate/dense/mul_3" -> "926 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"926 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "927 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"927 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "930 bert/encoder/layer_5/output/dense/MatMul"  [label="[]", style=solid];
"928 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "929 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"929 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "930 bert/encoder/layer_5/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"930 bert/encoder/layer_5/output/dense/MatMul" -> "931 bert/encoder/layer_5/output/dense/BiasAdd"  [label="[]", style=solid];
"931 bert/encoder/layer_5/output/dense/BiasAdd" -> "932 bert/encoder/layer_5/output/add"  [label="[]", style=solid];
"932 bert/encoder/layer_5/output/add" -> "933 bert/encoder/layer_5/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"932 bert/encoder/layer_5/output/add" -> "935 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"932 bert/encoder/layer_5/output/add" -> "944 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"933 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "934 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"933 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "942 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"934 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" -> "935 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"935 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" -> "936 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383"  [label="[]", style=solid];
"936 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" -> "937 bert/encoder/layer_5/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"937 bert/encoder/layer_5/output/LayerNorm/moments/variance" -> "938 bert/encoder/layer_5/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"938 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" -> "939 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"939 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" -> "940 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385"  [label="[]", style=solid];
"940 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" -> "941 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "942 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"941 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "944 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"942 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" -> "943 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"943 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" -> "945 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"944 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" -> "945 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"945 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"945 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "950 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"945 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "952 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"945 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "988 bert/encoder/layer_6/attention/output/add"  [label="[]", style=solid];
"946 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"947 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "954 bert/encoder/layer_6/attention/self/value/MatMul"  [label="[]", style=solid];
"948 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "949 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"949 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "954 bert/encoder/layer_6/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"950 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "951 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"951 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "960 bert/encoder/layer_6/attention/self/query/MatMul"  [label="[]", style=solid];
"952 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "953 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"953 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "968 bert/encoder/layer_6/attention/self/key/MatMul"  [label="[]", style=solid];
"954 bert/encoder/layer_6/attention/self/value/MatMul" -> "955 bert/encoder/layer_6/attention/self/value/BiasAdd"  [label="[]", style=solid];
"955 bert/encoder/layer_6/attention/self/value/BiasAdd" -> "956 bert/encoder/layer_6/attention/self/Reshape_2"  [label="[]", style=solid];
"956 bert/encoder/layer_6/attention/self/Reshape_2" -> "957 bert/encoder/layer_6/attention/self/transpose_2"  [label="[]", style=solid];
"957 bert/encoder/layer_6/attention/self/transpose_2" -> "979 bert/encoder/layer_6/attention/self/MatMul_1"  [label="[]", style=solid];
"958 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "959 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"959 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "960 bert/encoder/layer_6/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"960 bert/encoder/layer_6/attention/self/query/MatMul" -> "961 bert/encoder/layer_6/attention/self/query/BiasAdd"  [label="[]", style=solid];
"961 bert/encoder/layer_6/attention/self/query/BiasAdd" -> "962 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"962 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "963 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"963 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "964 bert/encoder/layer_6/attention/self/Reshape"  [label="[]", style=solid];
"964 bert/encoder/layer_6/attention/self/Reshape" -> "965 bert/encoder/layer_6/attention/self/transpose"  [label="[]", style=solid];
"965 bert/encoder/layer_6/attention/self/transpose" -> "975 bert/encoder/layer_6/attention/self/MatMul"  [label="[]", style=solid];
"966 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "967 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"967 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "968 bert/encoder/layer_6/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"968 bert/encoder/layer_6/attention/self/key/MatMul" -> "969 bert/encoder/layer_6/attention/self/key/BiasAdd"  [label="[]", style=solid];
"969 bert/encoder/layer_6/attention/self/key/BiasAdd" -> "970 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"970 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "971 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"971 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "972 bert/encoder/layer_6/attention/self/Reshape_1"  [label="[]", style=solid];
"972 bert/encoder/layer_6/attention/self/Reshape_1" -> "973 bert/encoder/layer_6/attention/self/transpose_1"  [label="[]", style=solid];
"973 bert/encoder/layer_6/attention/self/transpose_1" -> "974 bert/encoder/layer_6/attention/self/MatMul__390"  [label="[]", style=solid];
"974 bert/encoder/layer_6/attention/self/MatMul__390" -> "975 bert/encoder/layer_6/attention/self/MatMul"  [label="[]", style=solid];
"975 bert/encoder/layer_6/attention/self/MatMul" -> "976 bert/encoder/layer_6/attention/self/Mul"  [label="[]", style=solid];
"976 bert/encoder/layer_6/attention/self/Mul" -> "977 bert/encoder/layer_6/attention/self/add"  [label="[]", style=solid];
"977 bert/encoder/layer_6/attention/self/add" -> "978 bert/encoder/layer_6/attention/self/Softmax"  [label="[]", style=solid];
"978 bert/encoder/layer_6/attention/self/Softmax" -> "979 bert/encoder/layer_6/attention/self/MatMul_1"  [label="[]", style=solid];
"979 bert/encoder/layer_6/attention/self/MatMul_1" -> "980 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"980 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "981 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"981 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "982 bert/encoder/layer_6/attention/self/transpose_3"  [label="[]", style=solid];
"982 bert/encoder/layer_6/attention/self/transpose_3" -> "983 bert/encoder/layer_6/attention/self/Reshape_3"  [label="[]", style=solid];
"983 bert/encoder/layer_6/attention/self/Reshape_3" -> "986 bert/encoder/layer_6/attention/output/dense/MatMul"  [label="[]", style=solid];
"984 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "985 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"985 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "986 bert/encoder/layer_6/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"986 bert/encoder/layer_6/attention/output/dense/MatMul" -> "987 bert/encoder/layer_6/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"987 bert/encoder/layer_6/attention/output/dense/BiasAdd" -> "988 bert/encoder/layer_6/attention/output/add"  [label="[]", style=solid];
"988 bert/encoder/layer_6/attention/output/add" -> "989 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"988 bert/encoder/layer_6/attention/output/add" -> "991 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"988 bert/encoder/layer_6/attention/output/add" -> "1000 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"989 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "990 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"989 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "998 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"990 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" -> "991 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"991 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" -> "992 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393"  [label="[]", style=solid];
"992 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" -> "993 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"993 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" -> "994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"994 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" -> "995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"995 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" -> "996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395"  [label="[]", style=solid];
"996 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" -> "997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "998 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"997 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "1000 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"998 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" -> "999 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"999 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" -> "1001 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1000 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" -> "1001 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1001 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1002 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1001 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1022 bert/encoder/layer_6/output/add"  [label="[]", style=solid];
"1002 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1003 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1003 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1006 bert/encoder/layer_6/intermediate/dense/MatMul"  [label="[]", style=solid];
"1004 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1005 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1005 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1006 bert/encoder/layer_6/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1006 bert/encoder/layer_6/intermediate/dense/MatMul" -> "1007 bert/encoder/layer_6/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1007 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1008 bert/encoder/layer_6/intermediate/dense/Pow"  [label="[]", style=solid];
"1007 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1010 bert/encoder/layer_6/intermediate/dense/add"  [label="[]", style=solid];
"1007 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1015 bert/encoder/layer_6/intermediate/dense/mul_3"  [label="[]", style=solid];
"1008 bert/encoder/layer_6/intermediate/dense/Pow" -> "1009 bert/encoder/layer_6/intermediate/dense/mul"  [label="[]", style=solid];
"1009 bert/encoder/layer_6/intermediate/dense/mul" -> "1010 bert/encoder/layer_6/intermediate/dense/add"  [label="[]", style=solid];
"1010 bert/encoder/layer_6/intermediate/dense/add" -> "1011 bert/encoder/layer_6/intermediate/dense/mul_1"  [label="[]", style=solid];
"1011 bert/encoder/layer_6/intermediate/dense/mul_1" -> "1012 bert/encoder/layer_6/intermediate/dense/Tanh"  [label="[]", style=solid];
"1012 bert/encoder/layer_6/intermediate/dense/Tanh" -> "1013 bert/encoder/layer_6/intermediate/dense/add_1"  [label="[]", style=solid];
"1013 bert/encoder/layer_6/intermediate/dense/add_1" -> "1014 bert/encoder/layer_6/intermediate/dense/mul_2"  [label="[]", style=solid];
"1014 bert/encoder/layer_6/intermediate/dense/mul_2" -> "1015 bert/encoder/layer_6/intermediate/dense/mul_3"  [label="[]", style=solid];
"1015 bert/encoder/layer_6/intermediate/dense/mul_3" -> "1016 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1016 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1017 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1017 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1020 bert/encoder/layer_6/output/dense/MatMul"  [label="[]", style=solid];
"1018 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1019 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1019 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1020 bert/encoder/layer_6/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1020 bert/encoder/layer_6/output/dense/MatMul" -> "1021 bert/encoder/layer_6/output/dense/BiasAdd"  [label="[]", style=solid];
"1021 bert/encoder/layer_6/output/dense/BiasAdd" -> "1022 bert/encoder/layer_6/output/add"  [label="[]", style=solid];
"1022 bert/encoder/layer_6/output/add" -> "1023 bert/encoder/layer_6/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1022 bert/encoder/layer_6/output/add" -> "1025 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1022 bert/encoder/layer_6/output/add" -> "1034 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1023 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1024 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1023 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1032 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1024 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" -> "1025 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1025 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" -> "1026 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397"  [label="[]", style=solid];
"1026 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" -> "1027 bert/encoder/layer_6/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1027 bert/encoder/layer_6/output/LayerNorm/moments/variance" -> "1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1028 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" -> "1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1029 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" -> "1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399"  [label="[]", style=solid];
"1030 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" -> "1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1032 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1031 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1034 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1032 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" -> "1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1033 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" -> "1035 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1034 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" -> "1035 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1035 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1035 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1040 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1035 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1042 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1035 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1078 bert/encoder/layer_7/attention/output/add"  [label="[]", style=solid];
"1036 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1037 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1044 bert/encoder/layer_7/attention/self/value/MatMul"  [label="[]", style=solid];
"1038 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1039 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1039 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1044 bert/encoder/layer_7/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1040 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1041 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1041 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1050 bert/encoder/layer_7/attention/self/query/MatMul"  [label="[]", style=solid];
"1042 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1043 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1043 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1058 bert/encoder/layer_7/attention/self/key/MatMul"  [label="[]", style=solid];
"1044 bert/encoder/layer_7/attention/self/value/MatMul" -> "1045 bert/encoder/layer_7/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1045 bert/encoder/layer_7/attention/self/value/BiasAdd" -> "1046 bert/encoder/layer_7/attention/self/Reshape_2"  [label="[]", style=solid];
"1046 bert/encoder/layer_7/attention/self/Reshape_2" -> "1047 bert/encoder/layer_7/attention/self/transpose_2"  [label="[]", style=solid];
"1047 bert/encoder/layer_7/attention/self/transpose_2" -> "1069 bert/encoder/layer_7/attention/self/MatMul_1"  [label="[]", style=solid];
"1048 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1049 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1049 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1050 bert/encoder/layer_7/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1050 bert/encoder/layer_7/attention/self/query/MatMul" -> "1051 bert/encoder/layer_7/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1051 bert/encoder/layer_7/attention/self/query/BiasAdd" -> "1052 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1052 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1053 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1053 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1054 bert/encoder/layer_7/attention/self/Reshape"  [label="[]", style=solid];
"1054 bert/encoder/layer_7/attention/self/Reshape" -> "1055 bert/encoder/layer_7/attention/self/transpose"  [label="[]", style=solid];
"1055 bert/encoder/layer_7/attention/self/transpose" -> "1065 bert/encoder/layer_7/attention/self/MatMul"  [label="[]", style=solid];
"1056 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1057 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1057 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1058 bert/encoder/layer_7/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1058 bert/encoder/layer_7/attention/self/key/MatMul" -> "1059 bert/encoder/layer_7/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1059 bert/encoder/layer_7/attention/self/key/BiasAdd" -> "1060 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1060 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1061 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1061 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1062 bert/encoder/layer_7/attention/self/Reshape_1"  [label="[]", style=solid];
"1062 bert/encoder/layer_7/attention/self/Reshape_1" -> "1063 bert/encoder/layer_7/attention/self/transpose_1"  [label="[]", style=solid];
"1063 bert/encoder/layer_7/attention/self/transpose_1" -> "1064 bert/encoder/layer_7/attention/self/MatMul__404"  [label="[]", style=solid];
"1064 bert/encoder/layer_7/attention/self/MatMul__404" -> "1065 bert/encoder/layer_7/attention/self/MatMul"  [label="[]", style=solid];
"1065 bert/encoder/layer_7/attention/self/MatMul" -> "1066 bert/encoder/layer_7/attention/self/Mul"  [label="[]", style=solid];
"1066 bert/encoder/layer_7/attention/self/Mul" -> "1067 bert/encoder/layer_7/attention/self/add"  [label="[]", style=solid];
"1067 bert/encoder/layer_7/attention/self/add" -> "1068 bert/encoder/layer_7/attention/self/Softmax"  [label="[]", style=solid];
"1068 bert/encoder/layer_7/attention/self/Softmax" -> "1069 bert/encoder/layer_7/attention/self/MatMul_1"  [label="[]", style=solid];
"1069 bert/encoder/layer_7/attention/self/MatMul_1" -> "1070 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1070 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1071 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1071 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1072 bert/encoder/layer_7/attention/self/transpose_3"  [label="[]", style=solid];
"1072 bert/encoder/layer_7/attention/self/transpose_3" -> "1073 bert/encoder/layer_7/attention/self/Reshape_3"  [label="[]", style=solid];
"1073 bert/encoder/layer_7/attention/self/Reshape_3" -> "1076 bert/encoder/layer_7/attention/output/dense/MatMul"  [label="[]", style=solid];
"1074 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1075 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1075 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1076 bert/encoder/layer_7/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1076 bert/encoder/layer_7/attention/output/dense/MatMul" -> "1077 bert/encoder/layer_7/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1077 bert/encoder/layer_7/attention/output/dense/BiasAdd" -> "1078 bert/encoder/layer_7/attention/output/add"  [label="[]", style=solid];
"1078 bert/encoder/layer_7/attention/output/add" -> "1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1078 bert/encoder/layer_7/attention/output/add" -> "1081 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1078 bert/encoder/layer_7/attention/output/add" -> "1090 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1080 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1079 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1088 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1080 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" -> "1081 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1081 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" -> "1082 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407"  [label="[]", style=solid];
"1082 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" -> "1083 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1083 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" -> "1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1084 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" -> "1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1085 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409"  [label="[]", style=solid];
"1086 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" -> "1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1088 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1087 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1090 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1088 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" -> "1089 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1089 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" -> "1091 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1090 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" -> "1091 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1091 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1092 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1091 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1112 bert/encoder/layer_7/output/add"  [label="[]", style=solid];
"1092 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1093 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1093 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1096 bert/encoder/layer_7/intermediate/dense/MatMul"  [label="[]", style=solid];
"1094 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1095 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1095 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1096 bert/encoder/layer_7/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1096 bert/encoder/layer_7/intermediate/dense/MatMul" -> "1097 bert/encoder/layer_7/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1097 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1098 bert/encoder/layer_7/intermediate/dense/Pow"  [label="[]", style=solid];
"1097 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1100 bert/encoder/layer_7/intermediate/dense/add"  [label="[]", style=solid];
"1097 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1105 bert/encoder/layer_7/intermediate/dense/mul_3"  [label="[]", style=solid];
"1098 bert/encoder/layer_7/intermediate/dense/Pow" -> "1099 bert/encoder/layer_7/intermediate/dense/mul"  [label="[]", style=solid];
"1099 bert/encoder/layer_7/intermediate/dense/mul" -> "1100 bert/encoder/layer_7/intermediate/dense/add"  [label="[]", style=solid];
"1100 bert/encoder/layer_7/intermediate/dense/add" -> "1101 bert/encoder/layer_7/intermediate/dense/mul_1"  [label="[]", style=solid];
"1101 bert/encoder/layer_7/intermediate/dense/mul_1" -> "1102 bert/encoder/layer_7/intermediate/dense/Tanh"  [label="[]", style=solid];
"1102 bert/encoder/layer_7/intermediate/dense/Tanh" -> "1103 bert/encoder/layer_7/intermediate/dense/add_1"  [label="[]", style=solid];
"1103 bert/encoder/layer_7/intermediate/dense/add_1" -> "1104 bert/encoder/layer_7/intermediate/dense/mul_2"  [label="[]", style=solid];
"1104 bert/encoder/layer_7/intermediate/dense/mul_2" -> "1105 bert/encoder/layer_7/intermediate/dense/mul_3"  [label="[]", style=solid];
"1105 bert/encoder/layer_7/intermediate/dense/mul_3" -> "1106 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1106 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1107 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1107 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1110 bert/encoder/layer_7/output/dense/MatMul"  [label="[]", style=solid];
"1108 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1109 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1109 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1110 bert/encoder/layer_7/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1110 bert/encoder/layer_7/output/dense/MatMul" -> "1111 bert/encoder/layer_7/output/dense/BiasAdd"  [label="[]", style=solid];
"1111 bert/encoder/layer_7/output/dense/BiasAdd" -> "1112 bert/encoder/layer_7/output/add"  [label="[]", style=solid];
"1112 bert/encoder/layer_7/output/add" -> "1113 bert/encoder/layer_7/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1112 bert/encoder/layer_7/output/add" -> "1115 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1112 bert/encoder/layer_7/output/add" -> "1124 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1113 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1114 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1113 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1122 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1114 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" -> "1115 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1115 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" -> "1116 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411"  [label="[]", style=solid];
"1116 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" -> "1117 bert/encoder/layer_7/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1117 bert/encoder/layer_7/output/LayerNorm/moments/variance" -> "1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1118 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" -> "1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1119 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" -> "1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413"  [label="[]", style=solid];
"1120 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" -> "1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1122 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1124 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1122 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" -> "1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1123 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" -> "1125 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1124 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" -> "1125 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1125 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1125 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1130 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1125 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1132 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1125 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1168 bert/encoder/layer_8/attention/output/add"  [label="[]", style=solid];
"1126 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1127 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1134 bert/encoder/layer_8/attention/self/value/MatMul"  [label="[]", style=solid];
"1128 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1129 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1129 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1134 bert/encoder/layer_8/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1130 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1131 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1131 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1140 bert/encoder/layer_8/attention/self/query/MatMul"  [label="[]", style=solid];
"1132 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1133 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1133 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1148 bert/encoder/layer_8/attention/self/key/MatMul"  [label="[]", style=solid];
"1134 bert/encoder/layer_8/attention/self/value/MatMul" -> "1135 bert/encoder/layer_8/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1135 bert/encoder/layer_8/attention/self/value/BiasAdd" -> "1136 bert/encoder/layer_8/attention/self/Reshape_2"  [label="[]", style=solid];
"1136 bert/encoder/layer_8/attention/self/Reshape_2" -> "1137 bert/encoder/layer_8/attention/self/transpose_2"  [label="[]", style=solid];
"1137 bert/encoder/layer_8/attention/self/transpose_2" -> "1159 bert/encoder/layer_8/attention/self/MatMul_1"  [label="[]", style=solid];
"1138 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1139 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1139 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1140 bert/encoder/layer_8/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1140 bert/encoder/layer_8/attention/self/query/MatMul" -> "1141 bert/encoder/layer_8/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1141 bert/encoder/layer_8/attention/self/query/BiasAdd" -> "1142 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1142 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1143 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1143 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1144 bert/encoder/layer_8/attention/self/Reshape"  [label="[]", style=solid];
"1144 bert/encoder/layer_8/attention/self/Reshape" -> "1145 bert/encoder/layer_8/attention/self/transpose"  [label="[]", style=solid];
"1145 bert/encoder/layer_8/attention/self/transpose" -> "1155 bert/encoder/layer_8/attention/self/MatMul"  [label="[]", style=solid];
"1146 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1147 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1147 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1148 bert/encoder/layer_8/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1148 bert/encoder/layer_8/attention/self/key/MatMul" -> "1149 bert/encoder/layer_8/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1149 bert/encoder/layer_8/attention/self/key/BiasAdd" -> "1150 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1150 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1151 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1151 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1152 bert/encoder/layer_8/attention/self/Reshape_1"  [label="[]", style=solid];
"1152 bert/encoder/layer_8/attention/self/Reshape_1" -> "1153 bert/encoder/layer_8/attention/self/transpose_1"  [label="[]", style=solid];
"1153 bert/encoder/layer_8/attention/self/transpose_1" -> "1154 bert/encoder/layer_8/attention/self/MatMul__418"  [label="[]", style=solid];
"1154 bert/encoder/layer_8/attention/self/MatMul__418" -> "1155 bert/encoder/layer_8/attention/self/MatMul"  [label="[]", style=solid];
"1155 bert/encoder/layer_8/attention/self/MatMul" -> "1156 bert/encoder/layer_8/attention/self/Mul"  [label="[]", style=solid];
"1156 bert/encoder/layer_8/attention/self/Mul" -> "1157 bert/encoder/layer_8/attention/self/add"  [label="[]", style=solid];
"1157 bert/encoder/layer_8/attention/self/add" -> "1158 bert/encoder/layer_8/attention/self/Softmax"  [label="[]", style=solid];
"1158 bert/encoder/layer_8/attention/self/Softmax" -> "1159 bert/encoder/layer_8/attention/self/MatMul_1"  [label="[]", style=solid];
"1159 bert/encoder/layer_8/attention/self/MatMul_1" -> "1160 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1160 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1161 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1161 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1162 bert/encoder/layer_8/attention/self/transpose_3"  [label="[]", style=solid];
"1162 bert/encoder/layer_8/attention/self/transpose_3" -> "1163 bert/encoder/layer_8/attention/self/Reshape_3"  [label="[]", style=solid];
"1163 bert/encoder/layer_8/attention/self/Reshape_3" -> "1166 bert/encoder/layer_8/attention/output/dense/MatMul"  [label="[]", style=solid];
"1164 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1165 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1165 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1166 bert/encoder/layer_8/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1166 bert/encoder/layer_8/attention/output/dense/MatMul" -> "1167 bert/encoder/layer_8/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1167 bert/encoder/layer_8/attention/output/dense/BiasAdd" -> "1168 bert/encoder/layer_8/attention/output/add"  [label="[]", style=solid];
"1168 bert/encoder/layer_8/attention/output/add" -> "1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1168 bert/encoder/layer_8/attention/output/add" -> "1171 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1168 bert/encoder/layer_8/attention/output/add" -> "1180 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1170 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1169 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1178 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1170 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" -> "1171 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1171 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" -> "1172 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421"  [label="[]", style=solid];
"1172 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" -> "1173 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1173 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" -> "1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1174 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" -> "1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1175 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423"  [label="[]", style=solid];
"1176 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" -> "1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1178 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1177 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1180 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1178 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" -> "1179 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1179 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" -> "1181 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1180 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" -> "1181 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1181 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1182 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1181 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1202 bert/encoder/layer_8/output/add"  [label="[]", style=solid];
"1182 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1183 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1183 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1186 bert/encoder/layer_8/intermediate/dense/MatMul"  [label="[]", style=solid];
"1184 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1185 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1185 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1186 bert/encoder/layer_8/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1186 bert/encoder/layer_8/intermediate/dense/MatMul" -> "1187 bert/encoder/layer_8/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1187 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1188 bert/encoder/layer_8/intermediate/dense/Pow"  [label="[]", style=solid];
"1187 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1190 bert/encoder/layer_8/intermediate/dense/add"  [label="[]", style=solid];
"1187 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1195 bert/encoder/layer_8/intermediate/dense/mul_3"  [label="[]", style=solid];
"1188 bert/encoder/layer_8/intermediate/dense/Pow" -> "1189 bert/encoder/layer_8/intermediate/dense/mul"  [label="[]", style=solid];
"1189 bert/encoder/layer_8/intermediate/dense/mul" -> "1190 bert/encoder/layer_8/intermediate/dense/add"  [label="[]", style=solid];
"1190 bert/encoder/layer_8/intermediate/dense/add" -> "1191 bert/encoder/layer_8/intermediate/dense/mul_1"  [label="[]", style=solid];
"1191 bert/encoder/layer_8/intermediate/dense/mul_1" -> "1192 bert/encoder/layer_8/intermediate/dense/Tanh"  [label="[]", style=solid];
"1192 bert/encoder/layer_8/intermediate/dense/Tanh" -> "1193 bert/encoder/layer_8/intermediate/dense/add_1"  [label="[]", style=solid];
"1193 bert/encoder/layer_8/intermediate/dense/add_1" -> "1194 bert/encoder/layer_8/intermediate/dense/mul_2"  [label="[]", style=solid];
"1194 bert/encoder/layer_8/intermediate/dense/mul_2" -> "1195 bert/encoder/layer_8/intermediate/dense/mul_3"  [label="[]", style=solid];
"1195 bert/encoder/layer_8/intermediate/dense/mul_3" -> "1196 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1196 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1197 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1197 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1200 bert/encoder/layer_8/output/dense/MatMul"  [label="[]", style=solid];
"1198 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1199 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1199 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1200 bert/encoder/layer_8/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1200 bert/encoder/layer_8/output/dense/MatMul" -> "1201 bert/encoder/layer_8/output/dense/BiasAdd"  [label="[]", style=solid];
"1201 bert/encoder/layer_8/output/dense/BiasAdd" -> "1202 bert/encoder/layer_8/output/add"  [label="[]", style=solid];
"1202 bert/encoder/layer_8/output/add" -> "1203 bert/encoder/layer_8/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1202 bert/encoder/layer_8/output/add" -> "1205 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1202 bert/encoder/layer_8/output/add" -> "1214 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1203 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1204 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1203 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1212 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1204 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" -> "1205 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1205 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" -> "1206 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425"  [label="[]", style=solid];
"1206 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" -> "1207 bert/encoder/layer_8/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1207 bert/encoder/layer_8/output/LayerNorm/moments/variance" -> "1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1208 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" -> "1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1209 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" -> "1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427"  [label="[]", style=solid];
"1210 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" -> "1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1212 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1214 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1212 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" -> "1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1213 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" -> "1215 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1214 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" -> "1215 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1215 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1215 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1220 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1215 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1222 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1215 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1258 bert/encoder/layer_9/attention/output/add"  [label="[]", style=solid];
"1216 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1217 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1224 bert/encoder/layer_9/attention/self/value/MatMul"  [label="[]", style=solid];
"1218 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1219 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1219 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1224 bert/encoder/layer_9/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1220 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1221 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1221 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1230 bert/encoder/layer_9/attention/self/query/MatMul"  [label="[]", style=solid];
"1222 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1223 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1223 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1238 bert/encoder/layer_9/attention/self/key/MatMul"  [label="[]", style=solid];
"1224 bert/encoder/layer_9/attention/self/value/MatMul" -> "1225 bert/encoder/layer_9/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1225 bert/encoder/layer_9/attention/self/value/BiasAdd" -> "1226 bert/encoder/layer_9/attention/self/Reshape_2"  [label="[]", style=solid];
"1226 bert/encoder/layer_9/attention/self/Reshape_2" -> "1227 bert/encoder/layer_9/attention/self/transpose_2"  [label="[]", style=solid];
"1227 bert/encoder/layer_9/attention/self/transpose_2" -> "1249 bert/encoder/layer_9/attention/self/MatMul_1"  [label="[]", style=solid];
"1228 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1229 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1229 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1230 bert/encoder/layer_9/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1230 bert/encoder/layer_9/attention/self/query/MatMul" -> "1231 bert/encoder/layer_9/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1231 bert/encoder/layer_9/attention/self/query/BiasAdd" -> "1232 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1232 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1233 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1233 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1234 bert/encoder/layer_9/attention/self/Reshape"  [label="[]", style=solid];
"1234 bert/encoder/layer_9/attention/self/Reshape" -> "1235 bert/encoder/layer_9/attention/self/transpose"  [label="[]", style=solid];
"1235 bert/encoder/layer_9/attention/self/transpose" -> "1245 bert/encoder/layer_9/attention/self/MatMul"  [label="[]", style=solid];
"1236 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1237 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1237 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1238 bert/encoder/layer_9/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1238 bert/encoder/layer_9/attention/self/key/MatMul" -> "1239 bert/encoder/layer_9/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1239 bert/encoder/layer_9/attention/self/key/BiasAdd" -> "1240 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1240 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1241 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1241 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1242 bert/encoder/layer_9/attention/self/Reshape_1"  [label="[]", style=solid];
"1242 bert/encoder/layer_9/attention/self/Reshape_1" -> "1243 bert/encoder/layer_9/attention/self/transpose_1"  [label="[]", style=solid];
"1243 bert/encoder/layer_9/attention/self/transpose_1" -> "1244 bert/encoder/layer_9/attention/self/MatMul__432"  [label="[]", style=solid];
"1244 bert/encoder/layer_9/attention/self/MatMul__432" -> "1245 bert/encoder/layer_9/attention/self/MatMul"  [label="[]", style=solid];
"1245 bert/encoder/layer_9/attention/self/MatMul" -> "1246 bert/encoder/layer_9/attention/self/Mul"  [label="[]", style=solid];
"1246 bert/encoder/layer_9/attention/self/Mul" -> "1247 bert/encoder/layer_9/attention/self/add"  [label="[]", style=solid];
"1247 bert/encoder/layer_9/attention/self/add" -> "1248 bert/encoder/layer_9/attention/self/Softmax"  [label="[]", style=solid];
"1248 bert/encoder/layer_9/attention/self/Softmax" -> "1249 bert/encoder/layer_9/attention/self/MatMul_1"  [label="[]", style=solid];
"1249 bert/encoder/layer_9/attention/self/MatMul_1" -> "1250 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1250 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1251 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1251 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1252 bert/encoder/layer_9/attention/self/transpose_3"  [label="[]", style=solid];
"1252 bert/encoder/layer_9/attention/self/transpose_3" -> "1253 bert/encoder/layer_9/attention/self/Reshape_3"  [label="[]", style=solid];
"1253 bert/encoder/layer_9/attention/self/Reshape_3" -> "1256 bert/encoder/layer_9/attention/output/dense/MatMul"  [label="[]", style=solid];
"1254 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1255 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1255 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1256 bert/encoder/layer_9/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1256 bert/encoder/layer_9/attention/output/dense/MatMul" -> "1257 bert/encoder/layer_9/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1257 bert/encoder/layer_9/attention/output/dense/BiasAdd" -> "1258 bert/encoder/layer_9/attention/output/add"  [label="[]", style=solid];
"1258 bert/encoder/layer_9/attention/output/add" -> "1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1258 bert/encoder/layer_9/attention/output/add" -> "1261 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1258 bert/encoder/layer_9/attention/output/add" -> "1270 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1260 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1259 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1268 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1260 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" -> "1261 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1261 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" -> "1262 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435"  [label="[]", style=solid];
"1262 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" -> "1263 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1263 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" -> "1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1264 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" -> "1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1265 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437"  [label="[]", style=solid];
"1266 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" -> "1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1268 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1267 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1270 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1268 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" -> "1269 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1269 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" -> "1271 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1270 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" -> "1271 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1271 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1272 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1271 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1292 bert/encoder/layer_9/output/add"  [label="[]", style=solid];
"1272 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1273 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1273 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1276 bert/encoder/layer_9/intermediate/dense/MatMul"  [label="[]", style=solid];
"1274 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1275 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1275 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1276 bert/encoder/layer_9/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1276 bert/encoder/layer_9/intermediate/dense/MatMul" -> "1277 bert/encoder/layer_9/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1277 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1278 bert/encoder/layer_9/intermediate/dense/Pow"  [label="[]", style=solid];
"1277 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1280 bert/encoder/layer_9/intermediate/dense/add"  [label="[]", style=solid];
"1277 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1285 bert/encoder/layer_9/intermediate/dense/mul_3"  [label="[]", style=solid];
"1278 bert/encoder/layer_9/intermediate/dense/Pow" -> "1279 bert/encoder/layer_9/intermediate/dense/mul"  [label="[]", style=solid];
"1279 bert/encoder/layer_9/intermediate/dense/mul" -> "1280 bert/encoder/layer_9/intermediate/dense/add"  [label="[]", style=solid];
"1280 bert/encoder/layer_9/intermediate/dense/add" -> "1281 bert/encoder/layer_9/intermediate/dense/mul_1"  [label="[]", style=solid];
"1281 bert/encoder/layer_9/intermediate/dense/mul_1" -> "1282 bert/encoder/layer_9/intermediate/dense/Tanh"  [label="[]", style=solid];
"1282 bert/encoder/layer_9/intermediate/dense/Tanh" -> "1283 bert/encoder/layer_9/intermediate/dense/add_1"  [label="[]", style=solid];
"1283 bert/encoder/layer_9/intermediate/dense/add_1" -> "1284 bert/encoder/layer_9/intermediate/dense/mul_2"  [label="[]", style=solid];
"1284 bert/encoder/layer_9/intermediate/dense/mul_2" -> "1285 bert/encoder/layer_9/intermediate/dense/mul_3"  [label="[]", style=solid];
"1285 bert/encoder/layer_9/intermediate/dense/mul_3" -> "1286 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1286 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1287 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1287 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1290 bert/encoder/layer_9/output/dense/MatMul"  [label="[]", style=solid];
"1288 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1289 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1289 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1290 bert/encoder/layer_9/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1290 bert/encoder/layer_9/output/dense/MatMul" -> "1291 bert/encoder/layer_9/output/dense/BiasAdd"  [label="[]", style=solid];
"1291 bert/encoder/layer_9/output/dense/BiasAdd" -> "1292 bert/encoder/layer_9/output/add"  [label="[]", style=solid];
"1292 bert/encoder/layer_9/output/add" -> "1293 bert/encoder/layer_9/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1292 bert/encoder/layer_9/output/add" -> "1295 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1292 bert/encoder/layer_9/output/add" -> "1304 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1293 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1294 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1293 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1302 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1294 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" -> "1295 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1295 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" -> "1296 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439"  [label="[]", style=solid];
"1296 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" -> "1297 bert/encoder/layer_9/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1297 bert/encoder/layer_9/output/LayerNorm/moments/variance" -> "1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1298 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" -> "1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1299 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" -> "1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441"  [label="[]", style=solid];
"1300 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" -> "1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1302 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1301 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1304 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1302 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" -> "1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1303 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" -> "1305 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1304 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" -> "1305 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1305 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1305 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1310 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1305 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1312 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1305 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1348 bert/encoder/layer_10/attention/output/add"  [label="[]", style=solid];
"1306 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1307 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1314 bert/encoder/layer_10/attention/self/value/MatMul"  [label="[]", style=solid];
"1308 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1309 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1309 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1314 bert/encoder/layer_10/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1310 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1311 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1311 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1320 bert/encoder/layer_10/attention/self/query/MatMul"  [label="[]", style=solid];
"1312 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1313 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1313 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1328 bert/encoder/layer_10/attention/self/key/MatMul"  [label="[]", style=solid];
"1314 bert/encoder/layer_10/attention/self/value/MatMul" -> "1315 bert/encoder/layer_10/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1315 bert/encoder/layer_10/attention/self/value/BiasAdd" -> "1316 bert/encoder/layer_10/attention/self/Reshape_2"  [label="[]", style=solid];
"1316 bert/encoder/layer_10/attention/self/Reshape_2" -> "1317 bert/encoder/layer_10/attention/self/transpose_2"  [label="[]", style=solid];
"1317 bert/encoder/layer_10/attention/self/transpose_2" -> "1339 bert/encoder/layer_10/attention/self/MatMul_1"  [label="[]", style=solid];
"1318 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1319 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1319 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1320 bert/encoder/layer_10/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1320 bert/encoder/layer_10/attention/self/query/MatMul" -> "1321 bert/encoder/layer_10/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1321 bert/encoder/layer_10/attention/self/query/BiasAdd" -> "1322 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1322 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1323 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1323 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1324 bert/encoder/layer_10/attention/self/Reshape"  [label="[]", style=solid];
"1324 bert/encoder/layer_10/attention/self/Reshape" -> "1325 bert/encoder/layer_10/attention/self/transpose"  [label="[]", style=solid];
"1325 bert/encoder/layer_10/attention/self/transpose" -> "1335 bert/encoder/layer_10/attention/self/MatMul"  [label="[]", style=solid];
"1326 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1327 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1327 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1328 bert/encoder/layer_10/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1328 bert/encoder/layer_10/attention/self/key/MatMul" -> "1329 bert/encoder/layer_10/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1329 bert/encoder/layer_10/attention/self/key/BiasAdd" -> "1330 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1330 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1331 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1331 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1332 bert/encoder/layer_10/attention/self/Reshape_1"  [label="[]", style=solid];
"1332 bert/encoder/layer_10/attention/self/Reshape_1" -> "1333 bert/encoder/layer_10/attention/self/transpose_1"  [label="[]", style=solid];
"1333 bert/encoder/layer_10/attention/self/transpose_1" -> "1334 bert/encoder/layer_10/attention/self/MatMul__446"  [label="[]", style=solid];
"1334 bert/encoder/layer_10/attention/self/MatMul__446" -> "1335 bert/encoder/layer_10/attention/self/MatMul"  [label="[]", style=solid];
"1335 bert/encoder/layer_10/attention/self/MatMul" -> "1336 bert/encoder/layer_10/attention/self/Mul"  [label="[]", style=solid];
"1336 bert/encoder/layer_10/attention/self/Mul" -> "1337 bert/encoder/layer_10/attention/self/add"  [label="[]", style=solid];
"1337 bert/encoder/layer_10/attention/self/add" -> "1338 bert/encoder/layer_10/attention/self/Softmax"  [label="[]", style=solid];
"1338 bert/encoder/layer_10/attention/self/Softmax" -> "1339 bert/encoder/layer_10/attention/self/MatMul_1"  [label="[]", style=solid];
"1339 bert/encoder/layer_10/attention/self/MatMul_1" -> "1340 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1340 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1341 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1341 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1342 bert/encoder/layer_10/attention/self/transpose_3"  [label="[]", style=solid];
"1342 bert/encoder/layer_10/attention/self/transpose_3" -> "1343 bert/encoder/layer_10/attention/self/Reshape_3"  [label="[]", style=solid];
"1343 bert/encoder/layer_10/attention/self/Reshape_3" -> "1346 bert/encoder/layer_10/attention/output/dense/MatMul"  [label="[]", style=solid];
"1344 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1345 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1345 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1346 bert/encoder/layer_10/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1346 bert/encoder/layer_10/attention/output/dense/MatMul" -> "1347 bert/encoder/layer_10/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1347 bert/encoder/layer_10/attention/output/dense/BiasAdd" -> "1348 bert/encoder/layer_10/attention/output/add"  [label="[]", style=solid];
"1348 bert/encoder/layer_10/attention/output/add" -> "1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1348 bert/encoder/layer_10/attention/output/add" -> "1351 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1348 bert/encoder/layer_10/attention/output/add" -> "1360 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1350 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1349 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1358 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1350 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" -> "1351 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1351 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" -> "1352 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449"  [label="[]", style=solid];
"1352 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" -> "1353 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1353 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" -> "1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1354 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" -> "1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1355 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451"  [label="[]", style=solid];
"1356 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" -> "1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1358 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1357 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1360 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1358 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" -> "1359 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1359 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" -> "1361 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1360 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" -> "1361 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1361 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1362 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1361 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1382 bert/encoder/layer_10/output/add"  [label="[]", style=solid];
"1362 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1363 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1363 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1366 bert/encoder/layer_10/intermediate/dense/MatMul"  [label="[]", style=solid];
"1364 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1365 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1365 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1366 bert/encoder/layer_10/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1366 bert/encoder/layer_10/intermediate/dense/MatMul" -> "1367 bert/encoder/layer_10/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1367 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1368 bert/encoder/layer_10/intermediate/dense/Pow"  [label="[]", style=solid];
"1367 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1370 bert/encoder/layer_10/intermediate/dense/add"  [label="[]", style=solid];
"1367 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1375 bert/encoder/layer_10/intermediate/dense/mul_3"  [label="[]", style=solid];
"1368 bert/encoder/layer_10/intermediate/dense/Pow" -> "1369 bert/encoder/layer_10/intermediate/dense/mul"  [label="[]", style=solid];
"1369 bert/encoder/layer_10/intermediate/dense/mul" -> "1370 bert/encoder/layer_10/intermediate/dense/add"  [label="[]", style=solid];
"1370 bert/encoder/layer_10/intermediate/dense/add" -> "1371 bert/encoder/layer_10/intermediate/dense/mul_1"  [label="[]", style=solid];
"1371 bert/encoder/layer_10/intermediate/dense/mul_1" -> "1372 bert/encoder/layer_10/intermediate/dense/Tanh"  [label="[]", style=solid];
"1372 bert/encoder/layer_10/intermediate/dense/Tanh" -> "1373 bert/encoder/layer_10/intermediate/dense/add_1"  [label="[]", style=solid];
"1373 bert/encoder/layer_10/intermediate/dense/add_1" -> "1374 bert/encoder/layer_10/intermediate/dense/mul_2"  [label="[]", style=solid];
"1374 bert/encoder/layer_10/intermediate/dense/mul_2" -> "1375 bert/encoder/layer_10/intermediate/dense/mul_3"  [label="[]", style=solid];
"1375 bert/encoder/layer_10/intermediate/dense/mul_3" -> "1376 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1376 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1377 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1377 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1380 bert/encoder/layer_10/output/dense/MatMul"  [label="[]", style=solid];
"1378 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1379 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1379 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1380 bert/encoder/layer_10/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1380 bert/encoder/layer_10/output/dense/MatMul" -> "1381 bert/encoder/layer_10/output/dense/BiasAdd"  [label="[]", style=solid];
"1381 bert/encoder/layer_10/output/dense/BiasAdd" -> "1382 bert/encoder/layer_10/output/add"  [label="[]", style=solid];
"1382 bert/encoder/layer_10/output/add" -> "1383 bert/encoder/layer_10/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1382 bert/encoder/layer_10/output/add" -> "1385 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1382 bert/encoder/layer_10/output/add" -> "1394 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1383 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1384 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1383 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1392 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1384 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" -> "1385 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1385 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" -> "1386 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453"  [label="[]", style=solid];
"1386 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" -> "1387 bert/encoder/layer_10/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1387 bert/encoder/layer_10/output/LayerNorm/moments/variance" -> "1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1388 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" -> "1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1389 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" -> "1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455"  [label="[]", style=solid];
"1390 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" -> "1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1392 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1391 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1394 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1392 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" -> "1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1393 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" -> "1395 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1394 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" -> "1395 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1395 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1395 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1400 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1395 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1402 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1395 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1438 bert/encoder/layer_11/attention/output/add"  [label="[]", style=solid];
"1396 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1397 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1404 bert/encoder/layer_11/attention/self/value/MatMul"  [label="[]", style=solid];
"1398 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1399 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1399 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1404 bert/encoder/layer_11/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1400 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1401 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1401 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1410 bert/encoder/layer_11/attention/self/query/MatMul"  [label="[]", style=solid];
"1402 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1403 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1403 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1418 bert/encoder/layer_11/attention/self/key/MatMul"  [label="[]", style=solid];
"1404 bert/encoder/layer_11/attention/self/value/MatMul" -> "1405 bert/encoder/layer_11/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1405 bert/encoder/layer_11/attention/self/value/BiasAdd" -> "1406 bert/encoder/layer_11/attention/self/Reshape_2"  [label="[]", style=solid];
"1406 bert/encoder/layer_11/attention/self/Reshape_2" -> "1407 bert/encoder/layer_11/attention/self/transpose_2"  [label="[]", style=solid];
"1407 bert/encoder/layer_11/attention/self/transpose_2" -> "1429 bert/encoder/layer_11/attention/self/MatMul_1"  [label="[]", style=solid];
"1408 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1409 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1409 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1410 bert/encoder/layer_11/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1410 bert/encoder/layer_11/attention/self/query/MatMul" -> "1411 bert/encoder/layer_11/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1411 bert/encoder/layer_11/attention/self/query/BiasAdd" -> "1412 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1412 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1413 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1413 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1414 bert/encoder/layer_11/attention/self/Reshape"  [label="[]", style=solid];
"1414 bert/encoder/layer_11/attention/self/Reshape" -> "1415 bert/encoder/layer_11/attention/self/transpose"  [label="[]", style=solid];
"1415 bert/encoder/layer_11/attention/self/transpose" -> "1425 bert/encoder/layer_11/attention/self/MatMul"  [label="[]", style=solid];
"1416 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1417 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1417 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1418 bert/encoder/layer_11/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1418 bert/encoder/layer_11/attention/self/key/MatMul" -> "1419 bert/encoder/layer_11/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1419 bert/encoder/layer_11/attention/self/key/BiasAdd" -> "1420 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1420 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1421 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1421 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1422 bert/encoder/layer_11/attention/self/Reshape_1"  [label="[]", style=solid];
"1422 bert/encoder/layer_11/attention/self/Reshape_1" -> "1423 bert/encoder/layer_11/attention/self/transpose_1"  [label="[]", style=solid];
"1423 bert/encoder/layer_11/attention/self/transpose_1" -> "1424 bert/encoder/layer_11/attention/self/MatMul__460"  [label="[]", style=solid];
"1424 bert/encoder/layer_11/attention/self/MatMul__460" -> "1425 bert/encoder/layer_11/attention/self/MatMul"  [label="[]", style=solid];
"1425 bert/encoder/layer_11/attention/self/MatMul" -> "1426 bert/encoder/layer_11/attention/self/Mul"  [label="[]", style=solid];
"1426 bert/encoder/layer_11/attention/self/Mul" -> "1427 bert/encoder/layer_11/attention/self/add"  [label="[]", style=solid];
"1427 bert/encoder/layer_11/attention/self/add" -> "1428 bert/encoder/layer_11/attention/self/Softmax"  [label="[]", style=solid];
"1428 bert/encoder/layer_11/attention/self/Softmax" -> "1429 bert/encoder/layer_11/attention/self/MatMul_1"  [label="[]", style=solid];
"1429 bert/encoder/layer_11/attention/self/MatMul_1" -> "1430 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1430 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1431 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1431 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1432 bert/encoder/layer_11/attention/self/transpose_3"  [label="[]", style=solid];
"1432 bert/encoder/layer_11/attention/self/transpose_3" -> "1433 bert/encoder/layer_11/attention/self/Reshape_3"  [label="[]", style=solid];
"1433 bert/encoder/layer_11/attention/self/Reshape_3" -> "1436 bert/encoder/layer_11/attention/output/dense/MatMul"  [label="[]", style=solid];
"1434 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1435 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1435 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1436 bert/encoder/layer_11/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1436 bert/encoder/layer_11/attention/output/dense/MatMul" -> "1437 bert/encoder/layer_11/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1437 bert/encoder/layer_11/attention/output/dense/BiasAdd" -> "1438 bert/encoder/layer_11/attention/output/add"  [label="[]", style=solid];
"1438 bert/encoder/layer_11/attention/output/add" -> "1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1438 bert/encoder/layer_11/attention/output/add" -> "1441 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1438 bert/encoder/layer_11/attention/output/add" -> "1450 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1440 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1439 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1448 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1440 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" -> "1441 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1441 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" -> "1442 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463"  [label="[]", style=solid];
"1442 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" -> "1443 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1443 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" -> "1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1444 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" -> "1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1445 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465"  [label="[]", style=solid];
"1446 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" -> "1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1448 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1447 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1450 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1448 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" -> "1449 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1449 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" -> "1451 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1450 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" -> "1451 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1451 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1452 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1451 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1472 bert/encoder/layer_11/output/add"  [label="[]", style=solid];
"1452 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1453 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1453 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1456 bert/encoder/layer_11/intermediate/dense/MatMul"  [label="[]", style=solid];
"1454 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1455 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1455 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1456 bert/encoder/layer_11/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1456 bert/encoder/layer_11/intermediate/dense/MatMul" -> "1457 bert/encoder/layer_11/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1457 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1458 bert/encoder/layer_11/intermediate/dense/Pow"  [label="[]", style=solid];
"1457 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1460 bert/encoder/layer_11/intermediate/dense/add"  [label="[]", style=solid];
"1457 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1465 bert/encoder/layer_11/intermediate/dense/mul_3"  [label="[]", style=solid];
"1458 bert/encoder/layer_11/intermediate/dense/Pow" -> "1459 bert/encoder/layer_11/intermediate/dense/mul"  [label="[]", style=solid];
"1459 bert/encoder/layer_11/intermediate/dense/mul" -> "1460 bert/encoder/layer_11/intermediate/dense/add"  [label="[]", style=solid];
"1460 bert/encoder/layer_11/intermediate/dense/add" -> "1461 bert/encoder/layer_11/intermediate/dense/mul_1"  [label="[]", style=solid];
"1461 bert/encoder/layer_11/intermediate/dense/mul_1" -> "1462 bert/encoder/layer_11/intermediate/dense/Tanh"  [label="[]", style=solid];
"1462 bert/encoder/layer_11/intermediate/dense/Tanh" -> "1463 bert/encoder/layer_11/intermediate/dense/add_1"  [label="[]", style=solid];
"1463 bert/encoder/layer_11/intermediate/dense/add_1" -> "1464 bert/encoder/layer_11/intermediate/dense/mul_2"  [label="[]", style=solid];
"1464 bert/encoder/layer_11/intermediate/dense/mul_2" -> "1465 bert/encoder/layer_11/intermediate/dense/mul_3"  [label="[]", style=solid];
"1465 bert/encoder/layer_11/intermediate/dense/mul_3" -> "1466 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1466 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1467 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1467 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1470 bert/encoder/layer_11/output/dense/MatMul"  [label="[]", style=solid];
"1468 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1469 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1469 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1470 bert/encoder/layer_11/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1470 bert/encoder/layer_11/output/dense/MatMul" -> "1471 bert/encoder/layer_11/output/dense/BiasAdd"  [label="[]", style=solid];
"1471 bert/encoder/layer_11/output/dense/BiasAdd" -> "1472 bert/encoder/layer_11/output/add"  [label="[]", style=solid];
"1472 bert/encoder/layer_11/output/add" -> "1473 bert/encoder/layer_11/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1472 bert/encoder/layer_11/output/add" -> "1475 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1472 bert/encoder/layer_11/output/add" -> "1484 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1473 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1474 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1473 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1482 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1474 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" -> "1475 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1475 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" -> "1476 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467"  [label="[]", style=solid];
"1476 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" -> "1477 bert/encoder/layer_11/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1477 bert/encoder/layer_11/output/LayerNorm/moments/variance" -> "1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1478 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" -> "1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1479 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" -> "1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469"  [label="[]", style=solid];
"1480 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" -> "1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1482 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1481 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1484 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1482 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" -> "1483 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1483 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" -> "1485 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1484 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" -> "1485 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1485 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" -> "1486 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1486 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1487 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1487 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1488 bert/encoder/Reshape_13"  [label="[]", style=solid];
"1488 bert/encoder/Reshape_13" -> "1489 Shape_1"  [label="[]", style=solid];
"1488 bert/encoder/Reshape_13" -> "1501 Reshape"  [label="[]", style=solid];
"1489 Shape_1" -> "1490 Shape_1__472"  [label="[-1]", style=dashed];
"1490 Shape_1__472" -> "1491 strided_slice_1"  [label="[-1]", style=solid];
"1491 strided_slice_1" -> "1492 strided_slice_1__476"  [label="[-1]", style=solid];
"1492 strided_slice_1__476" -> "1493 strided_slice_1__477"  [label="[]", style=solid];
"1493 strided_slice_1__477" -> "1494 mul"  [label="[]", style=dashed];
"1493 strided_slice_1__477" -> "1498 Reshape_1/shape_Unsqueeze__478"  [label="[]", style=dashed];
"1494 mul" -> "1495 Reshape/shape_Unsqueeze__482"  [label="[]", style=dashed];
"1495 Reshape/shape_Unsqueeze__482" -> "1496 Reshape/shape_Concat__484"  [label="[1]", style=dashed];
"1496 Reshape/shape_Concat__484" -> "1497 Reshape__485"  [label="[2]", style=dashed];
"1497 Reshape__485" -> "1501 Reshape"  [label="[2]", style=dashed];
"1498 Reshape_1/shape_Unsqueeze__478" -> "1499 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"1499 Reshape_1/shape_Concat__481" -> "1500 Reshape_1__487"  [label="[3]", style=dashed];
"1500 Reshape_1__487" -> "1506 Reshape_1"  [label="[3]", style=dashed];
"1501 Reshape" -> "1504 MatMul"  [label="[]", style=solid];
"1502 QuantizeLinear_MatMul__486^0_1" -> "1503 DequantizeLinear_MatMul__486^0_1"  [label="[768, 2]", style=dashed];
"1503 DequantizeLinear_MatMul__486^0_1" -> "1504 MatMul"  [label="[768, 2]", style=solid];
"1504 MatMul" -> "1505 BiasAdd"  [label="[]", style=solid];
"1505 BiasAdd" -> "1506 Reshape_1"  [label="[]", style=solid];
"1506 Reshape_1" -> "1507 transpose"  [label="[]", style=solid];
"1507 transpose" -> "1508 unstack"  [label="[]", style=solid];
"1508 unstack" -> "1509 unstack__490"  [label="[]", style=solid];
"1508 unstack" -> "1511 unstack__488"  [label="[]", style=solid];
"1509 unstack__490" -> "1510 unstack_graph_outputs_Identity__4"  [label="[]", style=solid];
"1510 unstack_graph_outputs_Identity__4" -> "1517 nncf_model_output_0"  [label="[-1, 256]", style=solid];
"1511 unstack__488" -> "1512 unstack_graph_outputs_Identity__7"  [label="[]", style=solid];
"1512 unstack_graph_outputs_Identity__7" -> "1518 nncf_model_output_1"  [label="[-1, 256]", style=solid];
"1513 nncf_model_input_0" -> "0 unique_ids_graph_outputs_Identity__10"  [label="[-1]", style=dashed];
"1514 nncf_model_input_1" -> "185 bert/embeddings/Reshape_2"  [label="[-1, 256]", style=dashed];
"1515 nncf_model_input_2" -> "140 bert/encoder/Reshape"  [label="[-1, 256]", style=dashed];
"1516 nncf_model_input_3" -> "123 bert/encoder/Shape"  [label="[-1, 256]", style=dashed];
"1516 nncf_model_input_3" -> "189 bert/embeddings/ExpandDims"  [label="[-1, 256]", style=dashed];
}
