strict digraph  {
"0 unique_ids_graph_outputs_Identity__10" [id=0, type=Identity];
"1 bert/encoder/ones/packed_Unsqueeze__20" [id=1, type=Unsqueeze];
"2 bert/encoder/ones/packed_Unsqueeze__19" [id=2, type=Unsqueeze];
"3 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" [id=3, type=Unsqueeze];
"4 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" [id=4, type=Unsqueeze];
"5 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" [id=5, type=Unsqueeze];
"6 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" [id=6, type=Unsqueeze];
"7 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" [id=7, type=Unsqueeze];
"8 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" [id=8, type=Unsqueeze];
"9 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" [id=9, type=Unsqueeze];
"10 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" [id=10, type=Unsqueeze];
"11 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" [id=11, type=Unsqueeze];
"12 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" [id=12, type=Unsqueeze];
"13 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" [id=13, type=Unsqueeze];
"14 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" [id=14, type=Unsqueeze];
"15 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" [id=15, type=Unsqueeze];
"16 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" [id=16, type=Unsqueeze];
"17 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" [id=17, type=Unsqueeze];
"18 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" [id=18, type=Unsqueeze];
"19 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" [id=19, type=Unsqueeze];
"20 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" [id=20, type=Unsqueeze];
"21 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" [id=21, type=Unsqueeze];
"22 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" [id=22, type=Unsqueeze];
"23 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" [id=23, type=Unsqueeze];
"24 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" [id=24, type=Unsqueeze];
"25 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" [id=25, type=Unsqueeze];
"26 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" [id=26, type=Unsqueeze];
"27 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" [id=27, type=Unsqueeze];
"28 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" [id=28, type=Unsqueeze];
"29 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" [id=29, type=Unsqueeze];
"30 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" [id=30, type=Unsqueeze];
"31 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" [id=31, type=Unsqueeze];
"32 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" [id=32, type=Unsqueeze];
"33 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" [id=33, type=Unsqueeze];
"34 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" [id=34, type=Unsqueeze];
"35 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" [id=35, type=Unsqueeze];
"36 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" [id=36, type=Unsqueeze];
"37 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" [id=37, type=Unsqueeze];
"38 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" [id=38, type=Unsqueeze];
"39 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" [id=39, type=Unsqueeze];
"40 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" [id=40, type=Unsqueeze];
"41 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" [id=41, type=Unsqueeze];
"42 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" [id=42, type=Unsqueeze];
"43 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" [id=43, type=Unsqueeze];
"44 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" [id=44, type=Unsqueeze];
"45 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" [id=45, type=Unsqueeze];
"46 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" [id=46, type=Unsqueeze];
"47 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" [id=47, type=Unsqueeze];
"48 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" [id=48, type=Unsqueeze];
"49 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" [id=49, type=Unsqueeze];
"50 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" [id=50, type=Unsqueeze];
"51 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" [id=51, type=Unsqueeze];
"52 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" [id=52, type=Unsqueeze];
"53 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" [id=53, type=Unsqueeze];
"54 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" [id=54, type=Unsqueeze];
"55 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" [id=55, type=Unsqueeze];
"56 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" [id=56, type=Unsqueeze];
"57 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" [id=57, type=Unsqueeze];
"58 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" [id=58, type=Unsqueeze];
"59 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" [id=59, type=Unsqueeze];
"60 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" [id=60, type=Unsqueeze];
"61 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" [id=61, type=Unsqueeze];
"62 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" [id=62, type=Unsqueeze];
"63 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" [id=63, type=Unsqueeze];
"64 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" [id=64, type=Unsqueeze];
"65 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" [id=65, type=Unsqueeze];
"66 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" [id=66, type=Unsqueeze];
"67 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" [id=67, type=Unsqueeze];
"68 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" [id=68, type=Unsqueeze];
"69 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" [id=69, type=Unsqueeze];
"70 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" [id=70, type=Unsqueeze];
"71 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" [id=71, type=Unsqueeze];
"72 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" [id=72, type=Unsqueeze];
"73 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" [id=73, type=Unsqueeze];
"74 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" [id=74, type=Unsqueeze];
"75 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" [id=75, type=Unsqueeze];
"76 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" [id=76, type=Unsqueeze];
"77 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" [id=77, type=Unsqueeze];
"78 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" [id=78, type=Unsqueeze];
"79 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" [id=79, type=Unsqueeze];
"80 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" [id=80, type=Unsqueeze];
"81 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" [id=81, type=Unsqueeze];
"82 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" [id=82, type=Unsqueeze];
"83 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" [id=83, type=Unsqueeze];
"84 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" [id=84, type=Unsqueeze];
"85 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" [id=85, type=Unsqueeze];
"86 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" [id=86, type=Unsqueeze];
"87 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" [id=87, type=Unsqueeze];
"88 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" [id=88, type=Unsqueeze];
"89 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" [id=89, type=Unsqueeze];
"90 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" [id=90, type=Unsqueeze];
"91 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" [id=91, type=Unsqueeze];
"92 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" [id=92, type=Unsqueeze];
"93 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" [id=93, type=Unsqueeze];
"94 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" [id=94, type=Unsqueeze];
"95 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" [id=95, type=Unsqueeze];
"96 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" [id=96, type=Unsqueeze];
"97 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" [id=97, type=Unsqueeze];
"98 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" [id=98, type=Unsqueeze];
"99 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" [id=99, type=Unsqueeze];
"100 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" [id=100, type=Unsqueeze];
"101 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" [id=101, type=Unsqueeze];
"102 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" [id=102, type=Unsqueeze];
"103 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" [id=103, type=Unsqueeze];
"104 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" [id=104, type=Unsqueeze];
"105 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" [id=105, type=Unsqueeze];
"106 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" [id=106, type=Unsqueeze];
"107 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" [id=107, type=Unsqueeze];
"108 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" [id=108, type=Unsqueeze];
"109 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" [id=109, type=Unsqueeze];
"110 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" [id=110, type=Unsqueeze];
"111 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" [id=111, type=Unsqueeze];
"112 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" [id=112, type=Unsqueeze];
"113 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" [id=113, type=Unsqueeze];
"114 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" [id=114, type=Unsqueeze];
"115 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" [id=115, type=Unsqueeze];
"116 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" [id=116, type=Unsqueeze];
"117 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" [id=117, type=Unsqueeze];
"118 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" [id=118, type=Unsqueeze];
"119 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" [id=119, type=Unsqueeze];
"120 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" [id=120, type=Unsqueeze];
"121 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" [id=121, type=Unsqueeze];
"122 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" [id=122, type=Unsqueeze];
"123 bert/encoder/Shape" [id=123, type=Shape];
"124 bert/encoder/Shape__12" [id=124, type=Cast];
"125 bert/encoder/strided_slice" [id=125, type=Slice];
"126 bert/encoder/strided_slice__16" [id=126, type=Squeeze];
"127 bert/encoder/strided_slice__17" [id=127, type=Cast];
"128 bert/encoder/ones/packed_Unsqueeze__18" [id=128, type=Unsqueeze];
"129 bert/encoder/ones/packed_Concat__21" [id=129, type=Concat];
"130 bert/encoder/ones__22" [id=130, type=Cast];
"131 bert/encoder/ones" [id=131, type=ConstantOfShape];
"132 bert/encoder/Reshape_13/shape_Unsqueeze__300" [id=132, type=Unsqueeze];
"133 bert/encoder/Reshape_13/shape_Unsqueeze__299" [id=133, type=Unsqueeze];
"134 bert/encoder/Reshape_1__302" [id=134, type=Cast];
"135 bert/encoder/Reshape/shape_Unsqueeze__23" [id=135, type=Unsqueeze];
"136 bert/encoder/Reshape/shape_Unsqueeze__25" [id=136, type=Unsqueeze];
"137 bert/encoder/Reshape/shape_Unsqueeze__24" [id=137, type=Unsqueeze];
"138 bert/encoder/Reshape/shape_Concat__26" [id=138, type=Concat];
"139 bert/encoder/Reshape__27" [id=139, type=Cast];
"140 bert/encoder/Reshape" [id=140, type=Reshape];
"141 bert/encoder/Cast" [id=141, type=Cast];
"142 bert/encoder/mul" [id=142, type=Mul];
"143 bert/encoder/layer_9/attention/self/ExpandDims" [id=143, type=Reshape];
"144 bert/encoder/layer_9/attention/self/sub" [id=144, type=Sub];
"145 bert/encoder/layer_9/attention/self/mul_1" [id=145, type=Mul];
"146 bert/encoder/layer_8/attention/self/ExpandDims" [id=146, type=Reshape];
"147 bert/encoder/layer_8/attention/self/sub" [id=147, type=Sub];
"148 bert/encoder/layer_8/attention/self/mul_1" [id=148, type=Mul];
"149 bert/encoder/layer_7/attention/self/ExpandDims" [id=149, type=Reshape];
"150 bert/encoder/layer_7/attention/self/sub" [id=150, type=Sub];
"151 bert/encoder/layer_7/attention/self/mul_1" [id=151, type=Mul];
"152 bert/encoder/layer_6/attention/self/ExpandDims" [id=152, type=Reshape];
"153 bert/encoder/layer_6/attention/self/sub" [id=153, type=Sub];
"154 bert/encoder/layer_6/attention/self/mul_1" [id=154, type=Mul];
"155 bert/encoder/layer_5/attention/self/ExpandDims" [id=155, type=Reshape];
"156 bert/encoder/layer_5/attention/self/sub" [id=156, type=Sub];
"157 bert/encoder/layer_5/attention/self/mul_1" [id=157, type=Mul];
"158 bert/encoder/layer_4/attention/self/ExpandDims" [id=158, type=Reshape];
"159 bert/encoder/layer_4/attention/self/sub" [id=159, type=Sub];
"160 bert/encoder/layer_4/attention/self/mul_1" [id=160, type=Mul];
"161 bert/encoder/layer_3/attention/self/ExpandDims" [id=161, type=Reshape];
"162 bert/encoder/layer_3/attention/self/sub" [id=162, type=Sub];
"163 bert/encoder/layer_3/attention/self/mul_1" [id=163, type=Mul];
"164 bert/encoder/layer_2/attention/self/ExpandDims" [id=164, type=Reshape];
"165 bert/encoder/layer_2/attention/self/sub" [id=165, type=Sub];
"166 bert/encoder/layer_2/attention/self/mul_1" [id=166, type=Mul];
"167 bert/encoder/layer_11/attention/self/ExpandDims" [id=167, type=Reshape];
"168 bert/encoder/layer_11/attention/self/sub" [id=168, type=Sub];
"169 bert/encoder/layer_11/attention/self/mul_1" [id=169, type=Mul];
"170 bert/encoder/layer_10/attention/self/ExpandDims" [id=170, type=Reshape];
"171 bert/encoder/layer_10/attention/self/sub" [id=171, type=Sub];
"172 bert/encoder/layer_10/attention/self/mul_1" [id=172, type=Mul];
"173 bert/encoder/layer_1/attention/self/ExpandDims" [id=173, type=Reshape];
"174 bert/encoder/layer_1/attention/self/sub" [id=174, type=Sub];
"175 bert/encoder/layer_1/attention/self/mul_1" [id=175, type=Mul];
"176 bert/encoder/layer_0/attention/self/ExpandDims" [id=176, type=Reshape];
"177 bert/encoder/layer_0/attention/self/sub" [id=177, type=Sub];
"178 bert/encoder/layer_0/attention/self/mul_1" [id=178, type=Mul];
"179 bert/embeddings/Slice" [id=179, type=Slice];
"180 bert/embeddings/Reshape_4__42" [id=180, type=Cast];
"181 bert/embeddings/Reshape_4" [id=181, type=Reshape];
"182 bert/embeddings/Reshape_3/shape_Unsqueeze__69" [id=182, type=Unsqueeze];
"183 bert/embeddings/Reshape_3/shape_Unsqueeze__68" [id=183, type=Unsqueeze];
"184 bert/embeddings/Reshape_2__43" [id=184, type=Cast];
"185 bert/embeddings/Reshape_2" [id=185, type=Reshape];
"186 bert/embeddings/Reshape_1/shape_Unsqueeze__57" [id=186, type=Unsqueeze];
"187 bert/embeddings/Reshape_1/shape_Unsqueeze__56" [id=187, type=Unsqueeze];
"188 bert/embeddings/Reshape__59" [id=188, type=Cast];
"189 bert/embeddings/ExpandDims" [id=189, type=Reshape];
"190 bert/embeddings/Shape" [id=190, type=Shape];
"191 bert/embeddings/Shape__49" [id=191, type=Cast];
"192 bert/embeddings/strided_slice" [id=192, type=Slice];
"193 bert/embeddings/strided_slice__53" [id=193, type=Squeeze];
"194 bert/embeddings/strided_slice__54" [id=194, type=Cast];
"195 bert/embeddings/Reshape_1/shape_Unsqueeze__55" [id=195, type=Unsqueeze];
"196 bert/embeddings/Reshape_1/shape_Concat__58" [id=196, type=Concat];
"197 bert/embeddings/Reshape_1__60" [id=197, type=Cast];
"198 bert/embeddings/Reshape" [id=198, type=Reshape];
"199 bert/embeddings/GatherV2" [id=199, type=Gather];
"200 bert/embeddings/Reshape_1" [id=200, type=Reshape];
"201 bert/embeddings/Shape_1" [id=201, type=Shape];
"202 bert/embeddings/Shape_1__61" [id=202, type=Cast];
"203 bert/embeddings/strided_slice_1" [id=203, type=Slice];
"204 bert/embeddings/strided_slice_1__65" [id=204, type=Squeeze];
"205 bert/embeddings/strided_slice_1__66" [id=205, type=Cast];
"206 bert/embeddings/Reshape_3/shape_Unsqueeze__67" [id=206, type=Unsqueeze];
"207 bert/embeddings/Reshape_3/shape_Concat__70" [id=207, type=Concat];
"208 bert/embeddings/Reshape_3__71" [id=208, type=Cast];
"209 Unsqueeze__46" [id=209, type=Unsqueeze];
"210 Unsqueeze__45" [id=210, type=Unsqueeze];
"211 Unsqueeze__44" [id=211, type=Unsqueeze];
"212 Reshape_1/shape_Unsqueeze__480" [id=212, type=Unsqueeze];
"213 Reshape_1/shape_Unsqueeze__479" [id=213, type=Unsqueeze];
"214 Reshape/shape_Unsqueeze__483" [id=214, type=Unsqueeze];
"215 MatMul__486" [id=215, type=Transpose];
"216 Concat__47" [id=216, type=Concat];
"217 bert/embeddings/one_hot" [id=217, type=OneHot];
"218 QuantizeLinear_bert/embeddings/one_hot^0_1" [id=218, label="218 QuantizeLinear_bert/embeddings/one_hot:0_1", type=QuantizeLinear];
"219 DequantizeLinear_bert/embeddings/one_hot^0_1" [id=219, label="219 DequantizeLinear_bert/embeddings/one_hot:0_1", type=DequantizeLinear];
"220 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=220, label="220 QuantizeLinear_bert/embeddings/token_type_embeddings:0_1", type=QuantizeLinear];
"221 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" [id=221, label="221 DequantizeLinear_bert/embeddings/token_type_embeddings:0_1", type=DequantizeLinear];
"222 bert/embeddings/MatMul" [id=222, type=MatMul];
"223 bert/embeddings/Reshape_3" [id=223, type=Reshape];
"224 bert/embeddings/add" [id=224, type=Add];
"225 bert/embeddings/add_1" [id=225, type=Add];
"226 bert/embeddings/LayerNorm/moments/mean" [id=226, type=ReduceMean];
"227 bert/embeddings/LayerNorm/moments/StopGradient" [id=227, type=Identity];
"228 bert/embeddings/LayerNorm/moments/SquaredDifference" [id=228, type=Sub];
"229 bert/embeddings/LayerNorm/moments/SquaredDifference__72" [id=229, type=Mul];
"230 bert/embeddings/LayerNorm/moments/variance" [id=230, type=ReduceMean];
"231 bert/embeddings/LayerNorm/batchnorm/add" [id=231, type=Add];
"232 bert/embeddings/LayerNorm/batchnorm/Rsqrt" [id=232, type=Sqrt];
"233 QuantizeLinear_bert/embeddings/LayerNorm/batchnorm/Rsqrt^0_1" [id=233, label="233 QuantizeLinear_bert/embeddings/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"234 DequantizeLinear_bert/embeddings/LayerNorm/batchnorm/Rsqrt^0_1" [id=234, label="234 DequantizeLinear_bert/embeddings/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" [id=235, type=Reciprocal];
"236 bert/embeddings/LayerNorm/batchnorm/mul" [id=236, type=Mul];
"237 bert/embeddings/LayerNorm/batchnorm/mul_2" [id=237, type=Mul];
"238 bert/embeddings/LayerNorm/batchnorm/sub" [id=238, type=Sub];
"239 bert/embeddings/LayerNorm/batchnorm/mul_1" [id=239, type=Mul];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" [id=240, type=Add];
"241 bert/encoder/Shape_2" [id=241, type=Shape];
"242 bert/encoder/Shape_2__76" [id=242, type=Cast];
"243 bert/encoder/strided_slice_2" [id=243, type=Slice];
"244 bert/encoder/strided_slice_2__80" [id=244, type=Squeeze];
"245 bert/encoder/strided_slice_2__81" [id=245, type=Cast];
"246 bert/encoder/layer_9/attention/self/mul_2" [id=246, type=Mul];
"247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" [id=247, type=Unsqueeze];
"248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" [id=248, type=Concat];
"249 bert/encoder/layer_9/attention/self/Reshape_3__434" [id=249, type=Cast];
"250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" [id=250, type=Unsqueeze];
"251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" [id=251, type=Concat];
"252 bert/encoder/layer_9/attention/self/Reshape_2__429" [id=252, type=Cast];
"253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" [id=253, type=Unsqueeze];
"254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" [id=254, type=Concat];
"255 bert/encoder/layer_9/attention/self/Reshape_1__431" [id=255, type=Cast];
"256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" [id=256, type=Unsqueeze];
"257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" [id=257, type=Concat];
"258 bert/encoder/layer_9/attention/self/Reshape__430" [id=258, type=Cast];
"259 bert/encoder/layer_8/attention/self/mul_2" [id=259, type=Mul];
"260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" [id=260, type=Unsqueeze];
"261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" [id=261, type=Concat];
"262 bert/encoder/layer_8/attention/self/Reshape_3__420" [id=262, type=Cast];
"263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" [id=263, type=Unsqueeze];
"264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" [id=264, type=Concat];
"265 bert/encoder/layer_8/attention/self/Reshape_2__415" [id=265, type=Cast];
"266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" [id=266, type=Unsqueeze];
"267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" [id=267, type=Concat];
"268 bert/encoder/layer_8/attention/self/Reshape_1__417" [id=268, type=Cast];
"269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" [id=269, type=Unsqueeze];
"270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" [id=270, type=Concat];
"271 bert/encoder/layer_8/attention/self/Reshape__416" [id=271, type=Cast];
"272 bert/encoder/layer_7/attention/self/mul_2" [id=272, type=Mul];
"273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" [id=273, type=Unsqueeze];
"274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" [id=274, type=Concat];
"275 bert/encoder/layer_7/attention/self/Reshape_3__406" [id=275, type=Cast];
"276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" [id=276, type=Unsqueeze];
"277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" [id=277, type=Concat];
"278 bert/encoder/layer_7/attention/self/Reshape_2__401" [id=278, type=Cast];
"279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" [id=279, type=Unsqueeze];
"280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" [id=280, type=Concat];
"281 bert/encoder/layer_7/attention/self/Reshape_1__403" [id=281, type=Cast];
"282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" [id=282, type=Unsqueeze];
"283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" [id=283, type=Concat];
"284 bert/encoder/layer_7/attention/self/Reshape__402" [id=284, type=Cast];
"285 bert/encoder/layer_6/attention/self/mul_2" [id=285, type=Mul];
"286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" [id=286, type=Unsqueeze];
"287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" [id=287, type=Concat];
"288 bert/encoder/layer_6/attention/self/Reshape_3__392" [id=288, type=Cast];
"289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" [id=289, type=Unsqueeze];
"290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" [id=290, type=Concat];
"291 bert/encoder/layer_6/attention/self/Reshape_2__387" [id=291, type=Cast];
"292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" [id=292, type=Unsqueeze];
"293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" [id=293, type=Concat];
"294 bert/encoder/layer_6/attention/self/Reshape_1__389" [id=294, type=Cast];
"295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" [id=295, type=Unsqueeze];
"296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" [id=296, type=Concat];
"297 bert/encoder/layer_6/attention/self/Reshape__388" [id=297, type=Cast];
"298 bert/encoder/layer_5/attention/self/mul_2" [id=298, type=Mul];
"299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" [id=299, type=Unsqueeze];
"300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" [id=300, type=Concat];
"301 bert/encoder/layer_5/attention/self/Reshape_3__378" [id=301, type=Cast];
"302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" [id=302, type=Unsqueeze];
"303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" [id=303, type=Concat];
"304 bert/encoder/layer_5/attention/self/Reshape_2__373" [id=304, type=Cast];
"305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" [id=305, type=Unsqueeze];
"306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" [id=306, type=Concat];
"307 bert/encoder/layer_5/attention/self/Reshape_1__375" [id=307, type=Cast];
"308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" [id=308, type=Unsqueeze];
"309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" [id=309, type=Concat];
"310 bert/encoder/layer_5/attention/self/Reshape__374" [id=310, type=Cast];
"311 bert/encoder/layer_4/attention/self/mul_2" [id=311, type=Mul];
"312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" [id=312, type=Unsqueeze];
"313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" [id=313, type=Concat];
"314 bert/encoder/layer_4/attention/self/Reshape_3__364" [id=314, type=Cast];
"315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" [id=315, type=Unsqueeze];
"316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" [id=316, type=Concat];
"317 bert/encoder/layer_4/attention/self/Reshape_2__359" [id=317, type=Cast];
"318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" [id=318, type=Unsqueeze];
"319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" [id=319, type=Concat];
"320 bert/encoder/layer_4/attention/self/Reshape_1__361" [id=320, type=Cast];
"321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" [id=321, type=Unsqueeze];
"322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" [id=322, type=Concat];
"323 bert/encoder/layer_4/attention/self/Reshape__360" [id=323, type=Cast];
"324 bert/encoder/layer_3/attention/self/mul_2" [id=324, type=Mul];
"325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" [id=325, type=Unsqueeze];
"326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" [id=326, type=Concat];
"327 bert/encoder/layer_3/attention/self/Reshape_3__350" [id=327, type=Cast];
"328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" [id=328, type=Unsqueeze];
"329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" [id=329, type=Concat];
"330 bert/encoder/layer_3/attention/self/Reshape_2__345" [id=330, type=Cast];
"331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" [id=331, type=Unsqueeze];
"332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" [id=332, type=Concat];
"333 bert/encoder/layer_3/attention/self/Reshape_1__347" [id=333, type=Cast];
"334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" [id=334, type=Unsqueeze];
"335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" [id=335, type=Concat];
"336 bert/encoder/layer_3/attention/self/Reshape__346" [id=336, type=Cast];
"337 bert/encoder/layer_2/attention/self/mul_2" [id=337, type=Mul];
"338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" [id=338, type=Unsqueeze];
"339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" [id=339, type=Concat];
"340 bert/encoder/layer_2/attention/self/Reshape_3__336" [id=340, type=Cast];
"341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" [id=341, type=Unsqueeze];
"342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" [id=342, type=Concat];
"343 bert/encoder/layer_2/attention/self/Reshape_2__331" [id=343, type=Cast];
"344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" [id=344, type=Unsqueeze];
"345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" [id=345, type=Concat];
"346 bert/encoder/layer_2/attention/self/Reshape_1__333" [id=346, type=Cast];
"347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" [id=347, type=Unsqueeze];
"348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" [id=348, type=Concat];
"349 bert/encoder/layer_2/attention/self/Reshape__332" [id=349, type=Cast];
"350 bert/encoder/layer_11/attention/self/mul_2" [id=350, type=Mul];
"351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" [id=351, type=Unsqueeze];
"352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" [id=352, type=Concat];
"353 bert/encoder/layer_11/attention/self/Reshape_3__462" [id=353, type=Cast];
"354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" [id=354, type=Unsqueeze];
"355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" [id=355, type=Concat];
"356 bert/encoder/layer_11/attention/self/Reshape_2__457" [id=356, type=Cast];
"357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" [id=357, type=Unsqueeze];
"358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" [id=358, type=Concat];
"359 bert/encoder/layer_11/attention/self/Reshape_1__459" [id=359, type=Cast];
"360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" [id=360, type=Unsqueeze];
"361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" [id=361, type=Concat];
"362 bert/encoder/layer_11/attention/self/Reshape__458" [id=362, type=Cast];
"363 bert/encoder/layer_10/attention/self/mul_2" [id=363, type=Mul];
"364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" [id=364, type=Unsqueeze];
"365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" [id=365, type=Concat];
"366 bert/encoder/layer_10/attention/self/Reshape_3__448" [id=366, type=Cast];
"367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" [id=367, type=Unsqueeze];
"368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" [id=368, type=Concat];
"369 bert/encoder/layer_10/attention/self/Reshape_2__443" [id=369, type=Cast];
"370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" [id=370, type=Unsqueeze];
"371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" [id=371, type=Concat];
"372 bert/encoder/layer_10/attention/self/Reshape_1__445" [id=372, type=Cast];
"373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" [id=373, type=Unsqueeze];
"374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" [id=374, type=Concat];
"375 bert/encoder/layer_10/attention/self/Reshape__444" [id=375, type=Cast];
"376 bert/encoder/layer_1/attention/self/mul_2" [id=376, type=Mul];
"377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" [id=377, type=Unsqueeze];
"378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" [id=378, type=Concat];
"379 bert/encoder/layer_1/attention/self/Reshape_3__322" [id=379, type=Cast];
"380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" [id=380, type=Unsqueeze];
"381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" [id=381, type=Concat];
"382 bert/encoder/layer_1/attention/self/Reshape_2__317" [id=382, type=Cast];
"383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" [id=383, type=Unsqueeze];
"384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" [id=384, type=Concat];
"385 bert/encoder/layer_1/attention/self/Reshape_1__319" [id=385, type=Cast];
"386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" [id=386, type=Unsqueeze];
"387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" [id=387, type=Concat];
"388 bert/encoder/layer_1/attention/self/Reshape__318" [id=388, type=Cast];
"389 bert/encoder/layer_0/attention/self/mul_2" [id=389, type=Mul];
"390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" [id=390, type=Unsqueeze];
"391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" [id=391, type=Concat];
"392 bert/encoder/layer_0/attention/self/Reshape_3__308" [id=392, type=Cast];
"393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" [id=393, type=Unsqueeze];
"394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" [id=394, type=Concat];
"395 bert/encoder/layer_0/attention/self/Reshape_2__303" [id=395, type=Cast];
"396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" [id=396, type=Unsqueeze];
"397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" [id=397, type=Concat];
"398 bert/encoder/layer_0/attention/self/Reshape_1__305" [id=398, type=Cast];
"399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" [id=399, type=Unsqueeze];
"400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" [id=400, type=Concat];
"401 bert/encoder/layer_0/attention/self/Reshape__304" [id=401, type=Cast];
"402 bert/encoder/Reshape_13/shape_Unsqueeze__298" [id=402, type=Unsqueeze];
"403 bert/encoder/Reshape_13/shape_Concat__301" [id=403, type=Concat];
"404 bert/encoder/Reshape_13__471" [id=404, type=Cast];
"405 bert/encoder/Reshape_1" [id=405, type=Reshape];
"406 QuantizeLinear_bert/encoder/Reshape_1^0_3" [id=406, label="406 QuantizeLinear_bert/encoder/Reshape_1:0_3", type=QuantizeLinear];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_3" [id=407, label="407 DequantizeLinear_bert/encoder/Reshape_1:0_3", type=DequantizeLinear];
"408 QuantizeLinear_bert/encoder/Reshape_1^0_2" [id=408, label="408 QuantizeLinear_bert/encoder/Reshape_1:0_2", type=QuantizeLinear];
"409 DequantizeLinear_bert/encoder/Reshape_1^0_2" [id=409, label="409 DequantizeLinear_bert/encoder/Reshape_1:0_2", type=DequantizeLinear];
"410 QuantizeLinear_bert/encoder/Reshape_1^0_1" [id=410, label="410 QuantizeLinear_bert/encoder/Reshape_1:0_1", type=QuantizeLinear];
"411 DequantizeLinear_bert/encoder/Reshape_1^0_1" [id=411, label="411 DequantizeLinear_bert/encoder/Reshape_1:0_1", type=DequantizeLinear];
"412 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=412, label="412 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1", type=QuantizeLinear];
"413 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" [id=413, label="413 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel:0_1", type=DequantizeLinear];
"414 bert/encoder/layer_0/attention/self/value/MatMul" [id=414, type=MatMul];
"415 bert/encoder/layer_0/attention/self/value/BiasAdd" [id=415, type=Add];
"416 bert/encoder/layer_0/attention/self/Reshape_2" [id=416, type=Reshape];
"417 bert/encoder/layer_0/attention/self/transpose_2" [id=417, type=Transpose];
"418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=418, label="418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1", type=QuantizeLinear];
"419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" [id=419, label="419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel:0_1", type=DequantizeLinear];
"420 bert/encoder/layer_0/attention/self/query/MatMul" [id=420, type=MatMul];
"421 bert/encoder/layer_0/attention/self/query/BiasAdd" [id=421, type=Add];
"422 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=422, label="422 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"423 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" [id=423, label="423 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"424 bert/encoder/layer_0/attention/self/Reshape" [id=424, type=Reshape];
"425 bert/encoder/layer_0/attention/self/transpose" [id=425, type=Transpose];
"426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=426, label="426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1", type=QuantizeLinear];
"427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" [id=427, label="427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel:0_1", type=DequantizeLinear];
"428 bert/encoder/layer_0/attention/self/key/MatMul" [id=428, type=MatMul];
"429 bert/encoder/layer_0/attention/self/key/BiasAdd" [id=429, type=Add];
"430 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=430, label="430 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"431 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" [id=431, label="431 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"432 bert/encoder/layer_0/attention/self/Reshape_1" [id=432, type=Reshape];
"433 bert/encoder/layer_0/attention/self/transpose_1" [id=433, type=Transpose];
"434 bert/encoder/layer_0/attention/self/MatMul__306" [id=434, type=Transpose];
"435 bert/encoder/layer_0/attention/self/MatMul" [id=435, type=MatMul];
"436 bert/encoder/layer_0/attention/self/Mul" [id=436, type=Mul];
"437 bert/encoder/layer_0/attention/self/add" [id=437, type=Add];
"438 bert/encoder/layer_0/attention/self/Softmax" [id=438, type=Softmax];
"439 bert/encoder/layer_0/attention/self/MatMul_1" [id=439, type=MatMul];
"440 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=440, label="440 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"441 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" [id=441, label="441 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"442 bert/encoder/layer_0/attention/self/transpose_3" [id=442, type=Transpose];
"443 bert/encoder/layer_0/attention/self/Reshape_3" [id=443, type=Reshape];
"444 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=444, label="444 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"445 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" [id=445, label="445 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"446 bert/encoder/layer_0/attention/output/dense/MatMul" [id=446, type=MatMul];
"447 bert/encoder/layer_0/attention/output/dense/BiasAdd" [id=447, type=Add];
"448 bert/encoder/layer_0/attention/output/add" [id=448, type=Add];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" [id=449, type=ReduceMean];
"450 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" [id=450, type=Identity];
"451 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" [id=451, type=Sub];
"452 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" [id=452, type=Mul];
"453 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" [id=453, type=ReduceMean];
"454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" [id=454, type=Add];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" [id=455, type=Sqrt];
"456 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=456, label="456 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"457 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=457, label="457 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" [id=458, type=Reciprocal];
"459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" [id=459, type=Mul];
"460 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" [id=460, type=Mul];
"461 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" [id=461, type=Sub];
"462 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" [id=462, type=Mul];
"463 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" [id=463, type=Add];
"464 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=464, label="464 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"465 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=465, label="465 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"466 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=466, label="466 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"467 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" [id=467, label="467 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"468 bert/encoder/layer_0/intermediate/dense/MatMul" [id=468, type=MatMul];
"469 bert/encoder/layer_0/intermediate/dense/BiasAdd" [id=469, type=Add];
"470 bert/encoder/layer_0/intermediate/dense/Pow" [id=470, type=Pow];
"471 bert/encoder/layer_0/intermediate/dense/mul" [id=471, type=Mul];
"472 bert/encoder/layer_0/intermediate/dense/add" [id=472, type=Add];
"473 bert/encoder/layer_0/intermediate/dense/mul_1" [id=473, type=Mul];
"474 bert/encoder/layer_0/intermediate/dense/Tanh" [id=474, type=Tanh];
"475 bert/encoder/layer_0/intermediate/dense/add_1" [id=475, type=Add];
"476 bert/encoder/layer_0/intermediate/dense/mul_2" [id=476, type=Mul];
"477 bert/encoder/layer_0/intermediate/dense/mul_3" [id=477, type=Mul];
"478 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=478, label="478 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"479 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" [id=479, label="479 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"480 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=480, label="480 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1", type=QuantizeLinear];
"481 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" [id=481, label="481 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel:0_1", type=DequantizeLinear];
"482 bert/encoder/layer_0/output/dense/MatMul" [id=482, type=MatMul];
"483 bert/encoder/layer_0/output/dense/BiasAdd" [id=483, type=Add];
"484 bert/encoder/layer_0/output/add" [id=484, type=Add];
"485 bert/encoder/layer_0/output/LayerNorm/moments/mean" [id=485, type=ReduceMean];
"486 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" [id=486, type=Identity];
"487 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" [id=487, type=Sub];
"488 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" [id=488, type=Mul];
"489 bert/encoder/layer_0/output/LayerNorm/moments/variance" [id=489, type=ReduceMean];
"490 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" [id=490, type=Add];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" [id=491, type=Sqrt];
"492 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=492, label="492 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"493 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=493, label="493 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"494 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" [id=494, type=Reciprocal];
"495 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" [id=495, type=Mul];
"496 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" [id=496, type=Mul];
"497 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" [id=497, type=Sub];
"498 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" [id=498, type=Mul];
"499 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" [id=499, type=Add];
"500 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=500, label="500 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"501 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" [id=501, label="501 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"502 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=502, label="502 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"503 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" [id=503, label="503 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"504 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=504, label="504 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"505 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" [id=505, label="505 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"506 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=506, label="506 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1", type=QuantizeLinear];
"507 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" [id=507, label="507 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel:0_1", type=DequantizeLinear];
"508 bert/encoder/layer_1/attention/self/value/MatMul" [id=508, type=MatMul];
"509 bert/encoder/layer_1/attention/self/value/BiasAdd" [id=509, type=Add];
"510 bert/encoder/layer_1/attention/self/Reshape_2" [id=510, type=Reshape];
"511 bert/encoder/layer_1/attention/self/transpose_2" [id=511, type=Transpose];
"512 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=512, label="512 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1", type=QuantizeLinear];
"513 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" [id=513, label="513 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel:0_1", type=DequantizeLinear];
"514 bert/encoder/layer_1/attention/self/query/MatMul" [id=514, type=MatMul];
"515 bert/encoder/layer_1/attention/self/query/BiasAdd" [id=515, type=Add];
"516 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=516, label="516 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"517 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" [id=517, label="517 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"518 bert/encoder/layer_1/attention/self/Reshape" [id=518, type=Reshape];
"519 bert/encoder/layer_1/attention/self/transpose" [id=519, type=Transpose];
"520 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=520, label="520 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1", type=QuantizeLinear];
"521 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" [id=521, label="521 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel:0_1", type=DequantizeLinear];
"522 bert/encoder/layer_1/attention/self/key/MatMul" [id=522, type=MatMul];
"523 bert/encoder/layer_1/attention/self/key/BiasAdd" [id=523, type=Add];
"524 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=524, label="524 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"525 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" [id=525, label="525 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"526 bert/encoder/layer_1/attention/self/Reshape_1" [id=526, type=Reshape];
"527 bert/encoder/layer_1/attention/self/transpose_1" [id=527, type=Transpose];
"528 bert/encoder/layer_1/attention/self/MatMul__320" [id=528, type=Transpose];
"529 bert/encoder/layer_1/attention/self/MatMul" [id=529, type=MatMul];
"530 bert/encoder/layer_1/attention/self/Mul" [id=530, type=Mul];
"531 bert/encoder/layer_1/attention/self/add" [id=531, type=Add];
"532 bert/encoder/layer_1/attention/self/Softmax" [id=532, type=Softmax];
"533 bert/encoder/layer_1/attention/self/MatMul_1" [id=533, type=MatMul];
"534 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=534, label="534 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"535 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" [id=535, label="535 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"536 bert/encoder/layer_1/attention/self/transpose_3" [id=536, type=Transpose];
"537 bert/encoder/layer_1/attention/self/Reshape_3" [id=537, type=Reshape];
"538 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=538, label="538 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"539 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" [id=539, label="539 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"540 bert/encoder/layer_1/attention/output/dense/MatMul" [id=540, type=MatMul];
"541 bert/encoder/layer_1/attention/output/dense/BiasAdd" [id=541, type=Add];
"542 bert/encoder/layer_1/attention/output/add" [id=542, type=Add];
"543 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" [id=543, type=ReduceMean];
"544 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" [id=544, type=Identity];
"545 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" [id=545, type=Sub];
"546 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" [id=546, type=Mul];
"547 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" [id=547, type=ReduceMean];
"548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" [id=548, type=Add];
"549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" [id=549, type=Sqrt];
"550 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=550, label="550 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"551 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=551, label="551 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"552 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" [id=552, type=Reciprocal];
"553 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" [id=553, type=Mul];
"554 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" [id=554, type=Mul];
"555 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" [id=555, type=Sub];
"556 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" [id=556, type=Mul];
"557 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" [id=557, type=Add];
"558 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=558, label="558 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"559 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=559, label="559 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"560 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=560, label="560 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"561 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" [id=561, label="561 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"562 bert/encoder/layer_1/intermediate/dense/MatMul" [id=562, type=MatMul];
"563 bert/encoder/layer_1/intermediate/dense/BiasAdd" [id=563, type=Add];
"564 bert/encoder/layer_1/intermediate/dense/Pow" [id=564, type=Pow];
"565 bert/encoder/layer_1/intermediate/dense/mul" [id=565, type=Mul];
"566 bert/encoder/layer_1/intermediate/dense/add" [id=566, type=Add];
"567 bert/encoder/layer_1/intermediate/dense/mul_1" [id=567, type=Mul];
"568 bert/encoder/layer_1/intermediate/dense/Tanh" [id=568, type=Tanh];
"569 bert/encoder/layer_1/intermediate/dense/add_1" [id=569, type=Add];
"570 bert/encoder/layer_1/intermediate/dense/mul_2" [id=570, type=Mul];
"571 bert/encoder/layer_1/intermediate/dense/mul_3" [id=571, type=Mul];
"572 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=572, label="572 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"573 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" [id=573, label="573 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"574 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=574, label="574 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1", type=QuantizeLinear];
"575 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" [id=575, label="575 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel:0_1", type=DequantizeLinear];
"576 bert/encoder/layer_1/output/dense/MatMul" [id=576, type=MatMul];
"577 bert/encoder/layer_1/output/dense/BiasAdd" [id=577, type=Add];
"578 bert/encoder/layer_1/output/add" [id=578, type=Add];
"579 bert/encoder/layer_1/output/LayerNorm/moments/mean" [id=579, type=ReduceMean];
"580 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" [id=580, type=Identity];
"581 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" [id=581, type=Sub];
"582 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" [id=582, type=Mul];
"583 bert/encoder/layer_1/output/LayerNorm/moments/variance" [id=583, type=ReduceMean];
"584 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" [id=584, type=Add];
"585 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" [id=585, type=Sqrt];
"586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=586, label="586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=587, label="587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"588 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" [id=588, type=Reciprocal];
"589 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" [id=589, type=Mul];
"590 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" [id=590, type=Mul];
"591 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" [id=591, type=Sub];
"592 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" [id=592, type=Mul];
"593 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" [id=593, type=Add];
"594 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=594, label="594 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"595 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" [id=595, label="595 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"596 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=596, label="596 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"597 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" [id=597, label="597 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"598 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=598, label="598 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"599 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" [id=599, label="599 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"600 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=600, label="600 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1", type=QuantizeLinear];
"601 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" [id=601, label="601 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel:0_1", type=DequantizeLinear];
"602 bert/encoder/layer_2/attention/self/value/MatMul" [id=602, type=MatMul];
"603 bert/encoder/layer_2/attention/self/value/BiasAdd" [id=603, type=Add];
"604 bert/encoder/layer_2/attention/self/Reshape_2" [id=604, type=Reshape];
"605 bert/encoder/layer_2/attention/self/transpose_2" [id=605, type=Transpose];
"606 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=606, label="606 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1", type=QuantizeLinear];
"607 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" [id=607, label="607 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel:0_1", type=DequantizeLinear];
"608 bert/encoder/layer_2/attention/self/query/MatMul" [id=608, type=MatMul];
"609 bert/encoder/layer_2/attention/self/query/BiasAdd" [id=609, type=Add];
"610 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=610, label="610 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"611 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" [id=611, label="611 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"612 bert/encoder/layer_2/attention/self/Reshape" [id=612, type=Reshape];
"613 bert/encoder/layer_2/attention/self/transpose" [id=613, type=Transpose];
"614 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=614, label="614 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1", type=QuantizeLinear];
"615 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" [id=615, label="615 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel:0_1", type=DequantizeLinear];
"616 bert/encoder/layer_2/attention/self/key/MatMul" [id=616, type=MatMul];
"617 bert/encoder/layer_2/attention/self/key/BiasAdd" [id=617, type=Add];
"618 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=618, label="618 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"619 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" [id=619, label="619 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"620 bert/encoder/layer_2/attention/self/Reshape_1" [id=620, type=Reshape];
"621 bert/encoder/layer_2/attention/self/transpose_1" [id=621, type=Transpose];
"622 bert/encoder/layer_2/attention/self/MatMul__334" [id=622, type=Transpose];
"623 bert/encoder/layer_2/attention/self/MatMul" [id=623, type=MatMul];
"624 bert/encoder/layer_2/attention/self/Mul" [id=624, type=Mul];
"625 bert/encoder/layer_2/attention/self/add" [id=625, type=Add];
"626 bert/encoder/layer_2/attention/self/Softmax" [id=626, type=Softmax];
"627 bert/encoder/layer_2/attention/self/MatMul_1" [id=627, type=MatMul];
"628 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=628, label="628 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"629 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" [id=629, label="629 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"630 bert/encoder/layer_2/attention/self/transpose_3" [id=630, type=Transpose];
"631 bert/encoder/layer_2/attention/self/Reshape_3" [id=631, type=Reshape];
"632 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=632, label="632 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"633 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" [id=633, label="633 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"634 bert/encoder/layer_2/attention/output/dense/MatMul" [id=634, type=MatMul];
"635 bert/encoder/layer_2/attention/output/dense/BiasAdd" [id=635, type=Add];
"636 bert/encoder/layer_2/attention/output/add" [id=636, type=Add];
"637 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" [id=637, type=ReduceMean];
"638 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" [id=638, type=Identity];
"639 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" [id=639, type=Sub];
"640 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" [id=640, type=Mul];
"641 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" [id=641, type=ReduceMean];
"642 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" [id=642, type=Add];
"643 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" [id=643, type=Sqrt];
"644 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=644, label="644 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"645 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=645, label="645 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"646 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" [id=646, type=Reciprocal];
"647 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" [id=647, type=Mul];
"648 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" [id=648, type=Mul];
"649 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" [id=649, type=Sub];
"650 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" [id=650, type=Mul];
"651 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" [id=651, type=Add];
"652 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=652, label="652 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"653 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=653, label="653 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"654 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=654, label="654 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"655 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" [id=655, label="655 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"656 bert/encoder/layer_2/intermediate/dense/MatMul" [id=656, type=MatMul];
"657 bert/encoder/layer_2/intermediate/dense/BiasAdd" [id=657, type=Add];
"658 bert/encoder/layer_2/intermediate/dense/Pow" [id=658, type=Pow];
"659 bert/encoder/layer_2/intermediate/dense/mul" [id=659, type=Mul];
"660 bert/encoder/layer_2/intermediate/dense/add" [id=660, type=Add];
"661 bert/encoder/layer_2/intermediate/dense/mul_1" [id=661, type=Mul];
"662 bert/encoder/layer_2/intermediate/dense/Tanh" [id=662, type=Tanh];
"663 bert/encoder/layer_2/intermediate/dense/add_1" [id=663, type=Add];
"664 bert/encoder/layer_2/intermediate/dense/mul_2" [id=664, type=Mul];
"665 bert/encoder/layer_2/intermediate/dense/mul_3" [id=665, type=Mul];
"666 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=666, label="666 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"667 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" [id=667, label="667 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"668 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=668, label="668 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1", type=QuantizeLinear];
"669 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" [id=669, label="669 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel:0_1", type=DequantizeLinear];
"670 bert/encoder/layer_2/output/dense/MatMul" [id=670, type=MatMul];
"671 bert/encoder/layer_2/output/dense/BiasAdd" [id=671, type=Add];
"672 bert/encoder/layer_2/output/add" [id=672, type=Add];
"673 bert/encoder/layer_2/output/LayerNorm/moments/mean" [id=673, type=ReduceMean];
"674 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" [id=674, type=Identity];
"675 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" [id=675, type=Sub];
"676 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" [id=676, type=Mul];
"677 bert/encoder/layer_2/output/LayerNorm/moments/variance" [id=677, type=ReduceMean];
"678 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" [id=678, type=Add];
"679 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" [id=679, type=Sqrt];
"680 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=680, label="680 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"681 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=681, label="681 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"682 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" [id=682, type=Reciprocal];
"683 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" [id=683, type=Mul];
"684 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" [id=684, type=Mul];
"685 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" [id=685, type=Sub];
"686 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" [id=686, type=Mul];
"687 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" [id=687, type=Add];
"688 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=688, label="688 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"689 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" [id=689, label="689 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"690 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=690, label="690 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"691 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" [id=691, label="691 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"692 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=692, label="692 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"693 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" [id=693, label="693 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"694 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=694, label="694 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1", type=QuantizeLinear];
"695 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" [id=695, label="695 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel:0_1", type=DequantizeLinear];
"696 bert/encoder/layer_3/attention/self/value/MatMul" [id=696, type=MatMul];
"697 bert/encoder/layer_3/attention/self/value/BiasAdd" [id=697, type=Add];
"698 bert/encoder/layer_3/attention/self/Reshape_2" [id=698, type=Reshape];
"699 bert/encoder/layer_3/attention/self/transpose_2" [id=699, type=Transpose];
"700 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=700, label="700 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1", type=QuantizeLinear];
"701 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" [id=701, label="701 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel:0_1", type=DequantizeLinear];
"702 bert/encoder/layer_3/attention/self/query/MatMul" [id=702, type=MatMul];
"703 bert/encoder/layer_3/attention/self/query/BiasAdd" [id=703, type=Add];
"704 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=704, label="704 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"705 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" [id=705, label="705 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"706 bert/encoder/layer_3/attention/self/Reshape" [id=706, type=Reshape];
"707 bert/encoder/layer_3/attention/self/transpose" [id=707, type=Transpose];
"708 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=708, label="708 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1", type=QuantizeLinear];
"709 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" [id=709, label="709 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel:0_1", type=DequantizeLinear];
"710 bert/encoder/layer_3/attention/self/key/MatMul" [id=710, type=MatMul];
"711 bert/encoder/layer_3/attention/self/key/BiasAdd" [id=711, type=Add];
"712 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=712, label="712 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"713 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" [id=713, label="713 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"714 bert/encoder/layer_3/attention/self/Reshape_1" [id=714, type=Reshape];
"715 bert/encoder/layer_3/attention/self/transpose_1" [id=715, type=Transpose];
"716 bert/encoder/layer_3/attention/self/MatMul__348" [id=716, type=Transpose];
"717 bert/encoder/layer_3/attention/self/MatMul" [id=717, type=MatMul];
"718 bert/encoder/layer_3/attention/self/Mul" [id=718, type=Mul];
"719 bert/encoder/layer_3/attention/self/add" [id=719, type=Add];
"720 bert/encoder/layer_3/attention/self/Softmax" [id=720, type=Softmax];
"721 bert/encoder/layer_3/attention/self/MatMul_1" [id=721, type=MatMul];
"722 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=722, label="722 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"723 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" [id=723, label="723 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"724 bert/encoder/layer_3/attention/self/transpose_3" [id=724, type=Transpose];
"725 bert/encoder/layer_3/attention/self/Reshape_3" [id=725, type=Reshape];
"726 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=726, label="726 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"727 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" [id=727, label="727 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"728 bert/encoder/layer_3/attention/output/dense/MatMul" [id=728, type=MatMul];
"729 bert/encoder/layer_3/attention/output/dense/BiasAdd" [id=729, type=Add];
"730 bert/encoder/layer_3/attention/output/add" [id=730, type=Add];
"731 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" [id=731, type=ReduceMean];
"732 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" [id=732, type=Identity];
"733 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" [id=733, type=Sub];
"734 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" [id=734, type=Mul];
"735 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" [id=735, type=ReduceMean];
"736 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" [id=736, type=Add];
"737 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" [id=737, type=Sqrt];
"738 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=738, label="738 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"739 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=739, label="739 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"740 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" [id=740, type=Reciprocal];
"741 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" [id=741, type=Mul];
"742 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" [id=742, type=Mul];
"743 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" [id=743, type=Sub];
"744 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" [id=744, type=Mul];
"745 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" [id=745, type=Add];
"746 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=746, label="746 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"747 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=747, label="747 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"748 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=748, label="748 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"749 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" [id=749, label="749 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"750 bert/encoder/layer_3/intermediate/dense/MatMul" [id=750, type=MatMul];
"751 bert/encoder/layer_3/intermediate/dense/BiasAdd" [id=751, type=Add];
"752 bert/encoder/layer_3/intermediate/dense/Pow" [id=752, type=Pow];
"753 bert/encoder/layer_3/intermediate/dense/mul" [id=753, type=Mul];
"754 bert/encoder/layer_3/intermediate/dense/add" [id=754, type=Add];
"755 bert/encoder/layer_3/intermediate/dense/mul_1" [id=755, type=Mul];
"756 bert/encoder/layer_3/intermediate/dense/Tanh" [id=756, type=Tanh];
"757 bert/encoder/layer_3/intermediate/dense/add_1" [id=757, type=Add];
"758 bert/encoder/layer_3/intermediate/dense/mul_2" [id=758, type=Mul];
"759 bert/encoder/layer_3/intermediate/dense/mul_3" [id=759, type=Mul];
"760 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=760, label="760 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"761 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" [id=761, label="761 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"762 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=762, label="762 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1", type=QuantizeLinear];
"763 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" [id=763, label="763 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel:0_1", type=DequantizeLinear];
"764 bert/encoder/layer_3/output/dense/MatMul" [id=764, type=MatMul];
"765 bert/encoder/layer_3/output/dense/BiasAdd" [id=765, type=Add];
"766 bert/encoder/layer_3/output/add" [id=766, type=Add];
"767 bert/encoder/layer_3/output/LayerNorm/moments/mean" [id=767, type=ReduceMean];
"768 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" [id=768, type=Identity];
"769 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" [id=769, type=Sub];
"770 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" [id=770, type=Mul];
"771 bert/encoder/layer_3/output/LayerNorm/moments/variance" [id=771, type=ReduceMean];
"772 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" [id=772, type=Add];
"773 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" [id=773, type=Sqrt];
"774 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=774, label="774 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"775 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=775, label="775 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"776 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" [id=776, type=Reciprocal];
"777 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" [id=777, type=Mul];
"778 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" [id=778, type=Mul];
"779 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" [id=779, type=Sub];
"780 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" [id=780, type=Mul];
"781 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" [id=781, type=Add];
"782 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=782, label="782 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"783 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" [id=783, label="783 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"784 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=784, label="784 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"785 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" [id=785, label="785 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"786 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=786, label="786 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"787 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" [id=787, label="787 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"788 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=788, label="788 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1", type=QuantizeLinear];
"789 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" [id=789, label="789 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel:0_1", type=DequantizeLinear];
"790 bert/encoder/layer_4/attention/self/value/MatMul" [id=790, type=MatMul];
"791 bert/encoder/layer_4/attention/self/value/BiasAdd" [id=791, type=Add];
"792 bert/encoder/layer_4/attention/self/Reshape_2" [id=792, type=Reshape];
"793 bert/encoder/layer_4/attention/self/transpose_2" [id=793, type=Transpose];
"794 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=794, label="794 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1", type=QuantizeLinear];
"795 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" [id=795, label="795 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel:0_1", type=DequantizeLinear];
"796 bert/encoder/layer_4/attention/self/query/MatMul" [id=796, type=MatMul];
"797 bert/encoder/layer_4/attention/self/query/BiasAdd" [id=797, type=Add];
"798 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=798, label="798 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"799 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" [id=799, label="799 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"800 bert/encoder/layer_4/attention/self/Reshape" [id=800, type=Reshape];
"801 bert/encoder/layer_4/attention/self/transpose" [id=801, type=Transpose];
"802 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=802, label="802 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1", type=QuantizeLinear];
"803 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" [id=803, label="803 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel:0_1", type=DequantizeLinear];
"804 bert/encoder/layer_4/attention/self/key/MatMul" [id=804, type=MatMul];
"805 bert/encoder/layer_4/attention/self/key/BiasAdd" [id=805, type=Add];
"806 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=806, label="806 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"807 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" [id=807, label="807 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"808 bert/encoder/layer_4/attention/self/Reshape_1" [id=808, type=Reshape];
"809 bert/encoder/layer_4/attention/self/transpose_1" [id=809, type=Transpose];
"810 bert/encoder/layer_4/attention/self/MatMul__362" [id=810, type=Transpose];
"811 bert/encoder/layer_4/attention/self/MatMul" [id=811, type=MatMul];
"812 bert/encoder/layer_4/attention/self/Mul" [id=812, type=Mul];
"813 bert/encoder/layer_4/attention/self/add" [id=813, type=Add];
"814 bert/encoder/layer_4/attention/self/Softmax" [id=814, type=Softmax];
"815 bert/encoder/layer_4/attention/self/MatMul_1" [id=815, type=MatMul];
"816 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=816, label="816 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"817 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" [id=817, label="817 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"818 bert/encoder/layer_4/attention/self/transpose_3" [id=818, type=Transpose];
"819 bert/encoder/layer_4/attention/self/Reshape_3" [id=819, type=Reshape];
"820 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=820, label="820 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"821 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" [id=821, label="821 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"822 bert/encoder/layer_4/attention/output/dense/MatMul" [id=822, type=MatMul];
"823 bert/encoder/layer_4/attention/output/dense/BiasAdd" [id=823, type=Add];
"824 bert/encoder/layer_4/attention/output/add" [id=824, type=Add];
"825 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" [id=825, type=ReduceMean];
"826 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" [id=826, type=Identity];
"827 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" [id=827, type=Sub];
"828 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" [id=828, type=Mul];
"829 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" [id=829, type=ReduceMean];
"830 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" [id=830, type=Add];
"831 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" [id=831, type=Sqrt];
"832 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=832, label="832 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"833 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=833, label="833 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"834 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" [id=834, type=Reciprocal];
"835 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" [id=835, type=Mul];
"836 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" [id=836, type=Mul];
"837 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" [id=837, type=Sub];
"838 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" [id=838, type=Mul];
"839 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" [id=839, type=Add];
"840 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=840, label="840 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"841 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=841, label="841 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"842 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=842, label="842 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"843 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" [id=843, label="843 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"844 bert/encoder/layer_4/intermediate/dense/MatMul" [id=844, type=MatMul];
"845 bert/encoder/layer_4/intermediate/dense/BiasAdd" [id=845, type=Add];
"846 bert/encoder/layer_4/intermediate/dense/Pow" [id=846, type=Pow];
"847 bert/encoder/layer_4/intermediate/dense/mul" [id=847, type=Mul];
"848 bert/encoder/layer_4/intermediate/dense/add" [id=848, type=Add];
"849 bert/encoder/layer_4/intermediate/dense/mul_1" [id=849, type=Mul];
"850 bert/encoder/layer_4/intermediate/dense/Tanh" [id=850, type=Tanh];
"851 bert/encoder/layer_4/intermediate/dense/add_1" [id=851, type=Add];
"852 bert/encoder/layer_4/intermediate/dense/mul_2" [id=852, type=Mul];
"853 bert/encoder/layer_4/intermediate/dense/mul_3" [id=853, type=Mul];
"854 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=854, label="854 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"855 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" [id=855, label="855 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"856 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=856, label="856 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1", type=QuantizeLinear];
"857 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" [id=857, label="857 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel:0_1", type=DequantizeLinear];
"858 bert/encoder/layer_4/output/dense/MatMul" [id=858, type=MatMul];
"859 bert/encoder/layer_4/output/dense/BiasAdd" [id=859, type=Add];
"860 bert/encoder/layer_4/output/add" [id=860, type=Add];
"861 bert/encoder/layer_4/output/LayerNorm/moments/mean" [id=861, type=ReduceMean];
"862 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" [id=862, type=Identity];
"863 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" [id=863, type=Sub];
"864 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" [id=864, type=Mul];
"865 bert/encoder/layer_4/output/LayerNorm/moments/variance" [id=865, type=ReduceMean];
"866 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" [id=866, type=Add];
"867 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" [id=867, type=Sqrt];
"868 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=868, label="868 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"869 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=869, label="869 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"870 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" [id=870, type=Reciprocal];
"871 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" [id=871, type=Mul];
"872 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" [id=872, type=Mul];
"873 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" [id=873, type=Sub];
"874 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" [id=874, type=Mul];
"875 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" [id=875, type=Add];
"876 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=876, label="876 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"877 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" [id=877, label="877 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"878 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=878, label="878 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"879 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" [id=879, label="879 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"880 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=880, label="880 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"881 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" [id=881, label="881 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"882 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=882, label="882 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1", type=QuantizeLinear];
"883 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" [id=883, label="883 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel:0_1", type=DequantizeLinear];
"884 bert/encoder/layer_5/attention/self/value/MatMul" [id=884, type=MatMul];
"885 bert/encoder/layer_5/attention/self/value/BiasAdd" [id=885, type=Add];
"886 bert/encoder/layer_5/attention/self/Reshape_2" [id=886, type=Reshape];
"887 bert/encoder/layer_5/attention/self/transpose_2" [id=887, type=Transpose];
"888 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=888, label="888 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1", type=QuantizeLinear];
"889 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" [id=889, label="889 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel:0_1", type=DequantizeLinear];
"890 bert/encoder/layer_5/attention/self/query/MatMul" [id=890, type=MatMul];
"891 bert/encoder/layer_5/attention/self/query/BiasAdd" [id=891, type=Add];
"892 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=892, label="892 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"893 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" [id=893, label="893 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"894 bert/encoder/layer_5/attention/self/Reshape" [id=894, type=Reshape];
"895 bert/encoder/layer_5/attention/self/transpose" [id=895, type=Transpose];
"896 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=896, label="896 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1", type=QuantizeLinear];
"897 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" [id=897, label="897 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel:0_1", type=DequantizeLinear];
"898 bert/encoder/layer_5/attention/self/key/MatMul" [id=898, type=MatMul];
"899 bert/encoder/layer_5/attention/self/key/BiasAdd" [id=899, type=Add];
"900 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=900, label="900 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"901 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" [id=901, label="901 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"902 bert/encoder/layer_5/attention/self/Reshape_1" [id=902, type=Reshape];
"903 bert/encoder/layer_5/attention/self/transpose_1" [id=903, type=Transpose];
"904 bert/encoder/layer_5/attention/self/MatMul__376" [id=904, type=Transpose];
"905 bert/encoder/layer_5/attention/self/MatMul" [id=905, type=MatMul];
"906 bert/encoder/layer_5/attention/self/Mul" [id=906, type=Mul];
"907 bert/encoder/layer_5/attention/self/add" [id=907, type=Add];
"908 bert/encoder/layer_5/attention/self/Softmax" [id=908, type=Softmax];
"909 bert/encoder/layer_5/attention/self/MatMul_1" [id=909, type=MatMul];
"910 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=910, label="910 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"911 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" [id=911, label="911 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"912 bert/encoder/layer_5/attention/self/transpose_3" [id=912, type=Transpose];
"913 bert/encoder/layer_5/attention/self/Reshape_3" [id=913, type=Reshape];
"914 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=914, label="914 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"915 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" [id=915, label="915 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"916 bert/encoder/layer_5/attention/output/dense/MatMul" [id=916, type=MatMul];
"917 bert/encoder/layer_5/attention/output/dense/BiasAdd" [id=917, type=Add];
"918 bert/encoder/layer_5/attention/output/add" [id=918, type=Add];
"919 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" [id=919, type=ReduceMean];
"920 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" [id=920, type=Identity];
"921 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" [id=921, type=Sub];
"922 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" [id=922, type=Mul];
"923 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" [id=923, type=ReduceMean];
"924 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" [id=924, type=Add];
"925 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" [id=925, type=Sqrt];
"926 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=926, label="926 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"927 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=927, label="927 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"928 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" [id=928, type=Reciprocal];
"929 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" [id=929, type=Mul];
"930 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" [id=930, type=Mul];
"931 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" [id=931, type=Sub];
"932 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" [id=932, type=Mul];
"933 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" [id=933, type=Add];
"934 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=934, label="934 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"935 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=935, label="935 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"936 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=936, label="936 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"937 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" [id=937, label="937 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"938 bert/encoder/layer_5/intermediate/dense/MatMul" [id=938, type=MatMul];
"939 bert/encoder/layer_5/intermediate/dense/BiasAdd" [id=939, type=Add];
"940 bert/encoder/layer_5/intermediate/dense/Pow" [id=940, type=Pow];
"941 bert/encoder/layer_5/intermediate/dense/mul" [id=941, type=Mul];
"942 bert/encoder/layer_5/intermediate/dense/add" [id=942, type=Add];
"943 bert/encoder/layer_5/intermediate/dense/mul_1" [id=943, type=Mul];
"944 bert/encoder/layer_5/intermediate/dense/Tanh" [id=944, type=Tanh];
"945 bert/encoder/layer_5/intermediate/dense/add_1" [id=945, type=Add];
"946 bert/encoder/layer_5/intermediate/dense/mul_2" [id=946, type=Mul];
"947 bert/encoder/layer_5/intermediate/dense/mul_3" [id=947, type=Mul];
"948 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=948, label="948 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"949 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" [id=949, label="949 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"950 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=950, label="950 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1", type=QuantizeLinear];
"951 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" [id=951, label="951 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel:0_1", type=DequantizeLinear];
"952 bert/encoder/layer_5/output/dense/MatMul" [id=952, type=MatMul];
"953 bert/encoder/layer_5/output/dense/BiasAdd" [id=953, type=Add];
"954 bert/encoder/layer_5/output/add" [id=954, type=Add];
"955 bert/encoder/layer_5/output/LayerNorm/moments/mean" [id=955, type=ReduceMean];
"956 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" [id=956, type=Identity];
"957 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" [id=957, type=Sub];
"958 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" [id=958, type=Mul];
"959 bert/encoder/layer_5/output/LayerNorm/moments/variance" [id=959, type=ReduceMean];
"960 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" [id=960, type=Add];
"961 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" [id=961, type=Sqrt];
"962 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=962, label="962 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"963 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=963, label="963 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"964 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" [id=964, type=Reciprocal];
"965 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" [id=965, type=Mul];
"966 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" [id=966, type=Mul];
"967 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" [id=967, type=Sub];
"968 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" [id=968, type=Mul];
"969 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" [id=969, type=Add];
"970 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=970, label="970 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"971 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" [id=971, label="971 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"972 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=972, label="972 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"973 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" [id=973, label="973 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"974 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=974, label="974 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"975 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" [id=975, label="975 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"976 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=976, label="976 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1", type=QuantizeLinear];
"977 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" [id=977, label="977 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel:0_1", type=DequantizeLinear];
"978 bert/encoder/layer_6/attention/self/value/MatMul" [id=978, type=MatMul];
"979 bert/encoder/layer_6/attention/self/value/BiasAdd" [id=979, type=Add];
"980 bert/encoder/layer_6/attention/self/Reshape_2" [id=980, type=Reshape];
"981 bert/encoder/layer_6/attention/self/transpose_2" [id=981, type=Transpose];
"982 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=982, label="982 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1", type=QuantizeLinear];
"983 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" [id=983, label="983 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel:0_1", type=DequantizeLinear];
"984 bert/encoder/layer_6/attention/self/query/MatMul" [id=984, type=MatMul];
"985 bert/encoder/layer_6/attention/self/query/BiasAdd" [id=985, type=Add];
"986 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=986, label="986 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"987 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" [id=987, label="987 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"988 bert/encoder/layer_6/attention/self/Reshape" [id=988, type=Reshape];
"989 bert/encoder/layer_6/attention/self/transpose" [id=989, type=Transpose];
"990 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=990, label="990 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1", type=QuantizeLinear];
"991 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" [id=991, label="991 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel:0_1", type=DequantizeLinear];
"992 bert/encoder/layer_6/attention/self/key/MatMul" [id=992, type=MatMul];
"993 bert/encoder/layer_6/attention/self/key/BiasAdd" [id=993, type=Add];
"994 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=994, label="994 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"995 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" [id=995, label="995 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"996 bert/encoder/layer_6/attention/self/Reshape_1" [id=996, type=Reshape];
"997 bert/encoder/layer_6/attention/self/transpose_1" [id=997, type=Transpose];
"998 bert/encoder/layer_6/attention/self/MatMul__390" [id=998, type=Transpose];
"999 bert/encoder/layer_6/attention/self/MatMul" [id=999, type=MatMul];
"1000 bert/encoder/layer_6/attention/self/Mul" [id=1000, type=Mul];
"1001 bert/encoder/layer_6/attention/self/add" [id=1001, type=Add];
"1002 bert/encoder/layer_6/attention/self/Softmax" [id=1002, type=Softmax];
"1003 bert/encoder/layer_6/attention/self/MatMul_1" [id=1003, type=MatMul];
"1004 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=1004, label="1004 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1005 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" [id=1005, label="1005 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1006 bert/encoder/layer_6/attention/self/transpose_3" [id=1006, type=Transpose];
"1007 bert/encoder/layer_6/attention/self/Reshape_3" [id=1007, type=Reshape];
"1008 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=1008, label="1008 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1009 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" [id=1009, label="1009 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1010 bert/encoder/layer_6/attention/output/dense/MatMul" [id=1010, type=MatMul];
"1011 bert/encoder/layer_6/attention/output/dense/BiasAdd" [id=1011, type=Add];
"1012 bert/encoder/layer_6/attention/output/add" [id=1012, type=Add];
"1013 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" [id=1013, type=ReduceMean];
"1014 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" [id=1014, type=Identity];
"1015 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" [id=1015, type=Sub];
"1016 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" [id=1016, type=Mul];
"1017 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" [id=1017, type=ReduceMean];
"1018 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" [id=1018, type=Add];
"1019 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1019, type=Sqrt];
"1020 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1020, label="1020 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1021 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1021, label="1021 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1022 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" [id=1022, type=Reciprocal];
"1023 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" [id=1023, type=Mul];
"1024 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" [id=1024, type=Mul];
"1025 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" [id=1025, type=Sub];
"1026 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" [id=1026, type=Mul];
"1027 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" [id=1027, type=Add];
"1028 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1028, label="1028 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1029 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1029, label="1029 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1030 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1030, label="1030 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1031 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" [id=1031, label="1031 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1032 bert/encoder/layer_6/intermediate/dense/MatMul" [id=1032, type=MatMul];
"1033 bert/encoder/layer_6/intermediate/dense/BiasAdd" [id=1033, type=Add];
"1034 bert/encoder/layer_6/intermediate/dense/Pow" [id=1034, type=Pow];
"1035 bert/encoder/layer_6/intermediate/dense/mul" [id=1035, type=Mul];
"1036 bert/encoder/layer_6/intermediate/dense/add" [id=1036, type=Add];
"1037 bert/encoder/layer_6/intermediate/dense/mul_1" [id=1037, type=Mul];
"1038 bert/encoder/layer_6/intermediate/dense/Tanh" [id=1038, type=Tanh];
"1039 bert/encoder/layer_6/intermediate/dense/add_1" [id=1039, type=Add];
"1040 bert/encoder/layer_6/intermediate/dense/mul_2" [id=1040, type=Mul];
"1041 bert/encoder/layer_6/intermediate/dense/mul_3" [id=1041, type=Mul];
"1042 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1042, label="1042 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1043 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" [id=1043, label="1043 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1044 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1044, label="1044 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1", type=QuantizeLinear];
"1045 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" [id=1045, label="1045 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel:0_1", type=DequantizeLinear];
"1046 bert/encoder/layer_6/output/dense/MatMul" [id=1046, type=MatMul];
"1047 bert/encoder/layer_6/output/dense/BiasAdd" [id=1047, type=Add];
"1048 bert/encoder/layer_6/output/add" [id=1048, type=Add];
"1049 bert/encoder/layer_6/output/LayerNorm/moments/mean" [id=1049, type=ReduceMean];
"1050 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" [id=1050, type=Identity];
"1051 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" [id=1051, type=Sub];
"1052 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" [id=1052, type=Mul];
"1053 bert/encoder/layer_6/output/LayerNorm/moments/variance" [id=1053, type=ReduceMean];
"1054 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" [id=1054, type=Add];
"1055 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" [id=1055, type=Sqrt];
"1056 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1056, label="1056 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1057 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1057, label="1057 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1058 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" [id=1058, type=Reciprocal];
"1059 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" [id=1059, type=Mul];
"1060 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" [id=1060, type=Mul];
"1061 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" [id=1061, type=Sub];
"1062 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" [id=1062, type=Mul];
"1063 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" [id=1063, type=Add];
"1064 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1064, label="1064 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1065 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" [id=1065, label="1065 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1066 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1066, label="1066 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1067 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" [id=1067, label="1067 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1068 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1068, label="1068 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1069 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" [id=1069, label="1069 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1070 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1070, label="1070 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1071 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" [id=1071, label="1071 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1072 bert/encoder/layer_7/attention/self/value/MatMul" [id=1072, type=MatMul];
"1073 bert/encoder/layer_7/attention/self/value/BiasAdd" [id=1073, type=Add];
"1074 bert/encoder/layer_7/attention/self/Reshape_2" [id=1074, type=Reshape];
"1075 bert/encoder/layer_7/attention/self/transpose_2" [id=1075, type=Transpose];
"1076 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1076, label="1076 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1077 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" [id=1077, label="1077 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1078 bert/encoder/layer_7/attention/self/query/MatMul" [id=1078, type=MatMul];
"1079 bert/encoder/layer_7/attention/self/query/BiasAdd" [id=1079, type=Add];
"1080 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1080, label="1080 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1081 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" [id=1081, label="1081 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1082 bert/encoder/layer_7/attention/self/Reshape" [id=1082, type=Reshape];
"1083 bert/encoder/layer_7/attention/self/transpose" [id=1083, type=Transpose];
"1084 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1084, label="1084 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1085 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" [id=1085, label="1085 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1086 bert/encoder/layer_7/attention/self/key/MatMul" [id=1086, type=MatMul];
"1087 bert/encoder/layer_7/attention/self/key/BiasAdd" [id=1087, type=Add];
"1088 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1088, label="1088 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1089 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" [id=1089, label="1089 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1090 bert/encoder/layer_7/attention/self/Reshape_1" [id=1090, type=Reshape];
"1091 bert/encoder/layer_7/attention/self/transpose_1" [id=1091, type=Transpose];
"1092 bert/encoder/layer_7/attention/self/MatMul__404" [id=1092, type=Transpose];
"1093 bert/encoder/layer_7/attention/self/MatMul" [id=1093, type=MatMul];
"1094 bert/encoder/layer_7/attention/self/Mul" [id=1094, type=Mul];
"1095 bert/encoder/layer_7/attention/self/add" [id=1095, type=Add];
"1096 bert/encoder/layer_7/attention/self/Softmax" [id=1096, type=Softmax];
"1097 bert/encoder/layer_7/attention/self/MatMul_1" [id=1097, type=MatMul];
"1098 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1098, label="1098 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1099 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" [id=1099, label="1099 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1100 bert/encoder/layer_7/attention/self/transpose_3" [id=1100, type=Transpose];
"1101 bert/encoder/layer_7/attention/self/Reshape_3" [id=1101, type=Reshape];
"1102 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1102, label="1102 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1103 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" [id=1103, label="1103 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1104 bert/encoder/layer_7/attention/output/dense/MatMul" [id=1104, type=MatMul];
"1105 bert/encoder/layer_7/attention/output/dense/BiasAdd" [id=1105, type=Add];
"1106 bert/encoder/layer_7/attention/output/add" [id=1106, type=Add];
"1107 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" [id=1107, type=ReduceMean];
"1108 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" [id=1108, type=Identity];
"1109 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" [id=1109, type=Sub];
"1110 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" [id=1110, type=Mul];
"1111 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" [id=1111, type=ReduceMean];
"1112 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" [id=1112, type=Add];
"1113 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1113, type=Sqrt];
"1114 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1114, label="1114 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1115 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1115, label="1115 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1116 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" [id=1116, type=Reciprocal];
"1117 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" [id=1117, type=Mul];
"1118 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" [id=1118, type=Mul];
"1119 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" [id=1119, type=Sub];
"1120 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" [id=1120, type=Mul];
"1121 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" [id=1121, type=Add];
"1122 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1122, label="1122 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1123 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1123, label="1123 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1124 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1124, label="1124 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1125 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" [id=1125, label="1125 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1126 bert/encoder/layer_7/intermediate/dense/MatMul" [id=1126, type=MatMul];
"1127 bert/encoder/layer_7/intermediate/dense/BiasAdd" [id=1127, type=Add];
"1128 bert/encoder/layer_7/intermediate/dense/Pow" [id=1128, type=Pow];
"1129 bert/encoder/layer_7/intermediate/dense/mul" [id=1129, type=Mul];
"1130 bert/encoder/layer_7/intermediate/dense/add" [id=1130, type=Add];
"1131 bert/encoder/layer_7/intermediate/dense/mul_1" [id=1131, type=Mul];
"1132 bert/encoder/layer_7/intermediate/dense/Tanh" [id=1132, type=Tanh];
"1133 bert/encoder/layer_7/intermediate/dense/add_1" [id=1133, type=Add];
"1134 bert/encoder/layer_7/intermediate/dense/mul_2" [id=1134, type=Mul];
"1135 bert/encoder/layer_7/intermediate/dense/mul_3" [id=1135, type=Mul];
"1136 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1136, label="1136 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1137 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" [id=1137, label="1137 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1138 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1138, label="1138 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1", type=QuantizeLinear];
"1139 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" [id=1139, label="1139 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel:0_1", type=DequantizeLinear];
"1140 bert/encoder/layer_7/output/dense/MatMul" [id=1140, type=MatMul];
"1141 bert/encoder/layer_7/output/dense/BiasAdd" [id=1141, type=Add];
"1142 bert/encoder/layer_7/output/add" [id=1142, type=Add];
"1143 bert/encoder/layer_7/output/LayerNorm/moments/mean" [id=1143, type=ReduceMean];
"1144 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" [id=1144, type=Identity];
"1145 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" [id=1145, type=Sub];
"1146 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" [id=1146, type=Mul];
"1147 bert/encoder/layer_7/output/LayerNorm/moments/variance" [id=1147, type=ReduceMean];
"1148 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" [id=1148, type=Add];
"1149 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" [id=1149, type=Sqrt];
"1150 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1150, label="1150 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1151 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1151, label="1151 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1152 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" [id=1152, type=Reciprocal];
"1153 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" [id=1153, type=Mul];
"1154 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" [id=1154, type=Mul];
"1155 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" [id=1155, type=Sub];
"1156 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" [id=1156, type=Mul];
"1157 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" [id=1157, type=Add];
"1158 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1158, label="1158 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1159 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" [id=1159, label="1159 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1160 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1160, label="1160 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1161 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" [id=1161, label="1161 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1162 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1162, label="1162 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1163 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" [id=1163, label="1163 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1164 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1164, label="1164 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1165 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" [id=1165, label="1165 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1166 bert/encoder/layer_8/attention/self/value/MatMul" [id=1166, type=MatMul];
"1167 bert/encoder/layer_8/attention/self/value/BiasAdd" [id=1167, type=Add];
"1168 bert/encoder/layer_8/attention/self/Reshape_2" [id=1168, type=Reshape];
"1169 bert/encoder/layer_8/attention/self/transpose_2" [id=1169, type=Transpose];
"1170 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1170, label="1170 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1171 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" [id=1171, label="1171 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1172 bert/encoder/layer_8/attention/self/query/MatMul" [id=1172, type=MatMul];
"1173 bert/encoder/layer_8/attention/self/query/BiasAdd" [id=1173, type=Add];
"1174 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1174, label="1174 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1175 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" [id=1175, label="1175 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1176 bert/encoder/layer_8/attention/self/Reshape" [id=1176, type=Reshape];
"1177 bert/encoder/layer_8/attention/self/transpose" [id=1177, type=Transpose];
"1178 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1178, label="1178 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1179 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" [id=1179, label="1179 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1180 bert/encoder/layer_8/attention/self/key/MatMul" [id=1180, type=MatMul];
"1181 bert/encoder/layer_8/attention/self/key/BiasAdd" [id=1181, type=Add];
"1182 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1182, label="1182 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1183 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" [id=1183, label="1183 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1184 bert/encoder/layer_8/attention/self/Reshape_1" [id=1184, type=Reshape];
"1185 bert/encoder/layer_8/attention/self/transpose_1" [id=1185, type=Transpose];
"1186 bert/encoder/layer_8/attention/self/MatMul__418" [id=1186, type=Transpose];
"1187 bert/encoder/layer_8/attention/self/MatMul" [id=1187, type=MatMul];
"1188 bert/encoder/layer_8/attention/self/Mul" [id=1188, type=Mul];
"1189 bert/encoder/layer_8/attention/self/add" [id=1189, type=Add];
"1190 bert/encoder/layer_8/attention/self/Softmax" [id=1190, type=Softmax];
"1191 bert/encoder/layer_8/attention/self/MatMul_1" [id=1191, type=MatMul];
"1192 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1192, label="1192 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1193 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" [id=1193, label="1193 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1194 bert/encoder/layer_8/attention/self/transpose_3" [id=1194, type=Transpose];
"1195 bert/encoder/layer_8/attention/self/Reshape_3" [id=1195, type=Reshape];
"1196 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1196, label="1196 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1197 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" [id=1197, label="1197 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1198 bert/encoder/layer_8/attention/output/dense/MatMul" [id=1198, type=MatMul];
"1199 bert/encoder/layer_8/attention/output/dense/BiasAdd" [id=1199, type=Add];
"1200 bert/encoder/layer_8/attention/output/add" [id=1200, type=Add];
"1201 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" [id=1201, type=ReduceMean];
"1202 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" [id=1202, type=Identity];
"1203 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" [id=1203, type=Sub];
"1204 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" [id=1204, type=Mul];
"1205 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" [id=1205, type=ReduceMean];
"1206 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" [id=1206, type=Add];
"1207 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1207, type=Sqrt];
"1208 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1208, label="1208 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1209 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1209, label="1209 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1210 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" [id=1210, type=Reciprocal];
"1211 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" [id=1211, type=Mul];
"1212 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" [id=1212, type=Mul];
"1213 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" [id=1213, type=Sub];
"1214 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" [id=1214, type=Mul];
"1215 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" [id=1215, type=Add];
"1216 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1216, label="1216 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1217 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1217, label="1217 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1218 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1218, label="1218 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1219 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" [id=1219, label="1219 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1220 bert/encoder/layer_8/intermediate/dense/MatMul" [id=1220, type=MatMul];
"1221 bert/encoder/layer_8/intermediate/dense/BiasAdd" [id=1221, type=Add];
"1222 bert/encoder/layer_8/intermediate/dense/Pow" [id=1222, type=Pow];
"1223 bert/encoder/layer_8/intermediate/dense/mul" [id=1223, type=Mul];
"1224 bert/encoder/layer_8/intermediate/dense/add" [id=1224, type=Add];
"1225 bert/encoder/layer_8/intermediate/dense/mul_1" [id=1225, type=Mul];
"1226 bert/encoder/layer_8/intermediate/dense/Tanh" [id=1226, type=Tanh];
"1227 bert/encoder/layer_8/intermediate/dense/add_1" [id=1227, type=Add];
"1228 bert/encoder/layer_8/intermediate/dense/mul_2" [id=1228, type=Mul];
"1229 bert/encoder/layer_8/intermediate/dense/mul_3" [id=1229, type=Mul];
"1230 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1230, label="1230 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1231 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" [id=1231, label="1231 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1232 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1232, label="1232 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1", type=QuantizeLinear];
"1233 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" [id=1233, label="1233 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel:0_1", type=DequantizeLinear];
"1234 bert/encoder/layer_8/output/dense/MatMul" [id=1234, type=MatMul];
"1235 bert/encoder/layer_8/output/dense/BiasAdd" [id=1235, type=Add];
"1236 bert/encoder/layer_8/output/add" [id=1236, type=Add];
"1237 bert/encoder/layer_8/output/LayerNorm/moments/mean" [id=1237, type=ReduceMean];
"1238 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" [id=1238, type=Identity];
"1239 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" [id=1239, type=Sub];
"1240 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" [id=1240, type=Mul];
"1241 bert/encoder/layer_8/output/LayerNorm/moments/variance" [id=1241, type=ReduceMean];
"1242 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" [id=1242, type=Add];
"1243 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" [id=1243, type=Sqrt];
"1244 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1244, label="1244 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1245 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1245, label="1245 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1246 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" [id=1246, type=Reciprocal];
"1247 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" [id=1247, type=Mul];
"1248 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" [id=1248, type=Mul];
"1249 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" [id=1249, type=Sub];
"1250 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" [id=1250, type=Mul];
"1251 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" [id=1251, type=Add];
"1252 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1252, label="1252 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1253 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" [id=1253, label="1253 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1254 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1254, label="1254 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1255 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" [id=1255, label="1255 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1256 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1256, label="1256 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1257 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" [id=1257, label="1257 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1258 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1258, label="1258 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1259 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" [id=1259, label="1259 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1260 bert/encoder/layer_9/attention/self/value/MatMul" [id=1260, type=MatMul];
"1261 bert/encoder/layer_9/attention/self/value/BiasAdd" [id=1261, type=Add];
"1262 bert/encoder/layer_9/attention/self/Reshape_2" [id=1262, type=Reshape];
"1263 bert/encoder/layer_9/attention/self/transpose_2" [id=1263, type=Transpose];
"1264 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1264, label="1264 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1265 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" [id=1265, label="1265 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1266 bert/encoder/layer_9/attention/self/query/MatMul" [id=1266, type=MatMul];
"1267 bert/encoder/layer_9/attention/self/query/BiasAdd" [id=1267, type=Add];
"1268 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1268, label="1268 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1269 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" [id=1269, label="1269 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1270 bert/encoder/layer_9/attention/self/Reshape" [id=1270, type=Reshape];
"1271 bert/encoder/layer_9/attention/self/transpose" [id=1271, type=Transpose];
"1272 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1272, label="1272 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1273 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" [id=1273, label="1273 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1274 bert/encoder/layer_9/attention/self/key/MatMul" [id=1274, type=MatMul];
"1275 bert/encoder/layer_9/attention/self/key/BiasAdd" [id=1275, type=Add];
"1276 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1276, label="1276 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1277 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" [id=1277, label="1277 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1278 bert/encoder/layer_9/attention/self/Reshape_1" [id=1278, type=Reshape];
"1279 bert/encoder/layer_9/attention/self/transpose_1" [id=1279, type=Transpose];
"1280 bert/encoder/layer_9/attention/self/MatMul__432" [id=1280, type=Transpose];
"1281 bert/encoder/layer_9/attention/self/MatMul" [id=1281, type=MatMul];
"1282 bert/encoder/layer_9/attention/self/Mul" [id=1282, type=Mul];
"1283 bert/encoder/layer_9/attention/self/add" [id=1283, type=Add];
"1284 bert/encoder/layer_9/attention/self/Softmax" [id=1284, type=Softmax];
"1285 bert/encoder/layer_9/attention/self/MatMul_1" [id=1285, type=MatMul];
"1286 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1286, label="1286 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1287 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" [id=1287, label="1287 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1288 bert/encoder/layer_9/attention/self/transpose_3" [id=1288, type=Transpose];
"1289 bert/encoder/layer_9/attention/self/Reshape_3" [id=1289, type=Reshape];
"1290 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1290, label="1290 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1291 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" [id=1291, label="1291 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1292 bert/encoder/layer_9/attention/output/dense/MatMul" [id=1292, type=MatMul];
"1293 bert/encoder/layer_9/attention/output/dense/BiasAdd" [id=1293, type=Add];
"1294 bert/encoder/layer_9/attention/output/add" [id=1294, type=Add];
"1295 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" [id=1295, type=ReduceMean];
"1296 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" [id=1296, type=Identity];
"1297 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" [id=1297, type=Sub];
"1298 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" [id=1298, type=Mul];
"1299 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" [id=1299, type=ReduceMean];
"1300 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" [id=1300, type=Add];
"1301 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1301, type=Sqrt];
"1302 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1302, label="1302 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1303 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1303, label="1303 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1304 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" [id=1304, type=Reciprocal];
"1305 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" [id=1305, type=Mul];
"1306 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" [id=1306, type=Mul];
"1307 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" [id=1307, type=Sub];
"1308 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" [id=1308, type=Mul];
"1309 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" [id=1309, type=Add];
"1310 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1310, label="1310 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1311 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1311, label="1311 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1312 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1312, label="1312 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1313 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" [id=1313, label="1313 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1314 bert/encoder/layer_9/intermediate/dense/MatMul" [id=1314, type=MatMul];
"1315 bert/encoder/layer_9/intermediate/dense/BiasAdd" [id=1315, type=Add];
"1316 bert/encoder/layer_9/intermediate/dense/Pow" [id=1316, type=Pow];
"1317 bert/encoder/layer_9/intermediate/dense/mul" [id=1317, type=Mul];
"1318 bert/encoder/layer_9/intermediate/dense/add" [id=1318, type=Add];
"1319 bert/encoder/layer_9/intermediate/dense/mul_1" [id=1319, type=Mul];
"1320 bert/encoder/layer_9/intermediate/dense/Tanh" [id=1320, type=Tanh];
"1321 bert/encoder/layer_9/intermediate/dense/add_1" [id=1321, type=Add];
"1322 bert/encoder/layer_9/intermediate/dense/mul_2" [id=1322, type=Mul];
"1323 bert/encoder/layer_9/intermediate/dense/mul_3" [id=1323, type=Mul];
"1324 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1324, label="1324 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1325 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" [id=1325, label="1325 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1326 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1326, label="1326 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1", type=QuantizeLinear];
"1327 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" [id=1327, label="1327 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel:0_1", type=DequantizeLinear];
"1328 bert/encoder/layer_9/output/dense/MatMul" [id=1328, type=MatMul];
"1329 bert/encoder/layer_9/output/dense/BiasAdd" [id=1329, type=Add];
"1330 bert/encoder/layer_9/output/add" [id=1330, type=Add];
"1331 bert/encoder/layer_9/output/LayerNorm/moments/mean" [id=1331, type=ReduceMean];
"1332 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" [id=1332, type=Identity];
"1333 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" [id=1333, type=Sub];
"1334 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" [id=1334, type=Mul];
"1335 bert/encoder/layer_9/output/LayerNorm/moments/variance" [id=1335, type=ReduceMean];
"1336 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" [id=1336, type=Add];
"1337 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" [id=1337, type=Sqrt];
"1338 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1338, label="1338 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1339 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1339, label="1339 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1340 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" [id=1340, type=Reciprocal];
"1341 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" [id=1341, type=Mul];
"1342 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" [id=1342, type=Mul];
"1343 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" [id=1343, type=Sub];
"1344 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" [id=1344, type=Mul];
"1345 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" [id=1345, type=Add];
"1346 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1346, label="1346 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1347 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" [id=1347, label="1347 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1348 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1348, label="1348 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1349 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" [id=1349, label="1349 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1350 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1350, label="1350 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1351 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" [id=1351, label="1351 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1352 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1352, label="1352 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1353 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" [id=1353, label="1353 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1354 bert/encoder/layer_10/attention/self/value/MatMul" [id=1354, type=MatMul];
"1355 bert/encoder/layer_10/attention/self/value/BiasAdd" [id=1355, type=Add];
"1356 bert/encoder/layer_10/attention/self/Reshape_2" [id=1356, type=Reshape];
"1357 bert/encoder/layer_10/attention/self/transpose_2" [id=1357, type=Transpose];
"1358 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1358, label="1358 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1359 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" [id=1359, label="1359 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1360 bert/encoder/layer_10/attention/self/query/MatMul" [id=1360, type=MatMul];
"1361 bert/encoder/layer_10/attention/self/query/BiasAdd" [id=1361, type=Add];
"1362 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1362, label="1362 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1363 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" [id=1363, label="1363 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1364 bert/encoder/layer_10/attention/self/Reshape" [id=1364, type=Reshape];
"1365 bert/encoder/layer_10/attention/self/transpose" [id=1365, type=Transpose];
"1366 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1366, label="1366 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1367 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" [id=1367, label="1367 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1368 bert/encoder/layer_10/attention/self/key/MatMul" [id=1368, type=MatMul];
"1369 bert/encoder/layer_10/attention/self/key/BiasAdd" [id=1369, type=Add];
"1370 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1370, label="1370 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1371 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" [id=1371, label="1371 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1372 bert/encoder/layer_10/attention/self/Reshape_1" [id=1372, type=Reshape];
"1373 bert/encoder/layer_10/attention/self/transpose_1" [id=1373, type=Transpose];
"1374 bert/encoder/layer_10/attention/self/MatMul__446" [id=1374, type=Transpose];
"1375 bert/encoder/layer_10/attention/self/MatMul" [id=1375, type=MatMul];
"1376 bert/encoder/layer_10/attention/self/Mul" [id=1376, type=Mul];
"1377 bert/encoder/layer_10/attention/self/add" [id=1377, type=Add];
"1378 bert/encoder/layer_10/attention/self/Softmax" [id=1378, type=Softmax];
"1379 bert/encoder/layer_10/attention/self/MatMul_1" [id=1379, type=MatMul];
"1380 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1380, label="1380 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1381 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" [id=1381, label="1381 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1382 bert/encoder/layer_10/attention/self/transpose_3" [id=1382, type=Transpose];
"1383 bert/encoder/layer_10/attention/self/Reshape_3" [id=1383, type=Reshape];
"1384 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1384, label="1384 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1385 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" [id=1385, label="1385 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1386 bert/encoder/layer_10/attention/output/dense/MatMul" [id=1386, type=MatMul];
"1387 bert/encoder/layer_10/attention/output/dense/BiasAdd" [id=1387, type=Add];
"1388 bert/encoder/layer_10/attention/output/add" [id=1388, type=Add];
"1389 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" [id=1389, type=ReduceMean];
"1390 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" [id=1390, type=Identity];
"1391 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" [id=1391, type=Sub];
"1392 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" [id=1392, type=Mul];
"1393 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" [id=1393, type=ReduceMean];
"1394 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" [id=1394, type=Add];
"1395 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1395, type=Sqrt];
"1396 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1396, label="1396 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1397 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1397, label="1397 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1398 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" [id=1398, type=Reciprocal];
"1399 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" [id=1399, type=Mul];
"1400 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" [id=1400, type=Mul];
"1401 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" [id=1401, type=Sub];
"1402 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" [id=1402, type=Mul];
"1403 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" [id=1403, type=Add];
"1404 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1404, label="1404 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1405 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1405, label="1405 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1406 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1406, label="1406 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1407 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" [id=1407, label="1407 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1408 bert/encoder/layer_10/intermediate/dense/MatMul" [id=1408, type=MatMul];
"1409 bert/encoder/layer_10/intermediate/dense/BiasAdd" [id=1409, type=Add];
"1410 bert/encoder/layer_10/intermediate/dense/Pow" [id=1410, type=Pow];
"1411 bert/encoder/layer_10/intermediate/dense/mul" [id=1411, type=Mul];
"1412 bert/encoder/layer_10/intermediate/dense/add" [id=1412, type=Add];
"1413 bert/encoder/layer_10/intermediate/dense/mul_1" [id=1413, type=Mul];
"1414 bert/encoder/layer_10/intermediate/dense/Tanh" [id=1414, type=Tanh];
"1415 bert/encoder/layer_10/intermediate/dense/add_1" [id=1415, type=Add];
"1416 bert/encoder/layer_10/intermediate/dense/mul_2" [id=1416, type=Mul];
"1417 bert/encoder/layer_10/intermediate/dense/mul_3" [id=1417, type=Mul];
"1418 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1418, label="1418 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1419 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" [id=1419, label="1419 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1420 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1420, label="1420 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1", type=QuantizeLinear];
"1421 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" [id=1421, label="1421 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel:0_1", type=DequantizeLinear];
"1422 bert/encoder/layer_10/output/dense/MatMul" [id=1422, type=MatMul];
"1423 bert/encoder/layer_10/output/dense/BiasAdd" [id=1423, type=Add];
"1424 bert/encoder/layer_10/output/add" [id=1424, type=Add];
"1425 bert/encoder/layer_10/output/LayerNorm/moments/mean" [id=1425, type=ReduceMean];
"1426 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" [id=1426, type=Identity];
"1427 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" [id=1427, type=Sub];
"1428 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" [id=1428, type=Mul];
"1429 bert/encoder/layer_10/output/LayerNorm/moments/variance" [id=1429, type=ReduceMean];
"1430 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" [id=1430, type=Add];
"1431 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" [id=1431, type=Sqrt];
"1432 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1432, label="1432 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1433 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1433, label="1433 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1434 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" [id=1434, type=Reciprocal];
"1435 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" [id=1435, type=Mul];
"1436 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" [id=1436, type=Mul];
"1437 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" [id=1437, type=Sub];
"1438 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" [id=1438, type=Mul];
"1439 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" [id=1439, type=Add];
"1440 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1440, label="1440 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3", type=QuantizeLinear];
"1441 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" [id=1441, label="1441 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_3", type=DequantizeLinear];
"1442 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1442, label="1442 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2", type=QuantizeLinear];
"1443 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" [id=1443, label="1443 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_2", type=DequantizeLinear];
"1444 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1444, label="1444 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1445 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" [id=1445, label="1445 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1446 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1446, label="1446 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1", type=QuantizeLinear];
"1447 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" [id=1447, label="1447 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel:0_1", type=DequantizeLinear];
"1448 bert/encoder/layer_11/attention/self/value/MatMul" [id=1448, type=MatMul];
"1449 bert/encoder/layer_11/attention/self/value/BiasAdd" [id=1449, type=Add];
"1450 bert/encoder/layer_11/attention/self/Reshape_2" [id=1450, type=Reshape];
"1451 bert/encoder/layer_11/attention/self/transpose_2" [id=1451, type=Transpose];
"1452 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1452, label="1452 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1", type=QuantizeLinear];
"1453 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" [id=1453, label="1453 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel:0_1", type=DequantizeLinear];
"1454 bert/encoder/layer_11/attention/self/query/MatMul" [id=1454, type=MatMul];
"1455 bert/encoder/layer_11/attention/self/query/BiasAdd" [id=1455, type=Add];
"1456 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1456, label="1456 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1", type=QuantizeLinear];
"1457 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" [id=1457, label="1457 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd:0_1", type=DequantizeLinear];
"1458 bert/encoder/layer_11/attention/self/Reshape" [id=1458, type=Reshape];
"1459 bert/encoder/layer_11/attention/self/transpose" [id=1459, type=Transpose];
"1460 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1460, label="1460 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1", type=QuantizeLinear];
"1461 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" [id=1461, label="1461 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel:0_1", type=DequantizeLinear];
"1462 bert/encoder/layer_11/attention/self/key/MatMul" [id=1462, type=MatMul];
"1463 bert/encoder/layer_11/attention/self/key/BiasAdd" [id=1463, type=Add];
"1464 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1464, label="1464 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1", type=QuantizeLinear];
"1465 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" [id=1465, label="1465 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd:0_1", type=DequantizeLinear];
"1466 bert/encoder/layer_11/attention/self/Reshape_1" [id=1466, type=Reshape];
"1467 bert/encoder/layer_11/attention/self/transpose_1" [id=1467, type=Transpose];
"1468 bert/encoder/layer_11/attention/self/MatMul__460" [id=1468, type=Transpose];
"1469 bert/encoder/layer_11/attention/self/MatMul" [id=1469, type=MatMul];
"1470 bert/encoder/layer_11/attention/self/Mul" [id=1470, type=Mul];
"1471 bert/encoder/layer_11/attention/self/add" [id=1471, type=Add];
"1472 bert/encoder/layer_11/attention/self/Softmax" [id=1472, type=Softmax];
"1473 bert/encoder/layer_11/attention/self/MatMul_1" [id=1473, type=MatMul];
"1474 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1474, label="1474 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1", type=QuantizeLinear];
"1475 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" [id=1475, label="1475 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1:0_1", type=DequantizeLinear];
"1476 bert/encoder/layer_11/attention/self/transpose_3" [id=1476, type=Transpose];
"1477 bert/encoder/layer_11/attention/self/Reshape_3" [id=1477, type=Reshape];
"1478 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1478, label="1478 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1", type=QuantizeLinear];
"1479 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" [id=1479, label="1479 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel:0_1", type=DequantizeLinear];
"1480 bert/encoder/layer_11/attention/output/dense/MatMul" [id=1480, type=MatMul];
"1481 bert/encoder/layer_11/attention/output/dense/BiasAdd" [id=1481, type=Add];
"1482 bert/encoder/layer_11/attention/output/add" [id=1482, type=Add];
"1483 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" [id=1483, type=ReduceMean];
"1484 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" [id=1484, type=Identity];
"1485 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" [id=1485, type=Sub];
"1486 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" [id=1486, type=Mul];
"1487 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" [id=1487, type=ReduceMean];
"1488 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" [id=1488, type=Add];
"1489 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" [id=1489, type=Sqrt];
"1490 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1490, label="1490 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1491 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1491, label="1491 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1492 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" [id=1492, type=Reciprocal];
"1493 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" [id=1493, type=Mul];
"1494 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" [id=1494, type=Mul];
"1495 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" [id=1495, type=Sub];
"1496 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" [id=1496, type=Mul];
"1497 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" [id=1497, type=Add];
"1498 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1498, label="1498 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1499 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" [id=1499, label="1499 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1500 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1500, label="1500 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1", type=QuantizeLinear];
"1501 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" [id=1501, label="1501 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel:0_1", type=DequantizeLinear];
"1502 bert/encoder/layer_11/intermediate/dense/MatMul" [id=1502, type=MatMul];
"1503 bert/encoder/layer_11/intermediate/dense/BiasAdd" [id=1503, type=Add];
"1504 bert/encoder/layer_11/intermediate/dense/Pow" [id=1504, type=Pow];
"1505 bert/encoder/layer_11/intermediate/dense/mul" [id=1505, type=Mul];
"1506 bert/encoder/layer_11/intermediate/dense/add" [id=1506, type=Add];
"1507 bert/encoder/layer_11/intermediate/dense/mul_1" [id=1507, type=Mul];
"1508 bert/encoder/layer_11/intermediate/dense/Tanh" [id=1508, type=Tanh];
"1509 bert/encoder/layer_11/intermediate/dense/add_1" [id=1509, type=Add];
"1510 bert/encoder/layer_11/intermediate/dense/mul_2" [id=1510, type=Mul];
"1511 bert/encoder/layer_11/intermediate/dense/mul_3" [id=1511, type=Mul];
"1512 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1512, label="1512 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1", type=QuantizeLinear];
"1513 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" [id=1513, label="1513 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3:0_1", type=DequantizeLinear];
"1514 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1514, label="1514 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1", type=QuantizeLinear];
"1515 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" [id=1515, label="1515 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel:0_1", type=DequantizeLinear];
"1516 bert/encoder/layer_11/output/dense/MatMul" [id=1516, type=MatMul];
"1517 bert/encoder/layer_11/output/dense/BiasAdd" [id=1517, type=Add];
"1518 bert/encoder/layer_11/output/add" [id=1518, type=Add];
"1519 bert/encoder/layer_11/output/LayerNorm/moments/mean" [id=1519, type=ReduceMean];
"1520 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" [id=1520, type=Identity];
"1521 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" [id=1521, type=Sub];
"1522 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" [id=1522, type=Mul];
"1523 bert/encoder/layer_11/output/LayerNorm/moments/variance" [id=1523, type=ReduceMean];
"1524 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" [id=1524, type=Add];
"1525 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" [id=1525, type=Sqrt];
"1526 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1526, label="1526 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt:0_1", type=QuantizeLinear];
"1527 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt^0_1" [id=1527, label="1527 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt:0_1", type=DequantizeLinear];
"1528 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" [id=1528, type=Reciprocal];
"1529 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" [id=1529, type=Mul];
"1530 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" [id=1530, type=Mul];
"1531 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" [id=1531, type=Sub];
"1532 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" [id=1532, type=Mul];
"1533 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" [id=1533, type=Add];
"1534 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1534, label="1534 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1", type=QuantizeLinear];
"1535 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" [id=1535, label="1535 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0_1", type=DequantizeLinear];
"1536 bert/encoder/Reshape_13" [id=1536, type=Reshape];
"1537 Shape_1" [id=1537, type=Shape];
"1538 Shape_1__472" [id=1538, type=Cast];
"1539 strided_slice_1" [id=1539, type=Slice];
"1540 strided_slice_1__476" [id=1540, type=Squeeze];
"1541 strided_slice_1__477" [id=1541, type=Cast];
"1542 mul" [id=1542, type=Mul];
"1543 Reshape/shape_Unsqueeze__482" [id=1543, type=Unsqueeze];
"1544 Reshape/shape_Concat__484" [id=1544, type=Concat];
"1545 Reshape__485" [id=1545, type=Cast];
"1546 Reshape_1/shape_Unsqueeze__478" [id=1546, type=Unsqueeze];
"1547 Reshape_1/shape_Concat__481" [id=1547, type=Concat];
"1548 Reshape_1__487" [id=1548, type=Cast];
"1549 Reshape" [id=1549, type=Reshape];
"1550 QuantizeLinear_MatMul__486^0_1" [id=1550, label="1550 QuantizeLinear_MatMul__486:0_1", type=QuantizeLinear];
"1551 DequantizeLinear_MatMul__486^0_1" [id=1551, label="1551 DequantizeLinear_MatMul__486:0_1", type=DequantizeLinear];
"1552 MatMul" [id=1552, type=MatMul];
"1553 BiasAdd" [id=1553, type=Add];
"1554 Reshape_1" [id=1554, type=Reshape];
"1555 transpose" [id=1555, type=Transpose];
"1556 unstack" [id=1556, type=Split];
"1557 unstack__490" [id=1557, type=Squeeze];
"1558 unstack_graph_outputs_Identity__4" [id=1558, type=Identity];
"1559 unstack__488" [id=1559, type=Squeeze];
"1560 unstack_graph_outputs_Identity__7" [id=1560, type=Identity];
"1561 nncf_model_input_0" [id=1561, type=nncf_model_input];
"1562 nncf_model_input_1" [id=1562, type=nncf_model_input];
"1563 nncf_model_input_2" [id=1563, type=nncf_model_input];
"1564 nncf_model_input_3" [id=1564, type=nncf_model_input];
"1565 nncf_model_output_0" [id=1565, type=nncf_model_output];
"1566 nncf_model_output_1" [id=1566, type=nncf_model_output];
"1567 nncf_model_output_2" [id=1567, type=nncf_model_output];
"0 unique_ids_graph_outputs_Identity__10" -> "1567 nncf_model_output_2"  [label="[-1]", style=dashed];
"1 bert/encoder/ones/packed_Unsqueeze__20" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"2 bert/encoder/ones/packed_Unsqueeze__19" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"3 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__83" -> "248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84"  [label="[1]", style=dashed];
"4 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__88" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"5 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__87" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"6 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__86" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"7 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__93" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"8 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__92" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"9 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__91" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"10 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__98" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"11 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__97" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"12 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__96" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"13 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__101" -> "261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102"  [label="[1]", style=dashed];
"14 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__106" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"15 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__105" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"16 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__104" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"17 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__111" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"18 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__110" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"19 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__109" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"20 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__116" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"21 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__115" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"22 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__114" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"23 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__119" -> "274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120"  [label="[1]", style=dashed];
"24 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__124" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"25 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__123" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"26 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__122" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"27 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__129" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"28 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__128" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"29 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__127" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"30 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__134" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"31 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__133" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"32 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__132" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"33 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__137" -> "287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138"  [label="[1]", style=dashed];
"34 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__142" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"35 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__141" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"36 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__140" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"37 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__147" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"38 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__146" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"39 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__145" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"40 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__152" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"41 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__151" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"42 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__150" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"43 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__155" -> "300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156"  [label="[1]", style=dashed];
"44 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__160" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"45 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__159" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"46 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__158" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"47 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__165" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"48 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__164" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"49 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__163" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"50 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__170" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"51 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__169" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"52 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__168" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"53 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__173" -> "313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174"  [label="[1]", style=dashed];
"54 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__178" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"55 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__177" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"56 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__176" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"57 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__183" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"58 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__182" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"59 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__181" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"60 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__188" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"61 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__187" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"62 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__186" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"63 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__191" -> "326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192"  [label="[1]", style=dashed];
"64 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__196" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"65 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__195" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"66 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__194" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"67 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__201" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"68 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__200" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"69 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__199" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"70 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__206" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"71 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__205" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"72 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__204" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"73 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__209" -> "339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210"  [label="[1]", style=dashed];
"74 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__214" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"75 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__213" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"76 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__212" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"77 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__219" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"78 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__218" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"79 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__217" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"80 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__224" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"81 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__223" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"82 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__222" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"83 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__227" -> "352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228"  [label="[1]", style=dashed];
"84 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__232" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"85 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__231" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"86 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__230" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"87 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__237" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"88 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__236" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"89 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__235" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"90 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__242" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"91 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__241" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"92 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__240" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"93 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__245" -> "365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246"  [label="[1]", style=dashed];
"94 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__250" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"95 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__249" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"96 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__248" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"97 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__255" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"98 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__254" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"99 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__253" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"100 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__260" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"101 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__259" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"102 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__258" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"103 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__263" -> "378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264"  [label="[1]", style=dashed];
"104 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__268" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"105 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__267" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"106 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__266" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"107 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__273" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"108 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__272" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"109 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__271" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"110 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__278" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"111 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__277" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"112 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__276" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"113 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__281" -> "391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282"  [label="[1]", style=dashed];
"114 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__286" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"115 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__285" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"116 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__284" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"117 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__291" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"118 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__290" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"119 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__289" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"120 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__296" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"121 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__295" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"122 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__294" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"123 bert/encoder/Shape" -> "124 bert/encoder/Shape__12"  [label="[2]", style=dashed];
"124 bert/encoder/Shape__12" -> "125 bert/encoder/strided_slice"  [label="[2]", style=solid];
"125 bert/encoder/strided_slice" -> "126 bert/encoder/strided_slice__16"  [label="[1]", style=solid];
"126 bert/encoder/strided_slice__16" -> "127 bert/encoder/strided_slice__17"  [label="[]", style=solid];
"127 bert/encoder/strided_slice__17" -> "128 bert/encoder/ones/packed_Unsqueeze__18"  [label="[]", style=dashed];
"127 bert/encoder/strided_slice__17" -> "135 bert/encoder/Reshape/shape_Unsqueeze__23"  [label="[]", style=dashed];
"128 bert/encoder/ones/packed_Unsqueeze__18" -> "129 bert/encoder/ones/packed_Concat__21"  [label="[1]", style=dashed];
"129 bert/encoder/ones/packed_Concat__21" -> "130 bert/encoder/ones__22"  [label="[3]", style=dashed];
"130 bert/encoder/ones__22" -> "131 bert/encoder/ones"  [label="[3]", style=dashed];
"131 bert/encoder/ones" -> "142 bert/encoder/mul"  [label="[-1, -1, -1]", style=solid];
"132 bert/encoder/Reshape_13/shape_Unsqueeze__300" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"133 bert/encoder/Reshape_13/shape_Unsqueeze__299" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"134 bert/encoder/Reshape_1__302" -> "405 bert/encoder/Reshape_1"  [label="[2]", style=dashed];
"135 bert/encoder/Reshape/shape_Unsqueeze__23" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"136 bert/encoder/Reshape/shape_Unsqueeze__25" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"137 bert/encoder/Reshape/shape_Unsqueeze__24" -> "138 bert/encoder/Reshape/shape_Concat__26"  [label="[1]", style=dashed];
"138 bert/encoder/Reshape/shape_Concat__26" -> "139 bert/encoder/Reshape__27"  [label="[3]", style=dashed];
"139 bert/encoder/Reshape__27" -> "140 bert/encoder/Reshape"  [label="[3]", style=dashed];
"140 bert/encoder/Reshape" -> "141 bert/encoder/Cast"  [label="[]", style=dashed];
"141 bert/encoder/Cast" -> "142 bert/encoder/mul"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "143 bert/encoder/layer_9/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "146 bert/encoder/layer_8/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "149 bert/encoder/layer_7/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "152 bert/encoder/layer_6/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "155 bert/encoder/layer_5/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "158 bert/encoder/layer_4/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "161 bert/encoder/layer_3/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "164 bert/encoder/layer_2/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "167 bert/encoder/layer_11/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "170 bert/encoder/layer_10/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "173 bert/encoder/layer_1/attention/self/ExpandDims"  [label="[]", style=solid];
"142 bert/encoder/mul" -> "176 bert/encoder/layer_0/attention/self/ExpandDims"  [label="[]", style=solid];
"143 bert/encoder/layer_9/attention/self/ExpandDims" -> "144 bert/encoder/layer_9/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"144 bert/encoder/layer_9/attention/self/sub" -> "145 bert/encoder/layer_9/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"145 bert/encoder/layer_9/attention/self/mul_1" -> "1283 bert/encoder/layer_9/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"146 bert/encoder/layer_8/attention/self/ExpandDims" -> "147 bert/encoder/layer_8/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"147 bert/encoder/layer_8/attention/self/sub" -> "148 bert/encoder/layer_8/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"148 bert/encoder/layer_8/attention/self/mul_1" -> "1189 bert/encoder/layer_8/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"149 bert/encoder/layer_7/attention/self/ExpandDims" -> "150 bert/encoder/layer_7/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"150 bert/encoder/layer_7/attention/self/sub" -> "151 bert/encoder/layer_7/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"151 bert/encoder/layer_7/attention/self/mul_1" -> "1095 bert/encoder/layer_7/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"152 bert/encoder/layer_6/attention/self/ExpandDims" -> "153 bert/encoder/layer_6/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"153 bert/encoder/layer_6/attention/self/sub" -> "154 bert/encoder/layer_6/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"154 bert/encoder/layer_6/attention/self/mul_1" -> "1001 bert/encoder/layer_6/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"155 bert/encoder/layer_5/attention/self/ExpandDims" -> "156 bert/encoder/layer_5/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"156 bert/encoder/layer_5/attention/self/sub" -> "157 bert/encoder/layer_5/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"157 bert/encoder/layer_5/attention/self/mul_1" -> "907 bert/encoder/layer_5/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"158 bert/encoder/layer_4/attention/self/ExpandDims" -> "159 bert/encoder/layer_4/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"159 bert/encoder/layer_4/attention/self/sub" -> "160 bert/encoder/layer_4/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"160 bert/encoder/layer_4/attention/self/mul_1" -> "813 bert/encoder/layer_4/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"161 bert/encoder/layer_3/attention/self/ExpandDims" -> "162 bert/encoder/layer_3/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"162 bert/encoder/layer_3/attention/self/sub" -> "163 bert/encoder/layer_3/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"163 bert/encoder/layer_3/attention/self/mul_1" -> "719 bert/encoder/layer_3/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"164 bert/encoder/layer_2/attention/self/ExpandDims" -> "165 bert/encoder/layer_2/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"165 bert/encoder/layer_2/attention/self/sub" -> "166 bert/encoder/layer_2/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"166 bert/encoder/layer_2/attention/self/mul_1" -> "625 bert/encoder/layer_2/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"167 bert/encoder/layer_11/attention/self/ExpandDims" -> "168 bert/encoder/layer_11/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"168 bert/encoder/layer_11/attention/self/sub" -> "169 bert/encoder/layer_11/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"169 bert/encoder/layer_11/attention/self/mul_1" -> "1471 bert/encoder/layer_11/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"170 bert/encoder/layer_10/attention/self/ExpandDims" -> "171 bert/encoder/layer_10/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"171 bert/encoder/layer_10/attention/self/sub" -> "172 bert/encoder/layer_10/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"172 bert/encoder/layer_10/attention/self/mul_1" -> "1377 bert/encoder/layer_10/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"173 bert/encoder/layer_1/attention/self/ExpandDims" -> "174 bert/encoder/layer_1/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"174 bert/encoder/layer_1/attention/self/sub" -> "175 bert/encoder/layer_1/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"175 bert/encoder/layer_1/attention/self/mul_1" -> "531 bert/encoder/layer_1/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"176 bert/encoder/layer_0/attention/self/ExpandDims" -> "177 bert/encoder/layer_0/attention/self/sub"  [label="[-1, 1, 256, 256]", style=solid];
"177 bert/encoder/layer_0/attention/self/sub" -> "178 bert/encoder/layer_0/attention/self/mul_1"  [label="[-1, 1, 256, 256]", style=solid];
"178 bert/encoder/layer_0/attention/self/mul_1" -> "437 bert/encoder/layer_0/attention/self/add"  [label="[-1, 1, 256, 256]", style=solid];
"179 bert/embeddings/Slice" -> "181 bert/embeddings/Reshape_4"  [label="[256, 768]", style=solid];
"180 bert/embeddings/Reshape_4__42" -> "181 bert/embeddings/Reshape_4"  [label="[3]", style=dashed];
"181 bert/embeddings/Reshape_4" -> "225 bert/embeddings/add_1"  [label="[]", style=solid];
"182 bert/embeddings/Reshape_3/shape_Unsqueeze__69" -> "207 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"183 bert/embeddings/Reshape_3/shape_Unsqueeze__68" -> "207 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"184 bert/embeddings/Reshape_2__43" -> "185 bert/embeddings/Reshape_2"  [label="[1]", style=dashed];
"185 bert/embeddings/Reshape_2" -> "217 bert/embeddings/one_hot"  [label="[]", style=dashed];
"186 bert/embeddings/Reshape_1/shape_Unsqueeze__57" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"187 bert/embeddings/Reshape_1/shape_Unsqueeze__56" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"188 bert/embeddings/Reshape__59" -> "198 bert/embeddings/Reshape"  [label="[1]", style=dashed];
"189 bert/embeddings/ExpandDims" -> "190 bert/embeddings/Shape"  [label="[-1, 256, 1]", style=dashed];
"189 bert/embeddings/ExpandDims" -> "198 bert/embeddings/Reshape"  [label="[-1, 256, 1]", style=dashed];
"190 bert/embeddings/Shape" -> "191 bert/embeddings/Shape__49"  [label="[3]", style=dashed];
"191 bert/embeddings/Shape__49" -> "192 bert/embeddings/strided_slice"  [label="[3]", style=solid];
"192 bert/embeddings/strided_slice" -> "193 bert/embeddings/strided_slice__53"  [label="[1]", style=solid];
"193 bert/embeddings/strided_slice__53" -> "194 bert/embeddings/strided_slice__54"  [label="[]", style=solid];
"194 bert/embeddings/strided_slice__54" -> "195 bert/embeddings/Reshape_1/shape_Unsqueeze__55"  [label="[]", style=dashed];
"195 bert/embeddings/Reshape_1/shape_Unsqueeze__55" -> "196 bert/embeddings/Reshape_1/shape_Concat__58"  [label="[1]", style=dashed];
"196 bert/embeddings/Reshape_1/shape_Concat__58" -> "197 bert/embeddings/Reshape_1__60"  [label="[3]", style=dashed];
"197 bert/embeddings/Reshape_1__60" -> "200 bert/embeddings/Reshape_1"  [label="[3]", style=dashed];
"198 bert/embeddings/Reshape" -> "199 bert/embeddings/GatherV2"  [label="[]", style=dashed];
"199 bert/embeddings/GatherV2" -> "200 bert/embeddings/Reshape_1"  [label="[]", style=solid];
"200 bert/embeddings/Reshape_1" -> "201 bert/embeddings/Shape_1"  [label="[]", style=solid];
"200 bert/embeddings/Reshape_1" -> "224 bert/embeddings/add"  [label="[]", style=solid];
"201 bert/embeddings/Shape_1" -> "202 bert/embeddings/Shape_1__61"  [label="[-1]", style=dashed];
"202 bert/embeddings/Shape_1__61" -> "203 bert/embeddings/strided_slice_1"  [label="[-1]", style=solid];
"203 bert/embeddings/strided_slice_1" -> "204 bert/embeddings/strided_slice_1__65"  [label="[-1]", style=solid];
"204 bert/embeddings/strided_slice_1__65" -> "205 bert/embeddings/strided_slice_1__66"  [label="[]", style=solid];
"205 bert/embeddings/strided_slice_1__66" -> "206 bert/embeddings/Reshape_3/shape_Unsqueeze__67"  [label="[]", style=dashed];
"206 bert/embeddings/Reshape_3/shape_Unsqueeze__67" -> "207 bert/embeddings/Reshape_3/shape_Concat__70"  [label="[1]", style=dashed];
"207 bert/embeddings/Reshape_3/shape_Concat__70" -> "208 bert/embeddings/Reshape_3__71"  [label="[3]", style=dashed];
"208 bert/embeddings/Reshape_3__71" -> "223 bert/embeddings/Reshape_3"  [label="[3]", style=dashed];
"209 Unsqueeze__46" -> "216 Concat__47"  [label="[1]", style=solid];
"210 Unsqueeze__45" -> "216 Concat__47"  [label="[1]", style=solid];
"211 Unsqueeze__44" -> "217 bert/embeddings/one_hot"  [label="[1]", style=dashed];
"212 Reshape_1/shape_Unsqueeze__480" -> "1547 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"213 Reshape_1/shape_Unsqueeze__479" -> "1547 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"214 Reshape/shape_Unsqueeze__483" -> "1544 Reshape/shape_Concat__484"  [label="[1]", style=dashed];
"215 MatMul__486" -> "1550 QuantizeLinear_MatMul__486^0_1"  [label="[768, 2]", style=solid];
"216 Concat__47" -> "217 bert/embeddings/one_hot"  [label="[2]", style=solid];
"217 bert/embeddings/one_hot" -> "218 QuantizeLinear_bert/embeddings/one_hot^0_1"  [label="[]", style=solid];
"218 QuantizeLinear_bert/embeddings/one_hot^0_1" -> "219 DequantizeLinear_bert/embeddings/one_hot^0_1"  [label="[]", style=dashed];
"219 DequantizeLinear_bert/embeddings/one_hot^0_1" -> "222 bert/embeddings/MatMul"  [label="[]", style=solid];
"220 QuantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "221 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1"  [label="[2, 768]", style=dashed];
"221 DequantizeLinear_bert/embeddings/token_type_embeddings^0_1" -> "222 bert/embeddings/MatMul"  [label="[2, 768]", style=solid];
"222 bert/embeddings/MatMul" -> "223 bert/embeddings/Reshape_3"  [label="[]", style=solid];
"223 bert/embeddings/Reshape_3" -> "224 bert/embeddings/add"  [label="[]", style=solid];
"224 bert/embeddings/add" -> "225 bert/embeddings/add_1"  [label="[]", style=solid];
"225 bert/embeddings/add_1" -> "226 bert/embeddings/LayerNorm/moments/mean"  [label="[]", style=solid];
"225 bert/embeddings/add_1" -> "228 bert/embeddings/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"225 bert/embeddings/add_1" -> "239 bert/embeddings/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"226 bert/embeddings/LayerNorm/moments/mean" -> "227 bert/embeddings/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"226 bert/embeddings/LayerNorm/moments/mean" -> "237 bert/embeddings/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"227 bert/embeddings/LayerNorm/moments/StopGradient" -> "228 bert/embeddings/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"228 bert/embeddings/LayerNorm/moments/SquaredDifference" -> "229 bert/embeddings/LayerNorm/moments/SquaredDifference__72"  [label="[]", style=solid];
"229 bert/embeddings/LayerNorm/moments/SquaredDifference__72" -> "230 bert/embeddings/LayerNorm/moments/variance"  [label="[]", style=solid];
"230 bert/embeddings/LayerNorm/moments/variance" -> "231 bert/embeddings/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"231 bert/embeddings/LayerNorm/batchnorm/add" -> "232 bert/embeddings/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"232 bert/embeddings/LayerNorm/batchnorm/Rsqrt" -> "233 QuantizeLinear_bert/embeddings/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"233 QuantizeLinear_bert/embeddings/LayerNorm/batchnorm/Rsqrt^0_1" -> "234 DequantizeLinear_bert/embeddings/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"234 DequantizeLinear_bert/embeddings/LayerNorm/batchnorm/Rsqrt^0_1" -> "235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74"  [label="[]", style=solid];
"235 bert/embeddings/LayerNorm/batchnorm/Rsqrt__74" -> "236 bert/embeddings/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"236 bert/embeddings/LayerNorm/batchnorm/mul" -> "237 bert/embeddings/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"236 bert/embeddings/LayerNorm/batchnorm/mul" -> "239 bert/embeddings/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"237 bert/embeddings/LayerNorm/batchnorm/mul_2" -> "238 bert/embeddings/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"238 bert/embeddings/LayerNorm/batchnorm/sub" -> "240 bert/embeddings/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"239 bert/embeddings/LayerNorm/batchnorm/mul_1" -> "240 bert/embeddings/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" -> "241 bert/encoder/Shape_2"  [label="[]", style=solid];
"240 bert/embeddings/LayerNorm/batchnorm/add_1" -> "405 bert/encoder/Reshape_1"  [label="[]", style=solid];
"241 bert/encoder/Shape_2" -> "242 bert/encoder/Shape_2__76"  [label="[-1]", style=dashed];
"242 bert/encoder/Shape_2__76" -> "243 bert/encoder/strided_slice_2"  [label="[-1]", style=solid];
"243 bert/encoder/strided_slice_2" -> "244 bert/encoder/strided_slice_2__80"  [label="[-1]", style=solid];
"244 bert/encoder/strided_slice_2__80" -> "245 bert/encoder/strided_slice_2__81"  [label="[]", style=solid];
"245 bert/encoder/strided_slice_2__81" -> "246 bert/encoder/layer_9/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "259 bert/encoder/layer_8/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "272 bert/encoder/layer_7/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "285 bert/encoder/layer_6/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "298 bert/encoder/layer_5/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "311 bert/encoder/layer_4/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "324 bert/encoder/layer_3/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "337 bert/encoder/layer_2/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "350 bert/encoder/layer_11/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "363 bert/encoder/layer_10/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "376 bert/encoder/layer_1/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "389 bert/encoder/layer_0/attention/self/mul_2"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293"  [label="[]", style=dashed];
"245 bert/encoder/strided_slice_2__81" -> "402 bert/encoder/Reshape_13/shape_Unsqueeze__298"  [label="[]", style=dashed];
"246 bert/encoder/layer_9/attention/self/mul_2" -> "247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82"  [label="[]", style=dashed];
"247 bert/encoder/layer_9/attention/self/Reshape_3/shape_Unsqueeze__82" -> "248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84"  [label="[1]", style=dashed];
"248 bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__84" -> "249 bert/encoder/layer_9/attention/self/Reshape_3__434"  [label="[2]", style=dashed];
"249 bert/encoder/layer_9/attention/self/Reshape_3__434" -> "1289 bert/encoder/layer_9/attention/self/Reshape_3"  [label="[2]", style=dashed];
"250 bert/encoder/layer_9/attention/self/Reshape_2/shape_Unsqueeze__85" -> "251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89"  [label="[1]", style=dashed];
"251 bert/encoder/layer_9/attention/self/Reshape_2/shape_Concat__89" -> "252 bert/encoder/layer_9/attention/self/Reshape_2__429"  [label="[4]", style=dashed];
"252 bert/encoder/layer_9/attention/self/Reshape_2__429" -> "1262 bert/encoder/layer_9/attention/self/Reshape_2"  [label="[4]", style=dashed];
"253 bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__90" -> "254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94"  [label="[1]", style=dashed];
"254 bert/encoder/layer_9/attention/self/Reshape_1/shape_Concat__94" -> "255 bert/encoder/layer_9/attention/self/Reshape_1__431"  [label="[4]", style=dashed];
"255 bert/encoder/layer_9/attention/self/Reshape_1__431" -> "1278 bert/encoder/layer_9/attention/self/Reshape_1"  [label="[4]", style=dashed];
"256 bert/encoder/layer_9/attention/self/Reshape/shape_Unsqueeze__95" -> "257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99"  [label="[1]", style=dashed];
"257 bert/encoder/layer_9/attention/self/Reshape/shape_Concat__99" -> "258 bert/encoder/layer_9/attention/self/Reshape__430"  [label="[4]", style=dashed];
"258 bert/encoder/layer_9/attention/self/Reshape__430" -> "1270 bert/encoder/layer_9/attention/self/Reshape"  [label="[4]", style=dashed];
"259 bert/encoder/layer_8/attention/self/mul_2" -> "260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100"  [label="[]", style=dashed];
"260 bert/encoder/layer_8/attention/self/Reshape_3/shape_Unsqueeze__100" -> "261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102"  [label="[1]", style=dashed];
"261 bert/encoder/layer_8/attention/self/Reshape_3/shape_Concat__102" -> "262 bert/encoder/layer_8/attention/self/Reshape_3__420"  [label="[2]", style=dashed];
"262 bert/encoder/layer_8/attention/self/Reshape_3__420" -> "1195 bert/encoder/layer_8/attention/self/Reshape_3"  [label="[2]", style=dashed];
"263 bert/encoder/layer_8/attention/self/Reshape_2/shape_Unsqueeze__103" -> "264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107"  [label="[1]", style=dashed];
"264 bert/encoder/layer_8/attention/self/Reshape_2/shape_Concat__107" -> "265 bert/encoder/layer_8/attention/self/Reshape_2__415"  [label="[4]", style=dashed];
"265 bert/encoder/layer_8/attention/self/Reshape_2__415" -> "1168 bert/encoder/layer_8/attention/self/Reshape_2"  [label="[4]", style=dashed];
"266 bert/encoder/layer_8/attention/self/Reshape_1/shape_Unsqueeze__108" -> "267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112"  [label="[1]", style=dashed];
"267 bert/encoder/layer_8/attention/self/Reshape_1/shape_Concat__112" -> "268 bert/encoder/layer_8/attention/self/Reshape_1__417"  [label="[4]", style=dashed];
"268 bert/encoder/layer_8/attention/self/Reshape_1__417" -> "1184 bert/encoder/layer_8/attention/self/Reshape_1"  [label="[4]", style=dashed];
"269 bert/encoder/layer_8/attention/self/Reshape/shape_Unsqueeze__113" -> "270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117"  [label="[1]", style=dashed];
"270 bert/encoder/layer_8/attention/self/Reshape/shape_Concat__117" -> "271 bert/encoder/layer_8/attention/self/Reshape__416"  [label="[4]", style=dashed];
"271 bert/encoder/layer_8/attention/self/Reshape__416" -> "1176 bert/encoder/layer_8/attention/self/Reshape"  [label="[4]", style=dashed];
"272 bert/encoder/layer_7/attention/self/mul_2" -> "273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118"  [label="[]", style=dashed];
"273 bert/encoder/layer_7/attention/self/Reshape_3/shape_Unsqueeze__118" -> "274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120"  [label="[1]", style=dashed];
"274 bert/encoder/layer_7/attention/self/Reshape_3/shape_Concat__120" -> "275 bert/encoder/layer_7/attention/self/Reshape_3__406"  [label="[2]", style=dashed];
"275 bert/encoder/layer_7/attention/self/Reshape_3__406" -> "1101 bert/encoder/layer_7/attention/self/Reshape_3"  [label="[2]", style=dashed];
"276 bert/encoder/layer_7/attention/self/Reshape_2/shape_Unsqueeze__121" -> "277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125"  [label="[1]", style=dashed];
"277 bert/encoder/layer_7/attention/self/Reshape_2/shape_Concat__125" -> "278 bert/encoder/layer_7/attention/self/Reshape_2__401"  [label="[4]", style=dashed];
"278 bert/encoder/layer_7/attention/self/Reshape_2__401" -> "1074 bert/encoder/layer_7/attention/self/Reshape_2"  [label="[4]", style=dashed];
"279 bert/encoder/layer_7/attention/self/Reshape_1/shape_Unsqueeze__126" -> "280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130"  [label="[1]", style=dashed];
"280 bert/encoder/layer_7/attention/self/Reshape_1/shape_Concat__130" -> "281 bert/encoder/layer_7/attention/self/Reshape_1__403"  [label="[4]", style=dashed];
"281 bert/encoder/layer_7/attention/self/Reshape_1__403" -> "1090 bert/encoder/layer_7/attention/self/Reshape_1"  [label="[4]", style=dashed];
"282 bert/encoder/layer_7/attention/self/Reshape/shape_Unsqueeze__131" -> "283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135"  [label="[1]", style=dashed];
"283 bert/encoder/layer_7/attention/self/Reshape/shape_Concat__135" -> "284 bert/encoder/layer_7/attention/self/Reshape__402"  [label="[4]", style=dashed];
"284 bert/encoder/layer_7/attention/self/Reshape__402" -> "1082 bert/encoder/layer_7/attention/self/Reshape"  [label="[4]", style=dashed];
"285 bert/encoder/layer_6/attention/self/mul_2" -> "286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136"  [label="[]", style=dashed];
"286 bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__136" -> "287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138"  [label="[1]", style=dashed];
"287 bert/encoder/layer_6/attention/self/Reshape_3/shape_Concat__138" -> "288 bert/encoder/layer_6/attention/self/Reshape_3__392"  [label="[2]", style=dashed];
"288 bert/encoder/layer_6/attention/self/Reshape_3__392" -> "1007 bert/encoder/layer_6/attention/self/Reshape_3"  [label="[2]", style=dashed];
"289 bert/encoder/layer_6/attention/self/Reshape_2/shape_Unsqueeze__139" -> "290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143"  [label="[1]", style=dashed];
"290 bert/encoder/layer_6/attention/self/Reshape_2/shape_Concat__143" -> "291 bert/encoder/layer_6/attention/self/Reshape_2__387"  [label="[4]", style=dashed];
"291 bert/encoder/layer_6/attention/self/Reshape_2__387" -> "980 bert/encoder/layer_6/attention/self/Reshape_2"  [label="[4]", style=dashed];
"292 bert/encoder/layer_6/attention/self/Reshape_1/shape_Unsqueeze__144" -> "293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148"  [label="[1]", style=dashed];
"293 bert/encoder/layer_6/attention/self/Reshape_1/shape_Concat__148" -> "294 bert/encoder/layer_6/attention/self/Reshape_1__389"  [label="[4]", style=dashed];
"294 bert/encoder/layer_6/attention/self/Reshape_1__389" -> "996 bert/encoder/layer_6/attention/self/Reshape_1"  [label="[4]", style=dashed];
"295 bert/encoder/layer_6/attention/self/Reshape/shape_Unsqueeze__149" -> "296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153"  [label="[1]", style=dashed];
"296 bert/encoder/layer_6/attention/self/Reshape/shape_Concat__153" -> "297 bert/encoder/layer_6/attention/self/Reshape__388"  [label="[4]", style=dashed];
"297 bert/encoder/layer_6/attention/self/Reshape__388" -> "988 bert/encoder/layer_6/attention/self/Reshape"  [label="[4]", style=dashed];
"298 bert/encoder/layer_5/attention/self/mul_2" -> "299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154"  [label="[]", style=dashed];
"299 bert/encoder/layer_5/attention/self/Reshape_3/shape_Unsqueeze__154" -> "300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156"  [label="[1]", style=dashed];
"300 bert/encoder/layer_5/attention/self/Reshape_3/shape_Concat__156" -> "301 bert/encoder/layer_5/attention/self/Reshape_3__378"  [label="[2]", style=dashed];
"301 bert/encoder/layer_5/attention/self/Reshape_3__378" -> "913 bert/encoder/layer_5/attention/self/Reshape_3"  [label="[2]", style=dashed];
"302 bert/encoder/layer_5/attention/self/Reshape_2/shape_Unsqueeze__157" -> "303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161"  [label="[1]", style=dashed];
"303 bert/encoder/layer_5/attention/self/Reshape_2/shape_Concat__161" -> "304 bert/encoder/layer_5/attention/self/Reshape_2__373"  [label="[4]", style=dashed];
"304 bert/encoder/layer_5/attention/self/Reshape_2__373" -> "886 bert/encoder/layer_5/attention/self/Reshape_2"  [label="[4]", style=dashed];
"305 bert/encoder/layer_5/attention/self/Reshape_1/shape_Unsqueeze__162" -> "306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166"  [label="[1]", style=dashed];
"306 bert/encoder/layer_5/attention/self/Reshape_1/shape_Concat__166" -> "307 bert/encoder/layer_5/attention/self/Reshape_1__375"  [label="[4]", style=dashed];
"307 bert/encoder/layer_5/attention/self/Reshape_1__375" -> "902 bert/encoder/layer_5/attention/self/Reshape_1"  [label="[4]", style=dashed];
"308 bert/encoder/layer_5/attention/self/Reshape/shape_Unsqueeze__167" -> "309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171"  [label="[1]", style=dashed];
"309 bert/encoder/layer_5/attention/self/Reshape/shape_Concat__171" -> "310 bert/encoder/layer_5/attention/self/Reshape__374"  [label="[4]", style=dashed];
"310 bert/encoder/layer_5/attention/self/Reshape__374" -> "894 bert/encoder/layer_5/attention/self/Reshape"  [label="[4]", style=dashed];
"311 bert/encoder/layer_4/attention/self/mul_2" -> "312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172"  [label="[]", style=dashed];
"312 bert/encoder/layer_4/attention/self/Reshape_3/shape_Unsqueeze__172" -> "313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174"  [label="[1]", style=dashed];
"313 bert/encoder/layer_4/attention/self/Reshape_3/shape_Concat__174" -> "314 bert/encoder/layer_4/attention/self/Reshape_3__364"  [label="[2]", style=dashed];
"314 bert/encoder/layer_4/attention/self/Reshape_3__364" -> "819 bert/encoder/layer_4/attention/self/Reshape_3"  [label="[2]", style=dashed];
"315 bert/encoder/layer_4/attention/self/Reshape_2/shape_Unsqueeze__175" -> "316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179"  [label="[1]", style=dashed];
"316 bert/encoder/layer_4/attention/self/Reshape_2/shape_Concat__179" -> "317 bert/encoder/layer_4/attention/self/Reshape_2__359"  [label="[4]", style=dashed];
"317 bert/encoder/layer_4/attention/self/Reshape_2__359" -> "792 bert/encoder/layer_4/attention/self/Reshape_2"  [label="[4]", style=dashed];
"318 bert/encoder/layer_4/attention/self/Reshape_1/shape_Unsqueeze__180" -> "319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184"  [label="[1]", style=dashed];
"319 bert/encoder/layer_4/attention/self/Reshape_1/shape_Concat__184" -> "320 bert/encoder/layer_4/attention/self/Reshape_1__361"  [label="[4]", style=dashed];
"320 bert/encoder/layer_4/attention/self/Reshape_1__361" -> "808 bert/encoder/layer_4/attention/self/Reshape_1"  [label="[4]", style=dashed];
"321 bert/encoder/layer_4/attention/self/Reshape/shape_Unsqueeze__185" -> "322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189"  [label="[1]", style=dashed];
"322 bert/encoder/layer_4/attention/self/Reshape/shape_Concat__189" -> "323 bert/encoder/layer_4/attention/self/Reshape__360"  [label="[4]", style=dashed];
"323 bert/encoder/layer_4/attention/self/Reshape__360" -> "800 bert/encoder/layer_4/attention/self/Reshape"  [label="[4]", style=dashed];
"324 bert/encoder/layer_3/attention/self/mul_2" -> "325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190"  [label="[]", style=dashed];
"325 bert/encoder/layer_3/attention/self/Reshape_3/shape_Unsqueeze__190" -> "326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192"  [label="[1]", style=dashed];
"326 bert/encoder/layer_3/attention/self/Reshape_3/shape_Concat__192" -> "327 bert/encoder/layer_3/attention/self/Reshape_3__350"  [label="[2]", style=dashed];
"327 bert/encoder/layer_3/attention/self/Reshape_3__350" -> "725 bert/encoder/layer_3/attention/self/Reshape_3"  [label="[2]", style=dashed];
"328 bert/encoder/layer_3/attention/self/Reshape_2/shape_Unsqueeze__193" -> "329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197"  [label="[1]", style=dashed];
"329 bert/encoder/layer_3/attention/self/Reshape_2/shape_Concat__197" -> "330 bert/encoder/layer_3/attention/self/Reshape_2__345"  [label="[4]", style=dashed];
"330 bert/encoder/layer_3/attention/self/Reshape_2__345" -> "698 bert/encoder/layer_3/attention/self/Reshape_2"  [label="[4]", style=dashed];
"331 bert/encoder/layer_3/attention/self/Reshape_1/shape_Unsqueeze__198" -> "332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202"  [label="[1]", style=dashed];
"332 bert/encoder/layer_3/attention/self/Reshape_1/shape_Concat__202" -> "333 bert/encoder/layer_3/attention/self/Reshape_1__347"  [label="[4]", style=dashed];
"333 bert/encoder/layer_3/attention/self/Reshape_1__347" -> "714 bert/encoder/layer_3/attention/self/Reshape_1"  [label="[4]", style=dashed];
"334 bert/encoder/layer_3/attention/self/Reshape/shape_Unsqueeze__203" -> "335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207"  [label="[1]", style=dashed];
"335 bert/encoder/layer_3/attention/self/Reshape/shape_Concat__207" -> "336 bert/encoder/layer_3/attention/self/Reshape__346"  [label="[4]", style=dashed];
"336 bert/encoder/layer_3/attention/self/Reshape__346" -> "706 bert/encoder/layer_3/attention/self/Reshape"  [label="[4]", style=dashed];
"337 bert/encoder/layer_2/attention/self/mul_2" -> "338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208"  [label="[]", style=dashed];
"338 bert/encoder/layer_2/attention/self/Reshape_3/shape_Unsqueeze__208" -> "339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210"  [label="[1]", style=dashed];
"339 bert/encoder/layer_2/attention/self/Reshape_3/shape_Concat__210" -> "340 bert/encoder/layer_2/attention/self/Reshape_3__336"  [label="[2]", style=dashed];
"340 bert/encoder/layer_2/attention/self/Reshape_3__336" -> "631 bert/encoder/layer_2/attention/self/Reshape_3"  [label="[2]", style=dashed];
"341 bert/encoder/layer_2/attention/self/Reshape_2/shape_Unsqueeze__211" -> "342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215"  [label="[1]", style=dashed];
"342 bert/encoder/layer_2/attention/self/Reshape_2/shape_Concat__215" -> "343 bert/encoder/layer_2/attention/self/Reshape_2__331"  [label="[4]", style=dashed];
"343 bert/encoder/layer_2/attention/self/Reshape_2__331" -> "604 bert/encoder/layer_2/attention/self/Reshape_2"  [label="[4]", style=dashed];
"344 bert/encoder/layer_2/attention/self/Reshape_1/shape_Unsqueeze__216" -> "345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220"  [label="[1]", style=dashed];
"345 bert/encoder/layer_2/attention/self/Reshape_1/shape_Concat__220" -> "346 bert/encoder/layer_2/attention/self/Reshape_1__333"  [label="[4]", style=dashed];
"346 bert/encoder/layer_2/attention/self/Reshape_1__333" -> "620 bert/encoder/layer_2/attention/self/Reshape_1"  [label="[4]", style=dashed];
"347 bert/encoder/layer_2/attention/self/Reshape/shape_Unsqueeze__221" -> "348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225"  [label="[1]", style=dashed];
"348 bert/encoder/layer_2/attention/self/Reshape/shape_Concat__225" -> "349 bert/encoder/layer_2/attention/self/Reshape__332"  [label="[4]", style=dashed];
"349 bert/encoder/layer_2/attention/self/Reshape__332" -> "612 bert/encoder/layer_2/attention/self/Reshape"  [label="[4]", style=dashed];
"350 bert/encoder/layer_11/attention/self/mul_2" -> "351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226"  [label="[]", style=dashed];
"351 bert/encoder/layer_11/attention/self/Reshape_3/shape_Unsqueeze__226" -> "352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228"  [label="[1]", style=dashed];
"352 bert/encoder/layer_11/attention/self/Reshape_3/shape_Concat__228" -> "353 bert/encoder/layer_11/attention/self/Reshape_3__462"  [label="[2]", style=dashed];
"353 bert/encoder/layer_11/attention/self/Reshape_3__462" -> "1477 bert/encoder/layer_11/attention/self/Reshape_3"  [label="[2]", style=dashed];
"354 bert/encoder/layer_11/attention/self/Reshape_2/shape_Unsqueeze__229" -> "355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233"  [label="[1]", style=dashed];
"355 bert/encoder/layer_11/attention/self/Reshape_2/shape_Concat__233" -> "356 bert/encoder/layer_11/attention/self/Reshape_2__457"  [label="[4]", style=dashed];
"356 bert/encoder/layer_11/attention/self/Reshape_2__457" -> "1450 bert/encoder/layer_11/attention/self/Reshape_2"  [label="[4]", style=dashed];
"357 bert/encoder/layer_11/attention/self/Reshape_1/shape_Unsqueeze__234" -> "358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238"  [label="[1]", style=dashed];
"358 bert/encoder/layer_11/attention/self/Reshape_1/shape_Concat__238" -> "359 bert/encoder/layer_11/attention/self/Reshape_1__459"  [label="[4]", style=dashed];
"359 bert/encoder/layer_11/attention/self/Reshape_1__459" -> "1466 bert/encoder/layer_11/attention/self/Reshape_1"  [label="[4]", style=dashed];
"360 bert/encoder/layer_11/attention/self/Reshape/shape_Unsqueeze__239" -> "361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243"  [label="[1]", style=dashed];
"361 bert/encoder/layer_11/attention/self/Reshape/shape_Concat__243" -> "362 bert/encoder/layer_11/attention/self/Reshape__458"  [label="[4]", style=dashed];
"362 bert/encoder/layer_11/attention/self/Reshape__458" -> "1458 bert/encoder/layer_11/attention/self/Reshape"  [label="[4]", style=dashed];
"363 bert/encoder/layer_10/attention/self/mul_2" -> "364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244"  [label="[]", style=dashed];
"364 bert/encoder/layer_10/attention/self/Reshape_3/shape_Unsqueeze__244" -> "365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246"  [label="[1]", style=dashed];
"365 bert/encoder/layer_10/attention/self/Reshape_3/shape_Concat__246" -> "366 bert/encoder/layer_10/attention/self/Reshape_3__448"  [label="[2]", style=dashed];
"366 bert/encoder/layer_10/attention/self/Reshape_3__448" -> "1383 bert/encoder/layer_10/attention/self/Reshape_3"  [label="[2]", style=dashed];
"367 bert/encoder/layer_10/attention/self/Reshape_2/shape_Unsqueeze__247" -> "368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251"  [label="[1]", style=dashed];
"368 bert/encoder/layer_10/attention/self/Reshape_2/shape_Concat__251" -> "369 bert/encoder/layer_10/attention/self/Reshape_2__443"  [label="[4]", style=dashed];
"369 bert/encoder/layer_10/attention/self/Reshape_2__443" -> "1356 bert/encoder/layer_10/attention/self/Reshape_2"  [label="[4]", style=dashed];
"370 bert/encoder/layer_10/attention/self/Reshape_1/shape_Unsqueeze__252" -> "371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256"  [label="[1]", style=dashed];
"371 bert/encoder/layer_10/attention/self/Reshape_1/shape_Concat__256" -> "372 bert/encoder/layer_10/attention/self/Reshape_1__445"  [label="[4]", style=dashed];
"372 bert/encoder/layer_10/attention/self/Reshape_1__445" -> "1372 bert/encoder/layer_10/attention/self/Reshape_1"  [label="[4]", style=dashed];
"373 bert/encoder/layer_10/attention/self/Reshape/shape_Unsqueeze__257" -> "374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261"  [label="[1]", style=dashed];
"374 bert/encoder/layer_10/attention/self/Reshape/shape_Concat__261" -> "375 bert/encoder/layer_10/attention/self/Reshape__444"  [label="[4]", style=dashed];
"375 bert/encoder/layer_10/attention/self/Reshape__444" -> "1364 bert/encoder/layer_10/attention/self/Reshape"  [label="[4]", style=dashed];
"376 bert/encoder/layer_1/attention/self/mul_2" -> "377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262"  [label="[]", style=dashed];
"377 bert/encoder/layer_1/attention/self/Reshape_3/shape_Unsqueeze__262" -> "378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264"  [label="[1]", style=dashed];
"378 bert/encoder/layer_1/attention/self/Reshape_3/shape_Concat__264" -> "379 bert/encoder/layer_1/attention/self/Reshape_3__322"  [label="[2]", style=dashed];
"379 bert/encoder/layer_1/attention/self/Reshape_3__322" -> "537 bert/encoder/layer_1/attention/self/Reshape_3"  [label="[2]", style=dashed];
"380 bert/encoder/layer_1/attention/self/Reshape_2/shape_Unsqueeze__265" -> "381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269"  [label="[1]", style=dashed];
"381 bert/encoder/layer_1/attention/self/Reshape_2/shape_Concat__269" -> "382 bert/encoder/layer_1/attention/self/Reshape_2__317"  [label="[4]", style=dashed];
"382 bert/encoder/layer_1/attention/self/Reshape_2__317" -> "510 bert/encoder/layer_1/attention/self/Reshape_2"  [label="[4]", style=dashed];
"383 bert/encoder/layer_1/attention/self/Reshape_1/shape_Unsqueeze__270" -> "384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274"  [label="[1]", style=dashed];
"384 bert/encoder/layer_1/attention/self/Reshape_1/shape_Concat__274" -> "385 bert/encoder/layer_1/attention/self/Reshape_1__319"  [label="[4]", style=dashed];
"385 bert/encoder/layer_1/attention/self/Reshape_1__319" -> "526 bert/encoder/layer_1/attention/self/Reshape_1"  [label="[4]", style=dashed];
"386 bert/encoder/layer_1/attention/self/Reshape/shape_Unsqueeze__275" -> "387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279"  [label="[1]", style=dashed];
"387 bert/encoder/layer_1/attention/self/Reshape/shape_Concat__279" -> "388 bert/encoder/layer_1/attention/self/Reshape__318"  [label="[4]", style=dashed];
"388 bert/encoder/layer_1/attention/self/Reshape__318" -> "518 bert/encoder/layer_1/attention/self/Reshape"  [label="[4]", style=dashed];
"389 bert/encoder/layer_0/attention/self/mul_2" -> "390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280"  [label="[]", style=dashed];
"390 bert/encoder/layer_0/attention/self/Reshape_3/shape_Unsqueeze__280" -> "391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282"  [label="[1]", style=dashed];
"391 bert/encoder/layer_0/attention/self/Reshape_3/shape_Concat__282" -> "392 bert/encoder/layer_0/attention/self/Reshape_3__308"  [label="[2]", style=dashed];
"392 bert/encoder/layer_0/attention/self/Reshape_3__308" -> "443 bert/encoder/layer_0/attention/self/Reshape_3"  [label="[2]", style=dashed];
"393 bert/encoder/layer_0/attention/self/Reshape_2/shape_Unsqueeze__283" -> "394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287"  [label="[1]", style=dashed];
"394 bert/encoder/layer_0/attention/self/Reshape_2/shape_Concat__287" -> "395 bert/encoder/layer_0/attention/self/Reshape_2__303"  [label="[4]", style=dashed];
"395 bert/encoder/layer_0/attention/self/Reshape_2__303" -> "416 bert/encoder/layer_0/attention/self/Reshape_2"  [label="[4]", style=dashed];
"396 bert/encoder/layer_0/attention/self/Reshape_1/shape_Unsqueeze__288" -> "397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292"  [label="[1]", style=dashed];
"397 bert/encoder/layer_0/attention/self/Reshape_1/shape_Concat__292" -> "398 bert/encoder/layer_0/attention/self/Reshape_1__305"  [label="[4]", style=dashed];
"398 bert/encoder/layer_0/attention/self/Reshape_1__305" -> "432 bert/encoder/layer_0/attention/self/Reshape_1"  [label="[4]", style=dashed];
"399 bert/encoder/layer_0/attention/self/Reshape/shape_Unsqueeze__293" -> "400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297"  [label="[1]", style=dashed];
"400 bert/encoder/layer_0/attention/self/Reshape/shape_Concat__297" -> "401 bert/encoder/layer_0/attention/self/Reshape__304"  [label="[4]", style=dashed];
"401 bert/encoder/layer_0/attention/self/Reshape__304" -> "424 bert/encoder/layer_0/attention/self/Reshape"  [label="[4]", style=dashed];
"402 bert/encoder/Reshape_13/shape_Unsqueeze__298" -> "403 bert/encoder/Reshape_13/shape_Concat__301"  [label="[1]", style=dashed];
"403 bert/encoder/Reshape_13/shape_Concat__301" -> "404 bert/encoder/Reshape_13__471"  [label="[3]", style=dashed];
"404 bert/encoder/Reshape_13__471" -> "1536 bert/encoder/Reshape_13"  [label="[3]", style=dashed];
"405 bert/encoder/Reshape_1" -> "406 QuantizeLinear_bert/encoder/Reshape_1^0_3"  [label="[]", style=solid];
"405 bert/encoder/Reshape_1" -> "408 QuantizeLinear_bert/encoder/Reshape_1^0_2"  [label="[]", style=solid];
"405 bert/encoder/Reshape_1" -> "410 QuantizeLinear_bert/encoder/Reshape_1^0_1"  [label="[]", style=solid];
"405 bert/encoder/Reshape_1" -> "448 bert/encoder/layer_0/attention/output/add"  [label="[]", style=solid];
"406 QuantizeLinear_bert/encoder/Reshape_1^0_3" -> "407 DequantizeLinear_bert/encoder/Reshape_1^0_3"  [label="[]", style=dashed];
"407 DequantizeLinear_bert/encoder/Reshape_1^0_3" -> "428 bert/encoder/layer_0/attention/self/key/MatMul"  [label="[]", style=solid];
"408 QuantizeLinear_bert/encoder/Reshape_1^0_2" -> "409 DequantizeLinear_bert/encoder/Reshape_1^0_2"  [label="[]", style=dashed];
"409 DequantizeLinear_bert/encoder/Reshape_1^0_2" -> "420 bert/encoder/layer_0/attention/self/query/MatMul"  [label="[]", style=solid];
"410 QuantizeLinear_bert/encoder/Reshape_1^0_1" -> "411 DequantizeLinear_bert/encoder/Reshape_1^0_1"  [label="[]", style=dashed];
"411 DequantizeLinear_bert/encoder/Reshape_1^0_1" -> "414 bert/encoder/layer_0/attention/self/value/MatMul"  [label="[]", style=solid];
"412 QuantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "413 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"413 DequantizeLinear_bert/encoder/layer_0/attention/self/value/kernel^0_1" -> "414 bert/encoder/layer_0/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"414 bert/encoder/layer_0/attention/self/value/MatMul" -> "415 bert/encoder/layer_0/attention/self/value/BiasAdd"  [label="[]", style=solid];
"415 bert/encoder/layer_0/attention/self/value/BiasAdd" -> "416 bert/encoder/layer_0/attention/self/Reshape_2"  [label="[]", style=solid];
"416 bert/encoder/layer_0/attention/self/Reshape_2" -> "417 bert/encoder/layer_0/attention/self/transpose_2"  [label="[]", style=solid];
"417 bert/encoder/layer_0/attention/self/transpose_2" -> "439 bert/encoder/layer_0/attention/self/MatMul_1"  [label="[]", style=solid];
"418 QuantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"419 DequantizeLinear_bert/encoder/layer_0/attention/self/query/kernel^0_1" -> "420 bert/encoder/layer_0/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"420 bert/encoder/layer_0/attention/self/query/MatMul" -> "421 bert/encoder/layer_0/attention/self/query/BiasAdd"  [label="[]", style=solid];
"421 bert/encoder/layer_0/attention/self/query/BiasAdd" -> "422 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"422 QuantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "423 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"423 DequantizeLinear_bert/encoder/layer_0/attention/self/query/BiasAdd^0_1" -> "424 bert/encoder/layer_0/attention/self/Reshape"  [label="[]", style=solid];
"424 bert/encoder/layer_0/attention/self/Reshape" -> "425 bert/encoder/layer_0/attention/self/transpose"  [label="[]", style=solid];
"425 bert/encoder/layer_0/attention/self/transpose" -> "435 bert/encoder/layer_0/attention/self/MatMul"  [label="[]", style=solid];
"426 QuantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"427 DequantizeLinear_bert/encoder/layer_0/attention/self/key/kernel^0_1" -> "428 bert/encoder/layer_0/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"428 bert/encoder/layer_0/attention/self/key/MatMul" -> "429 bert/encoder/layer_0/attention/self/key/BiasAdd"  [label="[]", style=solid];
"429 bert/encoder/layer_0/attention/self/key/BiasAdd" -> "430 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"430 QuantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "431 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"431 DequantizeLinear_bert/encoder/layer_0/attention/self/key/BiasAdd^0_1" -> "432 bert/encoder/layer_0/attention/self/Reshape_1"  [label="[]", style=solid];
"432 bert/encoder/layer_0/attention/self/Reshape_1" -> "433 bert/encoder/layer_0/attention/self/transpose_1"  [label="[]", style=solid];
"433 bert/encoder/layer_0/attention/self/transpose_1" -> "434 bert/encoder/layer_0/attention/self/MatMul__306"  [label="[]", style=solid];
"434 bert/encoder/layer_0/attention/self/MatMul__306" -> "435 bert/encoder/layer_0/attention/self/MatMul"  [label="[]", style=solid];
"435 bert/encoder/layer_0/attention/self/MatMul" -> "436 bert/encoder/layer_0/attention/self/Mul"  [label="[]", style=solid];
"436 bert/encoder/layer_0/attention/self/Mul" -> "437 bert/encoder/layer_0/attention/self/add"  [label="[]", style=solid];
"437 bert/encoder/layer_0/attention/self/add" -> "438 bert/encoder/layer_0/attention/self/Softmax"  [label="[]", style=solid];
"438 bert/encoder/layer_0/attention/self/Softmax" -> "439 bert/encoder/layer_0/attention/self/MatMul_1"  [label="[]", style=solid];
"439 bert/encoder/layer_0/attention/self/MatMul_1" -> "440 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"440 QuantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "441 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"441 DequantizeLinear_bert/encoder/layer_0/attention/self/MatMul_1^0_1" -> "442 bert/encoder/layer_0/attention/self/transpose_3"  [label="[]", style=solid];
"442 bert/encoder/layer_0/attention/self/transpose_3" -> "443 bert/encoder/layer_0/attention/self/Reshape_3"  [label="[]", style=solid];
"443 bert/encoder/layer_0/attention/self/Reshape_3" -> "446 bert/encoder/layer_0/attention/output/dense/MatMul"  [label="[]", style=solid];
"444 QuantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "445 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"445 DequantizeLinear_bert/encoder/layer_0/attention/output/dense/kernel^0_1" -> "446 bert/encoder/layer_0/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"446 bert/encoder/layer_0/attention/output/dense/MatMul" -> "447 bert/encoder/layer_0/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"447 bert/encoder/layer_0/attention/output/dense/BiasAdd" -> "448 bert/encoder/layer_0/attention/output/add"  [label="[]", style=solid];
"448 bert/encoder/layer_0/attention/output/add" -> "449 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"448 bert/encoder/layer_0/attention/output/add" -> "451 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"448 bert/encoder/layer_0/attention/output/add" -> "462 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "450 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"449 bert/encoder/layer_0/attention/output/LayerNorm/moments/mean" -> "460 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"450 bert/encoder/layer_0/attention/output/LayerNorm/moments/StopGradient" -> "451 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"451 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference" -> "452 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309"  [label="[]", style=solid];
"452 bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__309" -> "453 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"453 bert/encoder/layer_0/attention/output/LayerNorm/moments/variance" -> "454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"454 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add" -> "455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"455 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt" -> "456 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"456 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "457 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"457 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311"  [label="[]", style=solid];
"458 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__311" -> "459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "460 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"459 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul" -> "462 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"460 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2" -> "461 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"461 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub" -> "463 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"462 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1" -> "463 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"463 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "464 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"463 bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1" -> "484 bert/encoder/layer_0/output/add"  [label="[]", style=solid];
"464 QuantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "465 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"465 DequantizeLinear_bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "468 bert/encoder/layer_0/intermediate/dense/MatMul"  [label="[]", style=solid];
"466 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "467 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"467 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/kernel^0_1" -> "468 bert/encoder/layer_0/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"468 bert/encoder/layer_0/intermediate/dense/MatMul" -> "469 bert/encoder/layer_0/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"469 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "470 bert/encoder/layer_0/intermediate/dense/Pow"  [label="[]", style=solid];
"469 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "472 bert/encoder/layer_0/intermediate/dense/add"  [label="[]", style=solid];
"469 bert/encoder/layer_0/intermediate/dense/BiasAdd" -> "477 bert/encoder/layer_0/intermediate/dense/mul_3"  [label="[]", style=solid];
"470 bert/encoder/layer_0/intermediate/dense/Pow" -> "471 bert/encoder/layer_0/intermediate/dense/mul"  [label="[]", style=solid];
"471 bert/encoder/layer_0/intermediate/dense/mul" -> "472 bert/encoder/layer_0/intermediate/dense/add"  [label="[]", style=solid];
"472 bert/encoder/layer_0/intermediate/dense/add" -> "473 bert/encoder/layer_0/intermediate/dense/mul_1"  [label="[]", style=solid];
"473 bert/encoder/layer_0/intermediate/dense/mul_1" -> "474 bert/encoder/layer_0/intermediate/dense/Tanh"  [label="[]", style=solid];
"474 bert/encoder/layer_0/intermediate/dense/Tanh" -> "475 bert/encoder/layer_0/intermediate/dense/add_1"  [label="[]", style=solid];
"475 bert/encoder/layer_0/intermediate/dense/add_1" -> "476 bert/encoder/layer_0/intermediate/dense/mul_2"  [label="[]", style=solid];
"476 bert/encoder/layer_0/intermediate/dense/mul_2" -> "477 bert/encoder/layer_0/intermediate/dense/mul_3"  [label="[]", style=solid];
"477 bert/encoder/layer_0/intermediate/dense/mul_3" -> "478 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"478 QuantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "479 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"479 DequantizeLinear_bert/encoder/layer_0/intermediate/dense/mul_3^0_1" -> "482 bert/encoder/layer_0/output/dense/MatMul"  [label="[]", style=solid];
"480 QuantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "481 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"481 DequantizeLinear_bert/encoder/layer_0/output/dense/kernel^0_1" -> "482 bert/encoder/layer_0/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"482 bert/encoder/layer_0/output/dense/MatMul" -> "483 bert/encoder/layer_0/output/dense/BiasAdd"  [label="[]", style=solid];
"483 bert/encoder/layer_0/output/dense/BiasAdd" -> "484 bert/encoder/layer_0/output/add"  [label="[]", style=solid];
"484 bert/encoder/layer_0/output/add" -> "485 bert/encoder/layer_0/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"484 bert/encoder/layer_0/output/add" -> "487 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"484 bert/encoder/layer_0/output/add" -> "498 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"485 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "486 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"485 bert/encoder/layer_0/output/LayerNorm/moments/mean" -> "496 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"486 bert/encoder/layer_0/output/LayerNorm/moments/StopGradient" -> "487 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"487 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference" -> "488 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313"  [label="[]", style=solid];
"488 bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__313" -> "489 bert/encoder/layer_0/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"489 bert/encoder/layer_0/output/LayerNorm/moments/variance" -> "490 bert/encoder/layer_0/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"490 bert/encoder/layer_0/output/LayerNorm/batchnorm/add" -> "491 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"491 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt" -> "492 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"492 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "493 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"493 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "494 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315"  [label="[]", style=solid];
"494 bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__315" -> "495 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"495 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "496 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"495 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul" -> "498 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"496 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2" -> "497 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"497 bert/encoder/layer_0/output/LayerNorm/batchnorm/sub" -> "499 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"498 bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1" -> "499 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"499 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "500 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"499 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "502 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"499 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "504 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"499 bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1" -> "542 bert/encoder/layer_1/attention/output/add"  [label="[]", style=solid];
"500 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "501 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"501 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_3" -> "522 bert/encoder/layer_1/attention/self/key/MatMul"  [label="[]", style=solid];
"502 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "503 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"503 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_2" -> "514 bert/encoder/layer_1/attention/self/query/MatMul"  [label="[]", style=solid];
"504 QuantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "505 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"505 DequantizeLinear_bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1^0_1" -> "508 bert/encoder/layer_1/attention/self/value/MatMul"  [label="[]", style=solid];
"506 QuantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "507 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"507 DequantizeLinear_bert/encoder/layer_1/attention/self/value/kernel^0_1" -> "508 bert/encoder/layer_1/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"508 bert/encoder/layer_1/attention/self/value/MatMul" -> "509 bert/encoder/layer_1/attention/self/value/BiasAdd"  [label="[]", style=solid];
"509 bert/encoder/layer_1/attention/self/value/BiasAdd" -> "510 bert/encoder/layer_1/attention/self/Reshape_2"  [label="[]", style=solid];
"510 bert/encoder/layer_1/attention/self/Reshape_2" -> "511 bert/encoder/layer_1/attention/self/transpose_2"  [label="[]", style=solid];
"511 bert/encoder/layer_1/attention/self/transpose_2" -> "533 bert/encoder/layer_1/attention/self/MatMul_1"  [label="[]", style=solid];
"512 QuantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "513 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"513 DequantizeLinear_bert/encoder/layer_1/attention/self/query/kernel^0_1" -> "514 bert/encoder/layer_1/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"514 bert/encoder/layer_1/attention/self/query/MatMul" -> "515 bert/encoder/layer_1/attention/self/query/BiasAdd"  [label="[]", style=solid];
"515 bert/encoder/layer_1/attention/self/query/BiasAdd" -> "516 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"516 QuantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "517 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"517 DequantizeLinear_bert/encoder/layer_1/attention/self/query/BiasAdd^0_1" -> "518 bert/encoder/layer_1/attention/self/Reshape"  [label="[]", style=solid];
"518 bert/encoder/layer_1/attention/self/Reshape" -> "519 bert/encoder/layer_1/attention/self/transpose"  [label="[]", style=solid];
"519 bert/encoder/layer_1/attention/self/transpose" -> "529 bert/encoder/layer_1/attention/self/MatMul"  [label="[]", style=solid];
"520 QuantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "521 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"521 DequantizeLinear_bert/encoder/layer_1/attention/self/key/kernel^0_1" -> "522 bert/encoder/layer_1/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"522 bert/encoder/layer_1/attention/self/key/MatMul" -> "523 bert/encoder/layer_1/attention/self/key/BiasAdd"  [label="[]", style=solid];
"523 bert/encoder/layer_1/attention/self/key/BiasAdd" -> "524 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"524 QuantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "525 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"525 DequantizeLinear_bert/encoder/layer_1/attention/self/key/BiasAdd^0_1" -> "526 bert/encoder/layer_1/attention/self/Reshape_1"  [label="[]", style=solid];
"526 bert/encoder/layer_1/attention/self/Reshape_1" -> "527 bert/encoder/layer_1/attention/self/transpose_1"  [label="[]", style=solid];
"527 bert/encoder/layer_1/attention/self/transpose_1" -> "528 bert/encoder/layer_1/attention/self/MatMul__320"  [label="[]", style=solid];
"528 bert/encoder/layer_1/attention/self/MatMul__320" -> "529 bert/encoder/layer_1/attention/self/MatMul"  [label="[]", style=solid];
"529 bert/encoder/layer_1/attention/self/MatMul" -> "530 bert/encoder/layer_1/attention/self/Mul"  [label="[]", style=solid];
"530 bert/encoder/layer_1/attention/self/Mul" -> "531 bert/encoder/layer_1/attention/self/add"  [label="[]", style=solid];
"531 bert/encoder/layer_1/attention/self/add" -> "532 bert/encoder/layer_1/attention/self/Softmax"  [label="[]", style=solid];
"532 bert/encoder/layer_1/attention/self/Softmax" -> "533 bert/encoder/layer_1/attention/self/MatMul_1"  [label="[]", style=solid];
"533 bert/encoder/layer_1/attention/self/MatMul_1" -> "534 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"534 QuantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "535 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"535 DequantizeLinear_bert/encoder/layer_1/attention/self/MatMul_1^0_1" -> "536 bert/encoder/layer_1/attention/self/transpose_3"  [label="[]", style=solid];
"536 bert/encoder/layer_1/attention/self/transpose_3" -> "537 bert/encoder/layer_1/attention/self/Reshape_3"  [label="[]", style=solid];
"537 bert/encoder/layer_1/attention/self/Reshape_3" -> "540 bert/encoder/layer_1/attention/output/dense/MatMul"  [label="[]", style=solid];
"538 QuantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "539 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"539 DequantizeLinear_bert/encoder/layer_1/attention/output/dense/kernel^0_1" -> "540 bert/encoder/layer_1/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"540 bert/encoder/layer_1/attention/output/dense/MatMul" -> "541 bert/encoder/layer_1/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"541 bert/encoder/layer_1/attention/output/dense/BiasAdd" -> "542 bert/encoder/layer_1/attention/output/add"  [label="[]", style=solid];
"542 bert/encoder/layer_1/attention/output/add" -> "543 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"542 bert/encoder/layer_1/attention/output/add" -> "545 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"542 bert/encoder/layer_1/attention/output/add" -> "556 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"543 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "544 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"543 bert/encoder/layer_1/attention/output/LayerNorm/moments/mean" -> "554 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"544 bert/encoder/layer_1/attention/output/LayerNorm/moments/StopGradient" -> "545 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"545 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference" -> "546 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323"  [label="[]", style=solid];
"546 bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__323" -> "547 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"547 bert/encoder/layer_1/attention/output/LayerNorm/moments/variance" -> "548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"548 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add" -> "549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"549 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt" -> "550 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"550 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "551 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"551 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "552 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325"  [label="[]", style=solid];
"552 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__325" -> "553 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"553 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "554 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"553 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul" -> "556 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"554 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2" -> "555 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"555 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub" -> "557 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"556 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1" -> "557 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"557 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "558 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"557 bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1" -> "578 bert/encoder/layer_1/output/add"  [label="[]", style=solid];
"558 QuantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "559 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"559 DequantizeLinear_bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "562 bert/encoder/layer_1/intermediate/dense/MatMul"  [label="[]", style=solid];
"560 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "561 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"561 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/kernel^0_1" -> "562 bert/encoder/layer_1/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"562 bert/encoder/layer_1/intermediate/dense/MatMul" -> "563 bert/encoder/layer_1/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"563 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "564 bert/encoder/layer_1/intermediate/dense/Pow"  [label="[]", style=solid];
"563 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "566 bert/encoder/layer_1/intermediate/dense/add"  [label="[]", style=solid];
"563 bert/encoder/layer_1/intermediate/dense/BiasAdd" -> "571 bert/encoder/layer_1/intermediate/dense/mul_3"  [label="[]", style=solid];
"564 bert/encoder/layer_1/intermediate/dense/Pow" -> "565 bert/encoder/layer_1/intermediate/dense/mul"  [label="[]", style=solid];
"565 bert/encoder/layer_1/intermediate/dense/mul" -> "566 bert/encoder/layer_1/intermediate/dense/add"  [label="[]", style=solid];
"566 bert/encoder/layer_1/intermediate/dense/add" -> "567 bert/encoder/layer_1/intermediate/dense/mul_1"  [label="[]", style=solid];
"567 bert/encoder/layer_1/intermediate/dense/mul_1" -> "568 bert/encoder/layer_1/intermediate/dense/Tanh"  [label="[]", style=solid];
"568 bert/encoder/layer_1/intermediate/dense/Tanh" -> "569 bert/encoder/layer_1/intermediate/dense/add_1"  [label="[]", style=solid];
"569 bert/encoder/layer_1/intermediate/dense/add_1" -> "570 bert/encoder/layer_1/intermediate/dense/mul_2"  [label="[]", style=solid];
"570 bert/encoder/layer_1/intermediate/dense/mul_2" -> "571 bert/encoder/layer_1/intermediate/dense/mul_3"  [label="[]", style=solid];
"571 bert/encoder/layer_1/intermediate/dense/mul_3" -> "572 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"572 QuantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "573 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"573 DequantizeLinear_bert/encoder/layer_1/intermediate/dense/mul_3^0_1" -> "576 bert/encoder/layer_1/output/dense/MatMul"  [label="[]", style=solid];
"574 QuantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "575 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"575 DequantizeLinear_bert/encoder/layer_1/output/dense/kernel^0_1" -> "576 bert/encoder/layer_1/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"576 bert/encoder/layer_1/output/dense/MatMul" -> "577 bert/encoder/layer_1/output/dense/BiasAdd"  [label="[]", style=solid];
"577 bert/encoder/layer_1/output/dense/BiasAdd" -> "578 bert/encoder/layer_1/output/add"  [label="[]", style=solid];
"578 bert/encoder/layer_1/output/add" -> "579 bert/encoder/layer_1/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"578 bert/encoder/layer_1/output/add" -> "581 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"578 bert/encoder/layer_1/output/add" -> "592 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"579 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "580 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"579 bert/encoder/layer_1/output/LayerNorm/moments/mean" -> "590 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"580 bert/encoder/layer_1/output/LayerNorm/moments/StopGradient" -> "581 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"581 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference" -> "582 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327"  [label="[]", style=solid];
"582 bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__327" -> "583 bert/encoder/layer_1/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"583 bert/encoder/layer_1/output/LayerNorm/moments/variance" -> "584 bert/encoder/layer_1/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"584 bert/encoder/layer_1/output/LayerNorm/batchnorm/add" -> "585 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"585 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt" -> "586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"586 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"587 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "588 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329"  [label="[]", style=solid];
"588 bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__329" -> "589 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"589 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "590 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"589 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul" -> "592 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"590 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2" -> "591 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"591 bert/encoder/layer_1/output/LayerNorm/batchnorm/sub" -> "593 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"592 bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1" -> "593 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"593 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "594 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"593 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "596 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"593 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "598 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"593 bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1" -> "636 bert/encoder/layer_2/attention/output/add"  [label="[]", style=solid];
"594 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "595 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"595 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_3" -> "616 bert/encoder/layer_2/attention/self/key/MatMul"  [label="[]", style=solid];
"596 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "597 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"597 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_2" -> "608 bert/encoder/layer_2/attention/self/query/MatMul"  [label="[]", style=solid];
"598 QuantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "599 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"599 DequantizeLinear_bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1^0_1" -> "602 bert/encoder/layer_2/attention/self/value/MatMul"  [label="[]", style=solid];
"600 QuantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "601 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"601 DequantizeLinear_bert/encoder/layer_2/attention/self/value/kernel^0_1" -> "602 bert/encoder/layer_2/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"602 bert/encoder/layer_2/attention/self/value/MatMul" -> "603 bert/encoder/layer_2/attention/self/value/BiasAdd"  [label="[]", style=solid];
"603 bert/encoder/layer_2/attention/self/value/BiasAdd" -> "604 bert/encoder/layer_2/attention/self/Reshape_2"  [label="[]", style=solid];
"604 bert/encoder/layer_2/attention/self/Reshape_2" -> "605 bert/encoder/layer_2/attention/self/transpose_2"  [label="[]", style=solid];
"605 bert/encoder/layer_2/attention/self/transpose_2" -> "627 bert/encoder/layer_2/attention/self/MatMul_1"  [label="[]", style=solid];
"606 QuantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "607 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"607 DequantizeLinear_bert/encoder/layer_2/attention/self/query/kernel^0_1" -> "608 bert/encoder/layer_2/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"608 bert/encoder/layer_2/attention/self/query/MatMul" -> "609 bert/encoder/layer_2/attention/self/query/BiasAdd"  [label="[]", style=solid];
"609 bert/encoder/layer_2/attention/self/query/BiasAdd" -> "610 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"610 QuantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "611 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"611 DequantizeLinear_bert/encoder/layer_2/attention/self/query/BiasAdd^0_1" -> "612 bert/encoder/layer_2/attention/self/Reshape"  [label="[]", style=solid];
"612 bert/encoder/layer_2/attention/self/Reshape" -> "613 bert/encoder/layer_2/attention/self/transpose"  [label="[]", style=solid];
"613 bert/encoder/layer_2/attention/self/transpose" -> "623 bert/encoder/layer_2/attention/self/MatMul"  [label="[]", style=solid];
"614 QuantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "615 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"615 DequantizeLinear_bert/encoder/layer_2/attention/self/key/kernel^0_1" -> "616 bert/encoder/layer_2/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"616 bert/encoder/layer_2/attention/self/key/MatMul" -> "617 bert/encoder/layer_2/attention/self/key/BiasAdd"  [label="[]", style=solid];
"617 bert/encoder/layer_2/attention/self/key/BiasAdd" -> "618 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"618 QuantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "619 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"619 DequantizeLinear_bert/encoder/layer_2/attention/self/key/BiasAdd^0_1" -> "620 bert/encoder/layer_2/attention/self/Reshape_1"  [label="[]", style=solid];
"620 bert/encoder/layer_2/attention/self/Reshape_1" -> "621 bert/encoder/layer_2/attention/self/transpose_1"  [label="[]", style=solid];
"621 bert/encoder/layer_2/attention/self/transpose_1" -> "622 bert/encoder/layer_2/attention/self/MatMul__334"  [label="[]", style=solid];
"622 bert/encoder/layer_2/attention/self/MatMul__334" -> "623 bert/encoder/layer_2/attention/self/MatMul"  [label="[]", style=solid];
"623 bert/encoder/layer_2/attention/self/MatMul" -> "624 bert/encoder/layer_2/attention/self/Mul"  [label="[]", style=solid];
"624 bert/encoder/layer_2/attention/self/Mul" -> "625 bert/encoder/layer_2/attention/self/add"  [label="[]", style=solid];
"625 bert/encoder/layer_2/attention/self/add" -> "626 bert/encoder/layer_2/attention/self/Softmax"  [label="[]", style=solid];
"626 bert/encoder/layer_2/attention/self/Softmax" -> "627 bert/encoder/layer_2/attention/self/MatMul_1"  [label="[]", style=solid];
"627 bert/encoder/layer_2/attention/self/MatMul_1" -> "628 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"628 QuantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "629 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"629 DequantizeLinear_bert/encoder/layer_2/attention/self/MatMul_1^0_1" -> "630 bert/encoder/layer_2/attention/self/transpose_3"  [label="[]", style=solid];
"630 bert/encoder/layer_2/attention/self/transpose_3" -> "631 bert/encoder/layer_2/attention/self/Reshape_3"  [label="[]", style=solid];
"631 bert/encoder/layer_2/attention/self/Reshape_3" -> "634 bert/encoder/layer_2/attention/output/dense/MatMul"  [label="[]", style=solid];
"632 QuantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "633 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"633 DequantizeLinear_bert/encoder/layer_2/attention/output/dense/kernel^0_1" -> "634 bert/encoder/layer_2/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"634 bert/encoder/layer_2/attention/output/dense/MatMul" -> "635 bert/encoder/layer_2/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"635 bert/encoder/layer_2/attention/output/dense/BiasAdd" -> "636 bert/encoder/layer_2/attention/output/add"  [label="[]", style=solid];
"636 bert/encoder/layer_2/attention/output/add" -> "637 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"636 bert/encoder/layer_2/attention/output/add" -> "639 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"636 bert/encoder/layer_2/attention/output/add" -> "650 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"637 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "638 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"637 bert/encoder/layer_2/attention/output/LayerNorm/moments/mean" -> "648 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"638 bert/encoder/layer_2/attention/output/LayerNorm/moments/StopGradient" -> "639 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"639 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference" -> "640 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337"  [label="[]", style=solid];
"640 bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__337" -> "641 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"641 bert/encoder/layer_2/attention/output/LayerNorm/moments/variance" -> "642 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"642 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add" -> "643 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"643 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt" -> "644 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"644 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "645 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"645 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "646 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339"  [label="[]", style=solid];
"646 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__339" -> "647 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"647 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "648 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"647 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul" -> "650 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"648 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2" -> "649 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"649 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub" -> "651 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"650 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1" -> "651 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"651 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "652 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"651 bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1" -> "672 bert/encoder/layer_2/output/add"  [label="[]", style=solid];
"652 QuantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "653 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"653 DequantizeLinear_bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "656 bert/encoder/layer_2/intermediate/dense/MatMul"  [label="[]", style=solid];
"654 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "655 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"655 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/kernel^0_1" -> "656 bert/encoder/layer_2/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"656 bert/encoder/layer_2/intermediate/dense/MatMul" -> "657 bert/encoder/layer_2/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"657 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "658 bert/encoder/layer_2/intermediate/dense/Pow"  [label="[]", style=solid];
"657 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "660 bert/encoder/layer_2/intermediate/dense/add"  [label="[]", style=solid];
"657 bert/encoder/layer_2/intermediate/dense/BiasAdd" -> "665 bert/encoder/layer_2/intermediate/dense/mul_3"  [label="[]", style=solid];
"658 bert/encoder/layer_2/intermediate/dense/Pow" -> "659 bert/encoder/layer_2/intermediate/dense/mul"  [label="[]", style=solid];
"659 bert/encoder/layer_2/intermediate/dense/mul" -> "660 bert/encoder/layer_2/intermediate/dense/add"  [label="[]", style=solid];
"660 bert/encoder/layer_2/intermediate/dense/add" -> "661 bert/encoder/layer_2/intermediate/dense/mul_1"  [label="[]", style=solid];
"661 bert/encoder/layer_2/intermediate/dense/mul_1" -> "662 bert/encoder/layer_2/intermediate/dense/Tanh"  [label="[]", style=solid];
"662 bert/encoder/layer_2/intermediate/dense/Tanh" -> "663 bert/encoder/layer_2/intermediate/dense/add_1"  [label="[]", style=solid];
"663 bert/encoder/layer_2/intermediate/dense/add_1" -> "664 bert/encoder/layer_2/intermediate/dense/mul_2"  [label="[]", style=solid];
"664 bert/encoder/layer_2/intermediate/dense/mul_2" -> "665 bert/encoder/layer_2/intermediate/dense/mul_3"  [label="[]", style=solid];
"665 bert/encoder/layer_2/intermediate/dense/mul_3" -> "666 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"666 QuantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "667 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"667 DequantizeLinear_bert/encoder/layer_2/intermediate/dense/mul_3^0_1" -> "670 bert/encoder/layer_2/output/dense/MatMul"  [label="[]", style=solid];
"668 QuantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "669 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"669 DequantizeLinear_bert/encoder/layer_2/output/dense/kernel^0_1" -> "670 bert/encoder/layer_2/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"670 bert/encoder/layer_2/output/dense/MatMul" -> "671 bert/encoder/layer_2/output/dense/BiasAdd"  [label="[]", style=solid];
"671 bert/encoder/layer_2/output/dense/BiasAdd" -> "672 bert/encoder/layer_2/output/add"  [label="[]", style=solid];
"672 bert/encoder/layer_2/output/add" -> "673 bert/encoder/layer_2/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"672 bert/encoder/layer_2/output/add" -> "675 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"672 bert/encoder/layer_2/output/add" -> "686 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"673 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "674 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"673 bert/encoder/layer_2/output/LayerNorm/moments/mean" -> "684 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"674 bert/encoder/layer_2/output/LayerNorm/moments/StopGradient" -> "675 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"675 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference" -> "676 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341"  [label="[]", style=solid];
"676 bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__341" -> "677 bert/encoder/layer_2/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"677 bert/encoder/layer_2/output/LayerNorm/moments/variance" -> "678 bert/encoder/layer_2/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"678 bert/encoder/layer_2/output/LayerNorm/batchnorm/add" -> "679 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"679 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt" -> "680 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"680 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "681 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"681 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "682 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343"  [label="[]", style=solid];
"682 bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__343" -> "683 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"683 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "684 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"683 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul" -> "686 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"684 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2" -> "685 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"685 bert/encoder/layer_2/output/LayerNorm/batchnorm/sub" -> "687 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"686 bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1" -> "687 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"687 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "688 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"687 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "690 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"687 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "692 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"687 bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1" -> "730 bert/encoder/layer_3/attention/output/add"  [label="[]", style=solid];
"688 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "689 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"689 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_3" -> "710 bert/encoder/layer_3/attention/self/key/MatMul"  [label="[]", style=solid];
"690 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "691 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"691 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_2" -> "702 bert/encoder/layer_3/attention/self/query/MatMul"  [label="[]", style=solid];
"692 QuantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "693 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"693 DequantizeLinear_bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1^0_1" -> "696 bert/encoder/layer_3/attention/self/value/MatMul"  [label="[]", style=solid];
"694 QuantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "695 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"695 DequantizeLinear_bert/encoder/layer_3/attention/self/value/kernel^0_1" -> "696 bert/encoder/layer_3/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"696 bert/encoder/layer_3/attention/self/value/MatMul" -> "697 bert/encoder/layer_3/attention/self/value/BiasAdd"  [label="[]", style=solid];
"697 bert/encoder/layer_3/attention/self/value/BiasAdd" -> "698 bert/encoder/layer_3/attention/self/Reshape_2"  [label="[]", style=solid];
"698 bert/encoder/layer_3/attention/self/Reshape_2" -> "699 bert/encoder/layer_3/attention/self/transpose_2"  [label="[]", style=solid];
"699 bert/encoder/layer_3/attention/self/transpose_2" -> "721 bert/encoder/layer_3/attention/self/MatMul_1"  [label="[]", style=solid];
"700 QuantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "701 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"701 DequantizeLinear_bert/encoder/layer_3/attention/self/query/kernel^0_1" -> "702 bert/encoder/layer_3/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"702 bert/encoder/layer_3/attention/self/query/MatMul" -> "703 bert/encoder/layer_3/attention/self/query/BiasAdd"  [label="[]", style=solid];
"703 bert/encoder/layer_3/attention/self/query/BiasAdd" -> "704 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"704 QuantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "705 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"705 DequantizeLinear_bert/encoder/layer_3/attention/self/query/BiasAdd^0_1" -> "706 bert/encoder/layer_3/attention/self/Reshape"  [label="[]", style=solid];
"706 bert/encoder/layer_3/attention/self/Reshape" -> "707 bert/encoder/layer_3/attention/self/transpose"  [label="[]", style=solid];
"707 bert/encoder/layer_3/attention/self/transpose" -> "717 bert/encoder/layer_3/attention/self/MatMul"  [label="[]", style=solid];
"708 QuantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "709 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"709 DequantizeLinear_bert/encoder/layer_3/attention/self/key/kernel^0_1" -> "710 bert/encoder/layer_3/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"710 bert/encoder/layer_3/attention/self/key/MatMul" -> "711 bert/encoder/layer_3/attention/self/key/BiasAdd"  [label="[]", style=solid];
"711 bert/encoder/layer_3/attention/self/key/BiasAdd" -> "712 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"712 QuantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "713 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"713 DequantizeLinear_bert/encoder/layer_3/attention/self/key/BiasAdd^0_1" -> "714 bert/encoder/layer_3/attention/self/Reshape_1"  [label="[]", style=solid];
"714 bert/encoder/layer_3/attention/self/Reshape_1" -> "715 bert/encoder/layer_3/attention/self/transpose_1"  [label="[]", style=solid];
"715 bert/encoder/layer_3/attention/self/transpose_1" -> "716 bert/encoder/layer_3/attention/self/MatMul__348"  [label="[]", style=solid];
"716 bert/encoder/layer_3/attention/self/MatMul__348" -> "717 bert/encoder/layer_3/attention/self/MatMul"  [label="[]", style=solid];
"717 bert/encoder/layer_3/attention/self/MatMul" -> "718 bert/encoder/layer_3/attention/self/Mul"  [label="[]", style=solid];
"718 bert/encoder/layer_3/attention/self/Mul" -> "719 bert/encoder/layer_3/attention/self/add"  [label="[]", style=solid];
"719 bert/encoder/layer_3/attention/self/add" -> "720 bert/encoder/layer_3/attention/self/Softmax"  [label="[]", style=solid];
"720 bert/encoder/layer_3/attention/self/Softmax" -> "721 bert/encoder/layer_3/attention/self/MatMul_1"  [label="[]", style=solid];
"721 bert/encoder/layer_3/attention/self/MatMul_1" -> "722 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"722 QuantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "723 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"723 DequantizeLinear_bert/encoder/layer_3/attention/self/MatMul_1^0_1" -> "724 bert/encoder/layer_3/attention/self/transpose_3"  [label="[]", style=solid];
"724 bert/encoder/layer_3/attention/self/transpose_3" -> "725 bert/encoder/layer_3/attention/self/Reshape_3"  [label="[]", style=solid];
"725 bert/encoder/layer_3/attention/self/Reshape_3" -> "728 bert/encoder/layer_3/attention/output/dense/MatMul"  [label="[]", style=solid];
"726 QuantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "727 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"727 DequantizeLinear_bert/encoder/layer_3/attention/output/dense/kernel^0_1" -> "728 bert/encoder/layer_3/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"728 bert/encoder/layer_3/attention/output/dense/MatMul" -> "729 bert/encoder/layer_3/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"729 bert/encoder/layer_3/attention/output/dense/BiasAdd" -> "730 bert/encoder/layer_3/attention/output/add"  [label="[]", style=solid];
"730 bert/encoder/layer_3/attention/output/add" -> "731 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"730 bert/encoder/layer_3/attention/output/add" -> "733 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"730 bert/encoder/layer_3/attention/output/add" -> "744 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"731 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "732 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"731 bert/encoder/layer_3/attention/output/LayerNorm/moments/mean" -> "742 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"732 bert/encoder/layer_3/attention/output/LayerNorm/moments/StopGradient" -> "733 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"733 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference" -> "734 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351"  [label="[]", style=solid];
"734 bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__351" -> "735 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"735 bert/encoder/layer_3/attention/output/LayerNorm/moments/variance" -> "736 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"736 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add" -> "737 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"737 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt" -> "738 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"738 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "739 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"739 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "740 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353"  [label="[]", style=solid];
"740 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__353" -> "741 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"741 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "742 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"741 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul" -> "744 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"742 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2" -> "743 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"743 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub" -> "745 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"744 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1" -> "745 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"745 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "746 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"745 bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1" -> "766 bert/encoder/layer_3/output/add"  [label="[]", style=solid];
"746 QuantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "747 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"747 DequantizeLinear_bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "750 bert/encoder/layer_3/intermediate/dense/MatMul"  [label="[]", style=solid];
"748 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "749 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"749 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/kernel^0_1" -> "750 bert/encoder/layer_3/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"750 bert/encoder/layer_3/intermediate/dense/MatMul" -> "751 bert/encoder/layer_3/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"751 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "752 bert/encoder/layer_3/intermediate/dense/Pow"  [label="[]", style=solid];
"751 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "754 bert/encoder/layer_3/intermediate/dense/add"  [label="[]", style=solid];
"751 bert/encoder/layer_3/intermediate/dense/BiasAdd" -> "759 bert/encoder/layer_3/intermediate/dense/mul_3"  [label="[]", style=solid];
"752 bert/encoder/layer_3/intermediate/dense/Pow" -> "753 bert/encoder/layer_3/intermediate/dense/mul"  [label="[]", style=solid];
"753 bert/encoder/layer_3/intermediate/dense/mul" -> "754 bert/encoder/layer_3/intermediate/dense/add"  [label="[]", style=solid];
"754 bert/encoder/layer_3/intermediate/dense/add" -> "755 bert/encoder/layer_3/intermediate/dense/mul_1"  [label="[]", style=solid];
"755 bert/encoder/layer_3/intermediate/dense/mul_1" -> "756 bert/encoder/layer_3/intermediate/dense/Tanh"  [label="[]", style=solid];
"756 bert/encoder/layer_3/intermediate/dense/Tanh" -> "757 bert/encoder/layer_3/intermediate/dense/add_1"  [label="[]", style=solid];
"757 bert/encoder/layer_3/intermediate/dense/add_1" -> "758 bert/encoder/layer_3/intermediate/dense/mul_2"  [label="[]", style=solid];
"758 bert/encoder/layer_3/intermediate/dense/mul_2" -> "759 bert/encoder/layer_3/intermediate/dense/mul_3"  [label="[]", style=solid];
"759 bert/encoder/layer_3/intermediate/dense/mul_3" -> "760 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"760 QuantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "761 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"761 DequantizeLinear_bert/encoder/layer_3/intermediate/dense/mul_3^0_1" -> "764 bert/encoder/layer_3/output/dense/MatMul"  [label="[]", style=solid];
"762 QuantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "763 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"763 DequantizeLinear_bert/encoder/layer_3/output/dense/kernel^0_1" -> "764 bert/encoder/layer_3/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"764 bert/encoder/layer_3/output/dense/MatMul" -> "765 bert/encoder/layer_3/output/dense/BiasAdd"  [label="[]", style=solid];
"765 bert/encoder/layer_3/output/dense/BiasAdd" -> "766 bert/encoder/layer_3/output/add"  [label="[]", style=solid];
"766 bert/encoder/layer_3/output/add" -> "767 bert/encoder/layer_3/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"766 bert/encoder/layer_3/output/add" -> "769 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"766 bert/encoder/layer_3/output/add" -> "780 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"767 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "768 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"767 bert/encoder/layer_3/output/LayerNorm/moments/mean" -> "778 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"768 bert/encoder/layer_3/output/LayerNorm/moments/StopGradient" -> "769 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"769 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference" -> "770 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355"  [label="[]", style=solid];
"770 bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__355" -> "771 bert/encoder/layer_3/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"771 bert/encoder/layer_3/output/LayerNorm/moments/variance" -> "772 bert/encoder/layer_3/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"772 bert/encoder/layer_3/output/LayerNorm/batchnorm/add" -> "773 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"773 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt" -> "774 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"774 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "775 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"775 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "776 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357"  [label="[]", style=solid];
"776 bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__357" -> "777 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"777 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "778 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"777 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul" -> "780 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"778 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2" -> "779 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"779 bert/encoder/layer_3/output/LayerNorm/batchnorm/sub" -> "781 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"780 bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1" -> "781 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"781 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "782 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"781 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "784 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"781 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "786 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"781 bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1" -> "824 bert/encoder/layer_4/attention/output/add"  [label="[]", style=solid];
"782 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "783 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"783 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_3" -> "804 bert/encoder/layer_4/attention/self/key/MatMul"  [label="[]", style=solid];
"784 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "785 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"785 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_2" -> "796 bert/encoder/layer_4/attention/self/query/MatMul"  [label="[]", style=solid];
"786 QuantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "787 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"787 DequantizeLinear_bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1^0_1" -> "790 bert/encoder/layer_4/attention/self/value/MatMul"  [label="[]", style=solid];
"788 QuantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "789 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"789 DequantizeLinear_bert/encoder/layer_4/attention/self/value/kernel^0_1" -> "790 bert/encoder/layer_4/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"790 bert/encoder/layer_4/attention/self/value/MatMul" -> "791 bert/encoder/layer_4/attention/self/value/BiasAdd"  [label="[]", style=solid];
"791 bert/encoder/layer_4/attention/self/value/BiasAdd" -> "792 bert/encoder/layer_4/attention/self/Reshape_2"  [label="[]", style=solid];
"792 bert/encoder/layer_4/attention/self/Reshape_2" -> "793 bert/encoder/layer_4/attention/self/transpose_2"  [label="[]", style=solid];
"793 bert/encoder/layer_4/attention/self/transpose_2" -> "815 bert/encoder/layer_4/attention/self/MatMul_1"  [label="[]", style=solid];
"794 QuantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "795 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"795 DequantizeLinear_bert/encoder/layer_4/attention/self/query/kernel^0_1" -> "796 bert/encoder/layer_4/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"796 bert/encoder/layer_4/attention/self/query/MatMul" -> "797 bert/encoder/layer_4/attention/self/query/BiasAdd"  [label="[]", style=solid];
"797 bert/encoder/layer_4/attention/self/query/BiasAdd" -> "798 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"798 QuantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "799 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"799 DequantizeLinear_bert/encoder/layer_4/attention/self/query/BiasAdd^0_1" -> "800 bert/encoder/layer_4/attention/self/Reshape"  [label="[]", style=solid];
"800 bert/encoder/layer_4/attention/self/Reshape" -> "801 bert/encoder/layer_4/attention/self/transpose"  [label="[]", style=solid];
"801 bert/encoder/layer_4/attention/self/transpose" -> "811 bert/encoder/layer_4/attention/self/MatMul"  [label="[]", style=solid];
"802 QuantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "803 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"803 DequantizeLinear_bert/encoder/layer_4/attention/self/key/kernel^0_1" -> "804 bert/encoder/layer_4/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"804 bert/encoder/layer_4/attention/self/key/MatMul" -> "805 bert/encoder/layer_4/attention/self/key/BiasAdd"  [label="[]", style=solid];
"805 bert/encoder/layer_4/attention/self/key/BiasAdd" -> "806 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"806 QuantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "807 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"807 DequantizeLinear_bert/encoder/layer_4/attention/self/key/BiasAdd^0_1" -> "808 bert/encoder/layer_4/attention/self/Reshape_1"  [label="[]", style=solid];
"808 bert/encoder/layer_4/attention/self/Reshape_1" -> "809 bert/encoder/layer_4/attention/self/transpose_1"  [label="[]", style=solid];
"809 bert/encoder/layer_4/attention/self/transpose_1" -> "810 bert/encoder/layer_4/attention/self/MatMul__362"  [label="[]", style=solid];
"810 bert/encoder/layer_4/attention/self/MatMul__362" -> "811 bert/encoder/layer_4/attention/self/MatMul"  [label="[]", style=solid];
"811 bert/encoder/layer_4/attention/self/MatMul" -> "812 bert/encoder/layer_4/attention/self/Mul"  [label="[]", style=solid];
"812 bert/encoder/layer_4/attention/self/Mul" -> "813 bert/encoder/layer_4/attention/self/add"  [label="[]", style=solid];
"813 bert/encoder/layer_4/attention/self/add" -> "814 bert/encoder/layer_4/attention/self/Softmax"  [label="[]", style=solid];
"814 bert/encoder/layer_4/attention/self/Softmax" -> "815 bert/encoder/layer_4/attention/self/MatMul_1"  [label="[]", style=solid];
"815 bert/encoder/layer_4/attention/self/MatMul_1" -> "816 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"816 QuantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "817 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"817 DequantizeLinear_bert/encoder/layer_4/attention/self/MatMul_1^0_1" -> "818 bert/encoder/layer_4/attention/self/transpose_3"  [label="[]", style=solid];
"818 bert/encoder/layer_4/attention/self/transpose_3" -> "819 bert/encoder/layer_4/attention/self/Reshape_3"  [label="[]", style=solid];
"819 bert/encoder/layer_4/attention/self/Reshape_3" -> "822 bert/encoder/layer_4/attention/output/dense/MatMul"  [label="[]", style=solid];
"820 QuantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "821 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"821 DequantizeLinear_bert/encoder/layer_4/attention/output/dense/kernel^0_1" -> "822 bert/encoder/layer_4/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"822 bert/encoder/layer_4/attention/output/dense/MatMul" -> "823 bert/encoder/layer_4/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"823 bert/encoder/layer_4/attention/output/dense/BiasAdd" -> "824 bert/encoder/layer_4/attention/output/add"  [label="[]", style=solid];
"824 bert/encoder/layer_4/attention/output/add" -> "825 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"824 bert/encoder/layer_4/attention/output/add" -> "827 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"824 bert/encoder/layer_4/attention/output/add" -> "838 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"825 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "826 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"825 bert/encoder/layer_4/attention/output/LayerNorm/moments/mean" -> "836 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"826 bert/encoder/layer_4/attention/output/LayerNorm/moments/StopGradient" -> "827 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"827 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference" -> "828 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365"  [label="[]", style=solid];
"828 bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__365" -> "829 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"829 bert/encoder/layer_4/attention/output/LayerNorm/moments/variance" -> "830 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"830 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add" -> "831 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"831 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt" -> "832 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"832 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "833 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"833 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "834 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367"  [label="[]", style=solid];
"834 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__367" -> "835 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"835 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "836 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"835 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul" -> "838 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"836 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2" -> "837 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"837 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub" -> "839 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"838 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1" -> "839 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"839 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "840 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"839 bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1" -> "860 bert/encoder/layer_4/output/add"  [label="[]", style=solid];
"840 QuantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "841 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"841 DequantizeLinear_bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "844 bert/encoder/layer_4/intermediate/dense/MatMul"  [label="[]", style=solid];
"842 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "843 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"843 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/kernel^0_1" -> "844 bert/encoder/layer_4/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"844 bert/encoder/layer_4/intermediate/dense/MatMul" -> "845 bert/encoder/layer_4/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"845 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "846 bert/encoder/layer_4/intermediate/dense/Pow"  [label="[]", style=solid];
"845 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "848 bert/encoder/layer_4/intermediate/dense/add"  [label="[]", style=solid];
"845 bert/encoder/layer_4/intermediate/dense/BiasAdd" -> "853 bert/encoder/layer_4/intermediate/dense/mul_3"  [label="[]", style=solid];
"846 bert/encoder/layer_4/intermediate/dense/Pow" -> "847 bert/encoder/layer_4/intermediate/dense/mul"  [label="[]", style=solid];
"847 bert/encoder/layer_4/intermediate/dense/mul" -> "848 bert/encoder/layer_4/intermediate/dense/add"  [label="[]", style=solid];
"848 bert/encoder/layer_4/intermediate/dense/add" -> "849 bert/encoder/layer_4/intermediate/dense/mul_1"  [label="[]", style=solid];
"849 bert/encoder/layer_4/intermediate/dense/mul_1" -> "850 bert/encoder/layer_4/intermediate/dense/Tanh"  [label="[]", style=solid];
"850 bert/encoder/layer_4/intermediate/dense/Tanh" -> "851 bert/encoder/layer_4/intermediate/dense/add_1"  [label="[]", style=solid];
"851 bert/encoder/layer_4/intermediate/dense/add_1" -> "852 bert/encoder/layer_4/intermediate/dense/mul_2"  [label="[]", style=solid];
"852 bert/encoder/layer_4/intermediate/dense/mul_2" -> "853 bert/encoder/layer_4/intermediate/dense/mul_3"  [label="[]", style=solid];
"853 bert/encoder/layer_4/intermediate/dense/mul_3" -> "854 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"854 QuantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "855 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"855 DequantizeLinear_bert/encoder/layer_4/intermediate/dense/mul_3^0_1" -> "858 bert/encoder/layer_4/output/dense/MatMul"  [label="[]", style=solid];
"856 QuantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "857 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"857 DequantizeLinear_bert/encoder/layer_4/output/dense/kernel^0_1" -> "858 bert/encoder/layer_4/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"858 bert/encoder/layer_4/output/dense/MatMul" -> "859 bert/encoder/layer_4/output/dense/BiasAdd"  [label="[]", style=solid];
"859 bert/encoder/layer_4/output/dense/BiasAdd" -> "860 bert/encoder/layer_4/output/add"  [label="[]", style=solid];
"860 bert/encoder/layer_4/output/add" -> "861 bert/encoder/layer_4/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"860 bert/encoder/layer_4/output/add" -> "863 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"860 bert/encoder/layer_4/output/add" -> "874 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"861 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "862 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"861 bert/encoder/layer_4/output/LayerNorm/moments/mean" -> "872 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"862 bert/encoder/layer_4/output/LayerNorm/moments/StopGradient" -> "863 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"863 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference" -> "864 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369"  [label="[]", style=solid];
"864 bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__369" -> "865 bert/encoder/layer_4/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"865 bert/encoder/layer_4/output/LayerNorm/moments/variance" -> "866 bert/encoder/layer_4/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"866 bert/encoder/layer_4/output/LayerNorm/batchnorm/add" -> "867 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"867 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt" -> "868 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"868 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "869 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"869 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "870 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371"  [label="[]", style=solid];
"870 bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__371" -> "871 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"871 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "872 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"871 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul" -> "874 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"872 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2" -> "873 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"873 bert/encoder/layer_4/output/LayerNorm/batchnorm/sub" -> "875 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"874 bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1" -> "875 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"875 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "876 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"875 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "878 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"875 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "880 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"875 bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1" -> "918 bert/encoder/layer_5/attention/output/add"  [label="[]", style=solid];
"876 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "877 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"877 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_3" -> "898 bert/encoder/layer_5/attention/self/key/MatMul"  [label="[]", style=solid];
"878 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "879 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"879 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_2" -> "890 bert/encoder/layer_5/attention/self/query/MatMul"  [label="[]", style=solid];
"880 QuantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "881 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"881 DequantizeLinear_bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1^0_1" -> "884 bert/encoder/layer_5/attention/self/value/MatMul"  [label="[]", style=solid];
"882 QuantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "883 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"883 DequantizeLinear_bert/encoder/layer_5/attention/self/value/kernel^0_1" -> "884 bert/encoder/layer_5/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"884 bert/encoder/layer_5/attention/self/value/MatMul" -> "885 bert/encoder/layer_5/attention/self/value/BiasAdd"  [label="[]", style=solid];
"885 bert/encoder/layer_5/attention/self/value/BiasAdd" -> "886 bert/encoder/layer_5/attention/self/Reshape_2"  [label="[]", style=solid];
"886 bert/encoder/layer_5/attention/self/Reshape_2" -> "887 bert/encoder/layer_5/attention/self/transpose_2"  [label="[]", style=solid];
"887 bert/encoder/layer_5/attention/self/transpose_2" -> "909 bert/encoder/layer_5/attention/self/MatMul_1"  [label="[]", style=solid];
"888 QuantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "889 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"889 DequantizeLinear_bert/encoder/layer_5/attention/self/query/kernel^0_1" -> "890 bert/encoder/layer_5/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"890 bert/encoder/layer_5/attention/self/query/MatMul" -> "891 bert/encoder/layer_5/attention/self/query/BiasAdd"  [label="[]", style=solid];
"891 bert/encoder/layer_5/attention/self/query/BiasAdd" -> "892 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"892 QuantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "893 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"893 DequantizeLinear_bert/encoder/layer_5/attention/self/query/BiasAdd^0_1" -> "894 bert/encoder/layer_5/attention/self/Reshape"  [label="[]", style=solid];
"894 bert/encoder/layer_5/attention/self/Reshape" -> "895 bert/encoder/layer_5/attention/self/transpose"  [label="[]", style=solid];
"895 bert/encoder/layer_5/attention/self/transpose" -> "905 bert/encoder/layer_5/attention/self/MatMul"  [label="[]", style=solid];
"896 QuantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "897 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"897 DequantizeLinear_bert/encoder/layer_5/attention/self/key/kernel^0_1" -> "898 bert/encoder/layer_5/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"898 bert/encoder/layer_5/attention/self/key/MatMul" -> "899 bert/encoder/layer_5/attention/self/key/BiasAdd"  [label="[]", style=solid];
"899 bert/encoder/layer_5/attention/self/key/BiasAdd" -> "900 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"900 QuantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "901 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"901 DequantizeLinear_bert/encoder/layer_5/attention/self/key/BiasAdd^0_1" -> "902 bert/encoder/layer_5/attention/self/Reshape_1"  [label="[]", style=solid];
"902 bert/encoder/layer_5/attention/self/Reshape_1" -> "903 bert/encoder/layer_5/attention/self/transpose_1"  [label="[]", style=solid];
"903 bert/encoder/layer_5/attention/self/transpose_1" -> "904 bert/encoder/layer_5/attention/self/MatMul__376"  [label="[]", style=solid];
"904 bert/encoder/layer_5/attention/self/MatMul__376" -> "905 bert/encoder/layer_5/attention/self/MatMul"  [label="[]", style=solid];
"905 bert/encoder/layer_5/attention/self/MatMul" -> "906 bert/encoder/layer_5/attention/self/Mul"  [label="[]", style=solid];
"906 bert/encoder/layer_5/attention/self/Mul" -> "907 bert/encoder/layer_5/attention/self/add"  [label="[]", style=solid];
"907 bert/encoder/layer_5/attention/self/add" -> "908 bert/encoder/layer_5/attention/self/Softmax"  [label="[]", style=solid];
"908 bert/encoder/layer_5/attention/self/Softmax" -> "909 bert/encoder/layer_5/attention/self/MatMul_1"  [label="[]", style=solid];
"909 bert/encoder/layer_5/attention/self/MatMul_1" -> "910 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"910 QuantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "911 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"911 DequantizeLinear_bert/encoder/layer_5/attention/self/MatMul_1^0_1" -> "912 bert/encoder/layer_5/attention/self/transpose_3"  [label="[]", style=solid];
"912 bert/encoder/layer_5/attention/self/transpose_3" -> "913 bert/encoder/layer_5/attention/self/Reshape_3"  [label="[]", style=solid];
"913 bert/encoder/layer_5/attention/self/Reshape_3" -> "916 bert/encoder/layer_5/attention/output/dense/MatMul"  [label="[]", style=solid];
"914 QuantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "915 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"915 DequantizeLinear_bert/encoder/layer_5/attention/output/dense/kernel^0_1" -> "916 bert/encoder/layer_5/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"916 bert/encoder/layer_5/attention/output/dense/MatMul" -> "917 bert/encoder/layer_5/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"917 bert/encoder/layer_5/attention/output/dense/BiasAdd" -> "918 bert/encoder/layer_5/attention/output/add"  [label="[]", style=solid];
"918 bert/encoder/layer_5/attention/output/add" -> "919 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"918 bert/encoder/layer_5/attention/output/add" -> "921 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"918 bert/encoder/layer_5/attention/output/add" -> "932 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"919 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "920 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"919 bert/encoder/layer_5/attention/output/LayerNorm/moments/mean" -> "930 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"920 bert/encoder/layer_5/attention/output/LayerNorm/moments/StopGradient" -> "921 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"921 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference" -> "922 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379"  [label="[]", style=solid];
"922 bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__379" -> "923 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"923 bert/encoder/layer_5/attention/output/LayerNorm/moments/variance" -> "924 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"924 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add" -> "925 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"925 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt" -> "926 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"926 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "927 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"927 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "928 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381"  [label="[]", style=solid];
"928 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__381" -> "929 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"929 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "930 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"929 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul" -> "932 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"930 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2" -> "931 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"931 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub" -> "933 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"932 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1" -> "933 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"933 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "934 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"933 bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1" -> "954 bert/encoder/layer_5/output/add"  [label="[]", style=solid];
"934 QuantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "935 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"935 DequantizeLinear_bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "938 bert/encoder/layer_5/intermediate/dense/MatMul"  [label="[]", style=solid];
"936 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "937 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"937 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/kernel^0_1" -> "938 bert/encoder/layer_5/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"938 bert/encoder/layer_5/intermediate/dense/MatMul" -> "939 bert/encoder/layer_5/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"939 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "940 bert/encoder/layer_5/intermediate/dense/Pow"  [label="[]", style=solid];
"939 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "942 bert/encoder/layer_5/intermediate/dense/add"  [label="[]", style=solid];
"939 bert/encoder/layer_5/intermediate/dense/BiasAdd" -> "947 bert/encoder/layer_5/intermediate/dense/mul_3"  [label="[]", style=solid];
"940 bert/encoder/layer_5/intermediate/dense/Pow" -> "941 bert/encoder/layer_5/intermediate/dense/mul"  [label="[]", style=solid];
"941 bert/encoder/layer_5/intermediate/dense/mul" -> "942 bert/encoder/layer_5/intermediate/dense/add"  [label="[]", style=solid];
"942 bert/encoder/layer_5/intermediate/dense/add" -> "943 bert/encoder/layer_5/intermediate/dense/mul_1"  [label="[]", style=solid];
"943 bert/encoder/layer_5/intermediate/dense/mul_1" -> "944 bert/encoder/layer_5/intermediate/dense/Tanh"  [label="[]", style=solid];
"944 bert/encoder/layer_5/intermediate/dense/Tanh" -> "945 bert/encoder/layer_5/intermediate/dense/add_1"  [label="[]", style=solid];
"945 bert/encoder/layer_5/intermediate/dense/add_1" -> "946 bert/encoder/layer_5/intermediate/dense/mul_2"  [label="[]", style=solid];
"946 bert/encoder/layer_5/intermediate/dense/mul_2" -> "947 bert/encoder/layer_5/intermediate/dense/mul_3"  [label="[]", style=solid];
"947 bert/encoder/layer_5/intermediate/dense/mul_3" -> "948 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"948 QuantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "949 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"949 DequantizeLinear_bert/encoder/layer_5/intermediate/dense/mul_3^0_1" -> "952 bert/encoder/layer_5/output/dense/MatMul"  [label="[]", style=solid];
"950 QuantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "951 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"951 DequantizeLinear_bert/encoder/layer_5/output/dense/kernel^0_1" -> "952 bert/encoder/layer_5/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"952 bert/encoder/layer_5/output/dense/MatMul" -> "953 bert/encoder/layer_5/output/dense/BiasAdd"  [label="[]", style=solid];
"953 bert/encoder/layer_5/output/dense/BiasAdd" -> "954 bert/encoder/layer_5/output/add"  [label="[]", style=solid];
"954 bert/encoder/layer_5/output/add" -> "955 bert/encoder/layer_5/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"954 bert/encoder/layer_5/output/add" -> "957 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"954 bert/encoder/layer_5/output/add" -> "968 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"955 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "956 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"955 bert/encoder/layer_5/output/LayerNorm/moments/mean" -> "966 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"956 bert/encoder/layer_5/output/LayerNorm/moments/StopGradient" -> "957 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"957 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference" -> "958 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383"  [label="[]", style=solid];
"958 bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__383" -> "959 bert/encoder/layer_5/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"959 bert/encoder/layer_5/output/LayerNorm/moments/variance" -> "960 bert/encoder/layer_5/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"960 bert/encoder/layer_5/output/LayerNorm/batchnorm/add" -> "961 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"961 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt" -> "962 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"962 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "963 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"963 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "964 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385"  [label="[]", style=solid];
"964 bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__385" -> "965 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"965 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "966 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"965 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul" -> "968 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"966 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2" -> "967 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"967 bert/encoder/layer_5/output/LayerNorm/batchnorm/sub" -> "969 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"968 bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1" -> "969 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"969 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "970 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"969 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "972 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"969 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "974 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"969 bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1" -> "1012 bert/encoder/layer_6/attention/output/add"  [label="[]", style=solid];
"970 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "971 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"971 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_3" -> "992 bert/encoder/layer_6/attention/self/key/MatMul"  [label="[]", style=solid];
"972 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "973 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"973 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_2" -> "984 bert/encoder/layer_6/attention/self/query/MatMul"  [label="[]", style=solid];
"974 QuantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "975 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"975 DequantizeLinear_bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1^0_1" -> "978 bert/encoder/layer_6/attention/self/value/MatMul"  [label="[]", style=solid];
"976 QuantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "977 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"977 DequantizeLinear_bert/encoder/layer_6/attention/self/value/kernel^0_1" -> "978 bert/encoder/layer_6/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"978 bert/encoder/layer_6/attention/self/value/MatMul" -> "979 bert/encoder/layer_6/attention/self/value/BiasAdd"  [label="[]", style=solid];
"979 bert/encoder/layer_6/attention/self/value/BiasAdd" -> "980 bert/encoder/layer_6/attention/self/Reshape_2"  [label="[]", style=solid];
"980 bert/encoder/layer_6/attention/self/Reshape_2" -> "981 bert/encoder/layer_6/attention/self/transpose_2"  [label="[]", style=solid];
"981 bert/encoder/layer_6/attention/self/transpose_2" -> "1003 bert/encoder/layer_6/attention/self/MatMul_1"  [label="[]", style=solid];
"982 QuantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "983 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"983 DequantizeLinear_bert/encoder/layer_6/attention/self/query/kernel^0_1" -> "984 bert/encoder/layer_6/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"984 bert/encoder/layer_6/attention/self/query/MatMul" -> "985 bert/encoder/layer_6/attention/self/query/BiasAdd"  [label="[]", style=solid];
"985 bert/encoder/layer_6/attention/self/query/BiasAdd" -> "986 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"986 QuantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "987 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"987 DequantizeLinear_bert/encoder/layer_6/attention/self/query/BiasAdd^0_1" -> "988 bert/encoder/layer_6/attention/self/Reshape"  [label="[]", style=solid];
"988 bert/encoder/layer_6/attention/self/Reshape" -> "989 bert/encoder/layer_6/attention/self/transpose"  [label="[]", style=solid];
"989 bert/encoder/layer_6/attention/self/transpose" -> "999 bert/encoder/layer_6/attention/self/MatMul"  [label="[]", style=solid];
"990 QuantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "991 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"991 DequantizeLinear_bert/encoder/layer_6/attention/self/key/kernel^0_1" -> "992 bert/encoder/layer_6/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"992 bert/encoder/layer_6/attention/self/key/MatMul" -> "993 bert/encoder/layer_6/attention/self/key/BiasAdd"  [label="[]", style=solid];
"993 bert/encoder/layer_6/attention/self/key/BiasAdd" -> "994 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"994 QuantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "995 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"995 DequantizeLinear_bert/encoder/layer_6/attention/self/key/BiasAdd^0_1" -> "996 bert/encoder/layer_6/attention/self/Reshape_1"  [label="[]", style=solid];
"996 bert/encoder/layer_6/attention/self/Reshape_1" -> "997 bert/encoder/layer_6/attention/self/transpose_1"  [label="[]", style=solid];
"997 bert/encoder/layer_6/attention/self/transpose_1" -> "998 bert/encoder/layer_6/attention/self/MatMul__390"  [label="[]", style=solid];
"998 bert/encoder/layer_6/attention/self/MatMul__390" -> "999 bert/encoder/layer_6/attention/self/MatMul"  [label="[]", style=solid];
"999 bert/encoder/layer_6/attention/self/MatMul" -> "1000 bert/encoder/layer_6/attention/self/Mul"  [label="[]", style=solid];
"1000 bert/encoder/layer_6/attention/self/Mul" -> "1001 bert/encoder/layer_6/attention/self/add"  [label="[]", style=solid];
"1001 bert/encoder/layer_6/attention/self/add" -> "1002 bert/encoder/layer_6/attention/self/Softmax"  [label="[]", style=solid];
"1002 bert/encoder/layer_6/attention/self/Softmax" -> "1003 bert/encoder/layer_6/attention/self/MatMul_1"  [label="[]", style=solid];
"1003 bert/encoder/layer_6/attention/self/MatMul_1" -> "1004 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1004 QuantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "1005 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1005 DequantizeLinear_bert/encoder/layer_6/attention/self/MatMul_1^0_1" -> "1006 bert/encoder/layer_6/attention/self/transpose_3"  [label="[]", style=solid];
"1006 bert/encoder/layer_6/attention/self/transpose_3" -> "1007 bert/encoder/layer_6/attention/self/Reshape_3"  [label="[]", style=solid];
"1007 bert/encoder/layer_6/attention/self/Reshape_3" -> "1010 bert/encoder/layer_6/attention/output/dense/MatMul"  [label="[]", style=solid];
"1008 QuantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "1009 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1009 DequantizeLinear_bert/encoder/layer_6/attention/output/dense/kernel^0_1" -> "1010 bert/encoder/layer_6/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1010 bert/encoder/layer_6/attention/output/dense/MatMul" -> "1011 bert/encoder/layer_6/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1011 bert/encoder/layer_6/attention/output/dense/BiasAdd" -> "1012 bert/encoder/layer_6/attention/output/add"  [label="[]", style=solid];
"1012 bert/encoder/layer_6/attention/output/add" -> "1013 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1012 bert/encoder/layer_6/attention/output/add" -> "1015 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1012 bert/encoder/layer_6/attention/output/add" -> "1026 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1013 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "1014 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1013 bert/encoder/layer_6/attention/output/LayerNorm/moments/mean" -> "1024 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1014 bert/encoder/layer_6/attention/output/LayerNorm/moments/StopGradient" -> "1015 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1015 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference" -> "1016 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393"  [label="[]", style=solid];
"1016 bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__393" -> "1017 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1017 bert/encoder/layer_6/attention/output/LayerNorm/moments/variance" -> "1018 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1018 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add" -> "1019 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1019 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1020 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1020 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1021 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1021 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1022 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395"  [label="[]", style=solid];
"1022 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__395" -> "1023 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1023 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "1024 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1023 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul" -> "1026 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1024 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2" -> "1025 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1025 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub" -> "1027 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1026 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1" -> "1027 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1027 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1028 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1027 bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1" -> "1048 bert/encoder/layer_6/output/add"  [label="[]", style=solid];
"1028 QuantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1029 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1029 DequantizeLinear_bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1032 bert/encoder/layer_6/intermediate/dense/MatMul"  [label="[]", style=solid];
"1030 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1031 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1031 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/kernel^0_1" -> "1032 bert/encoder/layer_6/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1032 bert/encoder/layer_6/intermediate/dense/MatMul" -> "1033 bert/encoder/layer_6/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1033 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1034 bert/encoder/layer_6/intermediate/dense/Pow"  [label="[]", style=solid];
"1033 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1036 bert/encoder/layer_6/intermediate/dense/add"  [label="[]", style=solid];
"1033 bert/encoder/layer_6/intermediate/dense/BiasAdd" -> "1041 bert/encoder/layer_6/intermediate/dense/mul_3"  [label="[]", style=solid];
"1034 bert/encoder/layer_6/intermediate/dense/Pow" -> "1035 bert/encoder/layer_6/intermediate/dense/mul"  [label="[]", style=solid];
"1035 bert/encoder/layer_6/intermediate/dense/mul" -> "1036 bert/encoder/layer_6/intermediate/dense/add"  [label="[]", style=solid];
"1036 bert/encoder/layer_6/intermediate/dense/add" -> "1037 bert/encoder/layer_6/intermediate/dense/mul_1"  [label="[]", style=solid];
"1037 bert/encoder/layer_6/intermediate/dense/mul_1" -> "1038 bert/encoder/layer_6/intermediate/dense/Tanh"  [label="[]", style=solid];
"1038 bert/encoder/layer_6/intermediate/dense/Tanh" -> "1039 bert/encoder/layer_6/intermediate/dense/add_1"  [label="[]", style=solid];
"1039 bert/encoder/layer_6/intermediate/dense/add_1" -> "1040 bert/encoder/layer_6/intermediate/dense/mul_2"  [label="[]", style=solid];
"1040 bert/encoder/layer_6/intermediate/dense/mul_2" -> "1041 bert/encoder/layer_6/intermediate/dense/mul_3"  [label="[]", style=solid];
"1041 bert/encoder/layer_6/intermediate/dense/mul_3" -> "1042 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1042 QuantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1043 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1043 DequantizeLinear_bert/encoder/layer_6/intermediate/dense/mul_3^0_1" -> "1046 bert/encoder/layer_6/output/dense/MatMul"  [label="[]", style=solid];
"1044 QuantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1045 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1045 DequantizeLinear_bert/encoder/layer_6/output/dense/kernel^0_1" -> "1046 bert/encoder/layer_6/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1046 bert/encoder/layer_6/output/dense/MatMul" -> "1047 bert/encoder/layer_6/output/dense/BiasAdd"  [label="[]", style=solid];
"1047 bert/encoder/layer_6/output/dense/BiasAdd" -> "1048 bert/encoder/layer_6/output/add"  [label="[]", style=solid];
"1048 bert/encoder/layer_6/output/add" -> "1049 bert/encoder/layer_6/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1048 bert/encoder/layer_6/output/add" -> "1051 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1048 bert/encoder/layer_6/output/add" -> "1062 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1049 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1050 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1049 bert/encoder/layer_6/output/LayerNorm/moments/mean" -> "1060 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1050 bert/encoder/layer_6/output/LayerNorm/moments/StopGradient" -> "1051 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1051 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference" -> "1052 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397"  [label="[]", style=solid];
"1052 bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__397" -> "1053 bert/encoder/layer_6/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1053 bert/encoder/layer_6/output/LayerNorm/moments/variance" -> "1054 bert/encoder/layer_6/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1054 bert/encoder/layer_6/output/LayerNorm/batchnorm/add" -> "1055 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1055 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt" -> "1056 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1056 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1057 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1057 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1058 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399"  [label="[]", style=solid];
"1058 bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__399" -> "1059 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1059 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1060 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1059 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul" -> "1062 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1060 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2" -> "1061 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1061 bert/encoder/layer_6/output/LayerNorm/batchnorm/sub" -> "1063 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1062 bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1" -> "1063 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1063 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1064 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1063 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1066 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1063 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1068 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1063 bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1" -> "1106 bert/encoder/layer_7/attention/output/add"  [label="[]", style=solid];
"1064 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1065 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1065 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_3" -> "1086 bert/encoder/layer_7/attention/self/key/MatMul"  [label="[]", style=solid];
"1066 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1067 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1067 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_2" -> "1078 bert/encoder/layer_7/attention/self/query/MatMul"  [label="[]", style=solid];
"1068 QuantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1069 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1069 DequantizeLinear_bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1^0_1" -> "1072 bert/encoder/layer_7/attention/self/value/MatMul"  [label="[]", style=solid];
"1070 QuantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1071 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1071 DequantizeLinear_bert/encoder/layer_7/attention/self/value/kernel^0_1" -> "1072 bert/encoder/layer_7/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1072 bert/encoder/layer_7/attention/self/value/MatMul" -> "1073 bert/encoder/layer_7/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1073 bert/encoder/layer_7/attention/self/value/BiasAdd" -> "1074 bert/encoder/layer_7/attention/self/Reshape_2"  [label="[]", style=solid];
"1074 bert/encoder/layer_7/attention/self/Reshape_2" -> "1075 bert/encoder/layer_7/attention/self/transpose_2"  [label="[]", style=solid];
"1075 bert/encoder/layer_7/attention/self/transpose_2" -> "1097 bert/encoder/layer_7/attention/self/MatMul_1"  [label="[]", style=solid];
"1076 QuantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1077 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1077 DequantizeLinear_bert/encoder/layer_7/attention/self/query/kernel^0_1" -> "1078 bert/encoder/layer_7/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1078 bert/encoder/layer_7/attention/self/query/MatMul" -> "1079 bert/encoder/layer_7/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1079 bert/encoder/layer_7/attention/self/query/BiasAdd" -> "1080 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1080 QuantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1081 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1081 DequantizeLinear_bert/encoder/layer_7/attention/self/query/BiasAdd^0_1" -> "1082 bert/encoder/layer_7/attention/self/Reshape"  [label="[]", style=solid];
"1082 bert/encoder/layer_7/attention/self/Reshape" -> "1083 bert/encoder/layer_7/attention/self/transpose"  [label="[]", style=solid];
"1083 bert/encoder/layer_7/attention/self/transpose" -> "1093 bert/encoder/layer_7/attention/self/MatMul"  [label="[]", style=solid];
"1084 QuantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1085 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1085 DequantizeLinear_bert/encoder/layer_7/attention/self/key/kernel^0_1" -> "1086 bert/encoder/layer_7/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1086 bert/encoder/layer_7/attention/self/key/MatMul" -> "1087 bert/encoder/layer_7/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1087 bert/encoder/layer_7/attention/self/key/BiasAdd" -> "1088 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1088 QuantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1089 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1089 DequantizeLinear_bert/encoder/layer_7/attention/self/key/BiasAdd^0_1" -> "1090 bert/encoder/layer_7/attention/self/Reshape_1"  [label="[]", style=solid];
"1090 bert/encoder/layer_7/attention/self/Reshape_1" -> "1091 bert/encoder/layer_7/attention/self/transpose_1"  [label="[]", style=solid];
"1091 bert/encoder/layer_7/attention/self/transpose_1" -> "1092 bert/encoder/layer_7/attention/self/MatMul__404"  [label="[]", style=solid];
"1092 bert/encoder/layer_7/attention/self/MatMul__404" -> "1093 bert/encoder/layer_7/attention/self/MatMul"  [label="[]", style=solid];
"1093 bert/encoder/layer_7/attention/self/MatMul" -> "1094 bert/encoder/layer_7/attention/self/Mul"  [label="[]", style=solid];
"1094 bert/encoder/layer_7/attention/self/Mul" -> "1095 bert/encoder/layer_7/attention/self/add"  [label="[]", style=solid];
"1095 bert/encoder/layer_7/attention/self/add" -> "1096 bert/encoder/layer_7/attention/self/Softmax"  [label="[]", style=solid];
"1096 bert/encoder/layer_7/attention/self/Softmax" -> "1097 bert/encoder/layer_7/attention/self/MatMul_1"  [label="[]", style=solid];
"1097 bert/encoder/layer_7/attention/self/MatMul_1" -> "1098 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1098 QuantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1099 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1099 DequantizeLinear_bert/encoder/layer_7/attention/self/MatMul_1^0_1" -> "1100 bert/encoder/layer_7/attention/self/transpose_3"  [label="[]", style=solid];
"1100 bert/encoder/layer_7/attention/self/transpose_3" -> "1101 bert/encoder/layer_7/attention/self/Reshape_3"  [label="[]", style=solid];
"1101 bert/encoder/layer_7/attention/self/Reshape_3" -> "1104 bert/encoder/layer_7/attention/output/dense/MatMul"  [label="[]", style=solid];
"1102 QuantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1103 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1103 DequantizeLinear_bert/encoder/layer_7/attention/output/dense/kernel^0_1" -> "1104 bert/encoder/layer_7/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1104 bert/encoder/layer_7/attention/output/dense/MatMul" -> "1105 bert/encoder/layer_7/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1105 bert/encoder/layer_7/attention/output/dense/BiasAdd" -> "1106 bert/encoder/layer_7/attention/output/add"  [label="[]", style=solid];
"1106 bert/encoder/layer_7/attention/output/add" -> "1107 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1106 bert/encoder/layer_7/attention/output/add" -> "1109 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1106 bert/encoder/layer_7/attention/output/add" -> "1120 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1107 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1108 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1107 bert/encoder/layer_7/attention/output/LayerNorm/moments/mean" -> "1118 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1108 bert/encoder/layer_7/attention/output/LayerNorm/moments/StopGradient" -> "1109 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1109 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference" -> "1110 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407"  [label="[]", style=solid];
"1110 bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__407" -> "1111 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1111 bert/encoder/layer_7/attention/output/LayerNorm/moments/variance" -> "1112 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1112 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add" -> "1113 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1113 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1114 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1114 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1115 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1115 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1116 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409"  [label="[]", style=solid];
"1116 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__409" -> "1117 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1117 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1118 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1117 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul" -> "1120 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1118 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2" -> "1119 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1119 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub" -> "1121 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1120 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1" -> "1121 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1122 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1121 bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1" -> "1142 bert/encoder/layer_7/output/add"  [label="[]", style=solid];
"1122 QuantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1123 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1123 DequantizeLinear_bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1126 bert/encoder/layer_7/intermediate/dense/MatMul"  [label="[]", style=solid];
"1124 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1125 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1125 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/kernel^0_1" -> "1126 bert/encoder/layer_7/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1126 bert/encoder/layer_7/intermediate/dense/MatMul" -> "1127 bert/encoder/layer_7/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1127 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1128 bert/encoder/layer_7/intermediate/dense/Pow"  [label="[]", style=solid];
"1127 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1130 bert/encoder/layer_7/intermediate/dense/add"  [label="[]", style=solid];
"1127 bert/encoder/layer_7/intermediate/dense/BiasAdd" -> "1135 bert/encoder/layer_7/intermediate/dense/mul_3"  [label="[]", style=solid];
"1128 bert/encoder/layer_7/intermediate/dense/Pow" -> "1129 bert/encoder/layer_7/intermediate/dense/mul"  [label="[]", style=solid];
"1129 bert/encoder/layer_7/intermediate/dense/mul" -> "1130 bert/encoder/layer_7/intermediate/dense/add"  [label="[]", style=solid];
"1130 bert/encoder/layer_7/intermediate/dense/add" -> "1131 bert/encoder/layer_7/intermediate/dense/mul_1"  [label="[]", style=solid];
"1131 bert/encoder/layer_7/intermediate/dense/mul_1" -> "1132 bert/encoder/layer_7/intermediate/dense/Tanh"  [label="[]", style=solid];
"1132 bert/encoder/layer_7/intermediate/dense/Tanh" -> "1133 bert/encoder/layer_7/intermediate/dense/add_1"  [label="[]", style=solid];
"1133 bert/encoder/layer_7/intermediate/dense/add_1" -> "1134 bert/encoder/layer_7/intermediate/dense/mul_2"  [label="[]", style=solid];
"1134 bert/encoder/layer_7/intermediate/dense/mul_2" -> "1135 bert/encoder/layer_7/intermediate/dense/mul_3"  [label="[]", style=solid];
"1135 bert/encoder/layer_7/intermediate/dense/mul_3" -> "1136 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1136 QuantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1137 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1137 DequantizeLinear_bert/encoder/layer_7/intermediate/dense/mul_3^0_1" -> "1140 bert/encoder/layer_7/output/dense/MatMul"  [label="[]", style=solid];
"1138 QuantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1139 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1139 DequantizeLinear_bert/encoder/layer_7/output/dense/kernel^0_1" -> "1140 bert/encoder/layer_7/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1140 bert/encoder/layer_7/output/dense/MatMul" -> "1141 bert/encoder/layer_7/output/dense/BiasAdd"  [label="[]", style=solid];
"1141 bert/encoder/layer_7/output/dense/BiasAdd" -> "1142 bert/encoder/layer_7/output/add"  [label="[]", style=solid];
"1142 bert/encoder/layer_7/output/add" -> "1143 bert/encoder/layer_7/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1142 bert/encoder/layer_7/output/add" -> "1145 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1142 bert/encoder/layer_7/output/add" -> "1156 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1143 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1144 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1143 bert/encoder/layer_7/output/LayerNorm/moments/mean" -> "1154 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1144 bert/encoder/layer_7/output/LayerNorm/moments/StopGradient" -> "1145 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1145 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference" -> "1146 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411"  [label="[]", style=solid];
"1146 bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__411" -> "1147 bert/encoder/layer_7/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1147 bert/encoder/layer_7/output/LayerNorm/moments/variance" -> "1148 bert/encoder/layer_7/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1148 bert/encoder/layer_7/output/LayerNorm/batchnorm/add" -> "1149 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1149 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt" -> "1150 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1150 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1151 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1151 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1152 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413"  [label="[]", style=solid];
"1152 bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__413" -> "1153 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1153 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1154 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1153 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul" -> "1156 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1154 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2" -> "1155 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1155 bert/encoder/layer_7/output/LayerNorm/batchnorm/sub" -> "1157 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1156 bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1" -> "1157 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1157 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1158 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1157 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1160 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1157 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1162 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1157 bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1" -> "1200 bert/encoder/layer_8/attention/output/add"  [label="[]", style=solid];
"1158 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1159 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1159 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_3" -> "1180 bert/encoder/layer_8/attention/self/key/MatMul"  [label="[]", style=solid];
"1160 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1161 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1161 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_2" -> "1172 bert/encoder/layer_8/attention/self/query/MatMul"  [label="[]", style=solid];
"1162 QuantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1163 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1163 DequantizeLinear_bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1^0_1" -> "1166 bert/encoder/layer_8/attention/self/value/MatMul"  [label="[]", style=solid];
"1164 QuantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1165 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1165 DequantizeLinear_bert/encoder/layer_8/attention/self/value/kernel^0_1" -> "1166 bert/encoder/layer_8/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1166 bert/encoder/layer_8/attention/self/value/MatMul" -> "1167 bert/encoder/layer_8/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1167 bert/encoder/layer_8/attention/self/value/BiasAdd" -> "1168 bert/encoder/layer_8/attention/self/Reshape_2"  [label="[]", style=solid];
"1168 bert/encoder/layer_8/attention/self/Reshape_2" -> "1169 bert/encoder/layer_8/attention/self/transpose_2"  [label="[]", style=solid];
"1169 bert/encoder/layer_8/attention/self/transpose_2" -> "1191 bert/encoder/layer_8/attention/self/MatMul_1"  [label="[]", style=solid];
"1170 QuantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1171 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1171 DequantizeLinear_bert/encoder/layer_8/attention/self/query/kernel^0_1" -> "1172 bert/encoder/layer_8/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1172 bert/encoder/layer_8/attention/self/query/MatMul" -> "1173 bert/encoder/layer_8/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1173 bert/encoder/layer_8/attention/self/query/BiasAdd" -> "1174 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1174 QuantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1175 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1175 DequantizeLinear_bert/encoder/layer_8/attention/self/query/BiasAdd^0_1" -> "1176 bert/encoder/layer_8/attention/self/Reshape"  [label="[]", style=solid];
"1176 bert/encoder/layer_8/attention/self/Reshape" -> "1177 bert/encoder/layer_8/attention/self/transpose"  [label="[]", style=solid];
"1177 bert/encoder/layer_8/attention/self/transpose" -> "1187 bert/encoder/layer_8/attention/self/MatMul"  [label="[]", style=solid];
"1178 QuantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1179 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1179 DequantizeLinear_bert/encoder/layer_8/attention/self/key/kernel^0_1" -> "1180 bert/encoder/layer_8/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1180 bert/encoder/layer_8/attention/self/key/MatMul" -> "1181 bert/encoder/layer_8/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1181 bert/encoder/layer_8/attention/self/key/BiasAdd" -> "1182 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1182 QuantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1183 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1183 DequantizeLinear_bert/encoder/layer_8/attention/self/key/BiasAdd^0_1" -> "1184 bert/encoder/layer_8/attention/self/Reshape_1"  [label="[]", style=solid];
"1184 bert/encoder/layer_8/attention/self/Reshape_1" -> "1185 bert/encoder/layer_8/attention/self/transpose_1"  [label="[]", style=solid];
"1185 bert/encoder/layer_8/attention/self/transpose_1" -> "1186 bert/encoder/layer_8/attention/self/MatMul__418"  [label="[]", style=solid];
"1186 bert/encoder/layer_8/attention/self/MatMul__418" -> "1187 bert/encoder/layer_8/attention/self/MatMul"  [label="[]", style=solid];
"1187 bert/encoder/layer_8/attention/self/MatMul" -> "1188 bert/encoder/layer_8/attention/self/Mul"  [label="[]", style=solid];
"1188 bert/encoder/layer_8/attention/self/Mul" -> "1189 bert/encoder/layer_8/attention/self/add"  [label="[]", style=solid];
"1189 bert/encoder/layer_8/attention/self/add" -> "1190 bert/encoder/layer_8/attention/self/Softmax"  [label="[]", style=solid];
"1190 bert/encoder/layer_8/attention/self/Softmax" -> "1191 bert/encoder/layer_8/attention/self/MatMul_1"  [label="[]", style=solid];
"1191 bert/encoder/layer_8/attention/self/MatMul_1" -> "1192 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1192 QuantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1193 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1193 DequantizeLinear_bert/encoder/layer_8/attention/self/MatMul_1^0_1" -> "1194 bert/encoder/layer_8/attention/self/transpose_3"  [label="[]", style=solid];
"1194 bert/encoder/layer_8/attention/self/transpose_3" -> "1195 bert/encoder/layer_8/attention/self/Reshape_3"  [label="[]", style=solid];
"1195 bert/encoder/layer_8/attention/self/Reshape_3" -> "1198 bert/encoder/layer_8/attention/output/dense/MatMul"  [label="[]", style=solid];
"1196 QuantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1197 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1197 DequantizeLinear_bert/encoder/layer_8/attention/output/dense/kernel^0_1" -> "1198 bert/encoder/layer_8/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1198 bert/encoder/layer_8/attention/output/dense/MatMul" -> "1199 bert/encoder/layer_8/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1199 bert/encoder/layer_8/attention/output/dense/BiasAdd" -> "1200 bert/encoder/layer_8/attention/output/add"  [label="[]", style=solid];
"1200 bert/encoder/layer_8/attention/output/add" -> "1201 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1200 bert/encoder/layer_8/attention/output/add" -> "1203 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1200 bert/encoder/layer_8/attention/output/add" -> "1214 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1201 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1202 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1201 bert/encoder/layer_8/attention/output/LayerNorm/moments/mean" -> "1212 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1202 bert/encoder/layer_8/attention/output/LayerNorm/moments/StopGradient" -> "1203 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1203 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference" -> "1204 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421"  [label="[]", style=solid];
"1204 bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__421" -> "1205 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1205 bert/encoder/layer_8/attention/output/LayerNorm/moments/variance" -> "1206 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1206 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add" -> "1207 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1207 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1208 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1208 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1209 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1209 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1210 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423"  [label="[]", style=solid];
"1210 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__423" -> "1211 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1212 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1211 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul" -> "1214 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1212 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2" -> "1213 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1213 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub" -> "1215 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1214 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1" -> "1215 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1215 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1216 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1215 bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1" -> "1236 bert/encoder/layer_8/output/add"  [label="[]", style=solid];
"1216 QuantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1217 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1217 DequantizeLinear_bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1220 bert/encoder/layer_8/intermediate/dense/MatMul"  [label="[]", style=solid];
"1218 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1219 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1219 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/kernel^0_1" -> "1220 bert/encoder/layer_8/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1220 bert/encoder/layer_8/intermediate/dense/MatMul" -> "1221 bert/encoder/layer_8/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1221 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1222 bert/encoder/layer_8/intermediate/dense/Pow"  [label="[]", style=solid];
"1221 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1224 bert/encoder/layer_8/intermediate/dense/add"  [label="[]", style=solid];
"1221 bert/encoder/layer_8/intermediate/dense/BiasAdd" -> "1229 bert/encoder/layer_8/intermediate/dense/mul_3"  [label="[]", style=solid];
"1222 bert/encoder/layer_8/intermediate/dense/Pow" -> "1223 bert/encoder/layer_8/intermediate/dense/mul"  [label="[]", style=solid];
"1223 bert/encoder/layer_8/intermediate/dense/mul" -> "1224 bert/encoder/layer_8/intermediate/dense/add"  [label="[]", style=solid];
"1224 bert/encoder/layer_8/intermediate/dense/add" -> "1225 bert/encoder/layer_8/intermediate/dense/mul_1"  [label="[]", style=solid];
"1225 bert/encoder/layer_8/intermediate/dense/mul_1" -> "1226 bert/encoder/layer_8/intermediate/dense/Tanh"  [label="[]", style=solid];
"1226 bert/encoder/layer_8/intermediate/dense/Tanh" -> "1227 bert/encoder/layer_8/intermediate/dense/add_1"  [label="[]", style=solid];
"1227 bert/encoder/layer_8/intermediate/dense/add_1" -> "1228 bert/encoder/layer_8/intermediate/dense/mul_2"  [label="[]", style=solid];
"1228 bert/encoder/layer_8/intermediate/dense/mul_2" -> "1229 bert/encoder/layer_8/intermediate/dense/mul_3"  [label="[]", style=solid];
"1229 bert/encoder/layer_8/intermediate/dense/mul_3" -> "1230 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1230 QuantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1231 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1231 DequantizeLinear_bert/encoder/layer_8/intermediate/dense/mul_3^0_1" -> "1234 bert/encoder/layer_8/output/dense/MatMul"  [label="[]", style=solid];
"1232 QuantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1233 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1233 DequantizeLinear_bert/encoder/layer_8/output/dense/kernel^0_1" -> "1234 bert/encoder/layer_8/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1234 bert/encoder/layer_8/output/dense/MatMul" -> "1235 bert/encoder/layer_8/output/dense/BiasAdd"  [label="[]", style=solid];
"1235 bert/encoder/layer_8/output/dense/BiasAdd" -> "1236 bert/encoder/layer_8/output/add"  [label="[]", style=solid];
"1236 bert/encoder/layer_8/output/add" -> "1237 bert/encoder/layer_8/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1236 bert/encoder/layer_8/output/add" -> "1239 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1236 bert/encoder/layer_8/output/add" -> "1250 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1237 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1238 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1237 bert/encoder/layer_8/output/LayerNorm/moments/mean" -> "1248 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1238 bert/encoder/layer_8/output/LayerNorm/moments/StopGradient" -> "1239 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1239 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference" -> "1240 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425"  [label="[]", style=solid];
"1240 bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__425" -> "1241 bert/encoder/layer_8/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1241 bert/encoder/layer_8/output/LayerNorm/moments/variance" -> "1242 bert/encoder/layer_8/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1242 bert/encoder/layer_8/output/LayerNorm/batchnorm/add" -> "1243 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1243 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt" -> "1244 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1244 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1245 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1245 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1246 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427"  [label="[]", style=solid];
"1246 bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__427" -> "1247 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1247 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1248 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1247 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul" -> "1250 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1248 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2" -> "1249 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1249 bert/encoder/layer_8/output/LayerNorm/batchnorm/sub" -> "1251 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1250 bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1" -> "1251 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1251 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1252 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1251 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1254 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1251 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1256 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1251 bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1" -> "1294 bert/encoder/layer_9/attention/output/add"  [label="[]", style=solid];
"1252 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1253 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1253 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_3" -> "1274 bert/encoder/layer_9/attention/self/key/MatMul"  [label="[]", style=solid];
"1254 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1255 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1255 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_2" -> "1266 bert/encoder/layer_9/attention/self/query/MatMul"  [label="[]", style=solid];
"1256 QuantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1257 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1257 DequantizeLinear_bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1^0_1" -> "1260 bert/encoder/layer_9/attention/self/value/MatMul"  [label="[]", style=solid];
"1258 QuantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1259 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1259 DequantizeLinear_bert/encoder/layer_9/attention/self/value/kernel^0_1" -> "1260 bert/encoder/layer_9/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1260 bert/encoder/layer_9/attention/self/value/MatMul" -> "1261 bert/encoder/layer_9/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1261 bert/encoder/layer_9/attention/self/value/BiasAdd" -> "1262 bert/encoder/layer_9/attention/self/Reshape_2"  [label="[]", style=solid];
"1262 bert/encoder/layer_9/attention/self/Reshape_2" -> "1263 bert/encoder/layer_9/attention/self/transpose_2"  [label="[]", style=solid];
"1263 bert/encoder/layer_9/attention/self/transpose_2" -> "1285 bert/encoder/layer_9/attention/self/MatMul_1"  [label="[]", style=solid];
"1264 QuantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1265 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1265 DequantizeLinear_bert/encoder/layer_9/attention/self/query/kernel^0_1" -> "1266 bert/encoder/layer_9/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1266 bert/encoder/layer_9/attention/self/query/MatMul" -> "1267 bert/encoder/layer_9/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1267 bert/encoder/layer_9/attention/self/query/BiasAdd" -> "1268 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1268 QuantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1269 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1269 DequantizeLinear_bert/encoder/layer_9/attention/self/query/BiasAdd^0_1" -> "1270 bert/encoder/layer_9/attention/self/Reshape"  [label="[]", style=solid];
"1270 bert/encoder/layer_9/attention/self/Reshape" -> "1271 bert/encoder/layer_9/attention/self/transpose"  [label="[]", style=solid];
"1271 bert/encoder/layer_9/attention/self/transpose" -> "1281 bert/encoder/layer_9/attention/self/MatMul"  [label="[]", style=solid];
"1272 QuantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1273 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1273 DequantizeLinear_bert/encoder/layer_9/attention/self/key/kernel^0_1" -> "1274 bert/encoder/layer_9/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1274 bert/encoder/layer_9/attention/self/key/MatMul" -> "1275 bert/encoder/layer_9/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1275 bert/encoder/layer_9/attention/self/key/BiasAdd" -> "1276 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1276 QuantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1277 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1277 DequantizeLinear_bert/encoder/layer_9/attention/self/key/BiasAdd^0_1" -> "1278 bert/encoder/layer_9/attention/self/Reshape_1"  [label="[]", style=solid];
"1278 bert/encoder/layer_9/attention/self/Reshape_1" -> "1279 bert/encoder/layer_9/attention/self/transpose_1"  [label="[]", style=solid];
"1279 bert/encoder/layer_9/attention/self/transpose_1" -> "1280 bert/encoder/layer_9/attention/self/MatMul__432"  [label="[]", style=solid];
"1280 bert/encoder/layer_9/attention/self/MatMul__432" -> "1281 bert/encoder/layer_9/attention/self/MatMul"  [label="[]", style=solid];
"1281 bert/encoder/layer_9/attention/self/MatMul" -> "1282 bert/encoder/layer_9/attention/self/Mul"  [label="[]", style=solid];
"1282 bert/encoder/layer_9/attention/self/Mul" -> "1283 bert/encoder/layer_9/attention/self/add"  [label="[]", style=solid];
"1283 bert/encoder/layer_9/attention/self/add" -> "1284 bert/encoder/layer_9/attention/self/Softmax"  [label="[]", style=solid];
"1284 bert/encoder/layer_9/attention/self/Softmax" -> "1285 bert/encoder/layer_9/attention/self/MatMul_1"  [label="[]", style=solid];
"1285 bert/encoder/layer_9/attention/self/MatMul_1" -> "1286 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1286 QuantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1287 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1287 DequantizeLinear_bert/encoder/layer_9/attention/self/MatMul_1^0_1" -> "1288 bert/encoder/layer_9/attention/self/transpose_3"  [label="[]", style=solid];
"1288 bert/encoder/layer_9/attention/self/transpose_3" -> "1289 bert/encoder/layer_9/attention/self/Reshape_3"  [label="[]", style=solid];
"1289 bert/encoder/layer_9/attention/self/Reshape_3" -> "1292 bert/encoder/layer_9/attention/output/dense/MatMul"  [label="[]", style=solid];
"1290 QuantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1291 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1291 DequantizeLinear_bert/encoder/layer_9/attention/output/dense/kernel^0_1" -> "1292 bert/encoder/layer_9/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1292 bert/encoder/layer_9/attention/output/dense/MatMul" -> "1293 bert/encoder/layer_9/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1293 bert/encoder/layer_9/attention/output/dense/BiasAdd" -> "1294 bert/encoder/layer_9/attention/output/add"  [label="[]", style=solid];
"1294 bert/encoder/layer_9/attention/output/add" -> "1295 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1294 bert/encoder/layer_9/attention/output/add" -> "1297 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1294 bert/encoder/layer_9/attention/output/add" -> "1308 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1295 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1296 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1295 bert/encoder/layer_9/attention/output/LayerNorm/moments/mean" -> "1306 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1296 bert/encoder/layer_9/attention/output/LayerNorm/moments/StopGradient" -> "1297 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1297 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference" -> "1298 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435"  [label="[]", style=solid];
"1298 bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__435" -> "1299 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1299 bert/encoder/layer_9/attention/output/LayerNorm/moments/variance" -> "1300 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1300 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add" -> "1301 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1301 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1302 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1302 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1303 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1303 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1304 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437"  [label="[]", style=solid];
"1304 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__437" -> "1305 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1305 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1306 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1305 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul" -> "1308 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1306 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2" -> "1307 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1307 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub" -> "1309 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1308 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1" -> "1309 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1309 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1310 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1309 bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1" -> "1330 bert/encoder/layer_9/output/add"  [label="[]", style=solid];
"1310 QuantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1311 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1311 DequantizeLinear_bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1314 bert/encoder/layer_9/intermediate/dense/MatMul"  [label="[]", style=solid];
"1312 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1313 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1313 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/kernel^0_1" -> "1314 bert/encoder/layer_9/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1314 bert/encoder/layer_9/intermediate/dense/MatMul" -> "1315 bert/encoder/layer_9/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1315 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1316 bert/encoder/layer_9/intermediate/dense/Pow"  [label="[]", style=solid];
"1315 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1318 bert/encoder/layer_9/intermediate/dense/add"  [label="[]", style=solid];
"1315 bert/encoder/layer_9/intermediate/dense/BiasAdd" -> "1323 bert/encoder/layer_9/intermediate/dense/mul_3"  [label="[]", style=solid];
"1316 bert/encoder/layer_9/intermediate/dense/Pow" -> "1317 bert/encoder/layer_9/intermediate/dense/mul"  [label="[]", style=solid];
"1317 bert/encoder/layer_9/intermediate/dense/mul" -> "1318 bert/encoder/layer_9/intermediate/dense/add"  [label="[]", style=solid];
"1318 bert/encoder/layer_9/intermediate/dense/add" -> "1319 bert/encoder/layer_9/intermediate/dense/mul_1"  [label="[]", style=solid];
"1319 bert/encoder/layer_9/intermediate/dense/mul_1" -> "1320 bert/encoder/layer_9/intermediate/dense/Tanh"  [label="[]", style=solid];
"1320 bert/encoder/layer_9/intermediate/dense/Tanh" -> "1321 bert/encoder/layer_9/intermediate/dense/add_1"  [label="[]", style=solid];
"1321 bert/encoder/layer_9/intermediate/dense/add_1" -> "1322 bert/encoder/layer_9/intermediate/dense/mul_2"  [label="[]", style=solid];
"1322 bert/encoder/layer_9/intermediate/dense/mul_2" -> "1323 bert/encoder/layer_9/intermediate/dense/mul_3"  [label="[]", style=solid];
"1323 bert/encoder/layer_9/intermediate/dense/mul_3" -> "1324 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1324 QuantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1325 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1325 DequantizeLinear_bert/encoder/layer_9/intermediate/dense/mul_3^0_1" -> "1328 bert/encoder/layer_9/output/dense/MatMul"  [label="[]", style=solid];
"1326 QuantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1327 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1327 DequantizeLinear_bert/encoder/layer_9/output/dense/kernel^0_1" -> "1328 bert/encoder/layer_9/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1328 bert/encoder/layer_9/output/dense/MatMul" -> "1329 bert/encoder/layer_9/output/dense/BiasAdd"  [label="[]", style=solid];
"1329 bert/encoder/layer_9/output/dense/BiasAdd" -> "1330 bert/encoder/layer_9/output/add"  [label="[]", style=solid];
"1330 bert/encoder/layer_9/output/add" -> "1331 bert/encoder/layer_9/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1330 bert/encoder/layer_9/output/add" -> "1333 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1330 bert/encoder/layer_9/output/add" -> "1344 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1331 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1332 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1331 bert/encoder/layer_9/output/LayerNorm/moments/mean" -> "1342 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1332 bert/encoder/layer_9/output/LayerNorm/moments/StopGradient" -> "1333 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1333 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference" -> "1334 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439"  [label="[]", style=solid];
"1334 bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__439" -> "1335 bert/encoder/layer_9/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1335 bert/encoder/layer_9/output/LayerNorm/moments/variance" -> "1336 bert/encoder/layer_9/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1336 bert/encoder/layer_9/output/LayerNorm/batchnorm/add" -> "1337 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1337 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt" -> "1338 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1338 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1339 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1339 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1340 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441"  [label="[]", style=solid];
"1340 bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__441" -> "1341 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1341 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1342 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1341 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul" -> "1344 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1342 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2" -> "1343 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1343 bert/encoder/layer_9/output/LayerNorm/batchnorm/sub" -> "1345 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1344 bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1" -> "1345 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1345 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1346 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1345 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1348 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1345 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1350 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1345 bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1" -> "1388 bert/encoder/layer_10/attention/output/add"  [label="[]", style=solid];
"1346 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1347 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1347 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_3" -> "1368 bert/encoder/layer_10/attention/self/key/MatMul"  [label="[]", style=solid];
"1348 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1349 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1349 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_2" -> "1360 bert/encoder/layer_10/attention/self/query/MatMul"  [label="[]", style=solid];
"1350 QuantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1351 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1351 DequantizeLinear_bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1^0_1" -> "1354 bert/encoder/layer_10/attention/self/value/MatMul"  [label="[]", style=solid];
"1352 QuantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1353 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1353 DequantizeLinear_bert/encoder/layer_10/attention/self/value/kernel^0_1" -> "1354 bert/encoder/layer_10/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1354 bert/encoder/layer_10/attention/self/value/MatMul" -> "1355 bert/encoder/layer_10/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1355 bert/encoder/layer_10/attention/self/value/BiasAdd" -> "1356 bert/encoder/layer_10/attention/self/Reshape_2"  [label="[]", style=solid];
"1356 bert/encoder/layer_10/attention/self/Reshape_2" -> "1357 bert/encoder/layer_10/attention/self/transpose_2"  [label="[]", style=solid];
"1357 bert/encoder/layer_10/attention/self/transpose_2" -> "1379 bert/encoder/layer_10/attention/self/MatMul_1"  [label="[]", style=solid];
"1358 QuantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1359 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1359 DequantizeLinear_bert/encoder/layer_10/attention/self/query/kernel^0_1" -> "1360 bert/encoder/layer_10/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1360 bert/encoder/layer_10/attention/self/query/MatMul" -> "1361 bert/encoder/layer_10/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1361 bert/encoder/layer_10/attention/self/query/BiasAdd" -> "1362 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1362 QuantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1363 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1363 DequantizeLinear_bert/encoder/layer_10/attention/self/query/BiasAdd^0_1" -> "1364 bert/encoder/layer_10/attention/self/Reshape"  [label="[]", style=solid];
"1364 bert/encoder/layer_10/attention/self/Reshape" -> "1365 bert/encoder/layer_10/attention/self/transpose"  [label="[]", style=solid];
"1365 bert/encoder/layer_10/attention/self/transpose" -> "1375 bert/encoder/layer_10/attention/self/MatMul"  [label="[]", style=solid];
"1366 QuantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1367 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1367 DequantizeLinear_bert/encoder/layer_10/attention/self/key/kernel^0_1" -> "1368 bert/encoder/layer_10/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1368 bert/encoder/layer_10/attention/self/key/MatMul" -> "1369 bert/encoder/layer_10/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1369 bert/encoder/layer_10/attention/self/key/BiasAdd" -> "1370 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1370 QuantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1371 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1371 DequantizeLinear_bert/encoder/layer_10/attention/self/key/BiasAdd^0_1" -> "1372 bert/encoder/layer_10/attention/self/Reshape_1"  [label="[]", style=solid];
"1372 bert/encoder/layer_10/attention/self/Reshape_1" -> "1373 bert/encoder/layer_10/attention/self/transpose_1"  [label="[]", style=solid];
"1373 bert/encoder/layer_10/attention/self/transpose_1" -> "1374 bert/encoder/layer_10/attention/self/MatMul__446"  [label="[]", style=solid];
"1374 bert/encoder/layer_10/attention/self/MatMul__446" -> "1375 bert/encoder/layer_10/attention/self/MatMul"  [label="[]", style=solid];
"1375 bert/encoder/layer_10/attention/self/MatMul" -> "1376 bert/encoder/layer_10/attention/self/Mul"  [label="[]", style=solid];
"1376 bert/encoder/layer_10/attention/self/Mul" -> "1377 bert/encoder/layer_10/attention/self/add"  [label="[]", style=solid];
"1377 bert/encoder/layer_10/attention/self/add" -> "1378 bert/encoder/layer_10/attention/self/Softmax"  [label="[]", style=solid];
"1378 bert/encoder/layer_10/attention/self/Softmax" -> "1379 bert/encoder/layer_10/attention/self/MatMul_1"  [label="[]", style=solid];
"1379 bert/encoder/layer_10/attention/self/MatMul_1" -> "1380 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1380 QuantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1381 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1381 DequantizeLinear_bert/encoder/layer_10/attention/self/MatMul_1^0_1" -> "1382 bert/encoder/layer_10/attention/self/transpose_3"  [label="[]", style=solid];
"1382 bert/encoder/layer_10/attention/self/transpose_3" -> "1383 bert/encoder/layer_10/attention/self/Reshape_3"  [label="[]", style=solid];
"1383 bert/encoder/layer_10/attention/self/Reshape_3" -> "1386 bert/encoder/layer_10/attention/output/dense/MatMul"  [label="[]", style=solid];
"1384 QuantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1385 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1385 DequantizeLinear_bert/encoder/layer_10/attention/output/dense/kernel^0_1" -> "1386 bert/encoder/layer_10/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1386 bert/encoder/layer_10/attention/output/dense/MatMul" -> "1387 bert/encoder/layer_10/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1387 bert/encoder/layer_10/attention/output/dense/BiasAdd" -> "1388 bert/encoder/layer_10/attention/output/add"  [label="[]", style=solid];
"1388 bert/encoder/layer_10/attention/output/add" -> "1389 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1388 bert/encoder/layer_10/attention/output/add" -> "1391 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1388 bert/encoder/layer_10/attention/output/add" -> "1402 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1389 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1390 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1389 bert/encoder/layer_10/attention/output/LayerNorm/moments/mean" -> "1400 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1390 bert/encoder/layer_10/attention/output/LayerNorm/moments/StopGradient" -> "1391 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1391 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference" -> "1392 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449"  [label="[]", style=solid];
"1392 bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__449" -> "1393 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1393 bert/encoder/layer_10/attention/output/LayerNorm/moments/variance" -> "1394 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1394 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add" -> "1395 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1395 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1396 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1396 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1397 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1397 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1398 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451"  [label="[]", style=solid];
"1398 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__451" -> "1399 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1399 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1400 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1399 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul" -> "1402 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1400 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2" -> "1401 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1401 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub" -> "1403 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1402 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1" -> "1403 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1403 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1404 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1403 bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1" -> "1424 bert/encoder/layer_10/output/add"  [label="[]", style=solid];
"1404 QuantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1405 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1405 DequantizeLinear_bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1408 bert/encoder/layer_10/intermediate/dense/MatMul"  [label="[]", style=solid];
"1406 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1407 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1407 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/kernel^0_1" -> "1408 bert/encoder/layer_10/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1408 bert/encoder/layer_10/intermediate/dense/MatMul" -> "1409 bert/encoder/layer_10/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1409 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1410 bert/encoder/layer_10/intermediate/dense/Pow"  [label="[]", style=solid];
"1409 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1412 bert/encoder/layer_10/intermediate/dense/add"  [label="[]", style=solid];
"1409 bert/encoder/layer_10/intermediate/dense/BiasAdd" -> "1417 bert/encoder/layer_10/intermediate/dense/mul_3"  [label="[]", style=solid];
"1410 bert/encoder/layer_10/intermediate/dense/Pow" -> "1411 bert/encoder/layer_10/intermediate/dense/mul"  [label="[]", style=solid];
"1411 bert/encoder/layer_10/intermediate/dense/mul" -> "1412 bert/encoder/layer_10/intermediate/dense/add"  [label="[]", style=solid];
"1412 bert/encoder/layer_10/intermediate/dense/add" -> "1413 bert/encoder/layer_10/intermediate/dense/mul_1"  [label="[]", style=solid];
"1413 bert/encoder/layer_10/intermediate/dense/mul_1" -> "1414 bert/encoder/layer_10/intermediate/dense/Tanh"  [label="[]", style=solid];
"1414 bert/encoder/layer_10/intermediate/dense/Tanh" -> "1415 bert/encoder/layer_10/intermediate/dense/add_1"  [label="[]", style=solid];
"1415 bert/encoder/layer_10/intermediate/dense/add_1" -> "1416 bert/encoder/layer_10/intermediate/dense/mul_2"  [label="[]", style=solid];
"1416 bert/encoder/layer_10/intermediate/dense/mul_2" -> "1417 bert/encoder/layer_10/intermediate/dense/mul_3"  [label="[]", style=solid];
"1417 bert/encoder/layer_10/intermediate/dense/mul_3" -> "1418 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1418 QuantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1419 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1419 DequantizeLinear_bert/encoder/layer_10/intermediate/dense/mul_3^0_1" -> "1422 bert/encoder/layer_10/output/dense/MatMul"  [label="[]", style=solid];
"1420 QuantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1421 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1421 DequantizeLinear_bert/encoder/layer_10/output/dense/kernel^0_1" -> "1422 bert/encoder/layer_10/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1422 bert/encoder/layer_10/output/dense/MatMul" -> "1423 bert/encoder/layer_10/output/dense/BiasAdd"  [label="[]", style=solid];
"1423 bert/encoder/layer_10/output/dense/BiasAdd" -> "1424 bert/encoder/layer_10/output/add"  [label="[]", style=solid];
"1424 bert/encoder/layer_10/output/add" -> "1425 bert/encoder/layer_10/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1424 bert/encoder/layer_10/output/add" -> "1427 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1424 bert/encoder/layer_10/output/add" -> "1438 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1425 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1426 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1425 bert/encoder/layer_10/output/LayerNorm/moments/mean" -> "1436 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1426 bert/encoder/layer_10/output/LayerNorm/moments/StopGradient" -> "1427 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1427 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference" -> "1428 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453"  [label="[]", style=solid];
"1428 bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__453" -> "1429 bert/encoder/layer_10/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1429 bert/encoder/layer_10/output/LayerNorm/moments/variance" -> "1430 bert/encoder/layer_10/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1430 bert/encoder/layer_10/output/LayerNorm/batchnorm/add" -> "1431 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1431 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt" -> "1432 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1432 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1433 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1433 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1434 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455"  [label="[]", style=solid];
"1434 bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__455" -> "1435 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1435 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1436 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1435 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul" -> "1438 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1436 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2" -> "1437 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1437 bert/encoder/layer_10/output/LayerNorm/batchnorm/sub" -> "1439 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1438 bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1" -> "1439 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1439 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1440 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=solid];
"1439 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1442 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=solid];
"1439 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1444 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1439 bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1" -> "1482 bert/encoder/layer_11/attention/output/add"  [label="[]", style=solid];
"1440 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1441 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3"  [label="[]", style=dashed];
"1441 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_3" -> "1462 bert/encoder/layer_11/attention/self/key/MatMul"  [label="[]", style=solid];
"1442 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1443 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2"  [label="[]", style=dashed];
"1443 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_2" -> "1454 bert/encoder/layer_11/attention/self/query/MatMul"  [label="[]", style=solid];
"1444 QuantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1445 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1445 DequantizeLinear_bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1^0_1" -> "1448 bert/encoder/layer_11/attention/self/value/MatMul"  [label="[]", style=solid];
"1446 QuantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1447 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1"  [label="[768, 768]", style=dashed];
"1447 DequantizeLinear_bert/encoder/layer_11/attention/self/value/kernel^0_1" -> "1448 bert/encoder/layer_11/attention/self/value/MatMul"  [label="[768, 768]", style=solid];
"1448 bert/encoder/layer_11/attention/self/value/MatMul" -> "1449 bert/encoder/layer_11/attention/self/value/BiasAdd"  [label="[]", style=solid];
"1449 bert/encoder/layer_11/attention/self/value/BiasAdd" -> "1450 bert/encoder/layer_11/attention/self/Reshape_2"  [label="[]", style=solid];
"1450 bert/encoder/layer_11/attention/self/Reshape_2" -> "1451 bert/encoder/layer_11/attention/self/transpose_2"  [label="[]", style=solid];
"1451 bert/encoder/layer_11/attention/self/transpose_2" -> "1473 bert/encoder/layer_11/attention/self/MatMul_1"  [label="[]", style=solid];
"1452 QuantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1453 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1"  [label="[768, 768]", style=dashed];
"1453 DequantizeLinear_bert/encoder/layer_11/attention/self/query/kernel^0_1" -> "1454 bert/encoder/layer_11/attention/self/query/MatMul"  [label="[768, 768]", style=solid];
"1454 bert/encoder/layer_11/attention/self/query/MatMul" -> "1455 bert/encoder/layer_11/attention/self/query/BiasAdd"  [label="[]", style=solid];
"1455 bert/encoder/layer_11/attention/self/query/BiasAdd" -> "1456 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1"  [label="[]", style=solid];
"1456 QuantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1457 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1"  [label="[]", style=dashed];
"1457 DequantizeLinear_bert/encoder/layer_11/attention/self/query/BiasAdd^0_1" -> "1458 bert/encoder/layer_11/attention/self/Reshape"  [label="[]", style=solid];
"1458 bert/encoder/layer_11/attention/self/Reshape" -> "1459 bert/encoder/layer_11/attention/self/transpose"  [label="[]", style=solid];
"1459 bert/encoder/layer_11/attention/self/transpose" -> "1469 bert/encoder/layer_11/attention/self/MatMul"  [label="[]", style=solid];
"1460 QuantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1461 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1"  [label="[768, 768]", style=dashed];
"1461 DequantizeLinear_bert/encoder/layer_11/attention/self/key/kernel^0_1" -> "1462 bert/encoder/layer_11/attention/self/key/MatMul"  [label="[768, 768]", style=solid];
"1462 bert/encoder/layer_11/attention/self/key/MatMul" -> "1463 bert/encoder/layer_11/attention/self/key/BiasAdd"  [label="[]", style=solid];
"1463 bert/encoder/layer_11/attention/self/key/BiasAdd" -> "1464 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1"  [label="[]", style=solid];
"1464 QuantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1465 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1"  [label="[]", style=dashed];
"1465 DequantizeLinear_bert/encoder/layer_11/attention/self/key/BiasAdd^0_1" -> "1466 bert/encoder/layer_11/attention/self/Reshape_1"  [label="[]", style=solid];
"1466 bert/encoder/layer_11/attention/self/Reshape_1" -> "1467 bert/encoder/layer_11/attention/self/transpose_1"  [label="[]", style=solid];
"1467 bert/encoder/layer_11/attention/self/transpose_1" -> "1468 bert/encoder/layer_11/attention/self/MatMul__460"  [label="[]", style=solid];
"1468 bert/encoder/layer_11/attention/self/MatMul__460" -> "1469 bert/encoder/layer_11/attention/self/MatMul"  [label="[]", style=solid];
"1469 bert/encoder/layer_11/attention/self/MatMul" -> "1470 bert/encoder/layer_11/attention/self/Mul"  [label="[]", style=solid];
"1470 bert/encoder/layer_11/attention/self/Mul" -> "1471 bert/encoder/layer_11/attention/self/add"  [label="[]", style=solid];
"1471 bert/encoder/layer_11/attention/self/add" -> "1472 bert/encoder/layer_11/attention/self/Softmax"  [label="[]", style=solid];
"1472 bert/encoder/layer_11/attention/self/Softmax" -> "1473 bert/encoder/layer_11/attention/self/MatMul_1"  [label="[]", style=solid];
"1473 bert/encoder/layer_11/attention/self/MatMul_1" -> "1474 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1"  [label="[]", style=solid];
"1474 QuantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1475 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1"  [label="[]", style=dashed];
"1475 DequantizeLinear_bert/encoder/layer_11/attention/self/MatMul_1^0_1" -> "1476 bert/encoder/layer_11/attention/self/transpose_3"  [label="[]", style=solid];
"1476 bert/encoder/layer_11/attention/self/transpose_3" -> "1477 bert/encoder/layer_11/attention/self/Reshape_3"  [label="[]", style=solid];
"1477 bert/encoder/layer_11/attention/self/Reshape_3" -> "1480 bert/encoder/layer_11/attention/output/dense/MatMul"  [label="[]", style=solid];
"1478 QuantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1479 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1"  [label="[768, 768]", style=dashed];
"1479 DequantizeLinear_bert/encoder/layer_11/attention/output/dense/kernel^0_1" -> "1480 bert/encoder/layer_11/attention/output/dense/MatMul"  [label="[768, 768]", style=solid];
"1480 bert/encoder/layer_11/attention/output/dense/MatMul" -> "1481 bert/encoder/layer_11/attention/output/dense/BiasAdd"  [label="[]", style=solid];
"1481 bert/encoder/layer_11/attention/output/dense/BiasAdd" -> "1482 bert/encoder/layer_11/attention/output/add"  [label="[]", style=solid];
"1482 bert/encoder/layer_11/attention/output/add" -> "1483 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1482 bert/encoder/layer_11/attention/output/add" -> "1485 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1482 bert/encoder/layer_11/attention/output/add" -> "1496 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1483 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1484 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1483 bert/encoder/layer_11/attention/output/LayerNorm/moments/mean" -> "1494 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1484 bert/encoder/layer_11/attention/output/LayerNorm/moments/StopGradient" -> "1485 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1485 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference" -> "1486 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463"  [label="[]", style=solid];
"1486 bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__463" -> "1487 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1487 bert/encoder/layer_11/attention/output/LayerNorm/moments/variance" -> "1488 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1488 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add" -> "1489 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1489 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt" -> "1490 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1490 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1491 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1491 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1492 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465"  [label="[]", style=solid];
"1492 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__465" -> "1493 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1493 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1494 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1493 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul" -> "1496 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1494 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2" -> "1495 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1495 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub" -> "1497 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1496 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1" -> "1497 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1497 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1498 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1497 bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1" -> "1518 bert/encoder/layer_11/output/add"  [label="[]", style=solid];
"1498 QuantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1499 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1499 DequantizeLinear_bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1^0_1" -> "1502 bert/encoder/layer_11/intermediate/dense/MatMul"  [label="[]", style=solid];
"1500 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1501 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1"  [label="[768, 3072]", style=dashed];
"1501 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/kernel^0_1" -> "1502 bert/encoder/layer_11/intermediate/dense/MatMul"  [label="[768, 3072]", style=solid];
"1502 bert/encoder/layer_11/intermediate/dense/MatMul" -> "1503 bert/encoder/layer_11/intermediate/dense/BiasAdd"  [label="[]", style=solid];
"1503 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1504 bert/encoder/layer_11/intermediate/dense/Pow"  [label="[]", style=solid];
"1503 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1506 bert/encoder/layer_11/intermediate/dense/add"  [label="[]", style=solid];
"1503 bert/encoder/layer_11/intermediate/dense/BiasAdd" -> "1511 bert/encoder/layer_11/intermediate/dense/mul_3"  [label="[]", style=solid];
"1504 bert/encoder/layer_11/intermediate/dense/Pow" -> "1505 bert/encoder/layer_11/intermediate/dense/mul"  [label="[]", style=solid];
"1505 bert/encoder/layer_11/intermediate/dense/mul" -> "1506 bert/encoder/layer_11/intermediate/dense/add"  [label="[]", style=solid];
"1506 bert/encoder/layer_11/intermediate/dense/add" -> "1507 bert/encoder/layer_11/intermediate/dense/mul_1"  [label="[]", style=solid];
"1507 bert/encoder/layer_11/intermediate/dense/mul_1" -> "1508 bert/encoder/layer_11/intermediate/dense/Tanh"  [label="[]", style=solid];
"1508 bert/encoder/layer_11/intermediate/dense/Tanh" -> "1509 bert/encoder/layer_11/intermediate/dense/add_1"  [label="[]", style=solid];
"1509 bert/encoder/layer_11/intermediate/dense/add_1" -> "1510 bert/encoder/layer_11/intermediate/dense/mul_2"  [label="[]", style=solid];
"1510 bert/encoder/layer_11/intermediate/dense/mul_2" -> "1511 bert/encoder/layer_11/intermediate/dense/mul_3"  [label="[]", style=solid];
"1511 bert/encoder/layer_11/intermediate/dense/mul_3" -> "1512 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1"  [label="[]", style=solid];
"1512 QuantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1513 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1"  [label="[]", style=dashed];
"1513 DequantizeLinear_bert/encoder/layer_11/intermediate/dense/mul_3^0_1" -> "1516 bert/encoder/layer_11/output/dense/MatMul"  [label="[]", style=solid];
"1514 QuantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1515 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1"  [label="[3072, 768]", style=dashed];
"1515 DequantizeLinear_bert/encoder/layer_11/output/dense/kernel^0_1" -> "1516 bert/encoder/layer_11/output/dense/MatMul"  [label="[3072, 768]", style=solid];
"1516 bert/encoder/layer_11/output/dense/MatMul" -> "1517 bert/encoder/layer_11/output/dense/BiasAdd"  [label="[]", style=solid];
"1517 bert/encoder/layer_11/output/dense/BiasAdd" -> "1518 bert/encoder/layer_11/output/add"  [label="[]", style=solid];
"1518 bert/encoder/layer_11/output/add" -> "1519 bert/encoder/layer_11/output/LayerNorm/moments/mean"  [label="[]", style=solid];
"1518 bert/encoder/layer_11/output/add" -> "1521 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1518 bert/encoder/layer_11/output/add" -> "1532 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1519 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1520 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient"  [label="[]", style=solid];
"1519 bert/encoder/layer_11/output/LayerNorm/moments/mean" -> "1530 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1520 bert/encoder/layer_11/output/LayerNorm/moments/StopGradient" -> "1521 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference"  [label="[]", style=solid];
"1521 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference" -> "1522 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467"  [label="[]", style=solid];
"1522 bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__467" -> "1523 bert/encoder/layer_11/output/LayerNorm/moments/variance"  [label="[]", style=solid];
"1523 bert/encoder/layer_11/output/LayerNorm/moments/variance" -> "1524 bert/encoder/layer_11/output/LayerNorm/batchnorm/add"  [label="[]", style=solid];
"1524 bert/encoder/layer_11/output/LayerNorm/batchnorm/add" -> "1525 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt"  [label="[]", style=solid];
"1525 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt" -> "1526 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=solid];
"1526 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1527 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt^0_1"  [label="[]", style=dashed];
"1527 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt^0_1" -> "1528 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469"  [label="[]", style=solid];
"1528 bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__469" -> "1529 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul"  [label="[]", style=solid];
"1529 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1530 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2"  [label="[]", style=solid];
"1529 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul" -> "1532 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1"  [label="[]", style=solid];
"1530 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2" -> "1531 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub"  [label="[]", style=solid];
"1531 bert/encoder/layer_11/output/LayerNorm/batchnorm/sub" -> "1533 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1532 bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1" -> "1533 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1"  [label="[]", style=solid];
"1533 bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1" -> "1534 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=solid];
"1534 QuantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1535 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1"  [label="[]", style=dashed];
"1535 DequantizeLinear_bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1^0_1" -> "1536 bert/encoder/Reshape_13"  [label="[]", style=solid];
"1536 bert/encoder/Reshape_13" -> "1537 Shape_1"  [label="[]", style=solid];
"1536 bert/encoder/Reshape_13" -> "1549 Reshape"  [label="[]", style=solid];
"1537 Shape_1" -> "1538 Shape_1__472"  [label="[-1]", style=dashed];
"1538 Shape_1__472" -> "1539 strided_slice_1"  [label="[-1]", style=solid];
"1539 strided_slice_1" -> "1540 strided_slice_1__476"  [label="[-1]", style=solid];
"1540 strided_slice_1__476" -> "1541 strided_slice_1__477"  [label="[]", style=solid];
"1541 strided_slice_1__477" -> "1542 mul"  [label="[]", style=dashed];
"1541 strided_slice_1__477" -> "1546 Reshape_1/shape_Unsqueeze__478"  [label="[]", style=dashed];
"1542 mul" -> "1543 Reshape/shape_Unsqueeze__482"  [label="[]", style=dashed];
"1543 Reshape/shape_Unsqueeze__482" -> "1544 Reshape/shape_Concat__484"  [label="[1]", style=dashed];
"1544 Reshape/shape_Concat__484" -> "1545 Reshape__485"  [label="[2]", style=dashed];
"1545 Reshape__485" -> "1549 Reshape"  [label="[2]", style=dashed];
"1546 Reshape_1/shape_Unsqueeze__478" -> "1547 Reshape_1/shape_Concat__481"  [label="[1]", style=dashed];
"1547 Reshape_1/shape_Concat__481" -> "1548 Reshape_1__487"  [label="[3]", style=dashed];
"1548 Reshape_1__487" -> "1554 Reshape_1"  [label="[3]", style=dashed];
"1549 Reshape" -> "1552 MatMul"  [label="[]", style=solid];
"1550 QuantizeLinear_MatMul__486^0_1" -> "1551 DequantizeLinear_MatMul__486^0_1"  [label="[768, 2]", style=dashed];
"1551 DequantizeLinear_MatMul__486^0_1" -> "1552 MatMul"  [label="[768, 2]", style=solid];
"1552 MatMul" -> "1553 BiasAdd"  [label="[]", style=solid];
"1553 BiasAdd" -> "1554 Reshape_1"  [label="[]", style=solid];
"1554 Reshape_1" -> "1555 transpose"  [label="[]", style=solid];
"1555 transpose" -> "1556 unstack"  [label="[]", style=solid];
"1556 unstack" -> "1557 unstack__490"  [label="[]", style=solid];
"1556 unstack" -> "1559 unstack__488"  [label="[]", style=solid];
"1557 unstack__490" -> "1558 unstack_graph_outputs_Identity__4"  [label="[]", style=solid];
"1558 unstack_graph_outputs_Identity__4" -> "1565 nncf_model_output_0"  [label="[-1, 256]", style=solid];
"1559 unstack__488" -> "1560 unstack_graph_outputs_Identity__7"  [label="[]", style=solid];
"1560 unstack_graph_outputs_Identity__7" -> "1566 nncf_model_output_1"  [label="[-1, 256]", style=solid];
"1561 nncf_model_input_0" -> "0 unique_ids_graph_outputs_Identity__10"  [label="[-1]", style=dashed];
"1562 nncf_model_input_1" -> "185 bert/embeddings/Reshape_2"  [label="[-1, 256]", style=dashed];
"1563 nncf_model_input_2" -> "140 bert/encoder/Reshape"  [label="[-1, 256]", style=dashed];
"1564 nncf_model_input_3" -> "123 bert/encoder/Shape"  [label="[-1, 256]", style=dashed];
"1564 nncf_model_input_3" -> "189 bert/embeddings/ExpandDims"  [label="[-1, 256]", style=dashed];
}
