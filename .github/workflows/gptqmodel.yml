name: gptqmodel
permissions: read-all


on:
  workflow_call:
  pull_request:
    paths:
      - .github/workflows/gptqmodel.yml
      - src/nncf/experimental/torch/gptqmodel/**
      - tests/integration/gptq_model/**

jobs:
  pytorch-cuda:
    timeout-minutes: 40
    runs-on: aks-linux-4-cores-28gb-gpu-tesla-t4
    defaults:
      run:
        shell: bash
    env:
      DEBIAN_FRONTEND: noninteractive
    steps:
      - name: Install dependencies
        run : |
          sudo apt-get update
          sudo apt-get --assume-yes install build-essential ninja-build libgl1-mesa-dev libglib2.0-0 wget make
      - name: Download CUDA
        run: |
          wget -q https://developer.download.nvidia.com/compute/cuda/12.6.3/local_installers/cuda_12.6.3_560.35.05_linux.run
          sudo sh cuda_12.6.3_560.35.05_linux.run --toolkit --silent
      - name: Runner info
        continue-on-error: true
        run: |
          nvidia-smi
          cat /proc/cpuinfo
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          lfs: true
      - uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # v6.2.0
        with:
          python-version: "3.10.14"
      - name: Install uv
        uses: astral-sh/setup-uv@5a095e7a2014a4212f075830d4f7277575a9d098 # v7.3.1
      - name: Install NNCF and test requirements
        run: uv pip install --system . -r tests/integration/gptq_model/requirements.txt
      - name: Install extra requirements
        run: uv pip install --system -r tests/integration/gptq_model/requirements_extra.txt
      - name: Print installed modules
        run: pip list
      - name: Check CUDA
        run: |
          python -c "import torch; print(torch.cuda.is_available())"
      - name: Run PyTorch precommit test scope
        run: |
          pytest -ra --durations=30 tests/integration/gptq_model/
