name: Test install
permissions: read-all

on:
  workflow_call:
  workflow_dispatch:
    inputs:
      pull_request_number:
        description: 'The pull request number'
        default: ''

jobs:
  install-cpu:
    name: Test install [${{ matrix.backend }} - ${{ matrix.runner }}]
    runs-on: ${{ matrix.runner }}
    strategy:
      fail-fast: false
      matrix:
        backend:  ["torch", "tf", "onnx", "openvino"]
        runner: ["windows-latest", "ubuntu-22.04"]
    defaults:
      run:
        shell: bash
    steps:
      - uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29 # v4.1.6
        with:
            lfs: true
            fetch-depth: 0  # Fetch full history to allow checking out any branch or PR
      - name: Fetch and Checkout the Pull Request Branch
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.pull_request_number != '' }}
        run: |
          git fetch origin pull/${{ github.event.inputs.pull_request_number }}/head:pr-${{ github.event.inputs.pull_request_number }}
          git checkout pr-${{ github.event.inputs.pull_request_number }}
      - uses: actions/setup-python@0a5c61591373683505ea898e09a3ea4f39ef2b9c # v5.0.0
        with:
          python-version: "3.10"
          cache: pip
      - name: Install test requirements
        run: |
          pip install -r tests/cross_fw/examples/requirements.txt
      - name: Print installed modules
        run: pip list
      - name: Run install test scope
        run: pytest tests/cross_fw/install -rA -s --host-configuration cpu --backend ${{ matrix.backend }}

  install-torch-gpu:
    name: Test install [torch - ubuntu-gpu]
    defaults:
      run:
        shell: bash
    runs-on: aks-linux-4-cores-28gb-gpu-tesla-t4
    env:
      DEBIAN_FRONTEND: noninteractive
    steps:
      - name: Install dependencies
        run : |
          sudo apt-get update
          sudo apt-get --assume-yes install build-essential ninja-build libgl1-mesa-dev libglib2.0-0 wget make virtualenv
      - name: Download CUDA
        run: |
          wget -q https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda_12.4.0_550.54.14_linux.run
          sudo sh cuda_12.4.0_550.54.14_linux.run --toolkit --silent
      - name: Runner info
        continue-on-error: true
        run: |
          export PATH=/usr/local/cuda-12.4/bin${PATH:+:${PATH}}
          export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
          nvidia-smi
          cat /proc/cpuinfo
          nvcc --version
      - uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29 # v4.1.6
        with:
          lfs: true
      - name: Fetch and Checkout the Pull Request Branch
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.pull_request_number != '' }}
        run: |
          git fetch origin pull/${{ github.event.inputs.pull_request_number }}/head:pr-${{ github.event.inputs.pull_request_number }}
          git checkout pr-${{ github.event.inputs.pull_request_number }}
      - uses: actions/setup-python@0a5c61591373683505ea898e09a3ea4f39ef2b9c # v5.0.0
        with:
          python-version: 3.10.14
          cache: pip
      - name: Install test requirements
        run: |
          pip install -r tests/cross_fw/examples/requirements.txt
      - name: Print installed modules
        run: pip list
      - name: Run install test scope
        run: |
          export PATH=/usr/local/cuda-12.4/bin${PATH:+:${PATH}}
          export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
          pytest tests/cross_fw/install -rA -s --host-configuration gpu --backend torch
